\chapter{Sincronización en memoria compartida. Monitores}
Suponiendo que existe una memoria común para los distintos procesos que ejecutan un programa concurrente, este Capítulo trata sobre la sincronización de los mismos usando para ello instrucciones que usan dicha memoria compartida.\\

Estudiaremos en profundidad el problema de la exclusión mutua, que ya obtuvo una solución en la asignatura de Arquitectura de Computadores, usando para ello cerrojos hardware o instrucciones máquina que nos proveían de funcionalidades deseadas a la hora de implementar una exclusión mutua.\\

Posteriormente, continuaremos con el problema de la sincronización de procesos en un programa concurrente, usando para ello conceptos con un mayor nivel de abstracción, los cuales nos permitirán resolver problemas más complejos de forma sencilla. Nos centraremos en el uso de los monitores, construcciones de alto nivel que nos ofrecen mayor libertad que los semáforos.\\

\section{Problema de la exclusión mutua}
En esta Sección tratamos de resolver el problema de la exclusión mutua mediante soluciones software, de forma que la solución no dependa del repertorio de instrucciones de una máquina, sino que sea una solución portable a cualquier dispositivo, de forma que podamos asegurar sobre los procesos de nuestros programas concurrentes todas las propiedades deseadas.\\

Consideraremos solo soluciones al problema en el que el acceso a la sección crítica se resuelva mediante instrucciones básicas de lectura y escritura sobre una o varias variables compartidas en memoria.\\

Como mecanismo para realizar la espera de los procesos en el acceso a la sección crítica usaremos la \textit{espera ocupada}, es decir, meteremos a los procesos que no deben entrar a la sección crítica todavía en un bucle que realice iteraciones ``vacías'' (sin ninguna utilidad) con la finalidad a que esperen a que el proceso que se encuentre en la sección crítica abandone la misma y deje pasar al siguiente.

Hemos de comentar que la espera ocupada no es la mejor solución de espera para los procesos, ya que introduce un uso innecesario de los procesadores con el fin de que ciertos procesos esperen. Puede considerarse una solución aceptable cuando el sistema no disponga de muchos procesos, pero en otro caso podríamos considerar otro tipo de esperas, como que el propio Sistema Operativo suspenda a los procesos.

\subsection{Condiciones de Dijkstra}
Dijkstra enunció que para obtener una solución parcialmente correcta al problema de la exclusión mutua, debían cumplirse 4 condiciones:
\begin{enumerate}
    \item \textit{No hacer ninguna suposición acerca de las instrucciones o número de procesos soportados por el multiprocesador.} Esto es, solo podremos hacer uso de operaciones que entendemos como básicas, tales como leer o escribir en una variable compartida para resolver el problema.

        Dichas instrucciones se ejecutarán de forma atómica, de forma que si dos procesos distintos intentan acceder a la vez a una misma posición de memoria, será el controlador de memoria quien determine de forma arbitraria qué proceso accederá antes y qué proceso después, de forma que el acceso a memoria se lleve a cabo secuencialmente, pero no de una forma predecible.
    \item \textit{No hacer ninguna suposición acerca de la velocidad de ejecución de los procesos}, salvo que esta no es cero, para que se cumpla la hipótesis de Progreso Finito.
    \item \textit{Cuando un proceso se encuentra ejecutando código fuera de la sección crítica, no puede impedir que otros entren a la misma.}
    \item \textit{La sección crítica será alcanzada finalmente por alguno de los procesos que quieran entrar.} Esta condición asegura la propiedad de \textit{alcanzabilidad}, que excluye la posibilidad de que los procesos lleguen a una situación de interbloqueo.

        Esta propiedad no asegura que todos los procesos entren alguna vez a la sección crítica, y mucho menos que lo hagan de forma equitativa.
\end{enumerate}

\subsection{Método de refinamiento sucesivo}
Dijkstra propuso a su vez una forma de obtener una solución al problema de la exclusión mutua, basada en 4 pasos, modificaciones o etapas a partir de un esquema inicial para obtener la solución de forma razonada, que terminará en una quinta etapa, denominada \textit{algoritmo de Dekker}.

\subsubsection{Primera etapa}
Inicialmente, se presupone que los procesos alternarán su entrada en la sección crítica según indique el valor de una variable compartida llamada \verb|turno|. Dicha variable contendrá el identificador del proceso que en cada momento puede entrar a la sección crítica.\\

En un escenario con dos procesos que se disponen a ejecutar una sección crítica, la primera etapa consta del siguiente código:

\begin{figure}[H]
    \centering
    \setlength{\columnsep}{1cm}
    \begin{multicols}{2}
\begin{minted}{pascal}
var turno : integer;

Process P1();
begin
   while true do
   begin
      { Acceso a la SC }
      while turno <> 1 do
      begin
         null;
      end do
      { Sección crítica }
      turno := 2;
   end do
end
\end{minted}
\begin{minted}{pascal}


Process P2();
begin
   while true do
   begin
      { Acceso a la SC }
      while turno <> 2 do
      begin
         null;
      end do
      { Sección crítica }
      turno := 1;
   end do
end
\end{minted}
\end{multicols}
\caption{Algoritmo para la primera etapa de refinamiento sucesivo.}
\end{figure}


Esta solución garantiza el acceso en exclusión mutua de los procesos a la sección crítica, por lo que la solución es segura.\\

Sin embargo, no cumple la tercera condición de Dijkstra, ya que la solución obliga a la alternancia entre los procesos en la entrada a la sección crítica. 

\subsubsection{Segunda etapa}
La alternancia que obtuvimos en la etapa anterior y que nos impedía cumplir con todas las condiciones de Dijkstra se debía a que para decidir qué proceso entraba en la sección crítica era necesario almacenar información global del estado del programa.

Para evitar esto, la idea ahora es asociar a cada proceso una variable que contenga su información de estado, variable que llamaremos \verb|clave|, la cual indicará de forma binaria si el proceso se encuentra o no en la sección crítica en dicho instante de ejecución del algoritmo, mediante dos estados:
\begin{itemize}
    \item Estado pasivo, el proceso no intenta acceder a la sección crítica, representado con un 1.
    \item El proceso intenta acceder a la sección crítica, representado con un 0.
\end{itemize}
En un escenario con dos procesos:
\begin{figure}[H]
    \centering
\setlength{\columnsep}{1cm}
\begin{multicols}{2}
    \begin{minted}{pascal}
        var c1, c2 : integer;
    
        Process P1();
        begin
           c1 := 1;
    
           while true do
           begin
              { Acceso a la SC }
              { Si P2 entró }
              while c2 = 0 do   
              begin
                 null;
              end do
    
              { Entra a la sección crítica }
              c1 := 0;
              { Sección crítica }
              c1 := 1;
           end do
        end
    \end{minted}
    \begin{minted}{pascal}

    
        Process P2();
        begin
           c2 := 1;
    
           while true do
           begin
              { Acceso a la SC }
              { Si P1 entró }
              while c1 = 0 do
              begin
                 null;
              end do
    
              { Entra a la sección crítica }
              c2 := 0;
              { Sección crítica }
              c2 := 1;
           end do
        end
    \end{minted}
\end{multicols}
\caption{Algoritmo para la segunda etapa de refinamiento sucesivo.}
\end{figure}
Como podemos ver, el protocolo de entrada consiste en leer el valor de la clave del otro proceso con la finalidad de consultar si dicho proceso ha entrado o no en la sección crítica, y esperar mientras el otro proceso se encuentre dentro de la sección crítica.\\

Sin embargo, en este caso la solución no es segura, ya que si $P1$ y $P2$ se ejecutan a la misma velocidad, entonces ambos entrarían a la vez a la sección crítica, ya que los dos verían que el estado del otro es pasivo, con lo que ninguno entraría en el bucle de espera ocupada.

Notemos que esto sucede porque cambiamos el estado de un proceso a 0 justo antes de entrar a la sección crítica, por lo que es ya tarde para impedir la entrada a otro proceso.

Como la bondad de la solución depende de la velocidad de ejecución relativa entre los procesos, se dice que es inaceptable por incumplir la segunda condición de Dijkstra.

\subsubsection{Tercera etapa}
Para esta etapa planteamos una sencilla modificación sobre la etapa anterior, que consiste en cambiar el valor de la variable clave a 0 antes de consultar el valor de la variable clave del otro proceso:

De esta forma, para que un proceso pueda entrar a la sección crítica, debe primero cambiar su estado a 0, con el fin de recuperar la condición de seguridad de que solo un proceso pueda entrar a la vez a la sección crítica.
\begin{figure}[H]
\setlength{\columnsep}{1cm}
\begin{multicols}{2}
    \begin{minted}{pascal}
        var c1, c2 : integer;
    
        Process P1();
        begin
           c1 := 1;
    
           while true do
           begin
              { Acceso a la SC }
              c1 := 0;
              { Si P2 entró }
              while c2 = 0 do
              begin
                 null;
              end do
              { Sección crítica }
              c1 := 1;
           end do
        end
    \end{minted}
    \begin{minted}{pascal}

    
        Process P2();
        begin
           c2 := 1;
    
           while true do
           begin
              { Acceso a la SC }
              c2 := 0;
              { Si P1 entró }
              while c1 = 0 do
              begin
                 null;
              end do
              { Sección crítica }
              c2 := 1;
           end do
        end
    \end{minted}
\end{multicols}
\caption{Algoritmo para la tercera etapa de refinamiento sucesivo.}
\end{figure}
Sin embargo, si ambos procesos tienen la misma velocidad, puede suceder que ambos cambien el valor de su clave a 0 al mismo tiempo, con lo que se de una situación de interbloqueo, que incumpliría la cuarta condición de Dijkstra.

\subsubsection{Cuarta etapa}
Lo que causó el problema en la tercera etapa fue que puede suceder que un proceso cambie el valor de su clave a la vez que el otro de forma concurrente, sin que este se de cuenta de que el otro lo ha hecho a la vez.

La solución que se propone en esta etapa es permitir a un proceso volver a cambiar el valor de su clave a 1 si después de asignar su clave a 0, comprueba que el otro proceso también cambió su clave al mismo valor:
\begin{figure}[H]
\setlength{\columnsep}{1cm}
\begin{multicols}{2}
    \begin{minted}{pascal}
    var c1, c2 : integer;

    Process P1();
    begin
       c1 := 1;

       while true do
       begin
          { Acceso a la SC }
          c1 := 0;
          { Si P2 entró }
          while c2 = 0 do
          begin
             c1 := 1;
             while c2 = 0 do
             begin
                null;
             end do
             c1 := 0;
          end do
          { Sección crítica }
          c1 := 1;
       end do
    end
\end{minted}
\begin{minted}{pascal}


    Process P2();
    begin
       c2 := 1;

       while true do
       begin
          { Acceso a la SC }
          c2 := 0;
          { Si P1 entró }
          while c1 = 0 do
          begin
             c2 := 1;
             while c1 = 0 do
             begin
                null;
             end do
             c2 := 0;
          end do
          { Sección crítica }
          c2 := 1;
       end do
    end
\end{minted}
\end{multicols}
\caption{Algoritmo para la cuarta etapa de refinamiento sucesivo.}
\end{figure}
Sin embargo, si ambos procesos se ejecutasen a la misma velocidad, se podría seguir produciendo un interbloqueo entre ambos procesos, aunque esta situación ahora sea más improbable. La solución no sería válida por incumplir tanto la segunda como la cuarta condición de Dijkstra.\\

La conclusión a la que llegamos tras todas estas etapas es que las variables \verb|c1| y \verb|c2| nos son útiles para coordinar la entrada a la sección crítica, pero no son suficientes para dar una solución correcta al problema que tratamos de resolver.\\

\subsection{Algoritmo de Dekker}
Se podría considerar como una quinta etapa del método de refinamiento sucesivo, pero esta vez obteniendo una solución válida del problema.

El algoritmo de Dekker junta las ideas presentes en la primera y cuarta etapa de refinamiento de Dijkstra:
\begin{itemize}
    \item La primera etapa producía una solución segura, pero obligaba a la alternancia en el acceso de los procesos a la sección crítica.
    \item Por otra parte, la cuarta etapa no cuenta con dicha alternancia en el acceso, pero puede llevar a un interbloqueo de los procesos del programa concurrente.
\end{itemize}
Para resolver el problema, se considera el código de la cuarta etapa de Dijkstra y se le añade un orden establecido en la entrada mediante una variable \verb|turno|, para desempatar la situación en la que los dos procesos quieran entrar exactamente al mismo tiempo en la sección crítica.\\

De esta forma, un proceso que quiera entrar en la sección crítica asignará primero su clave a 0, y si el otro proceso también tiene su clave a 0, lo primero que hará es comprobar de quién es el turno y si no dispone del mismo, cambiará su clave a 1 pasando a esperar y dejando al otro proceso continuar con la ejecución de la sección crítica.

\begin{figure}[H]
\setlength{\columnsep}{1cm}
\begin{multicols}{2}
    \begin{minted}{pascal}
    var c1, c2, turno : integer;

    Process P1();
    begin
       while true do
       begin
          { Acceso a la SC }
          c1 := 0;

          while c2 = 0 do
          begin
             if turno = 2 then
             begin

                c1 := 1;
                while turno = 2 do
                begin
                   null;
                end do
                c1 := 0;

             end
          end do

          { Sección crítica }
          turno := 2;
          c1 := 1;
       end do
    end
\end{minted}
\begin{minted}{pascal}


    Process P2();
    begin
       while true do
       begin
          { Acceso a la SC }
          c2 := 0;

          while c1 = 0 do
          begin
             if turno = 1 then
             begin

                c2 := 1;
                while turno = 1 do
                begin
                   null;
                end do
                c2 := 0;

             end
          end do

          { Sección crítica }
          turno := 1;
          c2 := 1;
       end do
    end
\end{minted}
\end{multicols}
\caption{Algorimo de Dekker.}
\end{figure}

\subsubsection{Propiedades de corrección}
En esta sección demostraremos que se cumple siempre el acceso en exclusión mutua a la sección crítica por parte de los procesos que intervienen en los programas concurrentes, sí como de la propiedad de alcanzabilidad de la sección crítica:

\begin{description}
    \item [Exclusión mutua.]~\\
    El proceso $P_i$ (con $i = 1$ ó $i=2$) entrará en la sección crítica solo si el otro proceso, $P_j$ mantiene su clave $cj$ a 1. Dado que la clave de un proceso solo la puede modificar el propio proceso y qeu el proceso $P_i$ comprueba la clave $cj$ solo después de asignar su propia clave $ci$ a 0, si el proceso $P_i$ entra en sección crítica, se ha de cumplir la condición $ci = 0 \land cj = 1$. Notemos que esta situación es incompatible con la condición de que el proceso $P_j$ entre en la sección crítica: $cj = 0 \land ci = 1$.
    \item [Alcanzabilidad de la sección crítica.]~\\
    Para demostrar la alcanzabilidad de la sección crítica, distinguimos casos:
    \begin{itemize}
        \item Si suponemos que el proceso $P_i$ intenta entrar solo en la sección crítica, entonces el otro proceso $P_j$ se mantendrá en estado pasivo, con lo que el valor de su clave $cj$ será 1. De esta forma, el proceso $P_i$ puede entrar a la sección crítica.
        \item Sin embargo, si tanto $P_i$ como $P_j$ intentan entrar a la vez a la sección crítica y suponemos que $turno = i$, entonces:
            \begin{itemize}
                \item Si $P_j$ encuentra la clave $ci$ a 1, entonces $P_j$ entrará en la sección crítica.
                \item Si $P_j$ encuentra la clave $ci$ a 0, como $turno = i$, entonces $P_j$ entrará en el segundo bucle interno para realizar la espera ocupada, poniendo antes su clave $cj$ a 1, que permitirá pasar al proceso $P_i$.
                \item Si $P_i$ encuetran la clave $cj$ a 0, se mantendrá realizando iteraciones en el bucle de espera ocupada más externo con $ci$ a 0, hasta que lea el valor de $cj$ a 1, que sucederá por el punto superior, con lo que $P_i$ entrará en la sección crítica.
            \end{itemize}
    \end{itemize}

    
    \item [Vivacidad.]~\\
    Dependiendo del hardware de control de acceso a memoria, el algoritmo de Dekker puede llegar a provocar la inanición de uno de los dos procesos:

    \begin{figure}[H]
    \centering
    \setlength{\columnsep}{1cm} % Ajusta el espacio entre columnas
    \begin{multicols}{2}
        Proceso 1.
        \begin{minted}{pascal}
            c1 := 0;

            while c2 = 0 do
            begin
               if turno = 2 then
               begin
                  c1 := 1;
                  while turno = 2 do
                  begin
                     null;
                  end do
                  c1 := 0;
               end
            end do

            { Sección crítica }
            turno := 2;
            c1 := 1;
        \end{minted}
        Proceso 2.
        \begin{minted}{pascal}
            c2 := 0;

            while c1 = 0 do
            begin
               if turno = 1 then
               begin
                  c2 := 1;
                  while turno = 1 do
                  begin
                     null;
                  end do
                  c2 := 0;
               end
            end do

            { Sección crítica }
            turno := 1;
            c2 := 1;
        \end{minted}
    \end{multicols}
        
    \end{figure}
    
    Supongamos que tenemos a los procesos $P1$ y $P2$ ejecutando su código, queriendo acceder continuamente a la sección crítica. Supongamos además que el proceso $P2$ se ejecuta a una velocidad bastante lenta en comparación al proceso $P1$.\\ 

    Nos encontramos en el caso en el que ambos procesos cambiaron sus claves al mismo tiempo y el turno inicial era 1, con lo que $P1$ pasó a ejecutar el código de la sección crítica y $P2$ se quedó esperando en el bucle más interno, con el valor de su clave \verb|c2| a 1.\\

    Debemos recordar que anteriormente mencionamos que el acceso al módulo de memoria no se hace de forma paralela, sino que se hace de forma secuencial, de forma que si dos procesos intentan acceder a la vez a una misma posición de memoria es el controlador de memoria quien determina el acceso a un proceso de forma arbitraria.\\

    Supongamos pues que $P1$ termina de ejecutar el código de la sección crítica, con lo que cambia el valor de la variable \verb|turno| a 2, \verb|c1| a 1 y cambia también \verb|c1| a 0. Posteriormente, como $P1$ cambió \verb|turno| a 2, el proceso $P2$ sale del bucle más interno, con lo que se dispone a cambiar el valor de su clave a 0.

    Sin embargo, en este momento sucede que tanto $P1$ como $P2$ intentan acceder a la vez al valor de \verb|c2|, $P1$ para leer (en la condición del \verb|while| exterior) y $P2$ para escribir. Si en dicho momento el controlador de memoria da prioridad a las lecturas, $P1$ volvería a introducirse en la sección crítica.

    Inmediatamente, $P2$ se dispondría a cambiar el vlor de su clave a 1, pero como mencionamos anteriormente, $P2$ es muy lento, con lo que resulta que le da tiempo a $P1$ a ejecutar la sección crítica y volver a la lectura de \verb|c2| en el bucle más externo a la vez que $P2$, con lo que el controlador de memoria puede volver a darle prioridad.\\

    Si este escenario sucede de forma indefinida, tenemos una falta de vivacidad en el proceso $P2$, ya que mientras $P1$ esté en funcionamiento, no podrá avanzar en su ejecución.

    \item [Equidad del protocolo.]~\\
    Como hemos comentado en el apartado de vivacidad, la equidad del algoritmo de Dekker dependerá de la equidad del hardware de la máquina en el que ejecutemos el programa concurrente. Si existen peticiones de acceso simultáneo a una misma dirección de memoria compartida por dos procesos, uno para lectura y otro para escritura de forma que el hardware da prioridad a las lecturas, no se puede demostrar que el algoritmo de Dekker sea equitativo, pudiendo llegar al escenario de inanición de uno de los procesos como ya se ha descrito anteriormente.
\end{description}

\subsection{Algoritmo de Dijkstra}
Una vez visto el algoritmo de Dekker, primera solución aceptable al problema de la exclusión mutua, nos encontramos con que no es generalizable para $n$ procesos, con lo que mostramos a continuación el algoritmo de Dijkstra, que resuelve el problema de la exclusión mutua para $n$ procesos utilizando un array de $n$ posiciones en las que cada proceso almacena su estado, destacando tres posibles estados:
\begin{itemize}
    \item Proceso pasivo, con lo que el proceso no itenta acceder al protocolo de entrada.
    \item Solicitando, el proceso intenta acceder al protocolo de entrada.
    \item En SC, el protocolo está dentro de la sección crítica.
\end{itemize}
\begin{figure}[H]
\begin{minted}{pascal}
    var c : array[0..n-1] of (pasivo, solicitando, en_SC);
        turno : 0..n-1;

    Process Pi();
    begin
       while true do
       begin
          { Acceso a la sección crítica }
          repeat
             c[i] := solicitando;

             { A }
             while turno <> i do
             begin
                if c[turno] = pasivo then turno := i;
             end do

             c[i] := en_SC;

             { B }
             j := 0;
             while (j<n) and (j=i or c[j] <> en_SC) do
             begin
                j := j+1;
             end do
          until j >= n

          { Sección crítica }
          c[i] := pasivo;
       end do
    end
\end{minted}
\caption{Algoritmo de Dijkstra, código para el $i$-ésimo proceso.}
\end{figure}

De esta forma, lo primero que hace un proceso $P_i$ al llegar al protocolo de entrada a la sección crítica es cambiar su estado a \verb|solicitando|. Posteriormente:
\begin{itemize}
    \item Si es su turno, no pasará en el bucle \verb|A|.
    \item Si no es su turno:
        \begin{itemize}
            \item Si el proceso que tiene el turno está en estado pasivo, entonces el proceso $P_i$ pone el turno a $i$, siendo ahora su turno con lo que pase del bucle \verb|A|.
            \item Si el proceso que tiene el turno no está en estado pasivo, entonces el proceso $P_i$ esperará hasta que este lo esté, es decir, hasta que el proceso $P_{\text{turno}}$ abandone la sección crítica.
        \end{itemize}
\end{itemize}
Una vez superado el bucle \verb|A|, entonces el estado del proceso $P_i$ pasará a \verb|en_SC|, y solo tendrá que superar el bucle \verb|B| para poder entrar a la sección crítica.\\

Puede suceder que dos procesos, $P_i$ y $P_j$ lleguen al bucle \verb|A| de forma que primero el proceso $P_i$ cambie el turno a $i$ (suponiendo que el proceso con el turno está pasivo) y que el proceso $P_j$ cambie el turno a $j$ y pasando el bucle \verb|A|, antes de que el proceso $P_i$ cambie su estado a \verb|en_SC|. En dicho caso, contamos con el bucle \verb|B| para cumplir con la condición de seguridad de tener un único proceso ejecutando la sección crítica a la vez.\\

Lo que hace el bucle \verb|B| es comprobar todos los estados de los procesos antes de dejar pasar al proceso $P_i$ entrar a la sección crítica, de forma que si todos los demás procesos tienen un estado distinto de \verb|en_SC|, entonces el contador \verb|j| llegará hasta \verb|n|, con lo que $P_i$ saldrá del bucle \verb|B| así como del \verb|repeat| de entrada a la sección crítica.\\

En el caso en el que dos procesos estén con estado \verb|en_SC|, entonces la variable \verb|j| no llegará a aumentar hasta \verb|n|, con lo que los procesos no podrán salir del \verb|repeat|, teniendo que volver a pasar por el bucle \verb|A|, donde el turno estará ya fijado en un proceso con un estado distinto de pasivo.

\subsubsection{Propiedades de corrección}
Pasamos ahora a demostrar las propiedades de corrección del algoritmo de Dijsktra.

\begin{description}
    \item [Exclusión mutua.]~\\
        El proceso $P_i$ (con $i \in \{0,\ldots,n-1\}$) entrará en la sección crítica solo si el resto de procesos $P_j$ con $j\neq i$ tienen su estado distinto de \verb|en_SC|. En dicho caso, $P_i$ pasará a ejecutar la sección crítica, poniendo su estado a \verb|en_SC|. 

        Supuesto que ahora otro proceso $P_j$ intenta acceder a la sección crítica, solo podrá hacerlo si el resto de procesos tienen su estado distinto de \verb|en_SC|, algo que no puede suceder hasta que el proceso $P_i$ salga de la sección crítica.
    \item [Alcanzabilidad de la sección crítica.]~\\
        Supuesto que disponemos que $m$ procesos $P_1, P_2, \ldots, P_m$ de forma que tratan de acceder a la sección crítica al mismo tiempo, entonces el valor de la variable compartida \verb|turno| será un cierto $k \in \{1,\ldots,m\}$, correspondiente al identificador del último proceso que cambió su valor. 

        Los procesos que superen el bucle \verb|A| junto con $P_k$ no podrán superar el bucle \verb|B| con un valor de \verb|j| igual o superior a \verb|n|, por lo que todos los procesos (junto con $P_k$) volverán al bucle \verb|A|.

        En dicho instante, el turno estará fijado a $k$ y \verb|c[k]| tendrá un valor distinto de pasivo, con lo que el proceso $P_k$ será ahora el único que consiga pasar el bucle \verb|A|, con lo que completará el bucle \verb|B| con un valor de \verb|j| igual a \verb|n|, lo que le permitirá acceder a la sección crítica.

    \item [Vivacidad.]~\\
        El algoritmo de Dijkstra también puede llevar a la inanición de uno de los procesos del programa concurrente, al igual que el algoritmo de Dekker.

        Para ver dicha situación, supongamos que tenemos dos procesos, $P_0$ y $P_1$, ambos intentando acceder a la sección crítica. Supongamos que ambos consiguen pasar por el bucle \verb|A|, primero $P_0$ y luego $P_1$, con lo que el turno quedará concedido a $P_1$ en la siguiente iteración del \verb|repeat|, que pasará a la sección crítica y el proceso $P_0$ quedará bloqueado en el bucle \verb|A| en espera ocupada.

        Cuando $P_1$ salva de la sección crítica y cambie su estado a pasivo, puede suceder que $P_0$ cambie el turno a 0, consiguiendo superar el bucle \verb|A| y que inmediatamente después $P_1$ consiga también superar el bucle \verb|A|, volviendo a dejar el turno en 1, con lo que se sucederá la situación anterior nuevamente.

        De esta forma, el proceso $P_1$ puede dejar al proceso $P_0$ en la zona de acceso a la sección crítica de forma indefinida.
\end{description}

\subsection{Algoritmo de Knuth}
Con la finalidad de no caer en los errores de los algoritmos de Dekker y Dijkstra (los cuales pueden llegar a un estado en el que un proceso sufra inanición), Donald Knuth añadió una quinta condición a las condiciones de Dijkstra para la corrección parcial de una solución al problema de la exclusión mutua:
\begin{enumerate}[label=5.]
    \item \textit{Se tiene que poder demostrar que todos los procesos pueden sufrir un retraso máximo en el acceso a la sección crítica que sea calculable.}

        Con el fin de garantizar que ningún proceso sufrirá de inanición, ya que en algún momento conseguirá entrar a la sección crítica.
\end{enumerate}

Donald Knuth se dió cuenta de que la propiedad de vivacidad no podía ser demostrada debido a que la variable compartida \verb|turno| utilizada en los algoritmos de Dekker y Dijkstra sufría condiciones de carrera. El algoritmo propuesto por Knuth hace uso de una variable local \verb|j| que copia el valor de la variable compartida \verb|turno|, con el fin de evitar dichas condiciones de carrera. Por lo demás, el algoritmo es similar al de Dijkstra:

\begin{figure}[H]
\begin{minted}{pascal}
    var c : array[0..n-1] of (pasivo, solicitando, en_SC);
        turno : 0..n-1;

    Process Pi();
    var j : 0..n-1;
    begin
       while true do
       begin
          repeat
             c[i] := solicitando;
             j := turno;

             { A }
             while j <> i do
             begin
                if c[j] <> pasivo then j := turno;
                else j := (j-1) mod n;
             end do

             c[i] := en_SC;
             k := 0;

             { B }
             while (k<n) and (k=i or c[k] <> en_SC) do
             begin
                k := k+1;
             end do
          until k >= n;

          turno := i;
          { Sección crítica }
          turno := (i-1) mod n;
          c[i] := pasivo;
       end do
    end
\end{minted}
\caption{Algoritmo de Knuth.}
\end{figure}
De esta forma, si es el turno de un proceso, entonces este se salta el bucle \verb|A|. Si no, entonces el proceso que tiene el turno está en estado pasivo, el proceso decrementa el valor de \verb|j| hasta que:
\begin{itemize}
    \item Encuentra un proceso que no está en estado pasivo, con lo que el proceso pasa a realizar una espera activa.
    \item El valor de \verb|j| coincida con \verb|i|, o que permita al proceso salir del bucle \verb|A|.
\end{itemize}
De esta forma, Knuth controla el número de veces que los procesos pueden adelantarse los unos a los otros dentro del bucle \verb|A|.\\

Por el resto, es idéntico al funcionamiento del algoritmo de Dijkstra, salvo que solo modifica el valor de la variable \verb|turno| una vez el proceso se encuentra dentro de la sección crítica, evitando condiciones de carrera.

\subsubsection{Propiedades de corrección}
\begin{description}
    \item [Exclusión mutua.]~\\
        Está garantizada gracias al bucle \verb|B|, tal y como razonamos en el algoritmo de Dijkstra.
    \item [Ausencia de inanición.]~\\
        Evita la inanición porque el valor de \verb|turno| se asigna tras la ejecución de la sección crítica, pasando el turno en orden circular.

        La instrucción \verb|(j-1) mod n| en el bucle \verb|A| permite recorrer los procesos para dar oportunidad a todos los procesos solicitantes.

        De hecho, el retraso máximo que puede sufrir un proceso en un escenario con $n$ procesos es de $2^{n-1}-1$.
    \item [Equidad.]~\\
        Está garantizada gracias a la asignación circular del turno.
\end{description}

% // TODO: Entender bien y poner un ejemplo

\subsection{Algoritmo de Peterson para 2 procesos}
Peterson propuso una forma simple de resolver el problema de la exclusión mutua para dos procesos, de forma que a partir de entonces se consideró la solución canónica a dicho problema. Esta es generalizable a $n$ procesos.

El algoritmo cuenta con las variables compartidas:
\begin{minted}{pascal}
    var c : array[1..2] of boolean;
        turno : 1..2;
\end{minted}
Donde el array \verb|c| se inicializa con todos sus valores a \verb|false|, de forma que \verb|c[i]| indica si el $i$-ésimo proceso está o no solicitando acceder a la sección crítica. La variable \verb|turno| sirve para resolver conflictos en el caso de que ambos procesos intenten acceder a la vez a la sección crítica.\\

Cuando un algoritmo quiere acceder a la sección crítica, lo que hace primero es cambiar su clave a ``solicitando sección crítica''. Posteriormente, se asigna el turno a dicho proceso. En el caso en el que ambos intenten acceder a la vez a la sección crítica, uno de ellos habrá sido necesariamente el último en asignarse el turno, y será el proceso que espere a que el otro ejecute la sección crítica.

\begin{figure}[H]
    \centering
    \setlength{\columnsep}{1cm}
    \begin{multicols}{2}
        \begin{minted}{pascal}
            Process P1();
            begin
               while true do
               begin
                  { Acceso a la SC }
                  c[1] := true;
                  turno := 1;

                  while (c[2] and turno = 1) do
                  begin
                     null;
                  end do

                  { Sección crítica }
                  c[1] := false;
               end do
            end
        \end{minted}
        \begin{minted}{pascal}
            Process P2();
            begin
               while true do
               begin
                  { Acceso a la SC }
                  c[2] := true;
                  turno := 2;

                  while (c[1] and turno = 2) do
                  begin
                     null;
                  end do

                  { Sección crítica }
                  c[2] := false;
               end do
            end
        \end{minted}
    \end{multicols}
    \caption{Algoritmo de Peterson para 2 procesos.}
\end{figure}

\subsubsection{Propiedades de corrección}
A continuación, mostramos que la solución de Peterson no solo es una solución para el problema de la exclusión mutua, sino que además garantiza la equidad en el acceso a la misma para los procesos que intervienen en un programa concurrente que usa dicho algoritmo.
\begin{description}
    \item [Exclusión mutua.]~\
        Suponiendo que nos encontramos en el proceso $P_i$ (con $i=1$ ó $i=2$), sea $j$ el otro proceso ($j =1$ si $i=2$ ó $j=2$ si $i=1$), supongamos que el proceso $P_i$ consigue entrar a la sección crítica. Esto sucede solo si $c[j]$ es falso o si \verb|turno| es $j$. Es decir, si $P_j$ no está intentando acceder a la sección crítica o si $P_j$ fue el último proceso en asignarse el turno. De esta forma, si el proceso $P_j$ intenta acceder a la vez a la sección crítica, quedará bloqueado, con lo que solo un proceso conseguirá al final entrar a la sección crítica.
    \item [Alcanzabilidad de la sección crítica.]~\\
        Supusto que dos procesos intenta acceder a la sección crítica, ambos cambiarán su valor de \verb|c| a \verb|true|, y cambiarán el valor de \verb|turno| a su identificador, quedando uno de ellos bloqueado (el último que modificó dicha variable) y el otro proceso consigue pasar el bucle, con lo que alcanza la sección crítica.
    \item [Equidad.]~\\
        El algoritmo de Peterson no solo garantiza la condición de vivacidad para los procesos del programa concurrente sino que garantiza la equidad en su acceso a la sección crítica:

        Supongamos que un proceso $P_i$ está bloqueado esperando a entrar a la sección crítica y un proceso $P_j$ está continuamente entrando y saliendo de la misma monopolizando us uso. Sin embargo, cuando $P_j$ salga de la sección crítica por primera vez, cambiará el valor de \verb|turno| a $j$, con lo que $P_j$ quedará bloqueado en el acceso a la sección crítica y $P_i$ conseguirá entrar a la misma, contradicción con que un proceso pueda quedar bloqueado.
\end{description}

\section{Definición de un monitor}
El concepto de semáforo se desarrolló previamente en el Seminario 1 de prácticas\footnote{Por lo que el lector debería estar familiarizado con ellos.}. Los semáforos presentan dos grandes limitaciones:
\begin{enumerate}
    \item Están basados en variables compartidas del programa, por lo que no fomentan la modularidad de los programas, impidiendo su reutilización.
    \item Las operaciones de los semáforos (\verb|sem_wait| y \verb|sem_signal|) se encuentran dispersas a lo largo del código del programa concurrente. Además, estas instrucciones no solo afectan al bloque de código en el que se encuentran, sino a cualquier otro bloque que use el mismo semáforo.
\end{enumerate}
En definitiva, los semáforos no son un buen mecanismo de programación concurrente, y además la verificación de programas que usan semáforos es muy complicada. 

Era necesario encontrar un nuevo mecanismo de programación concurrente que permitiera la encapsulación de la información y de la sincronización entre procesos, así como programar las operaciones de sincronización (como \verb|wait| o \verb|signal|) dentro de bloques o procedimientos que se ejecuten con instrucciones atómicas, para que las instrucciones de sincronización no se encuentren desperdigadas por el programa.
Fue Charles Antony Richard Hoare quien inventó los monitores, concepto en el que ahondaremos a lo largo de este Capítulo.\\

La idea básica de monitor es un módulo que contiene un conjunto de variables a las que llamaremos \textit{variables permanentes}\footnote{A pesar de su nombre, no serán constantes, sino que podremos modificar su valor.}, de forma que dichas variables solo podrán ser alteradas dentro de los procedimientos del módulo monitor. Garantizaremos que la ejecución de cada uno de esos procedimientos se ejecute la mayor parte del tiempo como una única instrucción atómica, salvo que se produzca algo por lo que interrumpir la ejecución del procedimiento.\\

Podemos pensar en un monitor como en un tipo de dato abstracto que define tipos y variables permanentes propias del monitor, así como un conjunto de procedimientos dentro de dicho módulo. No debemos pensar en los monitores como en una clase, ya que no pueden hacer lo mismo que ellas (no se pueden instanciar y tampoco existe polimorfismo o ligadura dinámica).

\subsubsection{Ventajas}
A continuación, los programas concurrentes estarán formados tanto por procesos que se ejecutarán de forma concurrente, como por monitores, los cuales velarán por la sincronización y acceso a variables compartidas de dichos procesos, de forma que no se produzcan condiciones de carrera o comportamientos indeseados. Podremos modelar tantas relaciones de interacción entre los procesos de un programa concurrente como queramos. De esta forma, el uso de los monitores o de procedimientos asociados a monitores no restringen las posibilidades del modelado de un sistema concurrente. 

Los procesos de un programa concurrente no tendrán que llamar a operaciones de sincronización, sino que llamarán a procedimientos del monitor, los cuales realizarán la funcionalidad deseada sobre las variables compartidas garantizando la sincronización entre los procesos.\\

Además, los monitores nos permiten una alta reusabilidad de código, ya que podremos reutilizar un monitor ya creado para resolver problemas similares. Sin embargo, la reutilización de código no es similar a la usada en programación orientada a objetos mediante instancias de una misma clase, sino que se hará por copias parametrizables: tendremos una definición de un monitor basada en parámetros, y cuando necesitemos usar un monitor, crearemos una copia de dicha definición parametrizándola (pasándole los parámetros que necesitemos para resolver nuestro problema). De esta forma, no es reutilización por instanciación, sino por \textit{parametrización}.\\

Los procesos que usemos en los progrmas concurrentes no verán el acceso a las variables compartidas, sino que será realizado por los procedimientos del monitor, garantizando que se hacen como deben hacerse, evitando condiciones de carrera. De esta forma, los monitores garantizan la ocultación de las variables compartidas, haciéndolas transparentes a los procesos del sistema concurrente.\\

Finalmente, existen unos axiomas que nos permiten verificar los programas concurrentes que usen monitores de forma sencilla. Dichas demostraciones estarán basadas en el uso de los invariables globales. Ahondaremos en la verificación de programas concurrentes que utilicen monitores más adelante.

\subsection{Concepto de monitor}\label{sec:concepto_de_monitor}
A modo de resumen para comenzar a definir lo que es un monitor, podemos decir que:
\begin{itemize}
    \item Es un módulo con un conjunto de variables permanentes que solo pueden ser modificadas por los procedimientos del monitor.
    \item Cada uno de los procedimientos\footnote{Podemos pensar en ellos como en los ``métodos'' de una clase, haciendo hincapié en que los monitores \textbf{no son} clases.} de un monitor se ejecutan en exclusión mutua (garantizando el acceso a las variables compartidas sin condiciones de carrera). Sin embargo, estos no tienen por qué ejecutarse completamente, sino que pueden interrumpirse y en algún momento futuro seguir ejecutándose en exclusión mutua.
    \item La ejecución de los procedimientos de un monitor modifican el estado interno del mismo (esto es, el conjunto de las variables permanentes asociadas al monitor).
    \item El estado inicial del monitor (de sus variables permanentes) se establece mediante la ejecución de un procedimiento especial, al que llamaremos \textit{código de inicialización}. Este se ejecuta tras la declaración de una variable de tipo monitor y da valores iniciales a las variables permanentes.
\end{itemize}
De esta forma, un monitor puede visualizarse de forma intuitiva en la Tabla~\ref{esq:monitor_1}, como un conjunto que englobla:
\begin{itemize}
    \item Un conjunto de variables, llamadas \textit{variables permanentes}, que no son accesibles desde fuera del monitor.
    \item Un conjunto de procedimientos que el monitor proporciona como servicio a los procesos de un programa concurrente (para por ejemplo, acceder a las variables permanentes que serán las variables que compartan dichos procesos), llamados \textit{procedimientos exportados} o \textit{exportables}.
    \item Un procedimiento especial llamado \textit{código de inicialización}, que permite inicializar las variable permanentes.
\end{itemize}

\begin{table}[H]
\centering
\begin{tabular}{|l|}
\hline
Variables \\
permanentes \\
\hline
Procedimientos \\
exportados \\
\hline
Código de \\ 
inicialización \\
\hline
\end{tabular}
\caption{Esquema de un monitor.}
\label{esq:monitor_1}
\end{table}

\begin{ejemplo}
    Aunque todavía no entendemos muy bien qué es un monitor, daremos a continuación un ejemplo de uso del mismo para ilustrar la definición que queremos dar de monitor, pese a que algunas cosas del ejemplo no podamos entenderlas todavía y deberemos dejarlas para más adelante\footnote{Como el tipo de dato \texttt{cond}.}.\\

    En este ejemplo, queremos solventar un problema mediante el paradigma productor/consumidor. Tendremos dos procesos, un productor y un consumidor, de forma que el productor escribirá en un buffer (o vector) que usaremos como cola cíclica (esto es, que si nos pasamos de la posición final, volvemos al inicio y con planificación FIFO), mientras que el consumidor irá leyendo los datos de dicho buffer. Siendo \verb|Buf| una variable de tipo monitor que luego definiremos en este ejemplo, el código del productor y del consumidor será el siguiente (pensando en que tenemos que usar procedimientos del monitor para el acceso a las variables compartidas, en este caso el buffer):
    \begin{minted}[escapeinside=\#\#]{pascal}
        Proceso Prod1::
          var d : tipo_dato;

          while true do begin
            d = producir();
            Buf.insertar(d); {mete d en el buffer}
          end do
    \end{minted}
    \begin{minted}[escapeinside=\#\#]{pascal}
        Proceso Cons1::
          var x : tipo_dato;

          while true do begin
            Buf.retirar(x); {retira del buffer en x}
            consumir(x);
          end do
    \end{minted}
    El código del monitor será el siguiente en pseudo-pascal (hemos omitido el código de inicialización):
    \begin{minted}[escapeinside=\#\#]{pascal}
        Monitor Buf
          var
            -elementos_ocupados : int;
            -frente, atras: 0..N-1;
            -no_vacio, no_lleno : cond;

          +insertar(d : tipo_dato);
          +retirar(var x : tipo_dato);
    \end{minted}
    Donde vemos 5 variables permanentes: \verb|elementos_ocupados|, que mide la cantidad de posiciones ocupadas del buffer, \verb|frente|, que marca la casilla en la que el productor insertará el próximo dato (por tanto, ha de estar siempre vacía), \verb|atras|, que marca la casilla de la que leerá el consumidor, \verb|no_vacio| y \verb|no_lleno|, variables de tipo \verb|cond|, las cuales aprenderemos lo que hacen más adelante.
    
    Contamos además con dos procedimientos: \verb|insertar|, que inserta un dato en el buffer en caso de que haya hueco (si no hay hueco, se bloquea hasta que el consumidor lea un dato y deje un hueco libre):
    \begin{minted}[escapeinside=\#\#]{pascal}
        procedure insertar(d : tipo_dato) begin
          if((frente + 1) mod N = frente) then no_lleno.wait();
          introducir(buf, frente, d);  {inserta d en la posicion frente en el buffer}
          elementos_ocupados += 1;
          frente = (frente + 1) mod N;
          no_vacio.signal();
        end
    \end{minted}
    Y con el procedimiento \verb|retirar|, que retira un dato del buffer y lo devuelve como resultado del procedimiento, siempre que esto sea posible (es decir, si no hay ningún dato que leer en el buffer, se bloquea esperando a que el productor ponga algún dato):
    \begin{minted}[escapeinside=\#\#]{pascal}
        procedure retirar(var x : tipo_dato) begin
          if(frente = atras) then no_vacio.wait();
          eliminar(buf, atras, x);  {inserta buf[atras] en x y lo borra del buffer}
          elementos_ocupados -= 1;
          atras = atras mod N + 1;
          no_lleno.signal();
        end
    \end{minted}
    Como hemos ya comentado mientras mostrábamos los pseudocódigos del ejemplo, hay que establecer condiciones que identifiquen las dos condiciones inseguras del ejemplo: que el buffer esté lleno o que el buffer esté vacío:
    \begin{itemize}
        \item Si \verb|frente = atras|, entonces el último dato que se ha de consumir está en una casilla vacía en la que el productor escribirá. Se trata de la situación en la que el buffer está vacío. Debemos por tanto, evitar que el consumidor lea un dato del buffer.
        \item Si \verb|(frente + 1) mod N = atras|, entonces el siguiente dato a introducir en el buffer está justo delante del dato a consumir. Se trata de la situación en la que el buffer está lleno. Debemos por tanto, evitar que el productor introduzca un dato en el buffer\footnote{Definimos anteriormente que \texttt{frente} siempre apunta a una casilla vacía, por lo que como máximo el buffer tendrá ocupados $N-1$ elementos.}.
    \end{itemize}
    Los procesos del programa llaman a los procedimientos del monitor, y no tienen acceso directo al buffer, por lo que no pueden saber cuándo este está lleno o vacío. De esta forma, lo que sucederá es que los procedimientos internos del monitor realizarán una sincronización interna mediante el uso de llamadas bloqueantes:
    \begin{itemize}
        \item Si el buffer está lleno y el productor se dispone a escribir un dato, quedará el proceso bloqueado hasta que un consumidor lea un dato. Este señalará (\verb|signal|) al productor, desbloqueándolo.
        \item Si el buffer está vacío y el consumidor se disopne a leer un dato, quedará bloqueado el proceso que ejecute el procedimiento del monitor. Cuando el productor escriba un dato, enviará una señal al consumidor, desbloqueándolo.
    \end{itemize}
    Esta funcionalidad se consigue mediante las variables de tipo \verb|cond|. Se verán a continuación, pero para entenderlas por ahora digamos que necesitamos tener una variable de tipo \verb|cond| por cada razón por la que queremos bloquear un proceso\footnote{En el caso de productor/consumidor, queremos bloquear un proceso si sucede alguno de los dos puntos superiores, condiciones inseguras, luego nos harán falta dos variables de tipo \texttt{cond}. En otros problemas, el número de variables de tipo \texttt{cond} podría ser otro.}.\\

    El código de los procedimientos es ejecutado por los propios procesos que ejecutan cada proceso (productor o consumidor, en este caso) del programa concurrente. Por tanto, si el productor ejecuta un procedimiento del monitor con un \verb|wait|, dicho proceso se bloqueará y no podrá ejecutar código hasta desbloquearse.\\

    Para que el código que hemos visto funcione adecuadamente, nos falta introducir un último concepto en los monitores, y es que mientras se ejecuta un procedimiento de un monitor, no se puede ejecutar ningún otro, sino que han de ejecutarse en \textbf{exclusión mutua}.
\end{ejemplo}

\subsection{Características de programación con monitores}
Una vez ilustrado el uso de la herramienta que estamos construyendo en este Capítulo mediante el ejemplo anterior, vamos ahora a introducir la noción de que solo puede ejecutarse a la vez un único procedimiento de un monitor.\\

Como ya hemos visto, los procedimientos de los monitores no tienen por qué ejecutarse de principio a fin, sino que un proceso puede comenzar a ejecutar un procedimiento, bloquearse (dejando por tanto libre al monitor) y que otro proceso comience a ejecutar un procedimiento de dicho monitor, sucediéndose un entrelazamiento de las trazas de ejecución de los procedimientos.\\

Cuando un proceso se encuentra ejecutando un procedimiento del monitor, decimos que el monitor está \emph{ocupado}. En caso contrario, diremos que este está \emph{libre}. Notemos que si un proceso se bloquea mientras ejecuta un procedimiento del monitor, el monitor tiene que quedar libre, ya que si no no habría forma de volver a despertar a dicho proceso (tenemos que ejecutar un \verb|signal| sobre la misma variable \verb|cond| que bloqueó al proceso\footnote{Se explicará más adelante.}). La situación de bloquear a un proceso y dejar que entre otro al monitor es delicada y debe hacerse con cuidado, para garantizar que solo haya un único proceso ejecutando un procedimiento del monitor al mismo tiempo.\\

Los monitores son objetos \emph{pasivos}. Esto es, no tienen una hebra dentro que ejecute su código, sino que simplemente proporciona código (sus procedimientos) a otros procesos para que sean ellos quien ejecuten el código del monitor.\\

Para implementar una librería con monitores en un lenguaje de programación base, este debe tener la propiedad de ser \emph{reentrante}.
\begin{definicion}
    Un lenguaje de programación tiene la propiedad de ser reentrante si, siempre que tengamos un proceso ejecutando una función y este se bloquea, sea capaz de conservar la siguiente instrucción a ejecutar y el valor de sus variables locales tras desbloquearse. Es decir, el proceso no debe enterarse localmente\footnote{Las variables locales a la función deben mantenerse, pero puede haber variables globales que sí hayan cambiado.} de que nada haya cambiado mientras estaba bloqueado.
\end{definicion}
Notemos que debemos tener esta propiedad en el lenguaje de programación con el que trabajemos para poder hacer uso de funciones bloqueantes (como \verb|wait|) dentro de los procedimientos de un monitor, algo básico en el funcionamiento de este. Afortunadamente, actualmente todos los lenguajes de programación que encontramos en el mercado son reentrantes.\\

\subsubsection{Copias paramétricas de un monitor}
El siguiente ejemplo nos ilustra cómo podemos crear nuevos monitores a partir de uno ya creado, fijando parámetros que use el código de inicialización.

\begin{ejemplo}
    Aunque los monitores están pensados para programas concurrentes (ya que no tiene sentido su uso en programas secuenciales), usaremos en este ejemplo un monitor en un programa secuencial, ya que solo nos interesa la forma en la que los monitores inicializan sus variables permanentes\footnote{Además, no hemos terminado de desarrollar cómo es que solo puede ejecutarse a la vez un único procedimiento del monitor, por lo que no entendemos hasta ahora cómo es que sirven para sincronizar programas concurrentes.}.\\

    Tenemos un programa en el que necesitamos dos variables, las cuales queremos consultar e incrementar mediante un incremento previamente fijado que no cambiará. Para ello, creamos un monitor de acceso a una variable, con parámetros de entrada, para luego poder crear dos copias parametrizadas del mismo. El código del monitor será algo parecido a:
    \begin{minted}[escapeinside=\#\#]{pascal}
        class monitor VariableProtegida(inicio, incremento : integer);
          var x, inc : integer;

          procedure incremento();
          begin
            x = x + inc;
          end

          procedure valor(var v : integer);
          begin
            v = x;
          end
          
          begin
            x = inicio; inc = incremento;
          end
    \end{minted}
    De esta forma, podemos usar dos copias del monitor de la forma:
    \begin{minted}[escapeinside=\#\#]{pascal}
        var mv1 : VariableProtegida(0,1);   {empieza en 0 e incrementa en 1}
            mv2 : VariableProtegida(10,4);  {empieza en 10 e incrementa en 4}
            a, b : integer;
        begin
          mv1.incremento();  {+=1}
          mv1.valor(a);      {a=1}
          mv2.incremento();  {+=4}
          mv2.valor(b);      {b=14}
        end
    \end{minted}
\end{ejemplo}

\subsection{Exclusión mutua en los procedimientos de un monitor}
Si tenemos varios procesos del programa concurrente que quieren hacer uso de procedimientos del monitor a la vez, solo podremos dejar pasar un proceso al monitor (suponiendo que este se encuentre libre). Para los otros procesos, almacenaremos su llamada al procedimiento. 

Para ello, todos los monitores tienen implementada una cola con planificación FIFO, llamada \emph{cola de entrada al monitor}. Si tenemos dos procesos que quieren acceder a un procedimiento de un monitor libre, solo podrá hacerlo un proceso. La llamada al procedimiento del monitor del otro proceso quedará almacenada en la cola de entrada al monitor, y este pasará a ejecutar el procedimiento deseado una vez el proceso anterior haya dejado libre el monitor. 
\begin{observacion}
    En esta asignatura, supondremos que la cola de entrada al monitor es suficientemente larga como para albergar a todos los procesos que necesiten esperar a que el monitor quede libre.
\end{observacion}

Podemos representar la vida de un proceso de un programa concurrente que hace uso de monitores para sincronizar a sus procesos con el siguiente diagrama:
\begin{figure}[H]
\centering
\begin{tikzpicture}[node/.style={rectangle, draw, minimum size=1cm, align=center},
                    edge/.style={-stealth}]
    \node[node] (A) {Procedimiento\\terminado};
    \node[node, left =of A] (B) {\begin{tabular}{c}Ejecutando código\\del proceso\\(fuera del monitor)\end{tabular}};
    \node[node, left =of B] (C) {\begin{tabular}{c}Llamando a\\procedimiento\\del monitor\end{tabular}};
    \node[node, below =of C] (D) {\begin{tabular}{c}Esperando en\\cola de entrada\\al monitor\end{tabular}};
    \node[node, right =of D] (E) {\begin{tabular}{c}Monitor\\libre\end{tabular}};
    \node[node, right =of E, xshift=.6cm] (F) {\begin{tabular}{c}Ejecutando procedimiento\\(dentro del monitor)\end{tabular}};
    
    \draw[edge] (A) -- (B);
    \draw[edge] (B) -- (C);
    \draw[edge] (C) -- (D);
    \draw[edge] (D) -- (E);
    \draw[edge] (E) -- (F);
    \draw[edge] (F) -- (A);
\end{tikzpicture}
\caption{Vida de un proceso en un programa concurrente con monitores.}
\end{figure}

De esta forma, podemos ahora reescribir la descripción gráfica de monitor que hicimos en la tabla~\ref{esq:monitor_1}, incluyendo ahora la cola de entrada al monitor, tal y como vemos en la tabla~\ref{esq:monitor_2}
\begin{table}[H]
\centering
\begin{tabular}{|l|}
\hline
Cola del\\
monitor \\
\hline
Variables \\
permanentes \\
\hline
Procedimientos \\
exportados \\
\hline
Código de \\ 
inicialización \\
\hline
\end{tabular}
\caption{Esquema de un monitor incluyendo la cola de entrada.}
\label{esq:monitor_2}
\end{table}

\subsection{Operaciones de sincronización}
Las operaciones de sincronización entre los procesos de un programa concurrente se programan, como ya hemos visto, dentro de los procedimientos del monitor. Son instrucciones que permiten detener la ejecución de un procedimiento de un monitor y bloquear en una cola al proceso que ha hecho la llamada del procedimiento del monitor. Tenemos para realizar esta acción dos operaciones principales: \verb|wait| y \verb|signal|.\\

Sin embargo, las operaciones \verb|wait| y \verb|signal| que manejamos en monitores no se parecen a las que usábamos en los semáforos:
\begin{itemize}
    \item En los semáforos, la ejecución de \verb|wait| ofrecía la posibilidad de bloquear al proceso, ya que no lo hacía si el entero de dentro del semáforo era mayor estricto que $0$. Por contra, en monitores la llamada \verb|wait| siempre será bloqueante.
    \item Las operaciones \verb|wait| y \verb|signal| eran relativas a un semáforo: hacía falta usar un semáforo por cada razón que tuviéramos dentro de un programa concurrente para bloquear a uno o varios procesos (en el caso del productor/consumidor, usar dos semáforos). Sin embargo, con un solo monitor podremos bloquear procesos por tantas razones como queramos, usando un nuevo tipo de dato.
\end{itemize}

\subsubsection{Tipo de dato \texttt{cond}}
En los monitores, para poder usar las operaciones de \verb|wait| y \verb|signal|, será necesario utilizar una variable de tipo de dato condición, o \verb|cond|. 

Las variables tipo \verb|cond| se encuentran junto con las variables permanentes de un monitor. Estas no se inicializan a ningún valor.\\

En nuestro monitor, tendremos varias razones por las que queramos bloquear a los procesos concurrentes de nuestro programa por alguna determinada razón, hasta que se cumpla una condición determinada, a la que llamaremos \textit{condición de sincronización}. Por ejemplo, en el problema del productor/consumidor:
\begin{itemize}
    \item Queremos bloquear a cualquier productor que intente escribir si la estructura de datos intermedia que usamos está llena. Desbloquearemos a un proceso productor cuando se vacíe un hueco en dicha estructura.
    \item Además, queremos bloquear a cualquier consumidor que intente leer de la estructura de datos intermedia cuando esta esté vacía. Desbloquearemos a un consumidor cuando algún productor haya escrito algún dato.
\end{itemize}
Por cada razón o condición distinta por la que queramos bloquear a los procesos de un programa concurrente en relación a una misma variable compartida (para evitar estados inseguros), crearemos una variable de tipo \verb|cond|. Es decir, una variable por cada una de las razones por las que queramos que esperen los procesos. En el ejemplo del productor/consumidor, son necesarias únicamente dos variables de tipo \verb|cond|.\\

Las variables de tipo \verb|cond| admiten 4 métodos (aunque solo recomendamos usar los dos primeros):
\begin{description}
    \item [wait] Bloquea al proceso que ejecuta este método. Dicho proceso pasa a una cola asociada a la variable condición correspondiente con planificación FIFO\@.
    \item [signal] En caso de haber algún proceso bloqueado en la cola asociada a la variable condición correspondiente, lo desbloquea\footnote{Hemos de tener cuidado con esto, se explicará más adelante.}. Si esta cola está vacía, es equivalente a una operación nula\footnote{Esto es, equivalente a la instrucción \texttt{;}.}.
    \item [queue] Devuelve un booleano que indica (\verb|true|) si la cola asociada a la variable condición contiene al menos un proceso bloqueado.
    \item [signal\_all] Desbloquea de una sola vez a todos los procesos bloqueados en la cola asociada a la variable condición. El orden de dicha cola no se mantiene para realizar la petición de acceso al monitor, por lo que se produce competencia entre los procesos para entrar al monitor, incumpliendo la propiedad de equidad entre procesos. Depende de la semántica de las señales del lenguaje\footnote{Se explicará más adelante qué es esto.}. Se recomienda \textbf{no usarla}.
\end{description}
De esta forma, la representación gráfica final de un monitor es la que se muestra en la tabla~\ref{esq:monitor_3}:
\begin{table}[H]
\centering
\begin{tabular}{|l|}
\hline
Cola del\\
monitor \\
\hline
Variables \\
permanentes \\
\hline
Variables \\
condición y\\
colas de procesos\\
bloqueados\\
\hline
Procedimientos \\
exportados \\
\hline
Código de \\ 
inicialización \\
\hline
\end{tabular}
\caption{Esquema de un monitor incluyendo las variables condición.}
\label{esq:monitor_3}
\end{table}

\subsubsection{Semánticas de señales}
Como hemos comentado ya, los monitores solo permiten que un único proceso se encuentre ejecutando un procedimiento del mismo. En este caso, decíamos que el monitor está ocupado. En caso de que un proceso que estaba ejecutando el procedimiento ejecute un \verb|wait| (o salga del procedimiento), hay que dejar el monitor libre para dejar pasar a otro. Se trata de un momento muy delicado, ya que se pueden producir condiciones de carrera entre los procesos que quieran conseguir el monitor. Esta situación la hemos solucionado ya con la cola de entrada al monitor, ya que con la planificación FIFO, solo podrá entrar un único proceso al monitor.\\

Si ahora el proceso nuevo que ejecuta el monitor ejecuta un \verb|signal| sobre una variable condición (recordemos que tenemos al menos un proceso bloqueado), desbloqueará al primer proceso de su cola asociada, que estaba ejecutando código del monitor, por lo que ahora tenemos dos procesos ejecutando código del monitor: el proceso que señala y el señalado (el recién desbloqueado). Esta condición no puede darse, ya que los procedimientos de un monitor deben ejecutarse en exclusión mutua. Una solución a este problema es que el procedimiento que señala se bloquee en la cola de entrada al monitor\footnote{Veremos más soluciones.}, dejando paso al recién desbloqueado.

Esta solución plantea un problema, y es que si el proceso señalador se bloquea, puede que en algún momento deje al monitor libre, por lo que se meta un proceso de la cola de entrada al monitor, planteando nuevamente la situación en la que tenemos dos procesos en el monitor (el desbloqueado y el primero que estaba esperando entrar al monitor). Deberá haber un mecanismo que elija quién de los dos acaba finalmente con el monitor. En caso de que sea el proceso que estaba esperando en la cola de entrada, diremos que se produce un \emph{robo de señal}, donde el proceso recién desbloqueado debe irse al final de la cola de entrada al monitor.\\

Para solucionar este segundo problema, algunos lenguajes implementan una \emph{semántica desplazante}\footnote{Se trabajará más adelante sobre las semánticas de las señales.} en las señales: el proceso que ejecuta el \verb|signal| le pasa el monitor al proceso que recibió la señal (el primero en la cola de bloqueados de la variable condición correspondiente), sin liberar en ningún momento el monitor, de forma que el proceso señalado tiene prioridad. Se dice que la señal usada con la operación \verb|signal| tiene \emph{semántica desplazante}.\\

Cabe destacar que \textbf{no todos los lenguajes con monitores tienen señales con semántica desplazante}, por lo que en dichos lenguajes pueden sucederse robos de señales. En esta sección y en la siguiente, supondremos que estaremos trabajando siempre con señales \verb|signal| con semántica desplazante, de forma que el proceso señalador se bloqueará tras ejecutar un \verb|signal| y podemos pensar que es enviado a la cola de entrada al monitor. En una futura sección veremos los tipos de semánticas de señales que podemos encontrarnos (cada uno hará que el comportamiento de \verb|signal| sea distinto).\\

\noindent
Como comentario final a la descripción de un monitor y para motivar la siguiente sección:
\begin{itemize}
    \item Se presupone que el programador de monitores es un programador experto, de forma que el compilador en ningún momento se dedicará a comprobar si hemos programado de forma correcta un monitor o un procedimiento de él, más allá de la sintaxis del código.
    \item No deben programarse operaciones \verb|wait| indebidas ni omitirse operaciones \verb|signal| innecesarias. Para comprobar esto, usaremos nuestro sistema de verificación formal.
\end{itemize}

\section{Verificación de programas con monitores}
En la verificación de los programas concurrentes que hemos manejado hasta ahora, hemos primero demostrado la corrección secuencial de cada proceso que forma parte de un programa secuencial, para luego demostrar la no interferencia entre los mismos. 

Sin embargo, ahora que introducimos los monitores, esto no podrá ser nunca más así, ya que un programador nunca puede conocer a priori la traza que genera un proceso que forma parte de un programa concurrente con monitores, ya que al ejecutar procedimientos de monitores, estos pueden quedar bloqueados y se ejecutarían en medio instrucciones de otros procesos que podrían alterar las variables compartidas del programa, falseando alguna precondición o poscondición del proceso bloqueado, por lo que tras desbloquearse, no podemos esperar nada de dicho proceso.\\

Es por tanto que ahora la estrategia a seguir en las demostraciones es mediante un Invariante de Monitor.

\subsection{Invariante de monitor}
\begin{definicion}[Invariante de Monitor]
    Un Invariante de Monitor (IM) es una relación entre las variables permanentes de un monitor que debe ser cierta en cualquier estado del programa concurrente, excepto cuando un proceso esté ejecutando código de un procedimiento del monitor.
\end{definicion}
De esta forma, un IM puede no ser cierto durante la ejecución de un procedimiento por parte de un proceso, pero este ha de cumplirse antes y después de la ejecución de dicho procedimiento.\\

Si conseguimos probar la existencia de un IM en un programa concurrente, entonces bastará con probar cada una de las secciones de código secuenciales entre llamadas a procedimientos del monitor. Para probar finalmente la corrección de los procesos, usaremos que los IM se mantienen antes y después de las llamadas a procedimientos, para conseguir probar finalmente la corrección de cada uno de los procesos. Si nuestro IM estaba relacionado con la solución al problema, como el acceso a variables compartidas estará controlado por los monitores, al final del programa todos los IMs demostrados se seguirán compliendo, por lo que tendremos probada la corrección de nuestro programa concurrente.

Es decir, primero demostraremos que por cada monitor que usamos se verifica un IM, y luego pasaremos a probar la corrección de cada proceso que interviene en el programa concurrente, usando para ello dichos IMs. Finamente, tendremos probado el programa concurrente.

\subsubsection{Esquema de demostración}
Suponiendo que hemos encontrado una relación matemática entre las variables permanentes de un monitor y queremos probar que se trata de un IM\footnote{A continuación, llamaremos a dicha condición \texttt{IM}, pese a no haber demostrado aún que se trate de verdad de un IM.}, lo primero será probar que $IM$ se cumple en el estado inicial del monitor, esto es, justo después de la inicialización de las variables permanentes, por lo que tendremos que probar que se verifica el \textbf{triple de inicialización de variables}:
\begin{equation*}
    \{V\}\ \text{código de inicialización}\ \{IM\}
\end{equation*}
Posteriormente, deberemos probar que $IM$ se mantiene antes y después de la llamada a cada procedimiento. Es decir, notando por $IN$ a las precondiciones que tenemos antes de la ejecución de un procedimiento y por $OUT$ a las poscondiciones que deseamos tener tras dicho procedimiento, debemos demostrar los \textbf{triples de procedimientos del monitor}, es decir, demostrar un triple
\begin{equation*}
    \{IM \land IN\}\ \text{procedimiento}\ \{IM \land OUT\}
\end{equation*}
por cada procedimiento que tenga nuestro monitor.

\subsubsection{Cuidado con las intereferencias}
Terminaremos de ver esto más adelante, pero es necesario darnos cuenta de un detalle, y es que si un procedimiento modifica el valor de alguna variable compartida que se usa en otro proceso, debemos demostrar la no interferencia entre dichas instrucciones. Ilustramos esto con el siguiente ejemplo.
\begin{ejemplo}
    Si tenemos un monitor llamado \verb|Buf| con un procedimientos \verb|retirar(x)|, de forma que modifica el valor del parámetro que le pasamos, ante el siguiente código (si \verb|x| es una variable compartida):
    \begin{minted}[escapeinside=\#\#]{pascal}
        cobegin y = x; #||# Buf.retirar(x); coend
    \end{minted}
    Tenemos que probar que al cambiar el valor de \verb|x| con el procedimiento \verb|retirar|, no hay interferencia con la instrucción de la izquierda. Es decir, tenemos que probar:
    \begin{align*}
        &NI(pre(y=x), Buf.retirar(x)) \\
        &NI(pos(y=x), Buf.retirar(x))
    \end{align*}
    Sin embargo, en caso de ejecutar el siguiente código:
    \begin{minted}[escapeinside=\#\#]{pascal}
        z = x;
        cobegin y=z; #||# Buf.retirar(x); coend
    \end{minted}
    No tendríamos que hacerlo, ya que el uso de variables disjuntas nos garantiza la no interferencia entre dichas instrucciones.
\end{ejemplo}

\subsection{Axiomas para operaciones de sincronización desplazantes}\label{sec:ax_desplazantes}
Sabemos ya demostrar toda la corrección de un programa secuencial que usa monitores, salvo por un detalle, y es que no sabemos nada sobre cómo demostrar los triples:
\begin{align*}
    \{P\}\ &c.wait();\ \{Q\} \\
    \{P\}\ &c.signal();\ \{Q\}
\end{align*}
para cualesquiera asertos $P$ y $Q$.

En esta subsección, trataremos de dar axiomas para la comprobación de dichos triples, razonándolos de forma intuitiva y mediante el uso de Invariantes de Monitores.\\

\subsubsection{Axioma de operación \texttt{wait}}
Comenzaremos primero con el triple $\{P\}\ c.wait();\ \{Q\}$. Para necesitar ejecutar una instrucción \verb|wait| en un procedimiento de un monitor, lo que sucede es que estamos cerca de un estado inseguro del programa (intuitivamente, que $IM$ está a punto de incumplirse), pero no llegamos a él, porque para ello ejecutamos esta operación, para impedir que el proceso ejecute una instrucción que falsee el $IM$. Por tanto, el proceso se bloquea, dejando libre el monitor, por lo que entra otro proceso a ejecutar otro procedimiento. 

Solo podremos desbloquear al proceso cuando nos alejemos de dicho estado inseguro, por lo que además de cumplirse el $IM$, deberá cumplirse una condición un tanto más estricta que el $IM$ (que nos indique que estamos lejos de aquel estado inseguro por el cual se bloqueó el proceso). Dicha condición recibe el nombre de \textit{condición de sincronización}, y la notaremos por $C$\footnote{Notemos que según hemos definido $C$, ha de verificarse que $IM\rightarrow C$.}. 

Resumiendo:
\begin{itemize}
    \item Antes de ejecutar la operación \verb|wait|, hemos de estar en un estado seguro del programa, por lo que ha de cumplirse el $IM$.
    \item Tras ejecutar la operación \verb|wait| (es decir, después de que el proceso haya sido desbloqueado), ha de cumplirse la condición de sincronización $C$.
\end{itemize}
Teniendo en cuenta que además se puede cumplir un invariante local al que llamamos $L$ (esto es, relaciones entre variables locales del procedimiento del monitor) antes y después\footnote{Gracias a que estamos en lenguajes reentrantes.} de dicha instrucción \verb|wait|.

De esta forma, acabamos de razonar de forma intuitiva el \textbf{Axioma de la operación wait}:
\begin{equation*}
    \{IM \land L\}\ c.wait();\ \{C \land L\}
\end{equation*}

\subsubsection{Axioma de operación \texttt{signal}}
Si nos disponemos a ejecutar una instrucción \verb|signal| en nuestro código, es porque el estado del programa se ha alejado de la condición insegura de la que hablábamos en la subsección anterior, que falsearía el valor de verdad de $IM$. Por tanto, el programa ha llegado a un punto en el que se cumple la condición de sincronización $C$, y ya puede desbloquear al proceso que anteriormente bloqueó. Tras su desbloqueo, este proceso podría ejecutar una instrucción que volviera a acercarnos a un estado inseguro, pero sin llegar a él (ya que $C$ era suficientemente restrictiva), por lo que como poscondición de la instrucción \verb|signal| no podremos garantizar $C$, sino solo podremos asegurar que se sigue cumpliendo $IM$.

Añadiendo la posibilidad de tener un invariante local $L$ y que si la cola de la variable condición está vacía, la operación \verb|signal| es una instrucción nula, llegamos al \textbf{Axioma de la operación signal}:
\begin{equation*}
    \{\lnot vacio(c) \land C \land L\}\ c.signal();\ \{IM \land L\}
\end{equation*}

o equivalentemente:
\begin{equation*}
    \{c.queue() \land C \land L\}\ c.signal();\ \{IM \land L\}
\end{equation*}
En caso de cumplirse que $c.queue() = false$, entonces negaría la precondición del triple, haciéndolo la regla cierta por un razonamiento por vacuidad.\\

\begin{observacion}
    Notemos que el axioma de la operación \verb|signal| funciona porque hemos suspuesto que \textbf{tenemos semántica desplazante}, ya que después de ejecutar \verb|signal| desbloqueamos al proceso que teníamos bloqueado, cediéndole el monitor, por lo que dicho proceso seguirá procesando su procedimiento. Cuando el proceso señalador vuelva al monitor, solo podremos garantizar que se cumple $IM$, ya que tanto el proceso señalado como cualquier otro que se introduzca en el monitor después del señalado (veremos más adelante si esto es posible), pueden cambiar la condición $C$, por lo que solo podemos esperar $IM$.
\end{observacion}~\\

Una vez vistos ya todos los axiomas sobre verificación de operaciones de sincronización de monitores, estamos listos para desmotrar la corrección de un $IM$. Lo haremos en el siguiente ejemplo.

\begin{ejemplo}
    En este ejemplo, queremos programar un monitor que simule el funcionamiento de un semáforo. Para ello, se nos ha ocurrido el siguiente código:
    \begin{minted}[escapeinside=\#\#]{pascal}
        Monitor Semaforo;
          var s : integer;
              c : cond;

          procedure P;
          begin
            if s=0 then
              c.wait;
            else
              null;
            end if
            s = s - 1;
          end

          procedure V;
          begin
            s = s + 1;
            c.signal;
          end

          begin   {código de inicialización}
            s = 0;
          end
    \end{minted}
    Donde hemos llamado \verb|P| a la función \verb|sem_wait| del semáforo y por \verb|V| a la función \verb|sem_signal|.\\

    Procedemos a realizar la demostración de que existe un Invariante de Monitor que se mantiene tras la inicialización de las variables permanentes de nuestro monitor y antes y después de cada procedimiento, con la finalidad de poder usar dicho IM en las demostraciones de cualquier programa concurrente que use el semáforo que acabamos de implementar mediante un monitor.
    \begin{proof}
        Tratamos de demostrar que este monitor tiene como IM el aserto
        \begin{equation*}
            IM \equiv \{s \geq 0\}
        \end{equation*}

        \begin{enumerate}
            \item Primero, tenemos que demostrar el triple de inicialización de variables:
                \begin{equation*}
                    \{V\}\ s=0;\ \{s\geq 0\}
                \end{equation*}
                Como el triple $\{V\}\ s=0;\ \{s=0\}$ es cierto por el axioma de asignación y tenemos que $\{s=0\}\rightarrow\{s\geq 0\}$, usando la primera regla de la consecuencia tenemos demostrado el triple.
            \item Posteriormente, demostraremos el triple de procedimiento del monitor para el procedimiento \verb|P|: $\{IM\}\ P\ \{IM\}$. Para ello, primero tendremos que probar el triple
                \begin{equation*}
                    \{IM\}\ \texttt{if\ }s=0\texttt{\ then\ }c.wait;\texttt{\ else\ }null;\texttt{\ end if}\ \{s>0\}
                \end{equation*}
                Luego usaremos la regla del \verb|if|, por lo que será suficiente con probar los triples:
                \begin{gather*}
                    \{IM \land s=0\}\ c.wait;\ \{s>0\} \\
                    \{IM \land s\neq0\}\ null;\ \{s>0\}
                \end{gather*}
                \begin{enumerate}
                    \item Comenzamos por el segundo, por ser más sencillo. Tenemos:
                        \begin{equation*}
                            {\{IM \land s\neq0\} \equiv \{s\geq 0 \land s\neq0\}\equiv \{s>0\}}
                        \end{equation*}
                        Por tanto, basta probar el triple ${\{s>0\}\ null;\ \{s>0\}}$, que es cierto por el axioma de la sentencia nula.
                    \item Para el primer triple, buscamos aplicar el axioma de la operación \verb|wait|, por lo que tenemos que buscar la condición de sincronización. Para ello, buscamos la precondición del \verb|signal| asociado a la misma variable condición, que se encuentra en el procedimiento \verb|V|. Para hallar la precondición de la instrucción \verb|c.signal|, tendremos que demostrar alguna instrucción de dicho procedimiento, con el fin de hallar la precondición.

                        Sobre el código de \verb|V|, vemos que antes de \verb|c.signal| se ejecuta una primera instrucción \verb|s=s+1;|. Suponemos que \verb|V| tiene como precondición $IM$, por lo que buscamos una poscondición para \verb|s=s+1;|:
                        \begin{equation*}
                            \{IM\}\equiv \{s\geq 0\}\ s=s+1;
                        \end{equation*}
                        Puede comprobarse con el axioma de asignación que la poscondición buscada es $\{s>0\}$. Por tanto, esta será la condición de sincronización de la variable condición \verb|c|:
                        \begin{equation*}
                            C \equiv \{s>0\}
                        \end{equation*}
                        Por tanto, por el axioma de la operación \verb|wait| usado con $L=\{V\}$, tenemos que el siguiente triple es cierto:
                        \begin{equation*}
                            \{IM\}\ c.wait;\ \{s>0\}
                        \end{equation*}
                        Como $\{IM \land s=0\}\to \{IM\}$, por la segunda regla de la consecuencia, tenemos demostrado el triple que buscábamos.
                \end{enumerate}
                Una vez demostrados los dos triples, tenemos probado el triple del \verb|if|, por lo que solo faltará probar el triple 
                \begin{equation*}
                    \{s>0\}\ s=s-1;\ \{IM\}
                \end{equation*}
                Para tener probado el triple del procedimiento \verb|P|.

                Como $\{IM\} \equiv \{s\geq 0\}$, basta aplicar el axioma de asignación, para obtener $\{s>0\}\ s=s-1;\ \{s\geq 0\}$.

                Aplicando finalmente la regla de composición sobre el triple del \verb|if| y este último triple, tenemos ya probado $\{IM\}\ P\ \{IM\}$.

            \item Finalmete, hemos de probar el triple $\{IM\}\ V\ \{IM\}$ para garantizar al fin que $IM$ es un IM\@. Para ello, hemos de probar el triple
                \begin{equation*}
                    \{IM\}\ s=s+1; c.signal;\ \{IM\}
                \end{equation*}
                Basta con probar los triples
                \begin{gather*}
                    \{IM\}\ s=s+1;\ \{s>0\} \\
                    \{s>0\}\ c.signal;\ \{IM\}
                \end{gather*}
                y aplicar la regla de composición. El primer triple ya lo demostramos en la demostración del triple del procedimiento \verb|P|, luego bastará probar el segundo, el cual es cierto gracias al axioma de la operación \verb|signal|.

                Acabamos de probar que $\{IM\}\ V\ \{IM\}$, que era el último procedimiento del monitor, luego $IM$ es un IM\@.
        \end{enumerate}
    \end{proof}
\end{ejemplo}

\begin{ejercicio*}
    Se pide demostrar que el siguiente monitor funciona como un semáforo de Habermann. Un semáforo de Habermann se trata de un semáforo normal que lleva la cuenta de:
    \begin{itemize}
        \item El número de llamadas realizadas a \verb|signal|, \verb|nv|.
        \item El número de llamadas realizadas a \verb|wait|, \verb|na|.
        \item El número de llamadas completadas a \verb|wait|, \verb|np|.
    \end{itemize}
    En este caso, llamaremos \verb|P| al procedimiento que simule la operación \verb|wait| y \verb|V| al procedimiento que simule la operación \verb|signal|.
    
    \begin{minted}[escapeinside=\#\#]{pascal}
        Monitor Semaforo;
          var na, np, nv : int;
              c : cond;

          procedure P;
          begin
            na = na + 1;
            if(na > nv) then c.wait();
            np = np + 1;
          end

          procedure V;
          begin
            nv = nv + 1;
            if(na > np) then c.signal();
          end

          begin
            na = 0; np = 0; nv = 0;
          end
    \end{minted}
    Buscamos un IM para preceder a la demostración del mismo. Notemos que las variables permanentes han de cumplir:
    \begin{itemize}
        \item $np \leq na$, ya que para completar una llamada \verb|P| hay que realizar una llamada.
        \item $np \leq nv$, ya que, como inicialmente $np = na = nv = 0$, para poder completar una llamada a \verb|P|, hay que previamente haber hecho una llamada a \verb|V|.
        \item $np \geq \min(na,nv)$, para no detener innecesariamente a los preocesos, cumpliendo la hipótesis de proceso finito.
    \end{itemize}
    De estas tres propiedades, deducimos que el invariante a usar es:
    \begin{equation*}
        \{IM\} \equiv \{np = \min(na,nv)\}
    \end{equation*}
    Pasemos ahora a la demostración del monitor:
    \begin{enumerate}
        \item En primer lugar, probaremos el triple de inicialización de variables:
            \begin{gather*}
                \{V\} \\
                na = 0;\ np=0;\ nv=0; \\
                \{na = 0 \land np = 0 \land nv = 0\} \rightarrow \{IM\}
            \end{gather*}
        \item Posteriormente, probaremos el triple del procedimiento \verb|P|:
            \begin{equation*}
                \{IM \land L\}\ P\ \{C \land L\}
            \end{equation*}

            para ello:
            \begin{gather*}
                \{IM\}\equiv \{np=\min(na,nv)\} \\
                na = na + 1;\\
                \{np = \min(na-1,nv)\} \\
                \texttt{if\ }(na > nv) \texttt{\ then\ } \\
                \{na > nv \land np = \min(na-1,nv)\} \rightarrow \{na-1\geq nv \land np = \min(na-1,nv)\} \rightarrow \\ 
                \rightarrow\{np = nv\} \rightarrow \{np = \min(na,nv)\} \\
                c.wait();
            \end{gather*}
            Donde en la precondición de la operación \verb|c.wait();| hemos necesitado comprobar que $IM$ se seguía compliendo.

            Y para poder seguir, hemos de buscar la precondición de la operación \verb|c.signal();| asociada a la misma variable condición, con lo que comenzamos a demostrar el procedimiento \verb|V|:
            \begin{gather*}
                \{IM\} \equiv \{np = \min(na,nv)\} \\
                nv = nv + 1; \\
                \{np = \min(na,nv-1)\} \\
                \texttt{if\ } (na > np) \texttt{\ then\ } \\
                \{na > np \land np = \min(na,nv-1)\} \rightarrow \{na > np \land np = nv-1\}
            \end{gather*}
            Luego tenemos ya la poscondición de la operación \verb|c.wait();|, con lo que podemos volver por donde íbamos:
            \begin{gather*}
                \{IM\} \equiv \{np = \min(na,nv)\} \\
                na = na + 1;\\
                \{np = \min(na-1,nv)\} \\
                \texttt{if\ }(na > nv) \texttt{\ then\ } \\
                \{na > nv \land np = \min(na-1,nv)\} \rightarrow \{na-1\geq nv \land np = \min(na-1,nv)\} \rightarrow \\ 
                \rightarrow\{np = nv\} \rightarrow \{np = \min(na,nv)\} \\
                c.wait(); \\
                \{na > np \land np = nv - 1\} \\
                \texttt{else do} \\
                \{na \leq nv \land np = \min(na-1,nv)\} \rightarrow \{na-1 < nv \land np = \min(na-1,nv)\} \rightarrow \\
                \rightarrow \{na-1 < nv \land np = na-1\} \rightarrow \{np < nv \land np = na-1\} \\
                \texttt{null;} \\
                \{np < nv \land np = na -1\} \\
                \texttt{endif}
            \end{gather*}
            Como las poscondiciones de cada bloque del \verb|if| son distintas, debemos relajarlas para buscar dos poscondiciones iguales, para poder aplicar la regla del \verb|if|. Notemos que:
            \begin{gather*}
                \{na > np \land np = nv-1\} \rightarrow \{na > nv-1 \land np = nv-1\} \rightarrow \\ \rightarrow \{na \geq nv \land np = nv - 1\} \\
                \{np < nv \land np = na-1\} \rightarrow \{na-1 < nv \land np = na-1\} \rightarrow\\\rightarrow \{na \leq nv \land np = na-1\}
            \end{gather*}
            Podemos por tanto, relajar ambas poscondiciones a la poscondición
            \begin{equation*}
                \{np+1 = \min(na,nv)\}
            \end{equation*}
            Con lo que ahora sí podemos aplicar la regla del \verb|if|, con lo que podemos finalizar la demostración del triple del procedimiento \verb|P|:
            \begin{gather*}
                \{IM\} \equiv \{np = \min(na,nv)\} \\
                na = na + 1;\\
                \{np = \min(na-1,nv)\} \\
                \texttt{if\ }(na > nv) \texttt{\ then\ } \\
                \{np = \min(na,nv)\} \\
                c.wait(); \\
                \{np+1 = \min(na,nv)\} \\
                \texttt{else do} \\
                \{np+1 = \min(na,nv)\} \\
                \texttt{null;} \\
                \{np+1 = \min(na,nv)\} \\
                \texttt{endif} \\
                \{np+1 = \min(na,nv)\} \\
                np = np + 1; \\
                \{np = \min(na,nv)\} \equiv \{IM\}
            \end{gather*}
        \item Para probar ahora el triple del procedimiento \verb|V|:
            \begin{gather*}
                \{IM\} \equiv \{np = \min(na,nv)\} \\
                nv = nv + 1; \\
                \{np = \min(na,nv-1)\} \\
                \texttt{if\ } (na > np) \texttt{\ then\ } \\
                \{na > np \land np = \min(na,nv-1)\} \rightarrow \{na > np \land np = nv-1\}\\
                c.signal(); \\
                \{np = \min(na,nv)\} \\
                \texttt{else do} \\
                \{na \leq np \land np = \min(na,nv-1)\}\rightarrow\{np = na\} \rightarrow \{np = \min(na,nv)\} \\
                \texttt{null;} \\
                \{np = \min(na,nv)\} \\
                \texttt{endif} \\
                \{np = \min(na,nv)\} \equiv \{IM\}
            \end{gather*}
    \end{enumerate}
    Con lo que tenemos provado que $IM$ es un IM\@.
\end{ejercicio*}

\subsection{Regla de concurrencia para programas con monitores}
Consideramos un programa concurrente en el que tenemos $n$ procesos ejecutándose que podemos representar como triples de Hoare ciertos $\{P_i\}\ S_i\ \{Q_i\}$ con \newline $i \in \{1, \ldots, n\}$ de forma que ninguna variable en $P_i$ o en $Q_i$ es modificada por ningún $S_j$ con $i\neq j$. Si en dicho código tenemos $m$ monitores de forma que para cada uno hemos conseguido probar un IM, $IM_k$ con $1 \leq k \leq m$, entonces podemos aplicar la \textbf{regla de concurrencia para programas con monitores}:
\begin{equation*}
    \dfrac{\{P_i\}\ S_i\ \{Q_i\} \quad 1 \leq i \leq n}{\begin{array}{c}
            \{MI_1 \land \ldots \land MI_m \land P_1 \land \ldots\land P_n\} \\
            cobegin\ S_1\ ||\ S_2\ ||\ \ldots\ ||\ S_n\ coend \\
            \{MI_1 \land \ldots \land MI_m \land Q_1 \land  \ldots\land Q_n\} 
        \end{array}}
\end{equation*}
Obteniendo así la verificación de nuestro programa concurrente.

\section{Patrones de uso de un monitor}
Al programar programas concurrentes que nos resuelvan un problema, encontramos muchas veces ciertos pequeños problemas a resolver que se repiten a menudo. En esta sección, destacamos tres de estos problemas, describiéndolos, planteando una solución mediante un monitor a utilizar en ellos y demostrando que el monitor realiza el funcionamiento esperado.

\subsection{Espera única}
Puede suceder que en un programa concurrente queramos que un proceso espere a que otro proceso haya realizado una cierta acción para seguir con su ejecución. Llamaremos al proceso que tiene que esperar al otro \textit{consumidor} y a dicho otro \textit{productor}.\\

El problema se resuelve de forma muy sencilla, con una variable compartida que indique si el productor ha realizado ya su acción por la que el consumidor debe esperar o si no lo ha hecho todavía. Cuando el consumidor se acerque a la zona en la que debe esperar al productor, consultará la variable compartida y en caso de que esta indique que no se ha realizado la acción, bloquearemos al proceso. Si se ha realizado la acción, no haremos nada.

Además, cuando el productor haya realizado la acción que ha de realizar, cambiaremos el valor de dicha variable compartida, indicando que ya se ha realizado la acción. En caso de que el consumidor se haya bloqueado antes de realizar la acción, lo desbloquearemos.\\

Observemos que estamos haciendo uso de una variable compartida, que es modificada por un proceso. Debemos por tanto acceder a ella en exclusión mutua. Esto es garantizado por el uso del monitor.

\subsubsection{Monitor a usar}
El monitor que usaremos tendrá dos procedimentos exportables, uno llamado \verb|esperar| que será el que use el proceso consumidor, y otro llamado \verb|notificar|, que será el que use el proceso productor para avisar al consumidor de que ya ha realizado la acción.

De esta forma, podemos ver el código monitor en pseudo código:
\begin{minted}[escapeinside=\#\#]{pascal}
    monitor EU;
    var terminado : boolean;  {si terminado = true, se ha realizado la acción}

        {variable auxiliar para la demostracion}
        autorizado : boolean; {si autorizado = true, consumidor puede ejecutarse}

        c : cond;

       procedure esperar(); begin
          if (not terminado) then
             c.wait();
          autorizado = true;
       end

       procedure notificar(); begin
          terminado = true; 
          c.signal();
       end

       begin {codigo de inicializacion}
          terminado = false; autorizado = false;
       end
\end{minted}
% // TODO: Capel incorpora un procedimiento terminar que hace lo mismo que el codigo de inicializacion, no se por qué.

Para su demostración, usaremos el invariante
\begin{equation*}
    \{IM\} \equiv \{terminado = false \Longrightarrow autorizado = false\}
\end{equation*}
La demostración se deja como ejercicio al lector.
% // TODO: Hacer la demostración y quitar lo de que se deja como ejercicio

\subsection{Exclusión mutua}
Es muy habitual que en programas concurrentes tengamos una o varias regiones de código que queramos que se ejecuten en exclusión mutua, llamadas secciones críticas. Es decir, mientras que un proceso se encuentre ejecutando una sección crítica, ningún otro proceso podrá estar ejecutando a la vez la misma sección crítica\footnote{Podemos tener dos secciones críticas con distintos códigos pero que sean referidas al acceso para la misma variable compartida. En dicho caso, pensamos que las secciones críticas son iguales, ya que solo puede haber un proceso que ejecute una u otra a la vez.}.\\

Usualmente, querremos tener exclusiones mutuas cuando varios procesos de un programa hagan uso de un recurso compartido, tal como una variable compartida, una salida a un fichero o imprimir información en un entorno gráfico.

\subsubsection{Monitor a usar}
El monitor que resuelve el problema de la exclusión mutua tendrá dos procedimientos exportables, \verb|entrar|, que se ejecutará antes de cualquier sección crítica, y \verb|salir|, que se ejecutará al final de cada sección crítica.

De esta forma, tenemos el monitor:
\begin{minted}[escapeinside=\#\#]{pascal}
    monitor EM;
    var ocupada : boolean;  {ocuapda = true si hay un proceso en seccion critica}
        cola : cond;

       procedure entrar(); begin
          if ocupada then
             cola.wait();
          ocupada = true;
       end

       procedure salir(); begin
          ocupada = false;
          cola.signal();
       end

       begin
          ocupada = false;
       end
\end{minted}
Para demostrarlo, primero definiremos la variable $num_{sc}$ como el número de procesos que se encuentran ejecutando la sección crítica. Una vez definido, el invariante a usar será
\begin{equation*}
    \{IM\} \equiv \{(ocupada = false \Longleftrightarrow num_{sc} = 0) \land 0\leq num_{sc} \leq 1\}
\end{equation*}
La demostración se deja como ejercicio al lector.
% // TODO: Hacer la demostración y quitar lo de que se deja como ejercicio

\subsection{Productores/Consumidores}
Volvemos otra vez al paradigma del productor/consumidor, el cual hemos explicado varias veces ya en este documento. Ahora, admitiremos la existencia de varios procesos productores que querrán generar datos y escribirlos en una variable compartida, así como varios consumidores, que querrán leer dicha variable compartida y realizar los cálculos pertinentes.

\subsubsection{Monitor a usar}
Usaremos un monitor con dos procedimientos: \verb|escribir|, que permitirá escribir en la variable compartida el valor indicado, y \verb|leer|, que permitirá leer el valor de la variable compartida. La ventaja de usar un monitor es que los códigos de sincronización solo los tenemos que realizar en el monitor, dejando limpios los códigos de los procesos.

Como tenemos dos condiciones de sincronización, bloquear a productores que quieran escribir en una variable que no se ha leído, o bloquear a consumidores que quieran leer de una variable cuyo valor ya ha sido leído, necesitaremos dos variables de tipo \verb|cond|:
\begin{minted}[escapeinside=\#\#]{pascal}
    monitor PC;
    var valor : integer;  {variable compartida a usar}
        pendiente : boolean;  {si pendiente = true, valor escrito y no leido}
        cola_prod, cola_cons : cond;

       procedure escribir(v : integer); begin
          if pendiente then
             cola_prod.wait();
          valor = v;
          pendiente = true;
          cola_cons.signal();
       end

       procedure leer() : integer; begin
          if (not pendiente) then
             cola_cons.wait();
          result = valor;
          pendiente = false;
          cola_prod.signal();
       end

       begin
          pendiente = false;
       end
\end{minted}
Para la demostración, debemos definir primero:
\begin{align*}
    E &= \text{\ número\ de\ llamadas\ a\ escribir\ \textbf{completadas}.} \\
    L &= \text{\ número\ de\ llamadas\ a\ leer\ \textbf{completadas}.} \\
\end{align*}
De esta forma, podemos definir el invariante
\begin{gather*}
    \{IM\} \equiv 
    \left\{E-L = \left\{\begin{array}{rl}
                0 & \text{\ si\ } pendiente = false \\
                1 & \text{\ si\ } pendiente = true \\
    \end{array}\right\}\right\} \equiv  \\
    \equiv \{(pendiente = false \land E-L=0) \lor (pendiente = true \land E-L=1)\}
\end{gather*}
La demostración se deja como ejercicio para el lector.
% // TODO: Hacer la demostración y quitar lo de que se deja como ejercicio

Asímismo, notemos que la demostración es similar a la del monitor para exclusión mutua, teniendo en cuenta que:
\begin{align*}
    E - L &= num_{sc} \\
    pendiente &= \lnot libre
\end{align*}

\begin{ejercicio*}
    Si ahora los productores no escriben sobre una misma variable compartida sino sobre un buffer (por ejemplo, un array con planificación FIFO), plantear un monitor que solucione el problema de los productores/consumidores, así como desmostrar que dicho monitor funciona correctamente.\newline
    (\textbf{Pista:} para la demostración, sustituir en el IM ``1'' por el tamaño del buffer)
\end{ejercicio*}

\section{Semánticas de señales}
Como comentamos ya al inicio del Capítulo, las operaciones \verb|signal| de las variables condición son operaciones delicadas, ya que son ejecutadas por un proceso que se encuentra ejecutando algún procedimiento del monitor y que lo que hacen es desbloquear a algún proceso se que se encontraba ejecutando código del monitor, por lo que (si no hacemos nada), tendremos dos procesos distintos ejecutando a la vez procedimientos (podría ser el mismo procedimiento) de un mismo monitor, algo que no puede darse.\\

Para solucionar el problema que nos plantea la operación \verb|signal|, plantearemos distintas \textit{semánticas de señales} \verb|signal|. Esto es, plantearemos varios paradigmas en los que la señal \verb|signal| tendrá un significado u otro, de forma que su finalidad sea siempre \textit{sacar al primero proceso de la cola de la variable condición} en cuestión y ponerlo en otro sitio que permita que dicho proceso entre al monitor en algún futuro próximo, garantizando la propiedad de vivacidad de que dicho proceso en algún momento volverá a entrar al monitor.\\

Además, clasificaremos los distintos tipos de semánticas de señales que veremos en \textbf{no desplazantes} y \textbf{desplazantes}.

\begin{definicion}
    Diremos que \textbf{una semántica de señal es desplazante} si, siempre que un proceso ejecute una operación \verb|signal| sobre una variable condición \verb|c|, en dicho instante cederá el monitor al primer proceso de la cola de bloqueados de la variable condición \verb|c| sin que el monitor quede libre en ningún momento\footnote{Evitando que entre al monitor cualquier otro proceos de la cola de entrada al monitor.}. Además, debe garantizarse la propiedad de vivacidad de que el proceso señalador volverá a entrar al monitor en algún momento.
\end{definicion}

Veremos ahora todas las posibles semánticas de señales que podemos encontrarnos, entendienod que el proceso \textit{señalador} es aquel que ejecuta la operación \verb|signal| sobre una variable condición; y que el proceso \textit{señalado} es aquel que estaba primero en la cola de bloqueados de la misma variable condición.

\subsection{Señalar y Continuar (SC)}
El proceso señalador no se bloquea tras ejecutar \verb|signal|, sino que sigue con la ejecución del procedimiento en cuestión. El proceso señalado se bloquea hasta que se pueda adquirir de nuevo el monitor.\\

Como podemos ver, se trata de una semántica no desplazante, ya que el proceso señalador no se bloquea tras ejecutar la instrucción \verb|signal|. En relación al proceso señalado, se produce una \textit{competición} contra el resto de procesos que esperan en la cola de entrada al monitor. Esta ``competición'' que hemos mencionado depende de la implementación que se haga, destacando dos posibilidades:
\begin{enumerate}
    \item El proceso señalado pasa al final de la cola de entrada al monitor.
    \item Después de que el proceso señalador deje libre el monitor (ya sea porque termina el procedimiento o se bloquea debido a una instrucción \verb|wait|), se desbloquea al proceso señalado y al primero de la cola de entrada al monitor, se sucede una condición de carrera entre ambos y el vencedor (el que primero llega al monitor), acaba ejecutándolo. El perdedor acaba al final de la cola de entrada al monitor.

        Como podemos entender, la primera opción es mejor, ya que en la segunda puede suceder que un proceso pierda varias veces la competición por el monitor, incumpliendo la condición de equidad entre procesos; además de que no sabemos qué sucede tras desbloquear a dicho proceso, debido a que la competición que es transparente para el programador.
\end{enumerate}
De esta forma, podemos representar la vida de un proceso que forma parte de un programa concurrente que usa monitores con semántica de señales de señalar y continuar con el diagrama de la Figura~\ref{fig:sc}.

% // TODO: Ver si fijar o no estos 4 grafos
\begin{figure}%[H]
\centering
\begin{tikzpicture}[node/.style={rectangle, draw, minimum size=1cm, align=center},
                    edge/.style={-stealth}]
    \node[node] (A) {Procedimiento\\terminado};
    \node[node, left =of A] (B) {\begin{tabular}{c}Ejecutando código\\del proceso\\(fuera del monitor)\end{tabular}};
    \node[node, left =of B] (C) {\begin{tabular}{c}Llamando a\\procedimiento\\del monitor\end{tabular}};
    \node[node, below =of C] (D) {\begin{tabular}{c}Esperando en\\cola de entrada\\al monitor\end{tabular}};
    \node[node, right =of D] (E) {\begin{tabular}{c}Monitor\\libre\end{tabular}};
    \node[node, right =of E, xshift=.6cm] (F) {\begin{tabular}{c}Ejecutando procedimiento\\(dentro del monitor)\end{tabular}};

    \node[node, below right =of F] (G) {\texttt{c.signal()}};
    \node[node, below =of F] (H) {\texttt{c.wait()}};
    \node[node, left =of H] (I) {\begin{tabular}{c}Bloqueado en una\\cola condición $c$\end{tabular}};
    \node[node, left =of I, xshift=-1.3cm] (J) {Señalado};
    
    \draw[edge] (A) -- (B);
    \draw[edge] (B) -- (C);
    \draw[edge] (C) -- (D);
    \draw[edge] (D) -- (E);
    \draw[edge] (E) -- (F);
    \draw[edge] (F) -- (A);

    % \draw[edge] (F) to[out=0, in=100] (G);
    % \draw[edge] (G) to[out=180, in=-50] (F);

    \draw[edge] (F) to[out=0, in=90] (G);
    \draw[edge] (G) to[out=180, in=-90] ([xshift=1.5cm]F.south);

    \draw[edge] (F) -- (H);
    \draw[edge] (H) -- (I);
    \draw[edge] (I) -- (J);
    \draw[edge] (J) -- (D);
\end{tikzpicture}
\caption{Vida de un proceso en un programa con monitores con semántica SC.}
\label{fig:sc}
\end{figure}

\subsubsection{A tener en cuenta para bloquear}
Como se trata de una semántica no desplazante, debemos tener cuidado con un detalle:

En semántica desplazante, bloqueamos a un proceso porque se acerca a un estado inseguro del programa. Cuando nos alejemos de dicho estado, realizaremos la instrucción \verb|signal|, por lo que el proceso que bloqueamos se podrá ejecutar al habernos alejado del estado inseguro del programa.\\

Por otra parte, ahora también desbloquearemos al proceso por alejarnos de dicho estado inseguro, pero el proceso señalado no se ejecutará tras esto, por lo que puede que se ejecuten procesos en medio que vuelvan a acercarse a este estado inseguro, luego tendremos que volver a comprobar si estamos cerca o no de dicho estado inseguro.\\

\noindent
Por tanto, en semánticas se señales no desplazantes, en vez de bloquear a procesos con:
\begin{minted}[escapeinside=\#\#]{pascal}
    if (cerca de estado inseguro) then
       c.wait();
\end{minted}
Tendremos que plantear el código
\begin{minted}[escapeinside=\#\#]{pascal}
    while (cerca de estado inseguro) do begin
       c.wait();
    end
\end{minted}
Ya que cuando el proceso señalado vuelva no sabremos si la condición por la que lo bloqueamos es cierta o no. Puede suceder que bloqueemos a un proceso por acercarse a un estado inseguro, que lo desbloqueemos cuando el estado del programa se aleje de dicho estado, que se ejecuten procesos que se acerquen a dicho estado y que cuando el proceso que fue señalado entre al monitor, se encuentre cerca del mismo estado inseguro por el que tuvo que bloquearse, teniendo que hacerlo nuevamente.

\subsection{Señalar y Salir (SS)}
El proceso señalador \textbf{finaliza} la ejecución de su procedimiento tras la ejecución de una instrucción \verb|signal|. El proceso señalado se desbloquea posteriormente y en todo este tiempo el monitor no queda libre en ningún momento. Se trata, por tanto, de una semántica desplazante, ya que el proceso señalador cede el monitor al proceso señalado.\\

Notemos que en señalar y salir, el proceso señalador \textbf{finaliza} la ejecución de su procedimiento. Es decir, cualquier instrucción que haya tras una operación \verb|signal| no se ejecutará nunca. Obliga por tanto a una disciplina de programación en la que si queremos realizar un \verb|signal| dentro de un procedimiento, esta instrucción debe ser la última dentro del procedimiento, para poder ejecutar antes todas las instrucciones que deseemos. 

Si recordamos el ejemplo de la Sección~\ref{sec:concepto_de_monitor}, observamos que en este las instrucciones \verb|signal| se encuentran al final de los procedimientos de forma natural. Por tanto, la semántica SS funciona bien para este monitor.\\

Al igual que hicimos para SC, podemos representar la vida de un proceso que forma parte de un programa concurrente que usa monitores con semántica de señales de señalar y salir con el diagrama de la Figura~\ref{fig:ss}.
\begin{figure}%[H]
\centering
\begin{tikzpicture}[node/.style={rectangle, draw, minimum size=1cm, align=center},
                    edge/.style={-stealth}]
    \node[node] (A) {Procedimiento\\terminado};
    \node[node, left =of A] (B) {\begin{tabular}{c}Ejecutando código\\del proceso\\(fuera del monitor)\end{tabular}};
    \node[node, left =of B] (C) {\begin{tabular}{c}Llamando a\\procedimiento\\del monitor\end{tabular}};
    \node[node, below =of C, yshift=-1.5cm] (D) {\begin{tabular}{c}Esperando en\\cola de entrada\\al monitor\end{tabular}};
    \node[node, right =of D] (E) {\begin{tabular}{c}Monitor\\libre\end{tabular}};
    \node[node, right =of E, xshift=.6cm] (F) {\begin{tabular}{c}Ejecutando procedimiento\\(dentro del monitor)\end{tabular}};

    \node[node, below =of B] (G) {\texttt{c.signal()}};
    \node[node, below right =of F] (H) {Señalado};
    \node[node, below left =of F] (I) {\texttt{c.wait()}};
    \node[node, below =of F, yshift=.1cm] (J) {\begin{tabular}{c}Bloqueado en una\\cola condición $c$\end{tabular}};

    \draw[edge] (A) -- (B);
    \draw[edge] (B) -- (C);
    \draw[edge] (C) -- (D);
    \draw[edge] (D) -- (E);
    \draw[edge] (E) -- (F);
    \draw[edge] (F) -- (A);

    \draw[edge] (F) -- (G);
    \draw[edge] (G) -- (B);

    \draw[edge] (F) -- (I);
    \draw[edge] (I) -- (J);

    \draw[edge] (H) -- (F);
    \draw[edge] (J) -- (H);
\end{tikzpicture}
\caption{Vida de un proceso en un programa con monitores con semántica SS.}
\label{fig:ss}
\end{figure}

\subsection{Señalar y Esperar (SE)}
El proceso señalador se bloquea al final de la cola de entrada al monitor y cede el monitor al proceso señalado. El monitor no queda libre en ningún momento. Se trata de otro tipo de señal con semántica desplazante.\\

Puede considerarse una semántica \textit{injusta}, ya que cada vez que un proceso ejecuta la operación \verb|signal|, debe irse al final de la cola de entrada al monitor, teniendo que esperar entre todos los procesos nuevamente (el proceso probablemente tuvo ya que esperar para entrar al monitor para ejecutar el procedimiento que contenía la operación \verb|signal|).

Podemos representar la vida de un proceso que forma parte de un programa concurrente que usa monitores con semántica de señales de señalar y esperar con el diagrama de la Figura~\ref{fig:se}.

\begin{figure}%[H]
\centering
\begin{tikzpicture}[node/.style={rectangle, draw, minimum size=1cm, align=center},
                    edge/.style={-stealth}]
    \node[node] (A) {Procedimiento\\terminado};
    \node[node, left =of A] (B) {\begin{tabular}{c}Ejecutando código\\del proceso\\(fuera del monitor)\end{tabular}};
    \node[node, left =of B] (C) {\begin{tabular}{c}Llamando a\\procedimiento\\del monitor\end{tabular}};
    \node[node, below =of C] (D) {\begin{tabular}{c}Esperando en\\cola de entrada\\al monitor\end{tabular}};
    \node[node, right =of D] (E) {\begin{tabular}{c}Monitor\\libre\end{tabular}};
    \node[node, right =of E, xshift=.6cm] (F) {\begin{tabular}{c}Ejecutando procedimiento\\(dentro del monitor)\end{tabular}};

    \node[node, below =of F, yshift=-1.5cm] (J) {\begin{tabular}{c}Bloqueado en una\\cola condición $c$\end{tabular}};
    \node[node, right =of J] (H) {Señalado};
    \node[node, left =of J] (I) {\texttt{c.wait()}};

    \node[node, below =of E, yshift=.3cm] (G) {\texttt{c.signal()}};

    \draw[edge] (A) -- (B);
    \draw[edge] (B) -- (C);
    \draw[edge] (C) -- (D);
    \draw[edge] (D) -- (E);
    \draw[edge] (E) -- (F);
    \draw[edge] (F) -- (A);

    \draw[edge] ([xshift=-2cm]F.south) to[out=-90, in=0] (G);
    \draw[edge] (G) to[out=180, in=-90] (D);

    \draw[edge] (F) -- (I);
    \draw[edge] (I) -- (J);

    \draw[edge] (H) -- (F);
    \draw[edge] (J) -- (H);
\end{tikzpicture}
\caption{Vida de un proceso en un programa con monitores con semántica SE.}
\label{fig:se}
\end{figure}

\subsection{Señalar y Espera Urgente (SU)}
El proceso señalador se bloquea en una nueva cola del monitor llamada \textit{cola de procesos urgentes}, cediendo el monitor al proceso señalado. El monitor no queda libre en ningún momento, por lo que se trata de una señal con semántica desplazante.\\

La nueva cola de procesos urgentes actúa como una nueva cola de entrada al monitor, pero con mayor preferencia que la cola de entrada que ya teníamos. De esta forma, es similar a la semántica de señalar y esperar pero sin ser tan \textit{injusta}, ya que da preferencia a los procesos que se bloquearon tras ejecutar un \verb|signal| y deja en segunda posición a los proceos que esperan para ejecutar procedimientos del monitor.\\

Esta semántica modifica la última representación gráfica que teníamos de un monitor en la Tabla~\ref{esq:monitor_3}, dejándola finalmente en la que observamos en la Tabla~\ref{esq:monitor_4}.

\begin{table}[H]
\centering
\begin{tabular}{|l|}
\hline
Cola del\\
monitor \\
\hline
Cola de\\
urgentes \\
\hline
Variables \\
permanentes \\
\hline
Variables \\
condición y\\
colas de procesos\\
bloqueados\\
\hline
Procedimientos \\
exportados \\
\hline
Código de \\ 
inicialización \\
\hline
\end{tabular}
\caption{Esquema de un monitor incluyendo la cola de urgentes.}
\label{esq:monitor_4}
\end{table}

Podemos representar la vida de un proceso que forma parte de un programa concurrente que sua monitores con semántica de señalar y espera urgente con el diagrama de la Figura~\ref{fig:su}.\\

Finalmente, cabe destacar que con semántica SU, la señal \verb|signal| \textbf{siempre} bloquea al proceso señalador en la cola de urgentes, incluso si la cola de dicha variable condición está vacía.

Esto nos permite desbloquear a los procesos de una variable condición de forma que el primer proceso desbloqueado desbloquee al segundo, el segundo al tercero, \ldots, y así hasta el último, de forma que el último pasará también como el resto a la cola de urgentes, con planificación FIFO, donde el primero volverá a entrar al monitor y así con los siguientes. Notemos que si \verb|signal| no bloquease a los procesos siempre (es decir, si la cola de la variable condición está vacía, no bloqueamos), entonces en el caso anterior la prioridad FIFO de entrada al monitor se invertiría, de forma que el último proceso bloqueado sea el primero que accede al monitor.

\begin{figure}%[H]
\centering
\begin{tikzpicture}[node/.style={rectangle, draw, minimum size=1cm, align=center},
                    edge/.style={-stealth}]
    \node[node] (A) {Procedimiento\\terminado};
    \node[node, left =of A] (B) {\begin{tabular}{c}Ejecutando código\\del proceso\\(fuera del monitor)\end{tabular}};
    \node[node, left =of B] (C) {\begin{tabular}{c}Llamando a\\procedimiento\\del monitor\end{tabular}};
    \node[node, below =of C] (D) {\begin{tabular}{c}Esperando en\\cola de entrada\\al monitor\end{tabular}};
    \node[node, right =of D] (E) {\begin{tabular}{c}Monitor\\libre\end{tabular}};
    \node[node, right =of E, xshift=.6cm] (F) {\begin{tabular}{c}Ejecutando procedimiento\\(dentro del monitor)\end{tabular}};

    \node[node, below =of D] (G) {\texttt{c.wait()}};
    \node[node, below =of G] (H) {\begin{tabular}{c}Bloqueado en una\\cola condición $c$\end{tabular}};
    \node[node, right =of H] (I) {Señalado};

    \node[node, below =of F, xshift=4cm] (J) {\begin{tabular}{c}Monitor\\libre\end{tabular}};
    \node[node, below =of J] (K) {\begin{tabular}{c}Bloqueado en\\cola de urgentes\end{tabular}};
    \node[node, left =of K] (L) {\texttt{c.signal()}};

    \draw[edge] (A) -- (B);
    \draw[edge] (B) -- (C);
    \draw[edge] (C) -- (D);
    \draw[edge] (D) -- (E);
    \draw[edge] (E) -- (F);
    \draw[edge] (F) -- (A);

    \draw[edge] ([xshift=-2cm]F.south) to[out=-90, in=0] (G);
    \draw[edge] (G) -- (H);
    \draw[edge] (H) -- (I);
    \draw[edge] (I) to[out=0, in=-90] ([xshift=-1cm]F.south);

    \draw[edge] (F) to[out=0, in=90] (J);
    \draw[edge] (J) -- (K);
    \draw[edge] (K) -- (L);
    \draw[edge] (L) -- (F);
\end{tikzpicture}
\caption{Vida de un proceso en un programa con monitores con semántica SU.}
\label{fig:su}
\end{figure}

\subsection{Comparativa}\label{cap:comp}
Antes de comparar las semánticas de señales que ya hemos descrito, destacamos un último tipo de semántica de señales, las \textit{señales automáticas} (SA). En estas, el programador programa las operaciones \verb|wait| y es el compilador quien analiza los códigos programados y decide cuándo desbloquear a los procesos, por lo que se trata de unas señales implícitas (ya que en ningún moemnto se especifica cuándo hacer una instrucción \verb|signal|). 

A pesar de que este tipo de semántica aparece en la bibliografía, no aparece en ningún lenguaje de programación conocido, por lo que no tendrá relevancia en la asignatura ni en la comparativa que ahora realizaremos.\\

En primer lugar, hemos de destacar que cualquiera de las primeras 4 semánticas vistas es capaz de resolver cualquier problema, por lo que nos guiaremos por la sencillez de uso de cada una y la eficiencia que cada una nos aporta a los programas concurrentes para elegir una u otra semántica.
\begin{itemize}
    \item En cuato a sencillez de uso, SC, SE y SU presentan la misma facilidad, mientras que SS nos condiciona a un paradigma de programación en el que las instrucciones \verb|signal| sean las últimas que se ejecuten en los procedimientos de un monitor que contenga alguna operación \verb|signal|.
    \item En cuanto a eficiencia:
        \begin{itemize}
            \item Las semánticas SE y SU resultan ineficientes cuando las instrucciones \verb|signal| se encuentran al final de los procedimientos (ya que habrá procesos que ejecutan un \verb|signal|, se bloquearán, esperarán en la cola correspondiente de entrada al monitor, y cuando por fín tengan acceso a él no realizarán nada, sino que simplemente terminarán la ejecución del procedimiento), por lo que se saturará la cola de entrada al monitor y se realizarán cambios de contexto de formas innecesarias.
            \item La semántica SC es poco eficiente, al tener que obligarnos a usar un bucle de comprobación para comprobar si estamos cerca de una situación insegura cada vez que entramos al monitor, como consecuencia de no tener semántica desplazante, pudiendo producirse robos de señal.
        \end{itemize}
        Por tanto, si no nos resulta incómodo tener que colocar todas las instrucciones \verb|signal| como última instrucción de los procedimientos en los que aparecen, SS será probablemente la semántica se señales más eficientes.
\end{itemize}

Para concluir la comparativa de las semánticas de señales, veremos el siguiente ejemplo, que muestra que a veces la semántica elegida condiciona la forma en la que programamos los monitores.

\begin{ejemplo}
    Queremos programar en un programa concurrente una \textit{barrera parcial}.

    A partir del concepto de barrera que ya manejamos en la asignatura de Arquitectura de Computadores\footnote{Consultar los apuntes si no se conoce el concepto.}, ahora no queremos tener a los procesos esperando a que todos los procesos que intervienen en el programa lleguen a un punto en específico, sino solo queremos que lo hagan $n$ procesos.

    De esta forma, cuando el primer proceso llegue al punto de la barrera, este se bloqueará. Estos les sucederá a los primeros $n-1$ procesos en llegar a la barrera. Cuando el proceso $n$-ésimo llegue a esta, se abrirá la barrera, dejando pasar a estos $n$ primeros procesos que llegaron a esta. La barrera no debe dejar pasar al proceso número $n+1$, sino que este deberá esperar al proceso número $2n$ para voler a abrir la barrera.\\

    Una vez descrito el problema a resolver, planteamos el siguiente monitor como primera solución:
    \begin{minted}[escapeinside=\#\#]{pascal}
        Monitor BP;
           var cola : cond;
               contador : integer;

           procedure barrera(); begin
              contador = contador + 1;
              if (contador < n) then
                 cola.wait();
              else begin
                 for i=1 to n-1 do
                    cola.signal();
                 end
                 contador = 0;
              end
              {Funcionalidad tras pasar la barrera parcial}
           end

           begin
              contador = 0;
           end
    \end{minted}
Veamos ahora el comportamiento del monitor, según la semántica de señales que hayamos escogido:
\begin{description}
    \item [Señalar y Continuar.] Cuando llega el $n$-ésimo proceso de un grupo, este desbloquea a los últimos $n-1$ procesos bloqueados, que pasan a competir por el monitor. Puede suceder que algún proceso del siguiente grupo adelante a uno de este grupo, por lo que no sería una solución válida.
    \item [Señalar y Salir.] El $n$-ésimo proceso solo podría despertar al primer proceso que llegó a la barrera (ya que tras ejecutar \verb|signal|, este terminaría la ejecución de su procedimiento), sin reestablecer el contador a 0, por lo que cualquier proceso que pase por la barrera despertaría al siguiente proceso bloqueado, de forma que los últimos $n$ procesos que ejecuten el protocolo \verb|barrera| quedarán bloqueados de forma indefinida.
    \item [Señalar y Esperar.] El $n$-ésimo proceso solo podría despertar al primer proceso que llegó a la barrera, volviendo el proceso señalador a la cola de entrada al monitor. El $n+1$-ésimo proceso solo podría despertar al segundo proceso, y se iría a la cola de entrada al monitor. Cuando el $2n$-ésimo proceso entre al monitor, este ya no ejecutará \verb|signal| (ya que como la cola está vacía, es equivalente a una instrucción nula), poniendo por fin el contador a 0 y comenzando otra vez con dicho comportamiento.

        No es una solución válida.
    \item [Señalar y Espera Urgente.] El $n$-ésimo proceso desbloquea al primer proceso que llegó a la barrera y a continuación se bloquearía en la cola de urgentes, cediendo el monitor al primer proceso, que finalizaría la ejecución del procedimiento y volvería a entrar el $n$-ésimo proceso, por tener la cola de urgentes mayor prioridad que la cola de entrada al monitor. El proceso se repetiría hasta que el $n$-ésimo proceso finalie la ejecución del procedimiento, restaurando la barrera parcial para los siguientes $n$ procesos.

        Sería un funcionamiento correcto de la barrera, pero hace que el $n$-ésimo proceso realice $n-1$ cambios de contexto innecesarios.
\end{description}
Mostramos ahora una versión alternativa para el monitor que resuelve el problema de la barrera parcial:
\begin{minted}[escapeinside=\#\#]{pascal}
    Monitor BP;
       var cola : cond;
           contador : integer;

       procedure barrera(); begin
          contador = contador + 1;
          if (contador < n) then
             cola.wait();
          contador = contador - 1;
          {Funcionalidad tras pasar la barrera parcial}
          if (contador > 0) then
             cola.signal();
       end

       begin
          contador = 0;
       end
\end{minted}
Vemos su comportamiento:
\begin{itemize}
    \item No funciona con la semántica SC\@.
    \item Funciona con cualquier semántica desplazante, ya que tras llegar a $n$ procesos en la barrera, el $n$-ésimo desbloquea al primero, que desbloquea al segundo, que desbloquea al tercero, \ldots, hasta llegar al $n-1$, que realiza su funcionalidad y viceversa hasta el $n$-ésimo proceso, que deja la barrera en el estado inicial para los siguientes grupos de procesos.
\end{itemize}
\end{ejemplo}~\\

En general, tenemos que tener cuidado con la semántica de señales que estemos empleando, sobre todo si las instrucciones \verb|signal| tienen instrucciones detrás. Además, la semántica SC suele complicar como norma general los diseños de los monitores.

\begin{ejercicio*}
    Determinar para qué tipo de semánticas (SC o desplazantes) funcionan los siguientes monitores que tratan de simular el comportamiento de un semáforo:
    \setlength{\columnsep}{1cm}
    \begin{multicols}{2}
        \begin{minted}[escapeinside=\#\#]{pascal}
            Monitor semaforo_FIFO1;
            var c : cond;
                s : int;

            procedure P;
            begin
                if (s = 0) then
                    c.wait();
                s := s - 1;
            end;

            procedure V;
            begin
                s := s + 1;
                c.signal();
            end

            begin
                s := 0;
            end
        \end{minted}
        \begin{minted}[escapeinside=\#\#]{pascal}
            Monitor semaforo_FIFO2;
            var c : cond;
                s : int;

            procedure P;
            begin
                while (s = 0) do
                    c.wait();
                end do;
                s := s - 1;
            end;

            procedure V;
            begin
                c.signal();
                s := s + 1;
            end

            begin
                s := 0;
            end
        \end{minted}
    \end{multicols}
    En primer lugar, notamos que el monitor de la izquierda realiza una instrucción \verb|if| antes de llamar a la operación \verb|wait|, luego solo sirve para semánticas desplazantes.

    Posteriormente, observamo que el monitor de la derecha realiza la operación \verb|wait| dentro de un bucle, por lo que este sirve para semánticas SC\@. Sin embargo, no sirve para semánticas desplazantes, ya que la operación \verb|signal| se realiza antes de incrementar la variable \verb|s|, por lo que nunca se realizaría dicho incremento, al bloquear al proceso señalador.
\end{ejercicio*}

\subsection{Axiomas para operaciones de sincronización no desplazantes}
Como comentamos ya en la Sección~\ref{sec:ax_desplazantes}, los axiomas que sabemos para demostrar las operaciones de sincronización en monitores solo aplican cuando trabajamos con señales con semánticas desplazantes. Por tanto, si nos encontramos trabajando con semánticas de señales no desplazantes como SC, necesitamos unas nuevas reglas a aplicar.

\begin{description}
    \item [Axioma de la operación \texttt{wait}.]~\\
        Sea $c$ una variable de tipo condición, $L$ un invariante local del procedimiento en el que nos encontremos y $IM$ el invariante del monitor que usamos para demostrar la corrección del mismo, se verifica que
        \begin{equation*}
            \{IM \land L\}\ c.wait();\ \{IM \land L\}
        \end{equation*}
        Es decir, antes y después de la operación \verb|wait| solo podemos asegurar que se cumple el IM (ya que podrían producirse robos de señal), por lo que para asegurarnos de que estamos lejos de un estado inseguro del programa, debemos hacer uso de un bucle \verb|while|, tal y como expusimos anteriormente:
        \begin{minted}[escapeinside=\#\#]{pascal}
            while (cerca de estado inseguro) do begin
               c.wait();
            end
        \end{minted}
    \item [Axioma de la operación \texttt{signal}.]~\\
        Como estamos ante una semántica no desplazante, el proceso señalador seguirá ejecutando el procedimiento que estaba ejecutando cuando ejecutó la operación \verb|signal|, por lo que nada habrá cambiado:
        \begin{equation*}
            \{P\}\ c.signal();\ \{P\}
        \end{equation*}
        Por tanto, la operación \verb|signal| tiene el mismo comportamiento que la instrucción nula en semánticas no desplazantes, ya que podemos poner como pre y poscondición el mismo aserto $P$ y el triple será cierto independientemente del aserto escogido.
\end{description}

\subsection{Intercambio de señales en programas que usan monitores}
En el Capítulo~\ref{cap:comp}, mencionamos que todas las semánticas de señales eran equivalentes para resolver cualquier problema. Esto se debe a que si se cumplen unas determinadas condiciones, entonces todas las señales (las automáticas, las desplazantes y las no desplazantes) son equivalentes. Esto significa que si estamos trabajando con una semántica, podemos reemplazar las señales de dicha semántica por cierto código que asemeja el comportamiento de otra semántica de señales.\\

Las condiciones que deben cumplirse dentro de un monitor para que podamos simular una semántica mediante otra son:
\begin{enumerate}
    \item Se tiene que exigir como poscondición de la operación \verb|wait| el invariante del monitor y nada más estricto (esto es, no podremos usar directamente la condición de sincronización tras la operación \verb|wait|, sino solamente el invariante del monitor\footnote{Notemos que esto no inclumple el axioma de la operación \texttt{wait}, ya que $C\rightarrow IM$.}).
    \item Con señales continuas, cuando realizamos un \verb|signal| no hay desplazamiento, por lo que para que se puedan asemejar a las señales desplazantes, hemos de obligar a que la llamada a \verb|signal| se haga siempre antes de suspender el proceso y salir del monitor.

        Esto es, que la operación \verb|signal| sea la última instrucción en el procedimiento de un monitor o que tras dicha operación haya una instrucción \verb|wait|.
    \item Finalmente, para que sean equivalentes los códigos, no podemos usar la operación \verb|signal_all|.
\end{enumerate}

\subsection{Señales \texttt{wait} con prioridad}
Como hemos visto hasta ahora, tras ejecutar una operación \verb|wait| sobre una variable condición \verb|c|, pasamos a la cola de bloqueados de la misma, con planificación FIFO\@. Sin embargo, en algunos lenguajes de programación aparece la operación \verb|wait| con prioridad sobre las variables de tipo condición, con el fin de solucionar situaciones en las que no queremos que tras una operación \verb|signal| se desbloquee el primero de la cola, sino aquel que tuviera más prioridad y lleve más tiempo en la misma.\\

En el caso descrito, la operación \verb|wait| aceptará un parámetro entero no negativo llamado \textit{prioridad}, de forma que a menor sea el valor de dicho parámetro, mayor prioridad tendrá en la cola de bloqueados. En este caso, la cola FIFO de la variable condición se sustituye por una cola con prioridad.\\

Mostramos a continuación un ejemplo para motivar por qué algunos lenguajes implementan esta operación \verb|wait|.
\begin{ejemplo}
    Queremos programar una alarma para procesos de tal manera que el proceso se bloquee al fijar la alarma y que este se desbloquee al cumplirse la hora previamente fijada. Para ello, implementaremos la alarma haciendo uso de un monitor con dos procedimientos:
    \begin{itemize}
        \item \verb|tick|, cableado a la interrupción de reloj del sistema operativo, con el fin de que el reloj sepa el instante en el que se encuentra en cada momento.
        \item \verb|despiertame|, que servirá para que cada proceso fije el momento en el que quiere ser despertado.
    \end{itemize}
    Para simplificar el ejemplo, usaremos como unidad de medida un ``tick''. Planteamos el siguiente monitor como solución al problema, usando señales \verb|wait| con prioridad:
    \begin{minted}[escapeinside=\#\#]{pascal}
        monitor despertador;
        var ahora : Long_integer;
            despertar : cond;  {variable condición prioritaria}

        procedure despiertame(n : integer);
        var alarma : Long_integer;
        begin
            alarma := ahora + n;    {hora para despertar}
            while ahora < alarma do 
                despertar.wait(alarma);
            end do;
            despertar.signal();
        end

        procedure tick();   {cableada a INT CLK}
        begin
            ahora := ahora + 1;
            despertar.signal();
        end

        begin
            ahora := 0;
        end
    \end{minted}
    De esta forma, lo que estamos haciendo es ordenar la cola de bloqueados de la variable condición \verb|despertar| poniendo al inicio de la misma el primer proceso a desbloquear.

    Por ejemplo, ante el siguiente uso del monitor por los procesos:
    \begin{table}
    \centering
    \begin{tabular}{|c|c|c|c|}
        \hline
        Proceso & Instante & Llamada & Cola de variable condición \\
        \hline
        P1 & 0 & \verb|despiertame(10)| & (P1) \\
        \hline
        P2 & 1 & \verb|despiertame(3)| & (P2 | P1) \\
        \hline
        P3 & 2 & \verb|despiertame(5)| & (P2 | P3 | P1) \\
        \hline
        P4 & 3 & \verb|despiertame(1)| & (P2 | P4 | P3 | P1) \\
        \hline
    \end{tabular}
    \caption{Ejemplo de uso del monitor}
    \end{table}
    Cuando la interrupción de reloj del sistema llame al procedimiento \verb|tick|, se desbloqueará al primer proceso de la cola de la variable condición, P2, que saldrá del bucle \verb|while| y desbloqueará al siguiente proceso de la cola, P4, que hará lo mismo, desbloqueando a P3, y como para P3 \verb|ahora < alarma|, volverá a bloquearse, quedando la cola de la variable condición como (P3 | P1).\\

    Notemos que con el uso de la operación \verb|wait| con prioridad minimizamos el número de procesos a desbloquear en cada nuevo instante, ya que tenemos la cola de bloqueados ordenada de forma que al inicio están los procesos que antes se desbloquearán, con lo que si encontramos el primer proceso que no se desbloquea, hemos terminado en dicho instante de despertar a los procesos.\\

    Si tratamos de programar este mismo problema sin operaciones \verb|wait| con prioridad, sino con la operación \verb|wait| que venimos usando a lo largo de este Capítulo, el procedimiento \verb|despiertame| quedaría como:
    \begin{minted}[escapeinside=\#\#]{pascal}
        procedure despiertame(n : integer);
        var alarma : Long_integer;
        begin
            alarma := ahora + n;    {hora para despertar}
            while ahora < alarma do 
                despertar.signal();
                despertar.wait();
            end do;
            despertar.signal();
        end
    \end{minted}
    Lo que sucede es que tenemos que estar continuamente desbloqueando a los procesos para comprobar si deben o no despertarse, al no tener ningún orden en dicha cola.
\end{ejemplo}

\section{Implementación de los monitores}
Podemos implementar todas las funcionalidades de un monitor usando semáforos. En esta sección, explicaremos cómo implementar un monitor con semántica de señales SU, que nos garantice el comportamiento de un proceso descrito en la Figura~\ref{fig:su}.\\

Para conseguir simular el comportamiento de un monitor, hemos de conseguir:
\begin{itemize}
    \item Tener una cola de entrada al monitor, que implementaremos usando un semáforo llamado \verb|mutex|.
    \item Tener una cola de procesos urgentes, que implementaremos con un semáforo llamado \verb|next|.
    \item Contabilizar el número de procesos bloqueados en la cola de urgentes\footnote{Con la finalidad de saber si dicha cola está o no vacía}, con una variable entera \verb|next_count|.
    \item Implementación de las variables condición.

        Para ello, por cada variable condición que queramos tener en un monitor, crearemos un semáforo nuevo y una variable entera que controle el número de procesos que bloquea dicho semáforo. Además, crearemos unas nuevas funciones \verb|wait| y \verb|signal| (llamadas \verb|x_wait| y \verb|x_signal|) que simulen el comportamiento de las operaciones \verb|wait| y \verb|signal| de las variables compartidas.
\end{itemize}

Inicializaremos las variables que nos permiten controlar el monitor de la forma:
\begin{minted}[escapeinside=\#\#]{pascal}
    mutex := 1;
    next := 0;
    next_count := 0;
\end{minted}

\subsubsection{Procedimientos del monitor}
Cada vez que nos dispongamos a crear un procedimiento nuevo para el monitor, deberemos ejecutar cierto código antes y después del mismo, con la finalidad de garantizar la exclusión mutua dentro del monitor. Para ello, crearemos dos funciones, \verb|entrada| y \verb|salida|, las cuales deberemos invocar antes y después del cuerpo del procedimiento a programar:
\begin{minted}{pascal}
    procedure P();
    begin
        entrada();
        {cuerpo del procedimiento}
        salida();
    end
\end{minted}
De esta forma, el código de entrada al monitor sería:
\setlength{\columnsep}{1cm}
\begin{minted}{pascal}
    procedure entrada();
    begin
        sem_wait(mutex);    {garantizar exclusión mutua}
    end
\end{minted}    
Y el de salida:
\begin{minted}{pascal}
    procedure salida();
    begin
        if(next_count <> 0)    {hay procesos en cola de urgentes}
            sem_signal(next);
        else
            sem_signal(mutex);   {liberamos el monitor}
        end if
    end
\end{minted}

\subsubsection{Variables condición}
Por cada variable condición a usar dentro del monitor necesitamos tener un par semáforo, entero. Mostramos ahora cómo podemos implementar las operaciones \verb|wait| y \verb|signal| de las variables condición usando semáforos.

Para ello, crearemos una función por cada operación a simular, la cual recibirá dos parámetros: el semáforo que simula la variable condición (\verb|x_sem|) y la cantidad de procesos que dicho semáforo tiene bloqueados (\verb|x_count|):
\begin{minted}{pascal}
    procedure x_wait(x_sem : semaphore, x_count : integer);
    begin
        x_count := x_count + 1;  {un bloqueado más}

        if(next_count <> 0) then  {hay procesos en cola de urgentes}
            sem_signal(next);
        else
            sem_signal(mutex);  {deja libre el monitor}
        end if

        sem_wait(x_sem);
        x_count := x_count - 1;
    end
\end{minted}
\begin{minted}{pascal}
    procedure x_signal(x_sem : semaphore, x_count : integer);
    begin
        if(x_count <> 0) then  {si no hay bloqueado no hace nada}
            next_count := next_count + 1;
            sem_signal(x_sem);
            sem_wait(next);
            next_count := next_count - 1;
        end if
    end
\end{minted}
Y con todas estas funciones tenemos \textbf{casi} implementados los monitores. Hay que tener en cuenta que los semáforos no tienen una política de planificación fija, sino que es el sistema operativo quien planifica los procesos desbloqueados por el semáforo.

Es necesario por tanto, usar semáforos con colas FIFO para tener totalmente implementados los monitores.
