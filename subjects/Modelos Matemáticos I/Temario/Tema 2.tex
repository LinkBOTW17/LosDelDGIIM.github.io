\chapter{Ecuaciones en diferencias lineales de orden superior}\label{chp:Tema2}

\begin{notacion}
    A lo largo del tema, notaremos a $\bb{N}\cup \{0\}$ por $\bb{N}_0$, considerando que $0\notin \bb{N}$.
\end{notacion}


Las ecuaciones lineales de orden superior son un caso particular de ecuaciones en diferencias de la forma:
\begin{equation*}
    h(x_n, x_{n+1}, \ldots, x_{n+k}, n) = 0
\end{equation*}
Con $h$ una función $h:I^{k+1}\times \bb{N}_0 \to I$, donde $I$ es un abierto de un cuerpo $\bb{K}$\footnote{En esta asignatura, trabajaremos con $\bb{K}=\bb{R}$ o $\bb{K}=\bb{C}$.} en su topología usual. También se puede escribir en su \ul{forma normal}:
\begin{equation*}
    x_{n+k} = f(x_n, x_{n+1}, \ldots, x_{n+k-1}, n)
\end{equation*}
Con $f$ una función $f:I^k\times \bb{N}_0 \to I$.

\begin{ejemplo} Veamos algunos ejemplos de ecuaciones en diferencias lineales de orden superior:
\begin{enumerate}
    \item Consideramos la siguiente ecuación en diferencias:
    \begin{equation*}
        x_{n+1} = ax_n + b\qquad a,b \in \bb{R}
    \end{equation*}
    Esta es ecuación lineal autónoma de orden 1, que es un caso particular de una ecuación lineal de orden superior. Su función asociada es:
    \Func{g}{I^2\times \bb{N}_0}{I}{(x,y,n)}{y-ax-b}
    En su forma normal, vendrá dada por una función dada por:
    \Func{f}{I\times \bb{N}_0}{I}{(x,n)}{ax+b}
    
    
    \item Consideramos la siguiente ecuación en diferencias:
        \begin{equation*}
            x_{n+2} = \dfrac{x_{n+1}+x_n}{2}
        \end{equation*}
        Se trata de una ecuación lineal autónoma de orden 2, que puede darse por la forma $h(x_n, x_{n+1}, x_{n+2}, n)= 0$ con $h$:
        \Func{h}{I^3\times \bb{N}_0}{I}{(x, y, z, n)}{z-\dfrac{y+x}{2}}
        Que puede expresarse de forma normal por:
        \Func{f}{I^2\times \bb{N}_0}{I}{(x,y, n)}{\dfrac{x+y}{2}}

    \item Consideramos la siguiente ecuación en diferencias:
        \begin{equation*}
            x_{n+3} = e^{x_n-x_{n+1}} \cdot x_{n+2}
        \end{equation*}
        Es una ecuación no lineal autónoma de orden 3, que puede darse por la ecuación $h(x_n, x_{n+1}, x_{n+2}, x_{n+3}, n)=0$, con $h$:
        \Func{h}{I^4\times \bb{N}_0}{I}{(x,y,z,t, n)}{t - ze^{x-y}}
        Dada en forma normal por:
        \Func{f}{I^3\times \bb{N}_0}{I}{(x,y,z, n)}{ze^{x-y}}

    \item Consideramos la siguiente ecuación en diferencias:
        \begin{equation*}
            x_{n+2} = x_n + 2^n
        \end{equation*}
        Se trata de una ecuación lineal no autónoma, de orden 2 que puede darse por la forma $h(x_n, x_{n+1}, x_{n+2}, n)= 0$ con $h$:
        \Func{h}{I^3\times \bb{N}_0}{I}{(x,y,z,n)}{z-x-2^n}
        Que en forma normal viene dada por:
        \Func{f}{I^2\times \bb{N}_0}{I}{(x,y,n)}{x+2^n}
\end{enumerate}
\end{ejemplo}

\begin{definicion}[Solución]
    Una solución de una ecuación en diferencias lineal de orden $k$ se trata de una sucesión de términos $\{x_n\}\subseteq I$ que verifica la ecuación $h(x_n, x_{n+1}, \ldots, x_{n+k}, n) = 0$ $\forall n \in \bb{N}$, para su función asociada $h:I^{k+1}\times \bb{N}_0\to I$.
\end{definicion}

\begin{definicion}[Problemas de Valores Iniciales]
    Un PVI se trata de un problema cuya solución es buscar la solución de una ecuación en diferencias de la cual se dan unas ciertas condiciones iniciales:

    \begin{equation*}
        \text{(PVI)}\equiv \left\{\begin{array}{l}
            h(x_n, x_{n+1}, \ldots, x_{n+k}, n) = 0 \\
            x_i = \alpha_i \in \bb{K},\quad i\in \{0, \ldots, k-1\}
        \end{array}\right.
    \end{equation*}

    Para una ecuación en diferencias de orden $k$, debemos tener $k$ datos iniciales para que tenga una única solución.
\end{definicion}

\begin{ejemplo} Veamos algunos ejemplos de PVI con y sin solución única.
    \begin{itemize}
        \item 
        Un ejemplo de PVI sin solución única es:
        \begin{equation*}
            \text{(PVI)}\equiv \left\{ \begin{array}{c}
                x_{n+2} = e^{x_n}\\
                x_0 = 1
            \end{array}\right.
        \end{equation*}

        \item Un ejemplo de PVI con solución única es:
        \begin{equation*}
            \text{(PVI)}\equiv \left\{ \begin{array}{c}
                x_{n+2} = e^{x_n}\\
                x_0 = x_1 = 1
            \end{array}\right.
        \end{equation*}
    \end{itemize}
\end{ejemplo}~\\

En este tema nos vamos a centrar en las ecuaciones lineales de orden $k\in \bb{N}$, que son de la forma:
\begin{multline}\label{eq:lineal_ordenk}
    x_{n+k} + a_{k-1}x_{n+k-1} + \ldots + a_0x_n = b_n \\
    a_i \in \bb{K}\quad \forall i\in \{0, \ldots, k-1\}, a_0\neq 0,~~b_n \in \bb{K} \quad\forall n\in \bb{N}
\end{multline}

\begin{definicion}[Parte homogénea]
    Dada una ecuación de la forma \ref{eq:lineal_ordenk}, llamamos parte homogénea de la ecuación a una nueva ecuación dada por:
    \begin{equation*}
        x_{n+k} + a_{k-1}x_{n+k-1} + \ldots + a_0x_n = 0 \qquad a_0 \neq 0, a_i\in \bb{K}
    \end{equation*}
    Exigimos la no nulidad de $a_0$ para que la ecuación sea realmente de orden $k$, ya que en caso contrario podríamos rebajar el orden de la ecuación.
\end{definicion}


\section{Soluciones}
Vamos a ver que las soluciones de~\ref{eq:lineal_ordenk} se construyen con las soluciones de su parte homogénea y una solución particular de~\ref{eq:lineal_ordenk}. Es decir, una solución de~\ref{eq:lineal_ordenk} la obtendremos sumando a una solución de la homogénea una solución particular de~\ref{eq:lineal_ordenk}.
Para probarlo, primero recordaremos que el espacio de las sucesiones en $\bb{K}$ es un espacio vectorial de dimensión infinita, que nos ayudará a realizar el trabajo necesario.

\begin{notacion}
    A continuación, notaremos por $\mathcal{S}$ al espacio de sucesiones en $\bb{K}$. Es decir:
    \begin{equation*}
        \mathcal{S} = \bb{K}^\bb{N}
    \end{equation*}
\end{notacion}
\begin{prop}\label{prop:S_dim_infinita}
    Se verifica que $\mathcal{S}$ es un espacio vectorial de dimensión infinita.
\end{prop}
\begin{proof}
    Gracias a las operaciones dadas por:
    \begin{enumerate}
        \item $\{x_n\} + \{y_n\} := \{x_n + y_n\}\quad \forall \{x_n\}, \{y_n\} \in \mathcal{S}$
        \item $a\cdot \{x_n\} := \{a\cdot x_n\}\quad \forall a\in\bb{K}\quad \forall \{x_n\}\in\mathcal{S}$.
    \end{enumerate}
    puede comprobarse fácilmente que $\mathcal{S}$ es un espacio vectorial. Veamos ahora que es de dimensión infinita. Fijado $k\in \bb{N}$, definimos la aplicación que a cada sucesión le asigna sus primeros $k$ términos:
    \Func{\varphi}{\mathcal{S}}{\bb{K}^k}{\{x_n\}}{(x_1, x_2, \ldots, x_k)}
    Veamos que es lineal y sobreyectiva:
    \begin{itemize}
        \item \ul{Lineal:} Dados $a,b \in \bb{K}$, $\{x_n\}, \{y_n\} \in \mathcal{S}$:
        \begin{align*}
            \varphi(\{ax_n + by_n\}) &= (ax_1 + by_1, ax_2 + by_2, \ldots, ax_k + by_k) \\
            &= a(x_1, x_2, \ldots, x_k) + b (y_1, y_2, \ldots, y_k) \\
            &= a\cdot \varphi(\{x_n\}) + b\cdot \varphi(\{y_n\})
        \end{align*}
        \item \ul{Sobreyectiva:} Dado $(x_1, x_2, \ldots, x_k) \in \bb{K}^k$, construimos la siguiente sucesión:
        \begin{equation*}
            x_n = \left\{\begin{array}{lcl}
                x_n & \text{\ si\ } & n\leq k \\
                0 & \text{\ si\ } & n> k
            \end{array} \right. \qquad \forall n \in \bb{N}
        \end{equation*}
    \end{itemize}
    Luego $\dim \mathcal{S} \geq \dim \bb{K}^k = k$, para todo $k\in \bb{N}$, por lo que $\mathcal{S}$ tiene dimensión infinita.
\end{proof}

Aunque el lector ya conozca el concepto de independencia lineal en un espacio vectorial, incluimos a continuación su definición por ser esta de vital importancia en el presente tema.
\begin{definicion}[Linealmente independientes]
    Dadas $\{x_n^1\}, \ldots, \{x_n^m\}$ sucesiones en $\bb{K}$, decimos que son linealmente independientes si cada vez que tengamos:
    \begin{equation*}
        a_1 \{x_n^1\} + \ldots + a_m \{x_n^m\} = 0\qquad \text{con\ } a_i\in \bb{K}\quad \forall i \in \{0, \ldots, m\}
    \end{equation*}
    Entonces, tendremos que $a_i = 0$, $\forall i\in \{0, \ldots, m\}$.
\end{definicion}

\begin{definicion}\label{def:FuncF}
    Dada una ecuación en diferencias como~\ref{eq:lineal_ordenk}  definimos una función $L:\mathcal{S}\rightarrow \mathcal{S}$ de forma que a cualquier sucesión $X\equiv \{x_n\} \in \mathcal{S}$ le haga corresponder:
    \begin{equation*}
        L(X) = \{ x_{n+k} + a_{k-1}x_{n+k-1} + \ldots + a_0 x_n \}
    \end{equation*}
    Y será usual notar $Y\equiv \{y_n\} = L(X)$. De esta forma, tendremos que: $$L(X) = \{y_n\} = \{b_n\}.$$
\end{definicion}

\begin{prop}
    El conjunto de soluciones de la parte homogénea de una ecuación del tipo~\ref{eq:lineal_ordenk} es un subespacio vectorial de $\mathcal{S}$.
\end{prop}
\begin{proof}
    Notemos que por ser la ecuación en diferencias~\ref{eq:lineal_ordenk} lineal, obtenemos que $L$ es una aplicación lineal y, por tanto, tendremos que 
    \begin{equation*}
        \ker L = \{X\in \mathcal{S} \mid L(X) = 0\}
    \end{equation*}
    es un subespacio vectorial de $\mathcal{S}$. Notemos que este subespacio vectorial corresponde con el conjunto de soluciones de la parte homogénea de~\ref{eq:lineal_ordenk}.
\end{proof}

\begin{ejemplo}\label{ejemplo:uso_L}
    Consideramos la siguiente ecuación en diferencias:
    \begin{equation*}
        x_{n+2} + 3x_{n+1} + 2x_n = 0
    \end{equation*}
    En este ejemplo, tenemos que $L(\{x_n\}) = \{x_{n+2} + 3x_{n+1} + 2x_n\}$ y nos preguntamos por:

    \begin{enumerate}
        \item $L(\{1\}) = \{6\}$
        \item $L(\{2^n\}) = \{2^{n+2} + 3\cdot 2^{n+1} + 2\cdot 2^n\} = \{2^{n+2} + 4\cdot 2^{n+1}\} = \{3\cdot 2^{n+2}\} =\{ 12\cdot 2^n\}$
        \item $L(\{n\}) = \{(n+2) + 3(n+1) + 2n\} = \{6n + 5\}$
        \item $L(\{{(-1)}^n\}) = \{(1 -3 + 2) (-1)^n\} = \{0\cdot (-1)^n\} = \{0\}$
        
        \item $L(\{{(-2)}^n\}) = \{(-2)^n[(-2)^2 + 3\cdot (-2) + 2]\} = \{(-2)^n\cdot 0\} = \{0\}$
    \end{enumerate}
    Esto nos lleva  a que $\{{(-1)}^n\}$ y $\{{(-2)}^n\}$ son soluciones de la ecuación en diferencias ${x_{n+2} + 3x_{n+1} + 2x_n = 0}$. Asimismo, como $L(\{1\}) = \{6\}$, tenemos que es una solución de la ecuación $x_{n+2} + 3x_{n+1} + 2x_n = 6$.
\end{ejemplo}

\begin{prop}
    Cualquier solución $X$ de~\ref{eq:lineal_ordenk} es de la forma una solución particular de~\ref{eq:lineal_ordenk} más una solución de su parte homogénea.
\end{prop}
\begin{proof}
Supongamos ahora que $\ol{X}$ es una solución particular de la ecuación~\ref{eq:lineal_ordenk}. Estudiemos ahora cómo son el resto de soluciones $X$ de la ecuación~\ref{eq:lineal_ordenk}. Sea por tanto $X$ otra solución de~\ref{eq:lineal_ordenk} distinta $\ol{X}$, y consideramos el cambio de variable $Y=X-\ol{X}$. Tenemos que:
\begin{equation*}
    L(Y) = L\left(X-\ol{X}\right) = L(X) - L\left(\ol{X}\right) = \{b_n\} - \{b_n\} = \{0\}
\end{equation*}
Llegamos por tanto a que $Y$ verifica la ecuación homogénea de~\ref{eq:lineal_ordenk} y, despejando $X$ llegamos a que $X = Y + \ol{X}$, siendo $X$ cualquier solución de~\ref{eq:lineal_ordenk}, que ha resultado ser suma de la solución de la parte homogénea más una solución particular.
\end{proof}

\begin{prop}
    Dada una ecuación en diferencias de la forma ~\ref{eq:lineal_ordenk} de orden $k$ y dada su función $L$, se tiene que $\dim \ker L = k$.
\end{prop}
\begin{proof}
    Para probarlo, consideramos la siguiente aplicación:
    \Func{\psi}{\ker L}{\bb{K}^k}{\{x_n\}}{(x_0, x_1, \ldots, x_{k-1})}
    Dicha función le asigna a cada sucesión de $\ker L$ una $k-$upla con sus primeros $k$ términos. Veamos ahora que:
    \begin{enumerate}
        \item $\psi$ es lineal.
        Dadas dos sucesiones $\{x_n\}, \{y_n\}\in \ker L$ y $a,b\in\bb{K}$, se tiene que:
        \begin{align*}
            \psi(a\{x_n\} + b\{y_n\}) &= \psi(\{ax_n + by_n\}) = (ax_0 + by_0, ax_1 + by_1, \ldots, ax_k + by_k)\\ 
            &= a(x_0, x_1, \ldots, x_k) + b(y_0, y_1, \ldots, y_k) = a\psi(\{x_n\}) + b\psi(\{y_n\})
        \end{align*}
        \item $\psi$ es biyectiva.
        
        \begin{itemize}
            \item Veamos que es inyectiva. Sean dos sucesiones $\{x_n\}, \{y_n\}\in \ker L$ tal que $\psi(\{x_n\}) = (x_0, x_1, \ldots, x_k) = (y_0, y_1, \ldots, y_k) = \psi(\{y_n\})$. Entonces, tenemos un PVI (cuya solución era única), luego $\{x_n\} = \{y_n\}$.

            \item Dado $(x_0, x_1, \ldots, x_k)\in \bb{K}^k$, acabamos de dar $k$ valores iniciales a una ecuación en diferencias de orden $k$, obteniendo un PVI, de donde podemos construir una solución $\{x_n\}$ de forma recursiva. De esta forma, tendremos que $\{x_n\}\in \ker L$ por ser solución de la parte homogénea, con ${\psi(\{x_n\})=(x_0, x_1, \ldots, x_k)}$.
        \end{itemize}
    \end{enumerate}

    Por tanto, como $\psi$ es lineal y biyectiva, tenemos que el dominio y el codominio tienen la misma dimensión, por lo que $\dim \ker L=\dim \bb{K}^k = k$.
\end{proof}

Por tanto, buscamos una base del espacio de soluciones de la parte homogénea de~\ref{eq:lineal_ordenk}, es decir, del espacio $\ker L$. Esta base serán $k$ sucesiones linealmente independientes que pertenezcan a $\ker L$. Introducimos la siguiente proposición, que nos servirá para ver cuándo distintas sucesiones son linealmente independientes.
\begin{prop}
    Sean $V,~W$ espacios vectoriales sobre un mismo cuerpo $\bb{K}$, sea una aplicación lineal $f:V\rightarrow W$ y $v_1, \ldots, v_k \in V$, si $f(v_1), \ldots, f(v_k)$ son linealmente independientes, entonces $v_1, \ldots, v_k$ también lo son.
\end{prop}
\begin{proof}
    Por reducción al absurdo, supongamos que $v_1, \ldots, v_k$ son linealmente dependientes. Por tanto, existen $a_1, \ldots, a_k \in \bb{K}$ no todos ellos nulos tales que:
    \begin{equation*}
        a_1 v_1 + \ldots + a_k v_k = 0
    \end{equation*}
    Y aplicando $L$ llegamos a que:
    \begin{equation*}
        0 = f(0) = f(a_1 v_1 + \ldots + a_k v_k) = a_1f(v_1) + \ldots + a_k f(v_k) 
    \end{equation*}
    Con no todos los $a_i\mid i \in \{1, \ldots, k\}$ nulos, luego $f(v_1), \ldots, f(v_k)$ son linealmente dependientes y llegamos a contradicción.
\end{proof}
\begin{coro}\label{coro:lin_indep_raices}
    Si $\lm_1,\dots,\lm_m\in \bb{K}$, con $\lm_i \neq \lm_j~\forall i,j\in \{1,\dots,m\},~i\neq j$, entonces $\{\lm_1^n\},\dots,\{\lm_m^n\}$ son linealmente independientes.
\end{coro}
\begin{proof}
    Empleamos la siguiente función, que en la Proposición~\ref{prop:S_dim_infinita} vimos que era lineal:
    \Func{\varphi}{\mathcal{S}}{\bb{K}^m}{\{x_n\}}{(x_0, x_1, \ldots, x_{m-1})}

    Tenemos que:
    \begin{align*}
        \varphi(\{\lm_1^n\}) &= (1,\lm_1, \dots,\lm_1^{m-1})\\
        &~ \vdots\\
        \varphi(\{\lm_m^n\}) &= (1,\lm_m, \dots,\lm_m^{m-1})\\
    \end{align*}

    Para ver que son linealmente independientes, necesitamos que el siguiente determinante, conocido como el determinante de Vandermonde\footnote{Ya estudiado en Métodos Numéricos I.}, no sea nulo:
    \begin{equation*}
        \left|
        \begin{array}{cccc}
            1 & 1 & \dots & 1\\
            \lm_1 & \lm_2 & \dots & \lm_m\\
            \vdots& \vdots& \ddots & \vdots\\
            \lm_1^{m-1} & \lm_2^{m-1} & \dots & \lm_m^{m-1}
        \end{array}
        \right| = \prod_{1\leq i<j\leq m} (\lm_i-\lm_j) \neq 0
    \end{equation*}
    Por tanto, por la proposición anterior tenemos que $\{\lm_1^n\},~\dots,~\{\lm_m^n\}$ son linealmente independientes.
\end{proof}

\subsection{Soluciones con multiplicidad simple}
Como idea intuitiva, si recordamos la ecuación lineal de orden $1$ dada por la ecuación ${x_{n+1} + a_0x_n = 0}$, vimos en el tema anterior que $x_{n} = (-a_0)^nx_0$. Por tanto, esto nos hace pensar que podremos encontrar $\lm\in \bb{K}$ tal que $x_n=\lm ^n$. Para que esto sea así, es necesario que:
\begin{equation*}
    0 = \lm^{n+k} + a_{k-1}\lm^{n+k-1} + \dots + a_0\lm^n = \lm^n \left(\lm^k + a_{k-1}\lm^{k-1} + \dots + a_0\right)
\end{equation*}

Tras haber sacado como factor común $\lm^n$, llegamos al polinomio 
\begin{equation*}
    \lm^k + a_{k-1}\lm^{k-1} + \dots + a_0
\end{equation*}
A este lo llamaremos polinomio característico de la ecuación en diferencias, ya que en la Sección \ref{sec:ecuacionesComoSistemas} veremos que
está asociado al polinomio característico de cierta matriz tal y como se definió en la asignatura Geometría II.
\begin{definicion}[Polinomio característico]
    Dada una ecuación en diferencias de orden $k$ de la forma~\ref{eq:lineal_ordenk}, se define su polinomio característico asociado como:
    \begin{equation*}
        p(\lm)=\lm^k + a_{k-1}\lm^{k-1} + \dots + a_0
    \end{equation*}
\end{definicion}

Por tanto, tenemos que $x_n=\lm^n$ es una solución de la parte homogénea de~\ref{eq:lineal_ordenk} si y sólo si $\lm^n p(\lm)=0$. La solución trivial $\lm=0$ no nos interesa, porque genera la sucesión $\{0^n\}=\{0\}$, que es cierto que pertenece a $\ker L$ pero es linealmente dependiente respecto de cualquier otra, por lo que no pertenecerá a la base. Por tanto, buscaremos las $k$ raíces del polinomio característico.

Supongamos que las $k$ raíces que encontramos son reales y además, distintas. Entonces, por el Corolario~\ref{coro:lin_indep_raices} las sucesiones generadas son linealmente independientes, y por tanto forman base de $\ker L$ y habremos calculado las soluciones de la parte homogénea de~\ref{eq:lineal_ordenk}.

\begin{ejemplo} Consideramos el PVI dado por:
    \begin{equation*}
        \text{(PVI)}\equiv \left\{
        \begin{array}{l}
            x_{n+2} + 3x_{n+1} + 2x_n = 0 \\
            x_0 = x_1 = 1
        \end{array}\right.
    \end{equation*}
    El polinomio característico asociado a dicha ecuación en diferencias es:
    \begin{equation*}
        p(\lm) = \lm^2 + 3\lm + 2 
    \end{equation*}
    Tenemos que:
    \begin{equation*}
        p(\lm)=0 \Longleftrightarrow
        \left\{\begin{array}{l}
            \lm_1=-1\\\lm_2=-2
        \end{array}\right.
    \end{equation*}
    Vemos entonces que tiene dos raíces distintas, luego $\{\lm_1^n\}$ y $\{\lm_2^n\}$ son soluciones de la ecuación, linealmente independientes por la Corolario~\ref{coro:lin_indep_raices}. Por tanto, como se trataba de una ecuación de orden 2 y $\dim \ker L=2$, tenemos que forman base del subespacio de las soluciones de la parte homogénea, $\ker L$. Por tanto, si $\{x_n\}$ es una solución de la parte homogénea, expresándolo en dicha base tendremos:
    \begin{equation*}
        x_n = a\lm_1^n + b\lm_2^n = a{(-1)}^n + b{(-2)}^n \qquad a,b\in \bb{K}
    \end{equation*}
    Para hallar los valores de $a,b$ que satisfacen el PVI, tenemos que:
    \begin{equation*}
        \left\{\begin{array}{l}
            x_0=1\\x_1=1
        \end{array}\right\}
        \Longleftrightarrow
        \left\{\begin{array}{l}
            1=a+b\\
            1 = -a-2b
        \end{array}\right\}
        \Longleftrightarrow
        \left\{\begin{array}{l}
            a=3\\
            b=-2
        \end{array}\right.
    \end{equation*}
    Por tanto, la solución única al PVI dado es:
    \begin{equation*}
        x_n = 3\cdot (-1)^n -2\cdot (-2)^n  \qquad \forall n\in \bb{N}
    \end{equation*}
\end{ejemplo}

\begin{ejemplo}
    Buscamos ahora resolver el PVI dado por:
    \begin{equation*}
        \text{(PVI)}\equiv \left\{
        \begin{array}{l}
            x_{n+2} + 3x_{n+1} + 2x_n = 6 \\
            x_0 = x_1 = 1
        \end{array}\right.
    \end{equation*}
    
    Por el ejemplo de la página \pageref{ejemplo:uso_L}, sabemos que $\{1\}$ es una solución particular. Por el ejemplo anterior, veíamos que cualquier solución de la parte homogénea es de la forma:
    \begin{equation*}
        x_n = a(-1)^n + b(-2)^n \qquad a,b\in \bb{K}
    \end{equation*}

    Como toda solución de una ecuación en diferencias no homogénea es la solución de la homogénea más una particular, deducimos que cualquier solución de la ecuación en diferencias planteada es de la forma:
    \begin{equation*}
        x_n = a{(-1)}^n + b{(-2)}^n + 1\qquad a,b\in \bb{K}
    \end{equation*}

    Para hallar los valores de $a,b$ que satisfacen el PVI, tenemos que:
    \begin{equation*}
        \left\{\begin{array}{l}
            x_0=1\\x_1=1
        \end{array}\right\}
        \Longleftrightarrow
        \left\{\begin{array}{l}
            1=a+b+1\\
            1 = -a-2b+1
        \end{array}\right\}
        \Longleftrightarrow
        \left\{\begin{array}{l}
            a=0\\
            b=0
        \end{array}\right.
    \end{equation*}
    Por tanto, la solución única al PVI dado es:
    \begin{equation*}
        x_n = 1 \qquad \forall n\in \bb{N}
    \end{equation*}
\end{ejemplo}

\subsection{Soluciones complejas}

Dado el polinomio característico de una ecuación del tipo~\ref{eq:lineal_ordenk}, estamos interesados en ver qué ocurre cuando este tiene raíces complejas. Mostramos los siguientes ejemplos como motivación:

\begin{ejemplo} Tratar de encontrar todas las soluciones de la ecuación en diferencias dada por:
    \begin{equation*}
        (PVI)\equiv \left\{ \begin{array}{l}
            x_{n+2} + x_n = 0 \\
            x_0, x_1 \text{\ dados.}
        \end{array}\right.
    \end{equation*}
    Esta ecuación tiene como polinomio característico $p(\lm) = \lm^2+1$, de raíces $\lm = \pm i$. Sabemos por tanto que la sucesión es:
    \begin{equation*}
        x_n = a\cdot i^n  + b\cdot {(-i)}^n
    \end{equation*}
    Es solución de la ecuación, para ciertos $a, b \in \bb{C}$. Tratamos ahora de encontrar dichos $a$ y $b$ solucionando el sistema:
    \begin{equation*}
        \left\{\begin{array}{l}
            x_0 = a + b \\
            x_1 = (a-b)i
        \end{array} \right.
    \end{equation*}

    Despejando $a$ en la primera ecuación y sustituyendo, tenemos:
    \begin{equation*}
        x_1 = (x_0-2b)i \Longrightarrow
        b = \frac{1}{2}\left(x_0-\frac{x_1}{i}\right)
        \Longrightarrow
        b=\frac{x_0+ix_1}{2}
        \Longrightarrow
        a = x_0-b = \frac{x_0-ix_1}{2}
    \end{equation*}
    Por tanto, cualquier solución al PVI dado es de la forma:
    \begin{equation*}
        x_n = \dfrac{x_0 - ix_1}{2}i^n + \dfrac{x_0 + ix_1}{2}{(-i)}^n
    \end{equation*}
    Sabiendo que $i^n$ es un $4-$ciclo, al multiplicarlo por una constante seguirá siendo un $4-$ciclo. Además, como la ecuación es lineal, sabemos que al sumar dos $4-$ciclos obtendremos otro $4-$ciclo, ya que la composición de aplicaciones lineales es lineal:
    \begin{equation*}
        f^4(x_n + y_n) = f^4(x_n) + f^4(y_n) = x_n + y_n
    \end{equation*}
    Por tanto, tenemos:
    \begin{align*}
        x_{4n} &= x_0\\
        x_{4n+1} &= x_1\\
        x_{4n+2} &= -\dfrac{x_0 - ix_1}{2} - \dfrac{x_0 + ix_1}{2}
        = -x_0 \\
        x_{4n+3} &= -i\dfrac{x_0 - ix_1}{2} +i \dfrac{x_0 + ix_1}{2} = i^2x_1 = -x_1
    \end{align*}  
    Notemos que, a pesar de que el término general de $\{x_n\}$ es un número complejo, si $x_0$ y $x_1$ son números reales, la solución será una sucesión real por ser $\bb{R}$ cerrado para operaciones.
\end{ejemplo}

\begin{ejemplo}
    Dada la ecuación en diferencias del ejemplo anterior, nos preguntamos qué pasa si tomamos como soluciones:
    \begin{align*}
        x_n^{(1)} &= i^n \\
        x_n^{(2)} &= {(-i)}^n
    \end{align*}
    Iterando, llegamos a que:
    \begin{align*}
        \{x_n^{(1)}\} &= \{1, i, -1, -i, 1, \ldots \} \\
        \{x_n^{(2)}\} &= \{1, -i, -1, i, 1, \ldots \}
    \end{align*}
    Ambas soluciones son un $4-$ciclo. Quedándonos con las partes real e imaginaria, tenemos:
    \begin{align*}
        \Re(\{x_n^{(1)}\}) = \{1, 0, -1, 0, 1, \ldots \} \\
        \Im(\{x_n^{(1)}\}) = \{0, 1, 0, -1, 0, \ldots \} \\
        \Re(\{x_n^{(2)}\}) = \{1, 0, -1, 0, 1, \ldots \} \\
        \Im(\{x_n^{(2)}\}) = \{0, -1, 0, 1, 0, \ldots \} 
    \end{align*}
    Notamos que las 4 sucesiones de números reales obtenidas también son soluciones a la ecuación en diferencias.
\end{ejemplo}

Recordamos que, dado un polinomio $p(x)$ con coeficientes reales, si $\lm \in \bb{C}$ es raíz de $p$, entonces $\ol{\lm}$ también es raíz de $p$.  Por tanto, siempre que $\lm\in \bb{C}$ sea raíz de un polinomio característico de una ecuación de la forma~\ref{eq:lineal_ordenk}, entonces $\{\lm^n\}$ y $\left\{\ol{\lm}^n\right\}$ serán soluciones de la ecuación en diferencias asociada al polinomio característico. Recordamos también que dado un número complejo $\lm$ con módulo $\rho$ y argumento $\theta$, podemos expresarlo en forma polar como:
\begin{align*}
    \lm &= \rho (\cos(\theta) + i\sen \theta)\\
    \ol{\lm} &= \rho (\cos(\theta) - i\sen \theta) = \rho(\cos(\theta) + i\sen(-\theta))
\end{align*}
Usando la Fórmula de Moivre, tenemos:
\begin{align*}
    \lm^n &= \rho^n (\cos(n\theta) + i\sen n\theta) \\
    \ol{\lm}^n &= \rho^n (\cos(n\theta) - i\sen(n\theta)) 
\end{align*}
Además, si $\lm = a+bi,~\ol{\lm} = a-bi$, podemos obtener su parte real y su parte imaginaria como:
\begin{align*}
    a = \Re(\lm) = \dfrac{\lm+\ol{\lm}}{2} \in \bb{R}\hspace{2cm}
    b = \Im(\lm) = \dfrac{\lm-\ol{\lm}}{2i}\in \bb{R}
\end{align*}
Por tanto, ahora consideramos las sucesiones $\{x_n\},~\{y_n\}$ siguientes, que toman valores reales puesto que $a,b\in \bb{R}$ y $\ol{\lm}^n = \ol{\lm^n}$:
\begin{align*}
    x_n = \dfrac{\lm^n+\ol{\lm}^n}{2} = \Re(\lm^n) \hspace{2cm}
    y_n = \dfrac{\lm^n-\ol{\lm}^n}{2i} = \Im(\lm^n)
\end{align*} 
Y como $\{\lm^n\}$ y $\left\{\ol{\lm}^n\right\}$ son soluciones de la ecuación en diferencias dada, entonces $\{x_n\}$ e $\{y_n\}$ son también soluciones porque son combinaciones lineales de dos soluciones. Además, estas dos son reales y linealmente independientes en el espacio de sucesiones de $\bb{C}$, luego en el de $\bb{R}$.
% // TODO: Probar que x_n y y_n son linealmente independientes.

Resumiendo, si nuestro polinomio característico tiene una raíz compleja, entonces sabemos que tiene al menos 2 y que la ecuación en diferencias asociada tiene también dos soluciones reales, que coinciden con la parte real e imaginaria de la solución dada por la raíz y que además son linealmente independientes, luego si el orden de la ecuación era 2, la tenemos resuelta.\\

Por tanto, y a modo de resumen, con un polinomio característico con coeficientes reales asociado a una ecuación en diferencias de orden 2 ocurrirán las siguientes casuísticas:
\begin{itemize}
    \item Si tiene raíces reales distintas, sabemos ya resolverlo.
    \item Si no tiene raíces reales, tendrá dos raíces complejas (conjugadas), y la parte real e imaginaria de estas formarán dos soluciones linealmente independientes.
    \item Si tiene una raíz reales con multiplicidad doble, no sabemos aún qué hacer. Lo veremos en la siguiente sección.
\end{itemize}

Por otra parte, notemos que si el polinomio característico dado tiene coeficientes complejos, no podemos asegurar que si $\lm$ es una raíz de dicho polinomio, entonces $\ol{\lm}$ también lo será, luego no podemos aplicar lo dicho. No obstante, por norma general esta situación no se nos dará en la asignatura de Modelos Matemáticos I.

\begin{ejercicio*}
    Resolver la ecuación en diferencias siguiente:
    \begin{equation*}
        \text{(PVI)}\equiv \left\{\begin{array}{l}
            x_{n+2} + x_{n+1} + x_n = 0 \\
            x_0,~x_1 \text{\ dado}
        \end{array} \right.
    \end{equation*}
    Como caso particular, emplear $x_0=x_1=1$.

    \begin{comment}

    Tenemos que su polinomio característico asociado es:
    \begin{equation*}
        p(\lm) = \lm^2 + \lm + 1
    \end{equation*}

    Sus soluciones son:
    \begin{equation*}
        \lm = \frac{-1+\sqrt{3}i}{2}
        \hspace{2cm} 
        \ol{\lm} = \frac{-1-\sqrt{3}i}{2}
    \end{equation*}

    \end{comment}
    % // TODO: Ejemplo soluciones complejas
\end{ejercicio*}

\subsection{Soluciones con multiplicidad múltiple}
A continuación, veremos qué ocurre cuando la multiplicidad es múltiple, ya que en este caso no podríamos obtener una base de $\ker L$ de forma directa. Veamos el siguiente ejemplo concreto para multiplicidad doble.
\begin{ejemplo}
    Se pide resolver la recurrencia:
    \begin{equation*}
        x_{n+2} -2 x_{n+1} + x_n = 0
    \end{equation*}

    Su polinomio característicos es:
    \begin{equation*}
        p(\lm) = \lm^2 -2\lm + 1 = {(\lm-1)}^2
    \end{equation*}
    
    Luego $\{x_n\} = \{1^n\} = \{1\}$ es solución de la ecuación. No obstante, como sabemos que $\dim \ker L=2$, nos falta otra solución linealmente independiente con $\{1\}$ para poder obtener la forma general de todas las soluciones. Nos preguntamos ahora si $\{x_n\} = \{n\}$ es solución de la ecuación:
    \begin{equation*}
        (n+2) - 2(n+1) + n = n+2-2n-2+n = 0
    \end{equation*}
    Por tanto, sí que es solución. Nos preguntamos ahora si $\{1\}$ y $\{n\}$ son linealmente independientes. La respuesta es afirmativa, luego todas las sucesiones de la ecuación se encuentran en el subespacio vectorial generado por los vectores $\{\{1\}, \{n\}\}$. Es decir, son de la forma:
    \begin{equation*}
        \{x_n\} = \{a + b\cdot n\}\qquad a,b \in \bb{K}
    \end{equation*}
\end{ejemplo}

En el ejemplo anterior, se podría decir que hemos tenido la ``suerte'' de obtener que $\{n\}$ es una solución. A continuación, vamos a razonar por qué se ha obtenido dicho valor. Para ello, recordamos el siguiente lema, cuya demostración no se incluye por ser materia de Álgebra I.
\begin{lema}
    Sea $p\in \bb{K}[x]$ un polinomio con coeficientes en $\bb{K}$. Supongamos que $\lm$ es una raíz de $p$ con multiplicidad $m$, es decir,
    \begin{equation*}
        p(x)=(x-\lm)^m q(x)     \qquad q\in \bb{K}[x]
    \end{equation*}
    Entonces, $p^{r)}(\lm)=0$ para todo $r\in \{0,\dots,m-1\}$ y $p^{m)}\neq 0$.
\end{lema}

Usando dicho lema, vamos a demostrar la siguiente proposición, que será un caso particular del Teorema~\ref{teo:soluciones_multiplicidad_multiple} para multiplicidad doble:
\begin{prop}
    Sea una ecuación lineal de orden $k$ de la forma~\ref{eq:lineal_ordenk}, y sea $\lm$ una raíz del polinomio característico con multiplicidad $2$. Entonces, $\{n\lm^n\}$ es una solución de la ecuación de la parte homogénea de dicha ecuación.
    \begin{proof}
        Tenemos que el polinomio característico de la ecuación es:
        \begin{equation*}
            p(x)=x^k+a_{k-1}x^{k-1} + \ldots + a_0
        \end{equation*}
    
        Definimos ahora el polinomio siguiente:
        \begin{align*}
            g(x) &= x^{n+k} + a_{k-1}x^{n+k-1} + \dots + a_0x^n =\\&= x^np(x)
        \end{align*}
    
        Derivando $g$, obtenemos:
        \begin{align*}
            g'(x) &= (n+k)x^{n+k-1} + a_{k-1}(n+k-1)x^{n+k-2} + \dots + a_0nx^{n-1} =\\&= nx^{n-1}p(x) + x^np'(x)
        \end{align*}
    
        Como $\lm$ es raíz de $p(x)$ con multiplicidad $2$, tenemos:
        \begin{align*}
            g'(\lm)&=(n+k)\lm^{n+k-1} + a_{k-1}(n+k-1)\lm^{n+k-2} + \dots + a_0n\lm^{n-1} =\\&= n\lm^{n-1}\cancelto{0}{p(\lm)} + \lm^n\cancelto{0}{p'(\lm)} = 0
        \end{align*}
    
        Queremos ver ahora que $\{n\lm^n\}$ es solución de la ecuación. Veamos si la verifica:
        \begin{align*}
            &(n+k)\lm^{n+k} + (n+k-1)a_{k-1}\lm^{n+k-1} + \dots + na_0\lm^{n}=\\
            &\qquad = \lm\cdot \left[(n+k)\lm^{n+k-1} + (n+k-1)a_{k-1}\lm^{n+k-2} + \dots + na_0\lm^{n-1}\right]
            = \lm \cdot 0 = 0
        \end{align*}
    
        Por tanto, $\{n\lm^n\}$ es solución.
    \end{proof}
\end{prop}

\begin{ejercicio*}
    Dada una recurrencia de orden $k$ de la forma~\ref{eq:lineal_ordenk} y $\lm\in \bb{K}$ raíz del polinomio característico con multiplicidad $2$, se pide ver si $\{q(n)\lm^n\}$ con $q$ un polinomio de grado $1$ es solución de la recurrencia.\\

    Sí, porque al ser $q$ de grado 1, tenemos que $q(n)=a+bn$ para ciertos $a,b\in \bb{K}$ y por tanto:
    \begin{equation*}
        \{q(n)\lm^n\}=\{(a+bn)\lm^n\}
        = \{a\lm^n + bn\lm^n\}
    \end{equation*}
    Como se ha visto que $\{\lm^n\},~\{n\lm^n\}$ son soluciones, una combinación lineal de ambas también lo será, por lo que $\{q(n)\lm^n\}$ es solución de la recurrencia.
\end{ejercicio*}

El teorema general es el siguiente, solo que no se incluirá la demostración por ser esta de excesiva complejidad.
% // TODO: Demostrar Teo Complicado
\begin{teo}\label{teo:soluciones_multiplicidad_multiple}
    Sea una ecuación lineal de orden $k$ de la forma~\ref{eq:lineal_ordenk}, y sea $\lm\in \bb{K}$ una raíz del polinomio característico con multiplicidad $m\in \bb{N},~m\leq k$. Entonces, $\{\lm^n\}, \{n\lm^n\}, \dots, \{n^{m-1}\lm^n\}$ son soluciones de la ecuación de la parte homogénea de dicha ecuación.
    Además, se tiene que $\{\lm^n\}, \{n\lm^n\}, \dots, \{n^{m-1}\lm^n\}$ son linealmente independientes.
\end{teo}

\subsection{Forma general de la solución de la parte homogénea}


A modo de resumen, dada una ecuación lineal de orden $k$ de la forma~\ref{eq:lineal_ordenk}, su polinomio característico lo podemos escribir como:
\begin{equation*}
    p(\lm) = \prod_{i=1}^\sigma {(\lm - \lm_i)}^{m_i}
\end{equation*}
donde $\lm_i\in \bb{K}$ $\forall i \in \{1, \ldots, \sigma\}$ es una raíz del polinomio característico, $m_i\in \bb{N}$ $\forall i \in \{1, \ldots, \sigma\}$ es su multiplicidad y $\sigma$ es el número de soluciones distintas del polinomio característico.\\

Como consecuencia de todo lo anteriormente visto, tenemos que las soluciones de la ecuación lineal~\ref{eq:lineal_ordenk} son de la forma:
\begin{equation*}
    x_n = \sum_{i=1}^\sigma f_i(n) \lm_i^n
\end{equation*}
Con cada $f_i\in \bb{K}[x]$ polinomios con $\deg(f_i)< m_i$.

\begin{comment}    
Como consecuencia, si los coeficientes $a_i$ de~\ref{eq:lineal_ordenk} son reales y existe algún \newline${\lm_t = \rho_t(\cos\theta_t + i\sen\theta_t) \in \bb{C}\setminus\bb{R}}$, entonces tenemos que $f_t(n)\cos(n\theta_t)\rho_t^n$ y\newline $f_t(n)\sen(n\theta_t)\rho_t^n$ son soluciones de la ecuación homogénea.
\end{comment}

\section{Comportamiento asintótico de las soluciones}
Introducimos la siguiente definición que, al igual que ocurría con la definición de polinomio característico de una recurrencia, se entenderá en el siguiente tema, donde generalizaremos dicha definición.
\begin{definicion}[Espectro]
    Llamamos ``espectro'' de una recurrencia al conjunto de raíces de un polinomio característico $p$ de la ecuación~\ref{eq:lineal_ordenk}, y lo notaremos por $\sigma(p)$:
    \begin{equation*}
        \sigma(p) = \{\lm \in \bb{K} \mid p(\lm) = 0\}
    \end{equation*}
    Habitualmente, notaremos por $\sigma$ al número de valores propios distintos; es decir, $\sigma=|\sigma(p)|$.
\end{definicion}
\begin{definicion}[Radio Espectral]
    Llamamos ``radio espectral'' de una recurrencia
    al máximo de los valores absolutos de los elementos de $\sigma(p)$:
    \begin{align*}
        \rho(p) :&= \max\{|\lm|\mid \lm\in \sigma(p)\}
    \end{align*}
\end{definicion}

\begin{prop}\label{prop:converger_0}
    Dada una ecuación lineal de orden $k$ de la forma~\ref{eq:lineal_ordenk} con polinomio característico $p$, se tiene que las siguientes afirmaciones son equivalentes:
    \begin{enumerate}
        \item Todas las soluciones de la ecuación homogénea tienden a 0.
        \item $\rho(p)<1$.
    \end{enumerate}
\end{prop}
\begin{proof} Demostramos por doble implicación:
    \begin{description}
        \item[$1)\Longrightarrow 2)$]
            Demostraremos el recíproco. Supongamos que $\exists \lm_i\in \sigma(p)$ con $|\lm_i|\geq 1$. Entonces, tenemos que $\{\lm_i^n\}$ es una solución, con:
            \begin{equation*}
                |\lm_i^n| = |\lm_i|^n \geq 1 \qquad \forall n
            \end{equation*}
            Por tanto, tenemos que no es posible que $\{\lm_i^n\}$ converja a 0.

        \item[$2)\Longrightarrow 1)$] Como hemos visto, todas las soluciones son de la forma:
        \begin{equation*}
            x_n = \sum_{i = 1}^{|\sigma(p)|} f_i(n) \lm_i^n
        \end{equation*}
        Tomando módulos, tenemos que:
        \begin{equation*}
            |x_n| = \left|\sum_{i = 1}^{|\sigma(p)|} f_i(n) \lm_i^n\right| \leq  \sum_{i = 1}^{|\sigma(p)|} |f_i(n)| |\lm_i^n|
            = \sum_{i = 1}^{|\sigma(p)|} |f_i(n)| |\lm_i|^n
            \leq \rho(p)^n\sum_{i = 1}^{|\sigma(p)|} |f_i(n)|
        \end{equation*}

        Ahora, para cada $i\in \{1,\dots,\sigma\}$, tenemos que $f_i\in \bb{K}[n]$ con $\deg f_i<m\leq k$. Por tanto, y usando la notación $O$ grande usual en Algorítmica\footnote{Debido a que estos ejercicios están orientados a alumnos del Doble Grado en Ingeniería Informática y Matemáticas, se presupone conocida esta notación. En caso contrario, se ha de probar que dado un polinomio $f\in \bb{K}[x]$ de grado $n$, existe una constante $C\in \bb{R}^+$ tal que $|f(x)|\leq C\cdot x^n$ para todo $x\geq 1$.}, tenemos que $f_i\in O(n^{k-1})$, por lo que $\exists C_i\in \bb{R}^+$ tal que $|f_i(n)|\leq C_i\cdot n^{k-1}$ para todo $n\in \bb{N}$.
        Por tanto, tenemos que:
        \begin{equation*}
            0\leq |x_n|\leq n^{k-1}\rho(p)^n\cdot \sum_{i = 1}^{|\sigma(p)|} C_i
        \end{equation*}
        Como $\{n^{k-1}\rho(p)^n\}\to 0$ por ser $\rho(p)\in [0,1[$, se tiene que $\{x_n\}\to 0$.
    \end{description}
\end{proof}

La utilidad de esta proposición no es tanto calcular las raíces y luego aplicarla, sino aplicarla sin incluso conocer las raíces. Esto se debe a que existen diversos criterios que nos informan sobre este hecho, como el siguiente (válido para polinomios de grado $2$):
\begin{lema}\label{lema:raices_orden2}
    Sea $p(\lm) = \lm^2 + a_1\lm + a_0$ con $a_0, a_1\in \bb{R}$ y sean $\lm_1$, $\lm_2\in \bb{C}$ las raíces de $p$. Entonces, se tiene que:
    \begin{equation}\label{eq:cond_lema_raices}
        |\lm_1|,~|\lm_2| < 1 \Longleftrightarrow \left\{\begin{array}{lcl}
            p(1) > 0 & \Longleftrightarrow & 1 + a_1 + a_0 > 0 \\
            p(-1) > 0 & \Longleftrightarrow  &1-a_1 + a_0 > 0 \\
            p(0) < 1 & \Longleftrightarrow & a_0 < 1 
        \end{array}\right.
    \end{equation}

    \begin{proof}
    Si $\lm_1$ y $\lm_2$ son raíces de $p$, entonces: 
    \begin{equation*}
        p(\lm) = (\lm - \lm_1)(\lm - \lm_2) = \lm^2 - (\lm_1 + \lm_2)\lm + \lm_1\lm_2
    \end{equation*}
    Por tanto, concluimos que $\lm_1\lm_2 = a_0$.
    \begin{description}
        \item[$\Longrightarrow)$] Supongamos que $|\lm_1| < 1$ y que $|\lm_2| < 1$:
        \begin{equation*}
            |a_0| = |\lm_1||\lm_2| = |\lm_1\lm_2| < 1 \Longrightarrow a_0 < 1 \Longrightarrow p(0) < 1
        \end{equation*}

        Veamos ahora que $p(1),p(-1)>0$ mediante contradicciones.
        \begin{itemize}
            \item Supongamos que $p(1) \leq 0$. Como la parábola es convexa, tenemos que $\lim\limits_{\lm\to \infty}p(\lm)=\infty$. Por tanto, por el Teorema de los Ceros de Bolzano, $\exists \lm\in [1,+\infty[$ tal que $p(\lm)=0$. No obstante, es una contradicción, ya que todas las raíces del polinomio cumplen que $|\lm|<1$.
            
            \item Supongamos que $p(-1) \leq 0$. Como la parábola es convexa, tenemos que $\lim\limits_{\lm\to -\infty}p(\lm)=\infty$. Por tanto, por el Teorema de los Ceros de Bolzano, $\exists \lm\in ]-\infty, -1]$ tal que $p(\lm)=0$. No obstante, es una contradicción, ya que todas las raíces del polinomio cumplen que $|\lm|<1$.
        \end{itemize}

        \item[$\Longleftarrow)$] Por el Teorema Fundamental del Álgebra, sabemos que $p$ tiene dos raíces; sean estas $\lm_1,\lm_2\in \bb{C}$. Distinguimos en función de si son reales o complejas:
        \begin{itemize}
            \item Si $\lm_1 \in \bb{C}\setminus\bb{R}$, tenemos que $\lm_2 = \ol{\lm_1}$, de donde:
            \begin{equation*}
                a_0 = \lm_1\lm_2 = \lm_1\ol{\lm_1} = |\lm_1|^2 < 1 \Longrightarrow |\lm_1|< 1 \land |\lm_2| < 1
            \end{equation*}
            \item Si $\lm_1$, $\lm_2 \in \bb{R}$:

            Sabemos que $\lm_1\lm_2 = a_0 < 1$. Además, tenemos que:
            \begin{equation*}
                \left\{\begin{array}{l}
                    p(1) = 1 + a_1 + a_0 > 0 \\
                    p(-1) = 1 - a_1 + a_0 > 0
                \end{array}\right.
            \end{equation*}
            Sumando, tenemos que $2+2a_0>0\sii a_0>-1$, de lo que deducimos que $|a_0|<1$. Por tanto, tenemos que:
            \begin{equation*}
                |a_0| = |\lm_1\lm_2| = |\lm_1|\cdot |\lm_2|<1
            \end{equation*}

            Por tanto, al menos una raíz tiene módulo menor que 1. Supongamos sin pérdida de generalidad que es $\lm_1$; es decir, $|\lm_1| < 1$.
            \begin{figure}[H]
                \centering
                \begin{tikzpicture}[scale=1.5]
                    % Ejes
                    \draw[-stealth] (-1.5,0) -- (1.5,0) node[right] {$x$};
                    \draw[-stealth] (0,-0.5) -- (0,1.7) node[above] {$y$};
                    
                    % Puntos
                    \filldraw (-1,0.5) circle (1pt) node[above left] {$p(-1)$};
                    \filldraw (1,1.2) circle (1pt) node[above right] {$p(1)$};
                    
                    \filldraw (-0.4,0) circle (1pt) node[below] {$\lm_1$};
                    \filldraw (-1,0) circle (1pt) node[below] {$-1$};
                    \draw[dashed] (-1,0) -- (-1,0.5);
                    \filldraw (1,0) circle (1pt) node[below] {$1$};
                    \draw[dashed] (1,0) -- (1,1.2);
                \end{tikzpicture}
            \end{figure}

            Por los valores que toma la parábola $p$ en las abscisas $-1,\lm_1,1$, deducimos que se produce un cambio de monotonía en el intervalo $]-1,1[~$. Por tanto, respecto de su monotonía tenemos:
            \begin{itemize}
                \item \ul{Si $\lm\leq -1$}: Tenemos que $p$ es estrictamente decreciente, por lo que $p(\lm)\geq p(-1)>0$. Por tanto, $\lm_2$ no pertenece a este intervalo.
                \item \ul{Si $\lm\geq 1$}: Tenemos que $p$ es estrictamente creciente, por lo que $p(\lm)\geq p(1)>0$. Por tanto, $\lm_2$ no pertenece a este intervalo.
            \end{itemize}
            Por tanto, deducimos que $\lm_2\in~]-1,1[$, y por tanto también llegamos a que $|\lm_2|<1$.
        \end{itemize}
    \end{description}
\end{proof}
\end{lema}

\begin{coro}
    Como consecuencia, si $\{x_n\}$ es solución de una ecuación lineal de orden $2$ y se cumplen las tres condiciones del Lema~\ref{lema:raices_orden2}, de la Proposición~\ref{prop:converger_0} deducimos que $\{x_n\} \rightarrow \{0\}$.
\end{coro}

A continuación, estudiaremos aplicaciones de las ecuaciones en diferencias lineales a la economía. Vamos a ver dos modelos que describen la evolución de la renta de un país, el primero de orden 1 (Modelo del efecto multiplicador) y el segundo de orden 2 (Modelo de Samuelson).
\section{Modelo del efecto multiplicador}
El siguiente modelo macro-económico incluye las siguientes magnitudes:
\begin{itemize}
    \item $Y$ representa la renta nacional.
    \item $C$ el consumo privado (de empresas o particulares).
    \item $I$ representa la inversión (puede ser privada, pública, \ldots)
\end{itemize}
Las hipótesis que se consideran en este modelo son:
\begin{itemize}
    \item Suponemos que se gasta toda la renta en el consumo y la inversión.
    \item Suponemos que no hay déficits.
    \item Suponemos también que la inversión $I$ es constante, $I\in \bb{R}^+$.
\end{itemize}

\begin{description}
    \item[Modelo estático]~\\
    En este caso, el consumo privado, $C\in \bb{R}^+$, es constante también, por lo que:
    \begin{equation*}
        Y = C+I\hspace{1cm} C,I\in \bb{R}^+
    \end{equation*}

    Esto implica que la renta no cambia a lo largo del tiempo, se mantiene de igual forma constante. Notemos que este modelo no tiene gran interés.
    
    \item[Modelo dinámico]~\\    
    Sea $n$ el número de unidades temporales (posiblemente años, o meses), y buscamos obtener la renta nacional de cada etapa. En este caso, el consumo $C_n$ es lineal en función de la renta:
    \begin{equation*}
        C_n = \alpha Y_{n-1}+a,\hspace{2cm} a\in \bb{R}^+,~\alpha\in ]0,1[
    \end{equation*}
    La marginal $\alpha$ indica la tendencia al gasto (qué porcentaje de la renta gastamos), mayor cuanto más cercano es el valor de $\alpha$ a $1$. La renta nacional de cada etapa queda:
    \begin{equation}\label{eq:modelo_multiplicador_dinamico}
        Y_n = C_n + I_n = \alpha Y_{n-1} + a +I \hspace{1cm} a,I\in \bb{R}^+,~\alpha\in ]0,1[
    \end{equation}
\end{description}

\subsection{Soluciones del modelo}
Buscamos ahora las soluciones del modelo del efecto multiplicador dinámico. Primero, resolvemos la ecuación homogénea:
$$Y_n^{(h)} = \alpha^n Y_0^{(h)}$$

Posteriormente, buscamos una solución particular de~\ref{eq:modelo_multiplicador_dinamico}. La forma más fácil es buscar una solución constante $Y_e$:
\begin{equation*}
    Y_e = \alpha Y_e + a + I \Longleftrightarrow Y_e = \dfrac{a+I}{1-\alpha} = \dfrac{a}{1-\alpha} + \dfrac{I}{1-\alpha}
\end{equation*}

De esta forma, todas las soluciones del modelo son de la forma:
\begin{equation*}
    Y_n = \alpha^n Y_0^{(h)} + \dfrac{a+I}{1-\alpha}
\end{equation*}
Si conocemos $Y_0$, la evolución de la renta viene dada por:
\begin{equation*}
    Y_n = (Y_0 - Y_e)\alpha^n+ Y_e \qquad \text{con}\quad Y_e = \dfrac{a+I}{1-\alpha}
\end{equation*}
Por ser $\alpha \in~]0,1[$, tenemos que $\lim\limits_{n\to \infty} Y_n = Y_e$.\\

Como $0<\alpha<1$, tenemos que $1 < \frac{1}{1-\alpha}$ por lo que $Y_e>I$. Por tanto, a largo plazo tendremos una renta mayor que la inversión realizada, produciéndose un efecto ``multiplicador''. De aquí viene el nombre del modelo.

\section{Modelo de Samuelson}
También llamado modelo del efecto acelerador/desacelerador, se trata de una modificación del modelo del efecto multiplicador. Parte de las mismas premisas pero en este caso se supone que la inversión no es constante, y que está dividida en inversión pública y privada:
\begin{equation*}
    I = I_{\text{pública}} + I_{\text{privada}}
\end{equation*}
\begin{itemize}
    \item La inversión pública (también llamada gasto) se supone constante:
    \begin{equation*}
        I_{\text{pública}} = G\in \bb{R}^+
    \end{equation*}
    \item La inversión privada viene dada por:
    \begin{equation*}
        I_{\text{privada}_n} = \beta (C_n - C_{n-1}) \qquad \beta \in \bb{R}^+
    \end{equation*}
    De esta forma, si el producto fue rentable en el año anterior y el consumo aumentó, la inversión aumenta (se acelera). Por otra parte, la inversión disminuye (desacelera) si el consumo disminuyó. El valor $\beta$ se conoce como \emph{coeficiente acelerador}.
\end{itemize}
De esta forma, tenemos que la inversión es:
\begin{equation*}
    I_n = I_{\text{pública}} + I_{\text{privada}_n} =  G + \beta(C_n - C_{n-1}) \qquad G,\beta \in \bb{R}^+
\end{equation*}
El consumo, no obstante, no cambia respecto del modelo anterior.
\begin{equation*}
    C_n = \alpha Y_{n-1} + a \qquad a\in \bb{R}^+ \quad \alpha \in~]0,1[
\end{equation*}
Escribimos la ecuación del modelo:
\begin{align*}
    Y_n &= C_n + I_n \\
    &= \alpha Y_{n-1} + a + G + \beta (C_n - C_{n-1}) \\
    &= \alpha Y_{n-1} + a + G + \beta (\alpha Y_{n-1} + \cancel{a} - \alpha Y_{n-2} - \cancel{a}) \\
    &= \alpha Y_{n-1} + a + G + \beta\alpha Y_{n-1} - \beta \alpha Y_{n-2} \\
    &= \alpha (\beta + 1) Y_{n-1}- \beta\alpha Y_{n-2} + a + G
\end{align*}
Muchos autores simplifican la parte constante $G + a$, llamándole $G$ (entendiendo que engloba al gasto más la constante $a$). De esta forma, la ecuación del modelo de Samuelson nos queda:
\begin{equation}\label{eq:samuelson}
    Y_n = \alpha(\beta + 1) Y_{n-1} - \alpha\beta Y_{n-2} + G
\end{equation}
Una ecuación de orden 2, que puede escribirse también de la forma:
\begin{equation*}
    Y_{n+2} = \alpha(\beta + 1) Y_{n+1} - \alpha\beta Y_{n} + G
\end{equation*}

\subsection{Soluciones del modelo}
Comenzamos pues buscando primero una solución particular de la ecuación~\ref{eq:samuelson}. Suponemos que existe una solución constante $Y_e$ y procedemos a calcularla:
\begin{align*}
    Y_e &= \alpha(\beta +1)Y_e - \alpha\beta Y_e + G \\
        &= \alpha Y_e (\beta + 1 -\beta) + G \\
        &= \alpha Y_e + G
\end{align*}
Por tanto, la solución constante tenemos que es:
\begin{equation*}
    Y_e = \dfrac{G}{1-\alpha}
\end{equation*}

A continuación, resolvemos la parte homogénea de~\ref{eq:samuelson}:
\begin{equation*}
    Y_n = \alpha(1+\beta)Y_{n-1} - \alpha\beta Y_{n-2}
\end{equation*}
Su polinomio característico es:
\begin{equation*}
    p(\lm) = \lm^2 - \alpha(1+\beta)\lm + \alpha\beta
\end{equation*}
Buscamos aplicar el Lema~\ref{lema:raices_orden2}, para evitar calcular las raíces de $p$:
\begin{align*}
    p(1) &=  1-\alpha(1+\beta) + \alpha\beta = 1 - \alpha > 0\\
    p(-1) &= 1 + \alpha(1+\beta)+\alpha\beta > 0 \\
    p(0) &= \alpha\beta
\end{align*}
Aplicando dicho Lema, tenemos que:
\begin{itemize}
    \item Si $\alpha\beta < 1$, entonces las soluciones de la parte homogénea tienden a cero, de donde cualquier solución de~\ref{eq:samuelson} tiende a la solución de equilibrio $Y_e = \frac{G}{1-\alpha}$.
    \item Si $\alpha\beta \geq 1$, entonces $Y_e$ no es atractor, puesto que las soluciones de la parte homogénea no tenderán a $0$.
\end{itemize}