\documentclass[12pt]{article}

\input{../../_assets/preambulo.tex}
\usepgfplotslibrary{fillbetween}
\DeclareMathOperator{\Var}{Var}
\DeclareMathOperator{\Cov}{Cov}
\begin{document}

    % 1. Foto de fondo
    % 2. Título
    % 3. Encabezado Izquierdo
    % 4. Color de fondo
    % 5. Coord x del titulo
    % 6. Coord y del titulo
    % 7. Fecha

    
    \input{../../_assets/portada}
    \portadaExamen{ffccA4.jpg}{Probabilidad\\Examen V}{Probabilidad. Examen V}{MidnightBlue}{-8}{28}{2024-2025}{Arturo Olivares Martos \\ José Juan Urrutia Milán}

    \begin{description}
        \item[Asignatura] Probabilidad.
        \item[Curso Académico] 2021-22.
        \item[Grado] Doble Grado en Ingeniería Informática y Matemáticas.
        \item[Grupo] Único.
        %\item[Profesor] José María Espinar García.
        \item[Descripción] Examen Ordinario 
        \item[Fecha] 21 de enero de 2022.
        % \item[Duración] 60 minutos.
    
    \end{description}
    \newpage

    \subsection*{PARTE 1 (2.5 puntos)}
    \begin{ejercicio}[0.25 puntos]
        Sean $X_1$, $X_2$, $X_3$ variables aleatorias independientes e idénticamente distribuidas según una ley Binomial, $B(3,\nicefrac{1}{2})$. Justificar que: $$P[X_1 + X_2 + X_3 = 8] = \frac{9}{2^9} $$
            
        Tenemos que:
        \begin{equation*}
            X_1, X_2,X_3 \sim B(3, \nicefrac{1}{2}) 
        \end{equation*}

        Por la reproductividad de la distribución binomial, como son independientes, tenemos que:
        \begin{equation*}
            X_1 + X_2+X_3 \sim B(9, \nicefrac{1}{2})
        \end{equation*}

        Por tanto, usando la función masa de probabilidad de la distribución binomial, tenemos que:
        \begin{equation*}
            P[X_1 + X_2 + X_3 = 8] = \binom{9}{8} \left(\frac{1}{2}\right)^8 \left(\frac{1}{2}\right)^1 = \frac{9}{2^9}
        \end{equation*}
    \end{ejercicio}

    \begin{ejercicio}[0.25 puntos]
        Sean $X_1$ y $X_2$ variables aleatorias independientes e idénticamente distribuidas según una ley de Poisson, $\cc{P}(3)$. Justificar que:
        $$P[X_1 + X_2 > 0] = \frac{e^6 - 1}{e^6}$$

        Tenemos que:
            \begin{equation*}
                X_1, X_2 \sim \cc{P}(3)
            \end{equation*}

            Por la reproductividad de la distribución de Poisson, por ser independientes tenemos que:
            \begin{equation*}
                X_1 + X_2 \sim \cc{P}(6)
            \end{equation*}

            Por tanto, tenemos que:
            \begin{equation*}
                P[X_1 + X_2> 0] = 1 - P[X_1 + X_2= 0] = 1 - \frac{e^{-6}6^0}{0!} = 1 - e^{-6} = \frac{e^6 - 1}{e^6}
            \end{equation*}
    \end{ejercicio}

    \begin{ejercicio}
        Para predecir los valores de una variable aleatoria $X$ a partir de los de otra variable aleatoria $Y$ se considera un modelo lineal:
        \begin{enumerate}
            \item \textbf{(0.50 puntos)} Obtener de forma razonada los coeficientes del modelo lineal considerado.
            
            Se busca aproximar $X$ como $\wh{X}=aY+b$. Para ello, se minimiza el error cuadrático medio:
            \begin{align*}
                \text{E.C.M.}(X\mid Y) &= E[(X-\wh{X})^2]
                = E\left[(X-aY-b)^2\right]
                =\\&= E\left[X^2-2aXY-2bX+a^2Y^2+2abY+b^2\right]
                =\\&= E[X^2]-2aE[XY]-2bE[X]+a^2E[Y^2]+2abE[Y]+b^2
            \end{align*}

            Para ello, se busca minizar la siguiente función:
            \begin{equation*}
                L(a,b) = E.C.M.(X\mid Y) = E[X^2]-2aE[XY]-2bE[X]+a^2E[Y^2]+2abE[Y]+b^2
            \end{equation*}

            Se tiene demostrado en Teoría que llegamos a la siguiente expresión (donde además, demostramos que se trata de un mínimo):
            \begin{equation*}
                \begin{cases}
                    a = \dfrac{\Cov[X,Y]}{\Var[Y]} \\
                    b = E[X]-aE[Y]
                \end{cases}
            \end{equation*}

            \item \textbf{(0.75 puntos)} Si $x-y=1$ y $2y-3x=-1$ son las dos rectas de regresión para el vector $(X,Y)$, se pide: identificar la recta de regresión del apartado anterior; obtener una medida de la bondad del ajuste y calcular la esperanza del vector $(X,Y)$.
            
            Suponemos que las rectas de regresión de $X$ sobre $Y$ y de $Y$ sobre $X$ son $x-y=1$ y $2y-3x=-1$, respectivamente. Por tanto, tenemos que:
            \begin{align*}
                x &= y+1 = \dfrac{\Cov[X,Y]}{\Var[Y]}\cdot y + E[X]-\dfrac{\Cov[X,Y]}{\Var[Y]}\cdot E[Y] \\
                y &= \dfrac{3}{2}x-\dfrac{1}{2} = \dfrac{\Cov[X,Y]}{\Var[X]}\cdot x + E[Y]-\dfrac{\Cov[X,Y]}{\Var[X]}\cdot E[X]
            \end{align*}

            Identificando términos, obtenemos que:
            \begin{equation*}
                \dfrac{\Cov[X,Y]}{\Var[X]}\cdot \dfrac{\Cov[X,Y]}{\Var[Y]} = \rho_{X,Y}^2 = 1\cdot \dfrac{3}{2} = \dfrac{3}{2}>1
            \end{equation*}

            Por tanto, llegamos a una contradicción, por lo que la suposición es incorrecta. La recta de regresión de $Y$ sobre $X$ es $y=x-1$ y la de $X$ sobre $Y$ es $x=\nicefrac{2}{3}y+\nicefrac{1}{3}$.

            La proporción de varianza de cada variable que queda explicada por el modelo de regresión lineal es el coeficiente de determinación, que en este caso es:
            \begin{equation*}
                \rho_{X,Y}^2 = \dfrac{2}{3}\cdot 1=\dfrac{2}{3}\approx 66.667\%
            \end{equation*}

            Por último, por identificación de términos, tenemos el siguiente sistema:
            \begin{equation*}
                \left\{\begin{array}{rcl}
                    E[Y]-E[X]&=&-1 \\
                    E[X]-\dfrac{2}{3}E[Y]&=&\dfrac{1}{3}
                \end{array}\right\}
                \Longrightarrow
                \begin{cases}
                    E[X]=-1 \\
                    E[Y]=-2
                \end{cases}
            \end{equation*}

            Por tanto, tenemos que:
            \begin{equation*}
                E[(X,Y)] = \begin{pmatrix}
                    -1 & -2
                \end{pmatrix}
            \end{equation*}
        \end{enumerate}
    \end{ejercicio}

    \begin{ejercicio}[0.75 puntos]
        Las componentes de un vector aleatorio continuo son variables aleatorias continuas. Sin embargo, en general, un conjunto de variables aleatorias continuas no da lugar a un vector aleatorio continuo. Justificar que este recíproco sí es cierto si consideramos un conjunto $X_1$, $X_2$, \ldots, $X_n$ de variables aleatorias continuas independientes.

        Definimos la siguiente función continua en $\bb{R}^n$:
        \Func{f_{(X_1,X_2,\ldots,X_n)}}{\bb{R}}{\bb{R}}{(x_1,x_2,\ldots,x_n)}{
            \prod\limits_{i=1}^n f_{X_i}(x_i)
        }
        y probaremos que es la función de densidad de $(X_1,X_2,\ldots,X_n)$. En primer lugar, está bien definida por estarlo cada una de las funciones de densidad de las variables aleatorias. Veamos que:
        \begin{align*}
            F_{(X_1,X_2,\ldots,X_n)}(x_1,x_2,\ldots,x_n) &= \int_{-\infty}^{x_1}\cdots\int_{-\infty}^{x_n} \prod\limits_{i=1}^n f_{X_i}(t_i) \,dt_1\cdots dt_n
        \end{align*}

        Para ello, como son independientes, tenemos que:
        \begin{equation*}
            P[X_1\leq x_1, X_2\leq x_2, \ldots, X_n\leq x_n] = \prod\limits_{i=1}^n P[X_i\leq x_i]
        \end{equation*}

        Por ser $f_{X_i}$ la función de densidad de $X_i$, tenemos que:
        \begin{equation*}
            F_{(X_1,X_2,\ldots,X_n)}(x_1,x_2,\ldots,x_n) = \prod\limits_{i=1}^n \int_{-\infty}^{x_i} f_{X_i}(t_i) \,dt_i
        \end{equation*}

        Por tanto, tenemos que la función que hemos definido efectivamente es la función de densidad de $(X_1,X_2,\ldots,X_n)$.\\

        Aunque no sería necesario, veamos que cumple las condiciones de toda función de densidad. En primer lugar, es no negativa, ya que cada término es mayor o igual que $0$. Veamos ahora que integra $1$:
        \begin{align*}
            \int_{\bb{R}^n} f_{(X_1,X_2,\ldots,X_n)}(x_1,x_2,\ldots,x_n) \,dx_1\cdots dx_n &= \int_{\bb{R}^n} \prod\limits_{i=1}^n f_{X_i}(x_i) \,dx_1\cdots dx_n
            =\\&= \prod\limits_{i=1}^n \int_{\bb{R}} f_{X_i}(x_i) \,dx_i
            = \prod\limits_{i=1}^n 1
            = 1
        \end{align*}
    \end{ejercicio}

    \subsection*{PARTE 2 (7.5 puntos)}
    \setcounter{ejercicio}{0}
    \begin{ejercicio}[5 puntos]
        Dado el vector aleatorio continuo $(X,Y)$ distribuido uniformemente en el recinto
        \begin{equation*}
            C = \{(x,y)\in \mathbb{R}^2 \mid x^2+y^2 < 1 \ \land\ x,y < 0\}
        \end{equation*}

    \begin{observacion}
        A tener en cuenta:
        \begin{itemize}
            \item En el \textbf{apartado 1.2} se obtiene \textbf{hasta 1 punto} si las integrales se dejan indicadas y \textbf{hasta 1.5 puntos} si se obtienen sus primitivas de forma explícita.
            \item Si necesitara obtener la primitiva de la función $f(x) = \sqrt{1-x^2}$, realizar el cambio de variable unidimensional $x=\sen(t)$.
            \item $\arcsen(0)=0$, $\arcsen(-1)=-\frac{\pi}{2}$, $\arcsen\left(-\frac{1}{\sqrt{2}}\right) = -\frac{\pi}{4}$.
            \item $\cos^2(x) = \frac{1+\cos(2x)}{2}$, $\sen^2(x) = \frac{1-\cos(2x)}{2}$.
        \end{itemize}
    \end{observacion}
\begin{enumerate}
    \item \textbf{(0.25 puntos)} Obtener la función de densidad conjunta.
    
    En primer lugar, y debido a que lo usaremos con mucha frecuencia, resolveremos la siguiente integral de forma genérica. Dados $a,b\in \left[0,1\right], a<b$, resolveremos la siguiente integral:
    \begin{align*}
        \int_{a}^{b} \sqrt{1-x^2} \, dx
    \end{align*}

    Haciendo el cambio de variable $x=\sen(t)$, tenemos que:
    \begin{align}\label{eq:primitiva}
        \int_{a}^{b} \sqrt{1-x^2} \, dx &= \int_{\arcsen(a)}^{\arcsen(b)} \cos(t)\cos(t) \, dt
        = \int_{\arcsen(a)}^{\arcsen(b)} \cos^2(t) \, dt
        =\\\notag&= \int_{\arcsen(a)}^{\arcsen(b)} \dfrac{1+\cos(2t)}{2} \, dt
        = \dfrac{1}{2}\int_{\arcsen(a)}^{\arcsen(b)} 1+\cos(2t) \, dt
        =\\\notag&= \dfrac{1}{2}\left[t+\dfrac{\sen(2t)}{2}\right]_{\arcsen(a)}^{\arcsen(b)}
        =\\\notag&= \dfrac{1}{2}\left[\arcsen(b)-\arcsen(a)+\dfrac{\sen(2\arcsen(b))}{2}-\dfrac{\sen(2\arcsen(a))}{2}\right]
        =\\\notag&= \dfrac{1}{2}\left[\arcsen(b)-\arcsen(a)+\dfrac{2b\sqrt{1-b^2}}{2}-\dfrac{2a\sqrt{1-a^2}}{2}\right]
        \AstIg\\\notag&\AstIg \dfrac{1}{2}\left[\arcsen(b)-\arcsen(a)+b\sqrt{1-b^2}-a\sqrt{1-a^2}\right]
    \end{align}
    donde en ($\ast$) hemos empleado, en primer lugar, el seno del ángulo doble, por lo que:
    \begin{align*}
        \sen(2\arcsen(x)) &= 2\sen(\arcsen(x))\cos(\arcsen(x))
        = 2x\sqrt{1-x^2}
    \end{align*}
    y ahí hemos empleado el valor de $\cos(\arcsen(x))$. Como $\arcsen(x)\in \left[-\nicefrac{\pi}{2},\nicefrac{\pi}{2}\right]$, su coseno es positivo. Por tanto:
    \begin{align*}
        \cos(\arcsen(x)) &= \sqrt{1-\sen^2(\arcsen(x))} = \sqrt{1-x^2}
    \end{align*}

    Una vez hecha esta integral (que usaremos en varios casos), procedemos con el ejercicio.
    Veamos en primer lugar la forma de $C$, que se muestra en la Figura~\ref{fig:recinto}.
    \begin{figure}
        \centering
        \begin{tikzpicture}
            \begin{axis}[
                axis lines = center,
                xlabel = $X$,
                ylabel = $Y$,
                xmin = -1.5, xmax = 0.5,
                ymin = -1.5, ymax = 0.5,
                xtick = {-1,0},
                ytick = {-1,0},
                axis equal,
            ]
                % R2: Cuarto de circunferencia
                \addplot [name path=A, blue, thick, forget plot, samples=70, domain=-1:0] {-sqrt(1-x^2)};
                
                % Dibuja la línea horizontal en y=0
                \addplot [name path=B, forget plot, draw=none] {0};

                % Dibuja la línea horizontal en y=-1
                \addplot [name path=C, forget plot, draw=none] {-1};
            
                % Rellena el área bajo la curva entre x=0 y x=1
                \addplot [
                    thick,
                    color=orange,
                    fill=orange,
                    fill opacity=0.4
                ]
                fill between [
                    of=B and A,
                    soft clip={domain=-1:0},
                ];
                
                % Señalamos zona R1
                \node at (-0.4, -0.4) {$R_1~(C)$};


                % R0
                \addplot[fill=teal, opacity=0.4, draw=none] coordinates {
                    (-1,-1) (-1,2) (-3,2) (-3,-3) (2,-3) (2,-1)
                } --cycle;
                \addplot [
                    thick,
                    color=teal,
                    fill=teal,
                    fill opacity=0.4,
                ]
                fill between [
                    of=A and C,
                    soft clip={domain=-1:0},
                ];
                \node at (-1, -1) {$R_0$};

                % R2
                \addplot[fill=red, opacity=0.2] coordinates {
                    (-1,0) (-1,2) (0,2) (0,0)
                } --cycle;
                \node at (-0.5, 0.25) {$R_2$};

                \addplot[fill=blue, opacity=0.2] coordinates {
                    (0, 0) (2,0) (2,-1) (0,-1)
                } --cycle;
                \node at (0.25, -0.5) {$R_3$};

                \addplot[fill=green, opacity=0.2] coordinates {
                    (0,0) (0,2) (2,2) (2,0)
                } --cycle;
                \node at (0.25, 0.25) {$R_4$};
            \end{axis}
        \end{tikzpicture}
        \caption{Recinto $C$.}
        \label{fig:recinto}
    \end{figure}
    
    La función de densidad conjunta es constante, por lo que:
    \begin{equation*}
        f(x, y) = \begin{cases}
            k, & (x, y) \in C \\
            0, & \text{en otro caso}.
        \end{cases}
    \end{equation*}

    Para que $f$ sea una función de densidad, tenemos que:
    \begin{align*}
        1&=\int_{-\infty}^{+\infty} \int_{-\infty}^{+\infty} f(x, y) \, dx \, dy
    \end{align*}

    Hay dos opciones:
    \begin{description}
        \item[Integrando de la forma usual:]
        
        Es necesario que:
        \begin{equation*}
            1=\int_{-1}^{0} \int_{-\sqrt{1-x^2}}^0 k \, dy \, dx = k\int_{-1}^{0} \sqrt{1-x^2} \, dx
            \stackrel{\eqref{eq:primitiva}}{=} \dfrac{k}{2}\left[0+\frac{\pi}{2}\right] = \dfrac{k\pi}{4} \Longrightarrow k=\dfrac{4}{\pi}.
        \end{equation*}

        \item[Razonando la forma de $C$:]
        
        Sabemos que $C$ es un cuarto de círculo de radio 1, por lo que su área es $\nicefrac{\pi}{4}$. Por tanto, tenemos que:
        \begin{equation*}
            1=\int_C f(x, y) = k\int_C 1 = k\cdot \lm(C) = k\cdot \dfrac{\pi}{4} \Longrightarrow k=\dfrac{4}{\pi}.
        \end{equation*}
    \end{description}
    
    \item \textbf{(1.50 puntos)} Obtener la función de distribuición de probabilidad conjunta.
    
    Distinguimos en función de los valores de $(x, y)$:
    \begin{itemize}
        \item \ul{Si $(x,y)\in R_0$:} ($x<-1$ o $y<-1$ o $-1<x,y<0$,$x^2+y^2\geq 1$)
        \begin{align*}
            F_{(X,Y)}(x, y) &= \int_{-\infty}^x \int_{-\infty}^y f_{(X,Y)}(u, v) \, dv \, du = 0
        \end{align*}

        \item \ul{Si $(x,y)\in R_1$:} ($-1<x,y<0$ y $x^2+y^2<1$)        
        \begin{align*}
            F_{(X,Y)}(x, y) & 
            = \int_{-\sqrt{1-y^2}}^x \int_{-\sqrt{1-u^2}}^y \dfrac{4}{\pi} \, dv \, du
            = \dfrac{4}{\pi} \int_{-\sqrt{1-y^2}}^x y+\sqrt{1-u^2} \, du
            \stackrel{\eqref{eq:primitiva}}{=}\\&\stackrel{\eqref{eq:primitiva}}{=} \dfrac{4}{\pi} \left[\left[yu\right]_{-\sqrt{1-y^2}}^x + \dfrac{1}{2}\left[\arcsen(x)-\arcsen\left(-\sqrt{1-y^2}\right)+\right.\right.
            \\&\qquad\qquad +\left.\left.x\sqrt{1-x^2}+\sqrt{1-y^2}\sqrt{1-1+y^2}\right]\right]
            =\\&= \dfrac{4}{\pi} \left[yx +y\sqrt{1-y^2} + \dfrac{1}{2}\left[\arcsen(x)-\arcsen\left(-\sqrt{1-y^2}\right)+\right.\right.
            \\&\qquad\qquad +\left.\left.x\sqrt{1-x^2}-y\sqrt{1-y^2}\right]\right]
            =\\&= \dfrac{4}{\pi} \left[yx + \dfrac{y\sqrt{1-y^2}}{2} + \dfrac{1}{2}\left[\arcsen(x)-\arcsen\left(-\sqrt{1-y^2}\right)+x\sqrt{1-x^2}\right]\right]
            =\\&= \dfrac{2}{\pi} \left[2xy + y\sqrt{1-y^2} + \arcsen(x)+\arcsen\left(\sqrt{1-y^2}\right)+x\sqrt{1-x^2}\right]
        \end{align*}

        \item \ul{Si $(x,y)\in R_2$:} ($-1<x<0$ y $0<y$)
        \begin{align*}
            F_{(X,Y)}(x, y) &= \int_{-1}^x \int_{-\sqrt{1-u^2}}^0 \dfrac{4}{\pi} \, dv \, du
            = \dfrac{4}{\pi} \int_{-1}^x \sqrt{1-u^2} \, du
            \stackrel{\eqref{eq:primitiva}}{=}\\&\stackrel{\eqref{eq:primitiva}}{=} \dfrac{2}{\pi}\left[\arcsen(x)+\frac{\pi}{2}+x\sqrt{1-x^2}\right]
        \end{align*}

        \item \ul{Si $(x,y)\in R_3$:} ($0<x$ y $-1<y<0$)
        \begin{align*}
            F_{(X,Y)}(x, y) &= \int_{-\sqrt{1-y^2}}^0 \int_{-\sqrt{1-u^2}}^y \dfrac{4}{\pi} \, dv \, du
            = \dfrac{4}{\pi} \int_{-\sqrt{1-y^2}}^0 y+\sqrt{1-u^2} \, du
            \stackrel{\eqref{eq:primitiva}}{=}\\&\stackrel{\eqref{eq:primitiva}}{=}
            \dfrac{4}{\pi} \left[\left[yu\right]_{-\sqrt{1-y^2}}^0 + \dfrac{1}{2}\left[\arcsen(0)-\arcsen\left(-\sqrt{1-y^2}\right)+\right.\right.
            \\&\qquad\qquad +\left.\left.0\sqrt{1-0^2}+\sqrt{1-y^2}\sqrt{1-1+y^2}\right]\right]
            =\\&= \dfrac{4}{\pi} \left[y\sqrt{1-y^2} + \dfrac{1}{2}\left[\arcsen\left(\sqrt{1-y^2}\right) -y\sqrt{1-y^2}\right]\right]
            =\\&= \dfrac{2}{\pi} \left[y\sqrt{1-y^2} + \arcsen\left(\sqrt{1-y^2}\right)\right]
        \end{align*}

        \item \ul{Si $(x,y)\in R_4$:} ($0<x$ y $0<y$)
        \begin{align*}
            F_{(X,Y)}(x, y) &= 1
        \end{align*}
    \end{itemize}

    Por tanto, la función de distribución conjunta es:
    \begin{equation*}
        \hspace{-2cm}
        F_{(X,Y)}(x, y) = \begin{cases}
            0, & (x, y) \in R_0 \\
            \nicefrac{2}{\pi} \left[2xy + y\sqrt{1-y^2} + \arcsen(x)+\arcsen\left(\sqrt{1-y^2}\right)+x\sqrt{1-x^2}\right], & (x, y) \in R_1 \\
            \nicefrac{2}{\pi}\left[\arcsen(x)+\frac{\pi}{2}+x\sqrt{1-x^2}\right], & (x, y) \in R_2 \\
            \nicefrac{2}{\pi} \left[y\sqrt{1-y^2} + \arcsen\left(\sqrt{1-y^2}\right)\right], & (x, y) \in R_3 \\
            1, & (x, y) \in R_4
        \end{cases}
    \end{equation*}
    \item \textbf{(0.75 puntos)} Obtener las funciones de densidad condicionadas.
    
    Para ello, calculamos en primer lugar las marginales. Tenemos que:
    \begin{align*}
        f_X(x) &= \int_{-\infty}^{+\infty} f_{X,Y}(x, y) \, dy
        = \int_{-\sqrt{1-x^2}}^0 \dfrac{4}{\pi} \, dy
        = \dfrac{4}{\pi} \cdot \sqrt{1-x^2}\qquad \forall x\in \left[-1,0\right]\\
        f_Y(y) &= \int_{-\infty}^{+\infty} f_{X,Y}(x, y) \, dx
        = \int_{-\sqrt{1-y^2}}^0 \dfrac{4}{\pi} \, dx
        = \dfrac{4}{\pi} \cdot \sqrt{1-y^2}\qquad \forall y\in \left[-1,0\right]
    \end{align*}

    Por tanto, dado $y^*\in \left[-1,0\right]$, tenemos que:
    \begin{align*}
        f_{X\mid Y=y^*}(x) &= \dfrac{f_{X,Y}(x, y^*)}{f_Y(y^*)}
        = \dfrac{\nicefrac{4}{\pi}}{\nicefrac{4}{\pi}\cdot \sqrt{1-y^{*2}}}
        = \dfrac{1}{\sqrt{1-y^{*2}}}\qquad \forall x\in \left[-\sqrt{1-y^{*2}},0\right]
    \end{align*}

    De forma análoga, dado $x^*\in \left[-1,0\right]$, tenemos que:
    \begin{align*}
        f_{Y\mid X=x^*}(y) &= \dfrac{f_{X,Y}(x^*, y)}{f_X(x^*)}
        = \dfrac{\nicefrac{4}{\pi}}{\nicefrac{4}{\pi}\cdot \sqrt{1-x^{*2}}}
        = \dfrac{1}{\sqrt{1-x^{*2}}}\qquad \forall y\in \left[-\sqrt{1-x^{*2}},0\right]
    \end{align*}
    \item \textbf{(0.50 puntos)} Obtener la probabilidad de que $X-Y>0$.
    
    Veamos gráficamente este conjunto en la Figura~\ref{fig:xy}, en el que el punto de corte es:
    \begin{equation*}
        -\sqrt{1-x^2} = x \Longrightarrow 1-x^2 = x^2 \Longrightarrow x=-\dfrac{\sqrt{2}}{2}
        \Longrightarrow \left(-\dfrac{\sqrt{2}}{2}, -\dfrac{\sqrt{2}}{2}\right)
    \end{equation*}
    \begin{figure}
        \centering
        \begin{tikzpicture}
            \begin{axis}[
                axis lines = center,
                xlabel = $X$,
                ylabel = $Y$,
                xmin = -1.5, xmax = 0.5,
                ymin = -1.5, ymax = 0.5,
                xtick = {-1,0},
                ytick = {-1,0},
                axis equal,
            ]
                % R2: Cuarto de circunferencia
                \addplot [name path=A, blue, thick, forget plot, samples=70, domain=-1:0] {-sqrt(1-x^2)};

                \addplot [name path=D, red, thick, forget plot, samples=2, domain=-3:3] {x};
                
                % Dibuja la línea horizontal en y=0
                \addplot [name path=B, forget plot, draw=none] {0};

                % Dibuja la línea horizontal en y=-1
                \addplot [name path=C, forget plot, draw=none] {-1};
            
                % Rellena el área bajo la curva entre x=0 y x=1
                \addplot [
                    thick,
                    color=orange,
                    fill=orange,
                    fill opacity=0.4
                ]
                fill between [
                    of=D and A,
                    soft clip={domain=-0.707:0},
                ];
                
                % Señalamos zona R1
                \node at (-0.4, -0.4) {$R_1~(C)$};

                % Señalamos el punto de corte
                \node[circle,fill,inner sep=2pt] at (-0.707, -0.707) {};
                \node[anchor=east] at (-0.707, -0.707) {$\left(-\dfrac{\sqrt{2}}{2}, -\dfrac{\sqrt{2}}{2}\right)$};
            \end{axis}
        \end{tikzpicture}
        \caption{Conjunto en el que se insersecan $C$ y $X-Y>0$.}
        \label{fig:xy}
    \end{figure}

    Por tanto, tenemos que:
    \begin{align*}
        \hspace{-2cm}
        P[X-Y>0] &= \int_{\nicefrac{-\sqrt{2}}{2}}^0 \int_{-\sqrt{1-x^2}}^{x} \dfrac{4}{\pi} \, dy \, dx
        = \dfrac{4}{\pi} \int_{\nicefrac{-\sqrt{2}}{2}}^0 x+\sqrt{1-x^2} \, dx
        =\\&= \dfrac{4}{\pi}\left[\left[\dfrac{x^2}{2}\right]_{\nicefrac{-\sqrt{2}}{2}}^0 + \dfrac{1}{2}\left[\arcsen(0)-\arcsen\left(\dfrac{-\sqrt{2}}{2}\right)+0\sqrt{1-0^2}+\dfrac{\sqrt{2}}{2}\sqrt{1-\nicefrac{2}{4}}\right]\right]
        =\\&= \dfrac{4}{\pi}\left[-\dfrac{1}{4} + \dfrac{1}{2}\left[\arcsen\left(\dfrac{\sqrt{2}}{2}\right)+\dfrac{\sqrt{2}}{2}\sqrt{1-\nicefrac{2}{4}}\right]\right]
        =\dfrac{4}{\pi}\left[-\dfrac{1}{4} + \dfrac{1}{2}\left[\frac{\pi}{4}+\frac{1}{2}\right]\right]
        =\\&= -\cancel{\frac{1}{\pi}} + \frac{1}{2} + \cancel{\frac{1}{\pi}} = \frac{1}{2}
    \end{align*}
    \item \textbf{(1.50 puntos)} Obtener la mejor aproximación mínimo cuadrática a la variable aleatoria $Y$ conocidos los valores de la variable $X$ y el error cuadrático medio de esta aproximación.
    
    La mejor aproximación por mínimos cuadrados es la curva de regresión de $Y$ sobre $X$:
    \begin{align*}
        E[Y\mid X=x] &= \int_{-\infty}^{+\infty} y\cdot f_{Y\mid X=x}(y) \, dy
        = \int_{-\sqrt{1-x^2}}^0 y\cdot \dfrac{1}{\sqrt{1-x^2}} \, dy
        = \dfrac{1}{\sqrt{1-x^2}} \left[\dfrac{y^2}{2}\right]_{-\sqrt{1-x^2}}^0
        =\\&= \dfrac{1}{\sqrt{1-x^2}} \left[0-\dfrac{1-x^2}{2}\right]
        = \dfrac{1}{\sqrt{1-x^2}} \left[-\dfrac{1-x^2}{2}\right]
        = -\dfrac{\sqrt{1-x^2}}{2}
        \qquad \forall x\in \left[-1,0\right]
    \end{align*}

    Por tanto, la mejor aproximación por mínimos cuadrados es:
    \begin{equation*}
        E[Y\mid X] = -\dfrac{\sqrt{1-X^2}}{2}
    \end{equation*}

    El error cuadrático medio de esta aproximación es:
    \begin{align*}
        \text{E.C.M.}(E[Y\mid X]) &= E[\Var[Y\mid X]] = E[Y^2] - E\left[E^2[Y\mid X]\right]
    \end{align*}

    Tenemos que:
    \begin{align*}
        E[Y^2] &= \int_{-\infty}^{+\infty} y^2\cdot f_Y(y) \, dy
        = \int_{-1}^0 y^2\cdot \dfrac{4}{\pi} \cdot \sqrt{1-y^2} \, dy
        = \dfrac{4}{\pi} \int_{-1}^0 y^2\cdot \sqrt{1-y^2} \, dy
    \end{align*}
    Aplicamos ahora el cambio de variable $y=\sen(t)$, por lo que:
    \begin{align*}
        E[Y^2] &= \dfrac{4}{\pi} \int_{-\nicefrac{\pi}{2}}^0 \sen^2(t)\cdot \sqrt{1-\sen^2(t)}\cdot \cos(t) \, dt
        = \dfrac{4}{\pi} \int_{-\nicefrac{\pi}{2}}^0 \sen^2(t)\cdot \cos^2(t) \, dt
        =\\&= \dfrac{4}{\pi} \int_{-\nicefrac{\pi}{2}}^0 \dfrac{1-\cos(2t)}{2}\cdot \dfrac{1+\cos(2t)}{2} \, dt
        = \dfrac{1}{\pi} \int_{-\nicefrac{\pi}{2}}^0 1-\cos^2(2t) \, dt
        =\\&= \dfrac{1}{\pi} \int_{-\nicefrac{\pi}{2}}^0 1-\dfrac{1+\cos(4t)}{2} \, dt
        = \dfrac{1}{\pi} \left[t-\dfrac{t}{2}-\dfrac{\sen(4t)}{8}\right]_{-\nicefrac{\pi}{2}}^0
        =\\&= \dfrac{1}{\pi} \left[\dfrac{t}{2}-\dfrac{\sen(4t)}{8}\right]_{-\nicefrac{\pi}{2}}^0 = \dfrac{1}{\pi} \left[\dfrac{\pi}{4}\right] = \dfrac{1}{4}
    \end{align*}

    Por otro lado, tenemos que:
    \begin{align*}
        E\left[E^2[Y\mid X]\right] &= E\left[\left(-\dfrac{\sqrt{1-X^2}}{2}\right)^2\right]
        = E\left[\dfrac{1-X^2}{4}\right]
        = \dfrac{1}{4}E[1-X^2]
        =\\&= \dfrac{1}{4}\left[1-E[X^2]\right]
        \AstIg \dfrac{1}{4}\left[1-\dfrac{1}{4}\right] = \dfrac{3}{16}
    \end{align*}
    donde en ($\ast$) hemos empleado que, como las funciones de densidad de $X$ y $Y$ son iguales, $E[X^2]=E[Y^2]$. Por tanto, tenemos que:
    \begin{align*}
        \text{E.C.M.}(E[Y\mid X]) &= E[Y^2] - E\left[E^2[Y\mid X]\right]
        = \dfrac{1}{4} - \dfrac{3}{16}
        = \dfrac{4-3}{16} = \dfrac{1}{16}
    \end{align*}
    \item \textbf{(0.50 puntos)} Obtener una media de la bondad del ajuste del apartado anterior.
    
    La media de la bondad del ajuste es el valor de $\eta^2_{Y\mid X}$:
    \begin{equation*}
        \eta^2_{Y\mid X} = \dfrac{\Var[E[Y\mid X]]}{\Var[Y]} = 1-\dfrac{\text{E.C.M.}(E[Y\mid X])}{\Var[Y]}
    \end{equation*}

    Tenemos que:
    \begin{align*}
        E[Y] &= \int_{-\infty}^{+\infty} y\cdot f_Y(y) \, dy
        = \int_{-1}^0 y\cdot \dfrac{4}{\pi} \cdot \sqrt{1-y^2} \, dy
        = \dfrac{4}{\pi} \int_{-1}^0 y\cdot \sqrt{1-y^2} \, dy
        =\\&= \dfrac{4}{\pi}\left[-\dfrac{1}{2}\cdot \dfrac{(1-y^2)^{\nicefrac{3}{2}}}{\nicefrac{3}{2}}\right]_{-1}^0
        = \dfrac{4}{\pi}\left[-\dfrac{1}{3}\right]
        = -\dfrac{4}{3\pi}\\
        E[Y^2] &= \dfrac{1}{4}\\
        \Var[Y] &= E[Y^2] - E^2[Y] = \dfrac{1}{4} - \left(-\dfrac{4}{3\pi}\right)^2 = \dfrac{1}{4} - \dfrac{16}{9\pi^2}
        = \dfrac{9\pi^2-64}{36\pi^2}
    \end{align*}

    Por tanto, tenemos que:
    \begin{align*}
        \eta^2_{Y\mid X} &= 1-\dfrac{\text{E.C.M.}(E[Y\mid X])}{\Var[Y]}
        = 1-\dfrac{\frac{1}{16}}{\frac{9\pi^2-64}{36\pi^2}}
        = 1-\dfrac{9\pi^2}{4(9\pi^2-64)}
        = \dfrac{36\pi^2-256-9\pi^2}{4(9\pi^2-64)}
        =\\&= \dfrac{27\pi^2-256}{4(9\pi^2-64)}\approx 0.10553
    \end{align*}

    Por tanto, vemos que el ajuste no es adecuado.
\end{enumerate}
    \end{ejercicio}

    \begin{ejercicio}[2.5 puntos]
        Dado el vector aleatorio $(X,Y)$ con función generatriz de momentos
        \begin{equation*}
            M_{(X,Y)}(t_1,t_2) = \exp\left(\dfrac{2t_1 + 4t_1^2 + 9t_2^2 + 6t_1t_2}{2}\right)
        \end{equation*}
        \begin{enumerate}
            \item \textbf{(0.75 puntos)} Obtener la razón de correlación y el coeficiente de correlación lineal de las variables $(X,Y)$.
            
            La función generatriz de momentos de una normal bivariante es:
            \begin{equation*}
                M_{(X,Y)}(t_1,t_2) = \exp\left(\mu_1t_1+\mu_2t_2+\dfrac{\sigma_{1}^2t_1^2+\sigma_{2}^2t_2^2+2\rho\sigma_1\sigma_2 t_1t_2}{2}\right)
            \end{equation*}

            Vemos por tanto que $(X,Y)$ sigue una distribución normal bivariante con parámetros:
            \begin{equation*}
                \begin{cases}
                    \mu_1 = 1\\
                    \mu_2 = 0\\
                    \sigma_1^2 = 4\\
                    \sigma_2^2 = 9\\
                    \rho\sigma_1\sigma_2 = 3
                \end{cases}
            \end{equation*}

            Por tanto, tenemos que $(X,Y)\sim \cc{N}_2(\mu,\Sigma)$, con:
            \begin{equation*}
                \mu = \begin{pmatrix}1&0\end{pmatrix},\qquad
                \Sigma = \begin{pmatrix}4 & 3\\3 & 9\end{pmatrix}
            \end{equation*}

            Por tanto, el coeficiente de correlación lineal es:
            \begin{equation*}
                \rho_{X,Y} =\rho =  \dfrac{3}{\sigma_1\sigma_2} = \dfrac{3}{2\cdot 3} = \dfrac{1}{2}
            \end{equation*}

            Por otro lado, sabemos que las curvas de regresión coinciden con las rectas de regresión, luego la razón de correlación es:
            \begin{equation*}
                \eta_{Y/X}^2=\eta_{X/Y}^2 = \rho_{X,Y}^2 = \dfrac{1}{4}
            \end{equation*}

            \item \textbf{(0.75 puntos)} Indicar las distribuciones de las variables aleatorias $Y\mid X = 1$ y $X\mid Y=0$.
            
            Sabemos que, dados $x^*,y^*\in \mathbb{R}$, las distribuciones condicionadas son:
            \begin{align*}
                Y\mid X=x^* &\sim \cc{N}\left(\mu_2+\rho\frac{\sigma_2}{\sigma_1}(x^*-\mu_1),\sigma_2^2(1-\rho^2)\right)\\
                X\mid Y=y^* &\sim \cc{N}\left(\mu_1+\rho\frac{\sigma_1}{\sigma_2}(y^*-\mu_2),\sigma_1^2(1-\rho^2)\right)
            \end{align*}

            Por tanto, tenemos que:
            \begin{align*}
                Y\mid X=1 &\sim \cc{N}\left(0+\dfrac{1}{2}\cdot \dfrac{3}{2}(1-1),9\left(1-\dfrac{1}{4}\right)\right)
                = \cc{N}\left(0,\nicefrac{27}{4}\right)\\
                X\mid Y=0 &\sim \cc{N}\left(1+\dfrac{1}{2}\cdot \dfrac{2}{3}(0-0),4\left(1-\dfrac{1}{4}\right)\right)
                = \cc{N}\left(1,3\right)
            \end{align*}
            \item \textbf{(1 punto)} Obtener la distribución de probabilidad del vector aleatorio $(2X, Y-X)$. Justificar que las variabes aleatorias $2X$ y $Y-X$ tienen cierta asociación lineal en sentido negativo.
            
            Tenemos que:
            \begin{equation*}
                (2X,Y-X) = \begin{pmatrix}
                    X & Y
                \end{pmatrix}A,\qquad A = 
                \begin{pmatrix}
                    2 & -1 \\ 0 & 1
                \end{pmatrix}
            \end{equation*}

            Por tanto, notando $X'=2X$ y $Y'=Y-X$, tenemos que $(X',Y')\sim \cc{N}(\mu A,A^t\Sigma A)$, donde:
            \begin{align*}
                \mu A &= \begin{pmatrix}
                    1&0
                \end{pmatrix}\begin{pmatrix}
                    2 & -1 \\ 0 & 1
                \end{pmatrix} = \begin{pmatrix}
                    2 & -1
                \end{pmatrix}
                \\
                A^t\Sigma A &= \begin{pmatrix}
                    2 & 0 \\ -1 & 1
                \end{pmatrix}\begin{pmatrix}
                    4 & 3 \\ 3 & 9
                \end{pmatrix}\begin{pmatrix}
                    2 & -1 \\ 0 & 1
                \end{pmatrix} = \begin{pmatrix}
                    8 & 6 \\ -1 & 6
                \end{pmatrix}
                \begin{pmatrix}
                    2 & -1 \\ 0 & 1
                \end{pmatrix}
                = \begin{pmatrix}
                    16 & -2 \\ -2 & 7
                \end{pmatrix}
            \end{align*}

            Por tanto, tenemos que:
            \begin{align*}
                \rho_{X',Y'} &= \dfrac{-2}{\sqrt{16}\sqrt{7}} \approx -0.18\\
                \rho_{X',Y'}^2 &= \dfrac{2^2}{16\cdot 7} = \dfrac{1}{28} = 0.03
            \end{align*}

            Por tanto, como $\rho_{X',Y'}^2$ es muy cercano a $0$, no tienen apenas asociación. No obstante, de tenerla, como $\rho_{X',Y'}$ es negativo, es en sentido negativo.
        \end{enumerate}
    \end{ejercicio}


\end{document}
