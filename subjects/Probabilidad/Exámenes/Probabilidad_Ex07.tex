\documentclass[12pt]{article}

\input{../../_assets/preambulo.tex}
\usepgfplotslibrary{fillbetween}
\DeclareMathOperator{\Var}{Var}
\DeclareMathOperator{\Cov}{Cov}

\begin{document}

    % 1. Foto de fondo
    % 2. Título
    % 3. Encabezado Izquierdo
    % 4. Color de fondo
    % 5. Coord x del titulo
    % 6. Coord y del titulo
    % 7. Fecha

    
    \input{../../_assets/portada}
    \portadaExamen{ffccA4.jpg}{Probabilidad\\Examen VII}{Probabilidad. Examen VII}{MidnightBlue}{-8}{28}{2024-2025}{Arturo Olivares Martos \\ José Juan Urrutia Milán}

    \begin{description}
        \item[Asignatura] Probabilidad.
        \item[Curso Académico] 2021-22.
        \item[Grado] Doble Grado en Ingeniería Informática y Matemáticas.
        \item[Grupo] Único.
        %\item[Profesor] José María Espinar García.
        \item[Descripción] Examen Extraordinario. 
        \item[Fecha] 15 de febrero de 2022.
        % \item[Duración] 60 minutos.
    
    \end{description}
    \newpage

    \begin{ejercicio}
        Sean $X_1$, $X_2$, \ldots, $X_n$ variables aleatorias continuas e independientes, tales que $\exists E[X_i]$ $\forall i=1,\ldots,n$, con momento no centrado de orden dos finito. Justificar que:
        \begin{enumerate}
            \item \textbf{(0.5 puntos)} $\exists \Var\left(\sum\limits_{i=1}^{n}a_iX_i\right) = \sum\limits_{i=1}^{n}a_i^2 \Var(X_i)$ $\forall a_1,\ldots,a_n\in \mathbb{R}$.
            \item \textbf{(0.5 puntos)} $(X_1, \ldots, X_n)$ es un vector aleatorio continuo.
        \end{enumerate}

        Ambos apartados se encuentran demostrados en el Tema correspondiente a independencia de variables aleatorias.
    \end{ejercicio}

    \begin{ejercicio}
        Sea $(X,Y)$ una variable aleatoria bidimensional con distribución uniforme en el recito
        \begin{equation*}
            C = \{(x,y)\in \mathbb{R}^2 \mid x^2+y^2 < 1 \quad x,y\geq 0\}
        \end{equation*}
        \begin{observacion}
            Si necesitara obtener la primitiva de la función $f(x) = \sqrt{1-x^2}$, realizar el cambio de variable unidimensional $x=\sen(t)$.
        \end{observacion}
        \begin{enumerate}
            \item \textbf{(1.25 puntos)} Calcular la función de distribución de probabilidad conjunta.
            \begin{observacion}
                Se obtiene \textbf{hasta 1 punto} si las integrales se dejan indicadas y \textbf{hasta 1.25 puntos} si se obtienen sus primitivas de forma explícita.
            \end{observacion}

            Calculamos en primer lugar la función de densidad conjunta.
            Esta es constante en $C$, por lo que:
            \begin{equation*}
                f(x, y) = \begin{cases}
                    k, & x^2+y^2<1, x,y\geq 0 \\
                    0, & \text{en otro caso}.
                \end{cases}
            \end{equation*}

            Para que $f$ sea una función de densidad, tenemos que:
            \begin{align*}
                1&=\int_{-\infty}^{+\infty} \int_{-\infty}^{+\infty} f(x, y) \, dx \, dy
            \end{align*}

            Hay dos opciones:
            \begin{description}
                \item[Integrando de la forma usual:]
                
                Es necesario que:
                \begin{equation*}
                    1=\int_{0}^{1} \int_{0}^{\sqrt{1-x^2}} k \, dy \, dx = k\int_{0}^{1} \sqrt{1-x^2} \, dx
                \end{equation*}

                Haciendo el cambio de variable $x=\sen(t)$, tenemos que:
                \begin{align*}
                    1&=k\int_{0}^{\frac{\pi}{2}} \cos(t)\cos(t) \, dt = k\int_{0}^{\frac{\pi}{2}} \cos^2(t) \, dt
                    = k\int_{0}^{\frac{\pi}{2}} \dfrac{1+\cos(2t)}{2} \, dt
                    =\\&= k\left[\dfrac{t}{2}+\dfrac{\sen(2t)}{4}\right]_0^{\frac{\pi}{2}}
                    = k\left[\dfrac{\pi}{4}\right] \Longrightarrow k=\dfrac{4}{\pi}.
                \end{align*}

                \item[Razonando la forma de $C$:]
                
                Sabemos que $C$ es un cuarto de círculo de radio 1, por lo que su área es $\nicefrac{\pi}{4}$. Por tanto, tenemos que:
                \begin{equation*}
                    1=\int_C f(x, y) = k\int_C 1 = k\cdot \lm(C) = k\cdot \dfrac{\pi}{4} \Longrightarrow k=\dfrac{4}{\pi}.
                \end{equation*}
            \end{description}


            Para calcular la función de distribución conjunta, dividimos el plano cartesiano en las distintas regiones:
            \begin{figure}[H]
                \centering
                \begin{tikzpicture}
                    \begin{axis}[
                        axis lines = center,
                        xlabel = $X$,
                        ylabel = $Y$,
                        xmin = -0.5, xmax = 1.5,
                        ymin = -0.5, ymax = 1.5,
                        xtick = {0,1},
                        ytick = {0,1},
                        yticklabel style = {yshift=-1.5ex},
                        xticklabel style = {xshift=-1.5ex},
                        axis equal,
                    ]
                        % R2: Cuarto de circunferencia
                        \addplot [name path=A, blue, thick, forget plot, samples=70, domain=0:1] {sqrt(1-x^2)};
                        
                        % Dibuja la línea horizontal en y=0
                        \addplot [name path=B, forget plot, draw=none] {0};

                        % Dibuja la línea horizontal en y=0
                        \addplot [name path=C, forget plot, draw=none] {1};
                    
                        % Rellena el área bajo la curva entre x=0 y x=1
                        \addplot [
                            thick,
                            color=orange,
                            fill=orange,
                            fill opacity=0.4
                        ]
                        fill between [
                            of=A and B,
                            soft clip={domain=0:1},
                        ];
                        
                        % Señalamos zona R2
                        \node at (0.5, 0.5) {$R_2$};

                        % R1: (0, 2), (-2, 2), (-2, -2), (2, -2), (2, 0), (0, 0)
                        \addplot[fill=red, opacity=0.2] coordinates {
                            (0, 2) (-2, 2) (-2, -2) (2, -2) (2, 0) (0, 0)
                        } --cycle;
                        \node at (-0.25, -0.25) {$R_1$};

                        \addplot [
                            thick,
                            color=teal,
                            fill=teal,
                            fill opacity=0.4
                        ]
                        fill between [
                            of=C and A,
                            soft clip={domain=0:1},
                        ];
                        \node at (0.8, 0.8) {$R_3$};

                        \addplot[fill=blue, opacity=0.2] coordinates {
                            (0, 1) (1,1) (1,2) (0,2)
                        } --cycle;
                        \node at (0.5, 1.25) {$R_4$};

                        \addplot[fill=green, opacity=0.2] coordinates {
                            (1, 1) (2,1) (2,0) (1,0)
                        } --cycle;
                        \node at (1.25, 0.5) {$R_5$};

                        \addplot[fill=olive, opacity=0.2] coordinates {
                            (1, 1) (2,1) (2,2) (1,2)
                        } --cycle;
                        \node at (1.25, 1.25) {$R_6$};
                    \end{axis}
                \end{tikzpicture}
            \end{figure}

            Distinguimos casos:
            \begin{itemize}
                \item \ul{Si $x\leq 0$ \quad o \quad $y\leq 0$} (zona $R_1$):
                \begin{equation*}
                    F_{(X,Y)}(x, y) = \int_{-\infty}^x \int_{-\infty}^y f(u, v) \, du \, dv = 0.
                \end{equation*}

                \item \ul{Si $x\in \left]0,1\right[$ \quad y \quad $y\in \left]0,\sqrt{1-x^2}\right[$} (zona $R_2$):
                \begin{align*}
                    F_{(X,Y)}(x, y) &= \int_{-\infty}^x \int_{-\infty}^y f(u, v) \, dv \, du = \int_{0}^x \int_{0}^y \dfrac{4}{\pi} \, dv \, du = \int_{0}^x \dfrac{4}{\pi}y \, du
                    =\\&= \dfrac{4}{\pi}\left[yu\right]_0^x = \dfrac{4}{\pi}\cdot xy
                \end{align*}

                \item \ul{Si $x\in \left]0,1\right[$ \quad y \quad $y\in \left]\sqrt{1-x^2},1\right[$} (zona $R_3$):
                \begin{align*}
                    F_{(X,Y)}(x, y) &= \int_{-\infty}^x \int_{-\infty}^y f(u, v) \, dv \, du =\\&= \int_{0}^{\sqrt{1-y^2}}\int_0^y \dfrac{4}{\pi} \, dv \, du + \int_{\sqrt{1-y^2}}^x \int_0^{\sqrt{1-u^2}} \dfrac{4}{\pi} \, dv \, du =\\
                    &= \int_{0}^{\sqrt{1-y^2}} \dfrac{4}{\pi}y \, du + \int_{\sqrt{1-y^2}}^x \dfrac{4}{\pi}\sqrt{1-u^2} \, du
                \end{align*}

                Para resolver la segunda integral, hacemos el cambio de variable dado por $u=\sen(t)$, $du=\cos(t)dt$:
                \begin{align*}
                    F_{(X,Y)}(x, y) &= \dfrac{4}{\pi} y\sqrt{1-y^2} + \dfrac{4}{\pi}\int_{\arcsen(\sqrt{1-y^2})}^{\arcsen(x)} \cos^2(t) \, dt
                    =\\&= \dfrac{4}{\pi} y\sqrt{1-y^2} + \dfrac{4}{\pi}\int_{\arcsen(\sqrt{1-y^2})}^{\arcsen(x)} \dfrac{1+\cos(2t)}{2} \, dt
                    =\\&= \dfrac{4}{\pi} y\sqrt{1-y^2} + \dfrac{4}{\pi}\left[\dfrac{t}{2}+\dfrac{\sen(2t)}{4}\right]_{\arcsen(\sqrt{1-y^2})}^{\arcsen(x)}
                    =\\&= \dfrac{4}{\pi} y\sqrt{1-y^2} + \dfrac{4}{\pi}\left[\dfrac{\arcsen(x)}{2}+\dfrac{\sen(2\arcsen(x))}{4}-\right.\\&\qquad -\left.\dfrac{\arcsen(\sqrt{1-y^2})}{2}-\dfrac{\sen(2\arcsen(\sqrt{1-y^2}))}{4}\right]
                \end{align*}

                Veamos cuánto vale anteriormente $\sen(2\arcsen(x))$ para cierto $x\in \bb{R}$:
                \begin{align*}
                    \sen(2\arcsen(x)) &= 2\sen(\arcsen(x))\cos(\arcsen(x)) = 2x\sqrt{1-x^2}.
                \end{align*}

                Por tanto, tenemos que:
                \begin{align*}
                    F_{(X,Y)}(x, y) &= \dfrac{4}{\pi} y\sqrt{1-y^2} + \dfrac{4}{\pi}\left[\dfrac{\arcsen(x)}{2}+\dfrac{2x\sqrt{1-x^2}}{4}-\right.\\&\qquad -\left.\dfrac{\arcsen(\sqrt{1-y^2})}{2}-\dfrac{2\sqrt{1-y^2}\sqrt{y^2}}{4}\right]
                    =\\&= \dfrac{4}{\pi} y\sqrt{1-y^2} + \dfrac{2}{\pi}\arcsen(x)+\dfrac{2}{\pi}x\sqrt{1-x^2}-\\&\qquad-\dfrac{2}{\pi}\arcsen(\sqrt{1-y^2})-\dfrac{2}{\pi}y\sqrt{1-y^2}.
                    =\\&= \dfrac{2}{\pi} y\sqrt{1-y^2} + \dfrac{2}{\pi}\arcsen(x)+\dfrac{2}{\pi}x\sqrt{1-x^2}-\dfrac{2}{\pi}\arcsen(\sqrt{1-y^2})
                \end{align*}

                \item \ul{Si $x\in \left]0,1\right[$ \quad y \quad $y\geq 1$} (zona $R_4$):
                \begin{align*}
                    F_{(X,Y)}(x, y) &= \int_{-\infty}^x \int_{-\infty}^y f(u, v) \, dv \, du = \int_{0}^x \int_{0}^{\sqrt{1-u^2}} \dfrac{4}{\pi} \, dv \, du
                    =\\&= \int_{0}^x \dfrac{4}{\pi}\sqrt{1-u^2} \, du
                \end{align*}

                Para resolver la integral, de nuevo hacemos el cambio de variable dado por $u=\sen(t)$, $du=\cos(t)dt$:
                \begin{align*}
                    F_{(X,Y)}(x, y) &= \dfrac{4}{\pi}\int_{0}^{\arcsen(x)} \cos^2(t) \, dt
                    = \dfrac{4}{\pi}\int_{0}^{\arcsen(x)} \dfrac{1+\cos(2t)}{2} \, dt
                    =\\&= \dfrac{4}{\pi}\left[\dfrac{t}{2}+\dfrac{\sen(2t)}{4}\right]_0^{\arcsen(x)}
                    = \dfrac{4}{\pi}\left[\dfrac{\arcsen(x)}{2}+\dfrac{\sen(2\arcsen(x))}{4}\right]
                    =\\&= \dfrac{4}{\pi}\left[\dfrac{\arcsen(x)}{2}+\dfrac{2x\sqrt{1-x^2}}{4}\right]
                    = \dfrac{2}{\pi}\arcsen(x)+\dfrac{2}{\pi}x\sqrt{1-x^2}.
                \end{align*}

                \item \ul{Si $y\in \left]0,1\right[$ \quad y \quad $x\geq 1$} (zona $R_5$):
                \begin{align*}
                    F_{(X,Y)}(x, y) &= \int_{-\infty}^x \int_{-\infty}^y f(u, v) \, dv \, du =\\
                    &= \int_{0}^{\sqrt{1-y^2}} \int_{0}^y \dfrac{4}{\pi} \, dv \, du + \int_{\sqrt{1-y^2}}^1 \int_{0}^{\sqrt{1-u^2}} \dfrac{4}{\pi} \, dv \, du
                    =\\&= \int_{0}^{\sqrt{1-y^2}} \dfrac{4}{\pi}y \, du + \int_{\sqrt{1-y^2}}^1 \dfrac{4}{\pi}\sqrt{1-u^2} \, du
                \end{align*}

                Para resolver la segunda integral, de nuevo hacemos el cambio de variable dado por $u=\sen(t)$, $du=\cos(t)dt$:
                \begin{align*}
                    F_{(X,Y)}(x, y) &= \dfrac{4}{\pi}y\left[u\right]_0^{\sqrt{1-y^2}} + \dfrac{4}{\pi}\int_{\arcsen(\sqrt{1-y^2})}^{\nicefrac{\pi}{2}} \cos^2(t) \, dt
                    =\\&= \dfrac{4}{\pi}y\sqrt{1-y^2} + \dfrac{4}{\pi}\int_{\arcsen(\sqrt{1-y^2})}^{\nicefrac{\pi}{2}} \dfrac{1+\cos(2t)}{2} \, dt
                    =\\&= \dfrac{4}{\pi}y\sqrt{1-y^2} + \dfrac{4}{\pi}\left[\dfrac{t}{2}+\dfrac{\sen(2t)}{4}\right]_{\arcsen(\sqrt{1-y^2})}^{\nicefrac{\pi}{2}}
                    =\\&= \dfrac{4}{\pi}y\sqrt{1-y^2} + \dfrac{4}{\pi}\left[\dfrac{\nicefrac{\pi}{2}}{2}+\dfrac{\sen(\pi)}{4}-\dfrac{\arcsen(\sqrt{1-y^2})}{2}-\right.\\&\qquad\left.-\dfrac{\sen(2\arcsen(\sqrt{1-y^2}))}{4}\right]
                    =\\&= \dfrac{4}{\pi}y\sqrt{1-y^2} + 1 - \dfrac{2}{\pi}\arcsen(\sqrt{1-y^2}) - \dfrac{2}{\pi}y\sqrt{1-y^2}
                    =\\&= \dfrac{2}{\pi}y\sqrt{1-y^2} + 1 - \dfrac{2}{\pi}\arcsen(\sqrt{1-y^2})
                \end{align*}

                \item \ul{Si $x,y\geq 1$} (zona $R_6$):
                \begin{equation*}
                    F_{(X,Y)}(x, y) = 1.
                \end{equation*}
            \end{itemize}

            Por tanto, tenemos que:
            \begin{equation*}
                F_{(X,Y)}(x, y) = \begin{cases}
                    0, & (x,y)\in R_1, \\
                    \nicefrac{4}{\pi}xy, & (x,y)\in R_2, \\
                    \nicefrac{2}{\pi}\left[y\sqrt{1-y^2} + x\sqrt{1-x^2}-\arcsen(\sqrt{1-y^2})\right], & (x,y)\in R_3 \\
                    \nicefrac{2}{\pi}\left[\arcsen(x)+x\sqrt{1-x^2}\right], & (x,y)\in R_4, \\
                    \nicefrac{2}{\pi}\left[y\sqrt{1-y^2} + \nicefrac{\pi}{2} - \arcsen(\sqrt{1-y^2})\right], & (x,y)\in R_5, \\
                    1, & (x,y)\in R_6.
                \end{cases}
            \end{equation*}
            \item \textbf{(1.25 puntos)} Calcular las funciones de densidad condicionadas.
            
            Para ello, calculamos en primer lugar las funciones de densidad marginales. Para $x\in [0,1]$, ya que la función de densidad es constante, tenemos que:
            \begin{align*}
                f_X(x) &= \int_{-\infty}^{+\infty} f(x, y) \, dy = \int_{0}^{\sqrt{1-x^2}} \dfrac{4}{\pi} \, dy = \dfrac{4}{\pi}\left[y\right]_{0}^{\sqrt{1-x^2}} = \dfrac{4}{\pi}\cdot \sqrt{1-x^2}.
            \end{align*}
    
            Para $y\in [0,1]$, ya que la función de densidad es constante, tenemos que:
            \begin{align*}
                f_Y(y) &= \int_{-\infty}^{+\infty} f(x, y) \, dx = \int_{0}^{\sqrt{1-y^2}} \dfrac{4}{\pi} \, dx = \dfrac{4}{\pi}\left[x\right]_{0}^{\sqrt{1-y^2}} = \dfrac{4}{\pi}\cdot \sqrt{1-y^2}.
            \end{align*}

            Una vez calculadas estas, calculamos las funciones de densidad condicionadas. Dado $x^\ast\in [0,1]$, tenemos para $y\in [0,\sqrt{1-(x^{\ast})^2}]$:
            \begin{equation*}
                f_{Y\mid X=x^\ast} (y) = \dfrac{f_{(X,Y)}(x^\ast, y)}{f_X(x^\ast)} = \dfrac{\nicefrac{4}{\pi}}{\dfrac{4}{\pi}\cdot \sqrt{1-(x^{\ast})^2}} = \dfrac{1}{\sqrt{1-(x^{\ast})^2}}.
            \end{equation*}
    
            Dado $y^\ast\in [0,1]$, tenemos para $x\in [0,\sqrt{1-(y^{\ast})^2}]$:
            \begin{equation*}
                f_{X\mid Y=y^\ast} (x) = \dfrac{f_{(X,Y)}(x, y^\ast)}{f_Y(y^\ast)} = \dfrac{\nicefrac{4}{\pi}}{\dfrac{4}{\pi}\cdot \sqrt{1-(y^{\ast})^2}} = \dfrac{1}{\sqrt{1-(y^{\ast})^2}}.
            \end{equation*}
        \end{enumerate}
    \end{ejercicio}

    \begin{ejercicio}
        Sea considera $(X,Y)$ la distribución uniforme en el cuadrado unidad.
        \begin{enumerate}
            \item \textbf{(1.25 puntos)} Calcular la función de densidad de probabilidad del vector aleatorio $Z = (X+Y,X-Y)$.
            
            Como cuadrado unidad, entendemos $C=[0,1]\times[0,1]$. La función de densidad conjunta es constante en $C$, por lo que:
            \begin{equation*}
                f_{(X,Y)}(x, y) = \begin{cases}
                    k, & (x,y)\in C, \\
                    0, & \text{en otro caso}.
                \end{cases}
            \end{equation*}

            Para que $f_{(X,Y)}$ sea una función de densidad, tenemos que:
            \begin{align*}
                1&=\int_{-\infty}^{+\infty} \int_{-\infty}^{+\infty} f_{(X,Y)}(x, y) \, dx \, dy
                =\\&= \int_{0}^{1} \int_{0}^{1} k \, dx \, dy
                = k\int_{0}^{1} \left[x\right]_{0}^{1} \, dy
                = k\int_{0}^{1} 1 \, dy
                = k\left[y\right]_{0}^{1}
                = k.
            \end{align*}

            Definimos ahora la transformación:
            \Func{g}{\bb{R}^2}{\bb{R}^2}{(X,Y)}{(Z,T)=(X+Y,X-Y)}

            Para obtener $g^{-1}$, buscamos despejar $(X,Y)$ en función de $(Z,T)$:
            \begin{equation*}
                \left\{
                    \begin{array}{l}
                        Z=X+Y\\
                        T=X-Y
                    \end{array}
                \right\}
                \Longrightarrow
                \left\{
                    \begin{array}{l}
                        X=\dfrac{Z+T}{2}\\
                        Y=\dfrac{Z-T}{2}
                    \end{array}
                \right\}
            \end{equation*}

            Por tanto, la inversa es:
            \Func{g^{-1}}{\bb{R}^2}{\bb{R}^2}{(Z,T)}{(X,Y)=\left(\dfrac{Z+T}{2},\dfrac{Z-T}{2}\right)}

            Todas las componentes de $g^{-1}$ son derivables, con:
            \begin{align*}
                \dfrac{\partial X}{\partial Z}(Z,T)&=\nicefrac{1}{2}, & \dfrac{\partial X}{\partial T}(Z,T)&=\nicefrac{1}{2},\\
                \dfrac{\partial Y}{\partial Z}(Z,T)&=\nicefrac{1}{2}, & \dfrac{\partial Y}{\partial T}(Z,T)&=\nicefrac{-1}{2}.
            \end{align*}

            Además, tenemos que:
            \begin{equation*}
                \det Jg^{-1}(z,t) = \begin{vmatrix}
                    \nicefrac{1}{2} & \nicefrac{1}{2}\\
                    \nicefrac{1}{2} & \nicefrac{-1}{2}
                \end{vmatrix}
                = \dfrac{1}{2^2}\cdot \begin{vmatrix}
                    1 & 1\\
                    1 & -1
                \end{vmatrix} = -\dfrac{1}{4}\cdot 2 = \frac{1}{2}\neq 0\qquad \forall (z,t)\in \bb{R}^2
            \end{equation*}

            Por tanto, $g(X,Y)$ es un vector aleatorio. Su función de densidad conjunta es:
            \begin{align*}
                f_{(Z,T)}(z,t) &= f_{(X,Y)}\left(\dfrac{z+t}{2},\dfrac{z-t}{2}\right) \cdot |Jg^{-1}(z,t)| = \frac{1}{2}\qquad \left(\dfrac{z+t}{2},\dfrac{z-t}{2}\right)\in R
            \end{align*}

            Veamos cuál es este conjunto. Tenemos que:
            \begin{align*}
                \left\{
                    \begin{array}{l}
                        0\leq \dfrac{z+t}{2}\leq 1\\
                        0\leq \dfrac{z-t}{2}\leq 1
                    \end{array}
                \right\}
                \Longleftrightarrow
                \left\{
                    \begin{array}{l}
                        0\leq z+t\leq 2\\
                        0\leq z-t\leq 2
                    \end{array}
                \right\}
            \end{align*}

            Por tanto, la función de densidad de probabilidad del vector aleatorio $Z = (X+Y,X-Y)$ es:
            \begin{equation*}
                f_{(Z,T)}(z,t) = \begin{cases}
                    \nicefrac{1}{2}, & 0\leq z+t\leq 2, 0\leq z-t\leq 2, \\
                    0, & \text{en otro caso}.
                \end{cases}
            \end{equation*}
            \item \textbf{(1.25 puntos)} La función de densidad de proababilidad conjunta del máximo y el mínimo.
            
            Calculamos en primer lugar la función de distribución conjunta:
            \begin{align*}
                F_{(\max\{X,Y\},\min\{X,Y\})}(z,t) &= P[\max\{X,Y\}\leq z, \min\{X,Y\}\leq t]
            \end{align*}

            Distinguimos en función de los valores de $z$ y $t$:
            \begin{itemize}
                \item \ul{Si $z\leq t$}:
                \begin{align*}
                    P[\max\{X,Y\}\leq z, \min\{X,Y\}\leq t]
                    = P[\max\{X,Y\}\leq z] = P[X\leq z, Y\leq z]
                \end{align*}

                Distinguimos en función del valor de $z$:
                \begin{itemize}
                    \item \ul{Si $z\leq 0$}:
                    \begin{align*}
                        P[\max\{X,Y\}\leq z, \min\{X,Y\}\leq t]
                        = P[X\leq z, Y\leq z] = 0
                    \end{align*}

                    \item \ul{Si $0\leq z\leq 1$}:
                    \begin{align*}
                        P[\max\{X,Y\}\leq z, \min\{X,Y\}\leq t]
                        = P[X\leq z, Y\leq z] = \int_0^z\int_0^z 1\ dxdy=z^2
                    \end{align*}

                    \item \ul{Si $1\leq z$}:
                    \begin{align*}
                        P[\max\{X,Y\}\leq z, \min\{X,Y\}\leq t]
                        = P[X\leq z, Y\leq z] = 1
                    \end{align*}
                \end{itemize}

                \item \ul{Si $t<z$}:
                \begin{align*}
                    P[\max\{X,Y\}\leq z, &\min\{X,Y\}\leq t]
                    =\\&= P[\max\{X,Y\}\leq z] - P[\max\{X,Y\}\leq z,\min\{X,Y\}>t]
                    =\\&= P[\max\{X,Y\}\leq z] - P[t<X\leq z,t<Y\leq z]
                \end{align*}

                Distinguimos en función del valor de $z$ (para tener así la distribución del máximo calculada):
                \begin{itemize}
                    \item \ul{Si $z\leq 0$}:
                    \begin{align*}
                        P[\max\{X,Y\}\leq z, &\min\{X,Y\}\leq t]
                        = -P[t<X\leq z,t<Y\leq z]
                    \end{align*}
                    Como la probabilidad debe ser positiva, tenemos que:
                    \begin{align*}
                        P[\max\{X,Y\}\leq z, &\min\{X,Y\}\leq t]=0
                    \end{align*}

                    \item \ul{Si $0\leq z\leq 1$}:
                    \begin{align*}
                        P[\max\{X,Y\}\leq z, \min\{X,Y\}\leq t]
                        = z^2- P[t<X\leq z,t<Y\leq z]
                    \end{align*}
                    Distinguimos ahora en función de $t$:
                    \begin{itemize}
                        \item \ul{Si $t\leq 0$}:
                        \begin{align*}
                            P[t<X\leq z,t<Y\leq z] = \int_0^z\int_0^z 1\ dxdy = z^2
                        \end{align*}

                        Por tanto:
                        \begin{align*}
                            P[\max\{X,Y\}\leq z, \min\{X,Y\}\leq t]
                            = z^2- z^2=0
                        \end{align*}

                        \item \ul{Si $0\leq t<z\leq 1$}:
                        \begin{align*}
                            P[t<X\leq z,t<Y\leq z] = \int_t^z\int_t^z 1\ dxdy = (z-t)^2
                        \end{align*}

                        Por tanto:
                        \begin{align*}
                            P[\max\{X,Y\}\leq z, \min\{X,Y\}\leq t]
                            &= z^2- (z-t)^2
                            =\\&= z^2-z^2-t^2+2tz = t(2z-t)
                        \end{align*}
                    \end{itemize}

                    \item \ul{Si $1\leq z$}:
                    \begin{align*}
                        P[\max\{X,Y\}\leq z, \min\{X,Y\}\leq t]
                        = 1- P[t<X\leq z,t<Y\leq z]
                    \end{align*}
                    Distinguimos ahora en función de $t$:
                    \begin{itemize}
                        \item \ul{Si $t\leq 0$}:
                        \begin{align*}
                            P[t<X\leq z,t<Y\leq z] = \int_0^1\int_0^1 1\ dxdy = 1
                        \end{align*}

                        Por tanto:
                        \begin{align*}
                            P[\max\{X,Y\}\leq z, \min\{X,Y\}\leq t]
                            = 1-1=0
                        \end{align*}

                        \item \ul{Si $0\leq t<1\leq z$}:
                        \begin{align*}
                            P[t<X\leq z,t<Y\leq z] = \int_t^1\int_t^1 1\ dxdy = (1-t)^2
                        \end{align*}

                        Por tanto:
                        \begin{align*}
                            P[\max\{X,Y\}\leq z, \min\{X,Y\}\leq t]
                            = 1- (1-t)^2
                            = 1-1-t^2+2t = t(2-t)
                        \end{align*}

                        \item \ul{Si $1\leq t<z$}:
                        \begin{align*}
                            P[t<X\leq z,t<Y\leq z] = 0
                        \end{align*}

                        Por tanto:
                        \begin{align*}
                            P[\max\{X,Y\}\leq z, \min\{X,Y\}\leq t]
                            = 1- 0=1
                        \end{align*}
                    \end{itemize}
                \end{itemize}
            \end{itemize}

            Por tanto, y uniendo las distintos conjuntos, tenemos que la función de distribución conjunta queda:
            \begin{align*}
                F_{(\max\{X,Y\},\min\{X,Y\})}(z,t)
                = \begin{cases}
                    0 & z\leq 0 \lor t\leq 0 \qquad (R_0)\\
                    z^2 & z\leq t,~0\leq z\leq 1 \qquad (R_1)\\
                    t(2z-t) & 0\leq t\leq z\leq 1 \qquad (R_2)\\
                    t(2-t) & 0\leq t\leq 1\leq z \qquad (R_3)\\
                    1 & 1\leq z \lor 1\leq t \qquad (R_4)\\
                \end{cases}
            \end{align*}

            En la Figura~\ref{fig:comprobacion} comprobamos que cubrimos la totalidad del plano.
            \begin{figure}[H]
                \centering
                \begin{tikzpicture}
                    \begin{axis}[
                        axis lines = center,
                        xlabel = $X$,
                        ylabel = $Y$,
                        xmin = -0.5, xmax = 1.5,
                        ymin = -0.5, ymax = 1.5,
                        xtick = {0,1},
                        ytick = {0,1},
                        yticklabel style = {yshift=-1.5ex},
                        xticklabel style = {xshift=-1.5ex},
                        axis equal,
                    ]
                        % Recta y=x
                        \addplot [name path=A, blue, forget plot, samples=2, domain=-3:3] {x};
                        
                        % Dibuja la línea horizontal en y=5
                        \addplot [name path=B, forget plot, draw=none] {5};

                        % Dibuja la línea horizontal en y=0
                        \addplot [name path=C, forget plot, draw=none] {0};
                    
                        % Rellena el área bajo la curva entre x=0 y x=1
                        \addplot [
                            thick,
                            color=orange,
                            fill=orange,
                            fill opacity=0.4
                        ]
                        fill between [
                            of=B and A,
                            soft clip={domain=0:1},
                        ];
                        % Señalamos zona R1
                        \node at (0.25, 0.75) {$R_1$};

                        % R0: (0, 2), (-2, 2), (-2, -2), (2, -2), (2, 0), (0, 0)
                        \addplot[fill=red, opacity=0.2] coordinates {
                            (0, 2) (-2, 2) (-2, -2) (2, -2) (2, 0) (0, 0)
                        } --cycle;
                        \node at (-0.25, -0.25) {$R_0$};

                        % Rellena el área bajo la curva entre x=0 y x=1
                        \addplot [
                            thick,
                            color=teal,
                            fill=teal,
                            fill opacity=0.4
                        ]
                        fill between [
                            of=A and C,
                            soft clip={domain=0:1},
                        ];
                        % Señalamos zona R1
                        \node at (0.75, 0.25) {$R_2$};

                        \addplot[fill=green, opacity=0.2] coordinates {
                            (1, 1) (2,1) (2,0) (1,0)
                        } --cycle;
                        \node at (1.5, 0.5) {$R_3$};

                        \addplot[fill=olive, opacity=0.2] coordinates {
                            (1, 1) (2,1) (2,2) (1,2)
                        } --cycle;
                        \node at (1.5, 1.25) {$R_4$};
                    \end{axis}
                \end{tikzpicture}
                \caption{Comprobación de la función de distribución conjunta.}
                \label{fig:comprobacion}
            \end{figure}

            Una vez calculada la función de distribución, su función de densidad es:
            \begin{equation*}
                f_{(\max\{X,Y\},\min\{X,Y\})}(z,t) = \dfrac{\partial^2 F_{(\max\{X,Y\},\min\{X,Y\})}(z,t)}{\partial z\partial t}
                = \begin{cases}
                    0 & z\leq 0 \lor t\leq 0 \qquad (R_0)\\
                    0 & z\leq t,~0\leq z\leq 1 \qquad (R_1)\\
                    2 & 0\leq t\leq z\leq 1 \qquad (R_2)\\
                    0 & 0\leq t\leq 1\leq z \qquad (R_3)\\
                    0 & 1\leq z \lor 1\leq t \qquad (R_4)\\
                \end{cases}
            \end{equation*}

            Uniendo casos, tenemos que:
            \begin{equation*}
                f_{(\max\{X,Y\},\min\{X,Y\})}(z,t)
                = \begin{cases}
                    2 & 0\leq t\leq z\leq 1 \qquad (R_2)\\
                    0 & \text{en caso contrario}
                \end{cases}
            \end{equation*}

            Notemos que $f_{(\max\{X,Y\},\min\{X,Y\})}(z,t)$ es la función de densidad de probabilidad de una variable aleatoria continua uniformemente distribuida en el triángulo $R_2$. Por tanto, tenemos que:
            \begin{equation*}
                (\max\{X,Y\},\min\{X,Y\})\sim \cc{U}(R_2).
            \end{equation*}
        \end{enumerate}
    \end{ejercicio}

    \begin{ejercicio}
        Dado un vector aleatorio con función generatriz de momentos
        \begin{equation*}
            M_{X_1,X_2}(t_1,t_2) = {\left(\dfrac{e^{t_1}}{2}+\dfrac{e^{t_2}}{4}+\dfrac{1}{4}\right)}^{5} \qquad t_1,t_2 \in \mathbb{R}
        \end{equation*}
        Calcular la razón de correlación y el coeficiente de correlación lineal de las variables $X_1$ y $X_2$.\\

        Sabemos que la función generatriz de momentos de una variable aleatoria $X$ tal que $X\sim M_2(n,p_1,p_2)$ es:
        \begin{equation*}
            M_X(t_1,t_2) = {\left(p_1e^{t_1}+p_2e^{t_2}+(1-p_1-p_2)\right)}^n.
        \end{equation*}

        Por tanto, tenemos que:
        \begin{equation*}
            (X_1,X_2)\sim M_2(5,\nicefrac{1}{2},\nicefrac{1}{4})
        \end{equation*}

        Por tanto, sabemos que $X_1\sim B(5,\nicefrac{1}{2})$ y $X_2\sim B(5,\nicefrac{1}{4})$. Además,
        $$\Cov[X_1,X_2]=-n\cdot p_1p_2$$

        Al tratarse de una multinomial, tenemos que las curvas de regresión son rectas, luego la razón de correlación es:
        \begin{align*}
            \eta^2_{X_1/X_2}
            =& \eta^2_{X_2/X_1}
            = \rho_{X_1,X_2}^2
            = \dfrac{\Cov^2[X_1,X_2]}{\Var[X_1]\Var[X_2]}
            = \dfrac{np_1^2p_2^2}{np_1(1-p_1)\cdot np_2(1-p_2)}
            = \dfrac{p_1p_2}{(1-p_1)(1-p_2)}
            =\\&= \dfrac{\nicefrac{1}{2}\cdot \nicefrac{1}{4}}{\nicefrac{1}{2}\cdot \nicefrac{3}{4}}
            = \dfrac{1}{3}
        \end{align*}

        Por otro lado, como $\Cov[X_1,X_2]=-np_1p_2<0$, tenemos que el coeficiente de correlación lineal es:
        \begin{equation*}
            \rho_{X_1,X_2} = -\sqrt{\rho_{X_1,X_2}^2}
            = -\dfrac{\sqrt{3}}{3}
        \end{equation*}
    \end{ejercicio}

    \begin{ejercicio}
        Dado el vector bidimensional $(X,Y)$ con la siguiente función masa de probabilidad conjunta:
        \begin{table}[H]
        \centering
        \begin{tabular}{|c|ccc|}
            \hline
            $X|Y$ & 0 & 1 & 2 \\
            \hline
            1 & $\nicefrac{1}{4}$ & 0 & 0 \\
            2 & 0 & $\nicefrac{1}{4}$ & 0 \\
            3 & $\nicefrac{1}{4}$ & 0 & $\nicefrac{1}{4}$ \\
            \hline
        \end{tabular}
        \end{table}
        \begin{enumerate}
            \item \textbf{(1.25 puntos)} Obtener la mejor aproximación minimo-cuadrática a la variable $Y$ conocidos valores de la variable $X$, así como calcular una medida de la bondad del ajuste.
            
            Completamos en primer lugar la función masa de probabilidad conjunta calculando las marginales:
            \begin{table}[H]
                \centering
                \begin{tabular}{c|ccc||c}
                    $X\backslash Y$ & 0 & 1 & 2 \\
                    \hline
                    1 & $\nicefrac{1}{4}$ & 0 & 0 & $\nicefrac{1}{4}$\\
                    2 & 0 & $\nicefrac{1}{4}$ & 0 & $\nicefrac{1}{4}$ \\
                    3 & $\nicefrac{1}{4}$ & 0 & $\nicefrac{1}{4}$ & $\nicefrac{1}{2}$ \\ \hline
                    \hline
                    & $\nicefrac{1}{2}$ & $\nicefrac{1}{4}$ & $\nicefrac{1}{4}$
                \end{tabular}
                \end{table}
            
            Mostramos ahora en la siguiente tabla la distribución condicionada a $X$, es decir, $P[Y|X=x]$:
            \begin{table}[H]
            \centering
            \begin{tabular}{c|ccc}
                $X\backslash Y$ & 0 & 1 & 2 \\
                \hline
                1 & $1$ & 0 & 0 \\
                2 & 0 & $1$ & 0 \\
                3 & $\nicefrac{1}{2}$ & 0 & $\nicefrac{1}{2}$
            \end{tabular}
            \end{table}

            Por tanto, tenemos que:
            \begin{align*}
                E[Y|X=1] &= 0\cdot 1 + 1\cdot 0 + 2\cdot 0 = 0 \\
                E[Y|X=2] &= 0\cdot 0 + 1\cdot 1 + 2\cdot 0 = 1 \\
                E[Y|X=3] &= 0\cdot \nicefrac{1}{2} + 1\cdot 0 + 2\cdot \nicefrac{1}{2} = 1
            \end{align*}

            Por tanto, la mejor aproximación minimo-cuadrática a la variable $Y$ conocidos valores de la variable $X$ es:
            \begin{equation*}
                \hat{Y} = \begin{cases}
                    0 & \text{si } X=1 \\
                    1 & \text{si } X=2,3
                \end{cases}
            \end{equation*}

            Calculamos ahora una medida de la bondad del ajuste. Calculamos previamente:
            \begin{align*}
                E[Y]&=0\cdot \nicefrac{1}{2} + 1\cdot \nicefrac{1}{4} + 2\cdot \nicefrac{1}{4} = \nicefrac{3}{4}\\
                E[Y^2]&=0^2\cdot \nicefrac{1}{2} + 1^2\cdot \nicefrac{1}{4} + 2^2\cdot \nicefrac{1}{4} = \nicefrac{5}{4}\\
                \Var[Y] &= E[Y^2] - E[Y]^2 = \nicefrac{5}{4} - \nicefrac{9}{16} = \nicefrac{11}{16}\\
                E[(E[Y|X])^2] &= \sum_{x\in \{1,2,3\}} E[Y|X=x]^2P[X=x] = 0^2\cdot \nicefrac{1}{4} + 1^2\cdot \nicefrac{1}{4} + 1^2\cdot \nicefrac{1}{2} = \nicefrac{3}{4}\\
                E[E[Y|X]] &= E[Y] = \nicefrac{3}{4}\\
                \Var[E[Y|X]] &= E[(E[Y|X])^2] - E[E[Y|X]]^2 = \nicefrac{3}{4} - \nicefrac{9}{16} = \nicefrac{3}{16}
            \end{align*}

            Por tanto, la medida de la bondad del ajuste es:
            \begin{align*}
                \eta_{Y/X}^2 &= \dfrac{\Var[E[Y|X]]}{\Var[Y]} = \dfrac{\nicefrac{3}{16}}{\nicefrac{11}{16}} = \dfrac{3}{11}
            \end{align*}
            \item \textbf{(1.25 puntos)} Obtener las ecuaciones de la rectas de regresión de $Y\mid X$ y $X\mid Y$ y el error cuadrático medio.
            
            Calculamos en primer lugar los resultados necesarios:
            \begin{align*}
                E[X]&=1\cdot \nicefrac{1}{4} + 2\cdot \nicefrac{1}{4} + 3\cdot \nicefrac{1}{2} = \nicefrac{9}{4} \\
                E[X^2]&=1^2\cdot \nicefrac{1}{4} + 2^2\cdot \nicefrac{1}{4} + 3^2\cdot \nicefrac{1}{2} = \nicefrac{23}{4} \\
                \Var[X] &= E[X^2] - E[X]^2 = \nicefrac{23}{4} - \nicefrac{81}{16} = \nicefrac{11}{16} \\
                E[XY] &= 2\cdot 1\cdot \nicefrac{1}{4}+3\cdot 2\cdot \nicefrac{1}{4}=2\\
                \Cov[X,Y] &= E[XY] - E[X]E[Y] = 2 - \nicefrac{9}{4}\cdot \nicefrac{3}{4} = \nicefrac{5}{16}
            \end{align*}

            Calculamos ahora las rectas de regresión.
            \begin{itemize}
                \item Recta de regresión de $Y$ sobre $X$:
                \begin{align*}
                    Y-E[Y] &= \dfrac{\Cov[X,Y]}{\Var[X]}(X-E[X]) \\
                    Y-\frac{3}{4} &= \dfrac{\nicefrac{5}{16}}{\nicefrac{11}{16}}\left(X-\frac{9}{4}\right) \\
                    Y &= \dfrac{5}{11}X - \dfrac{3}{11}
                \end{align*}

                \item Recta de regresión de $X$ sobre $Y$:
                \begin{align*}
                    X-E[X] &= \dfrac{\Cov[X,Y]}{\Var[Y]}(Y-E[Y]) \\
                    X-\frac{9}{4} &= \dfrac{\nicefrac{5}{16}}{\nicefrac{11}{16}}\left(Y-\frac{3}{4}\right) \\
                    X &= \dfrac{5}{11}Y + \dfrac{21}{11}
                \end{align*}
            \end{itemize}

            Respecto a los errores cuadráticos medios, tenemos que el error cuadrático medio de $Y$ sobre $X$ es:
            \begin{equation*}
                \text{E.C.M.}(Y|X) = \Var[Y] - \dfrac{\Cov^2[X,Y]}{\Var[X]} = \frac{11}{16} - \dfrac{\left(\nicefrac{5}{16}\right)^2}{\nicefrac{11}{16}} = \frac{6}{11}
            \end{equation*}

            Además, como $\Var[X]=\Var[Y]$, el error cuadrático medio de $X$ sobre $Y$ es el mismo:
            \begin{equation*}
                \text{E.C.M.}(X|Y) = \frac{6}{11}
            \end{equation*}
        \end{enumerate}
    \end{ejercicio}

\end{document}
