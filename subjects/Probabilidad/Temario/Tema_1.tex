\chapter{Distribuciones de Probabilidad Continua}

En el presente capítulo, se estudiarán las distribuciones de probabilidad continua más importantes. Al igual que 
en la asignatura de EDIP se vieron para variables aleatorias discretas, en este tema se presentarán las más
relevantes para variables aleatorias continuas.

\section{Distribución Uniforme Continua}

\begin{definicion}[Distribución Uniforme Continua]
    Una variable aleatoria continua $X$ sigue una distribución uniforme en el intervalo $[a,b]$, con $a,b\in \bb{R}$, $a<b$, si su función de densidad
    toma un valor constante en dicho intervalo, siendo nula fuera de él.
    Lo denotaremos como $X\sim \cc{U}(a,b)$.
\end{definicion}

\begin{prop}
    Sea $X\sim \cc{U}(a,b)$, entonces su función de densidad es:
    \Func{f}{\bb{R}}{[0,1]}{x}{\frac{1}{b-a}}
\end{prop}
\begin{proof}
    Sea $f$ la función de densidad de $X$. Para que sea una función de densidad, debe cumplir:
    \begin{equation*}
        \int_{-\infty}^{\infty} f(x)dx = \int_{a}^{b} f(x)dx = 1
    \end{equation*}

    Como $f$ es constante en $[a,b]$, sea entonces $f(x) = k$ para $x\in [a,b]$. Entonces:
    \begin{equation*}
        \int_{a}^{b} f(x)dx =
        \int_{a}^{b} kdx = k\int_{a}^{b} dx = k(b-a) = 1 \Longrightarrow k = \frac{1}{b-a}
    \end{equation*}

    Por tanto, la función de densidad de $X$ es:
    \begin{equation*}
        f(x) = \frac{1}{b-a} \quad \forall x\in [a,b]
    \end{equation*}
\end{proof}

\begin{prop}
    Sea $X\sim \cc{U}(a,b)$, entonces su función de distribución es:
    \Func{F_X}{\bb{R}}{[0,1]}{x}{\begin{cases}
        0 & x < a\\
        \dfrac{x-a}{b-a} & x\in [a,b]\\
        1 & x > b
    \end{cases}}
\end{prop}
\begin{proof}
    Tenemos que:
    \begin{align*}
        F_X(x) = \int_{-\infty}^x f(t)~dt
        = \int_{a}^{x} \dfrac{1}{b-a}~dt
        = \dfrac{1}{b-a} \int_a^x ~dt
        = \dfrac{x-a}{b-a}
    \end{align*}
\end{proof}

Como consecuencia inmediata a la proposición anterior, vemos como definición alternativa
que, si $X$ es una variable aleatoria continua tal que $X\sim \cc{U}(a,b)$, entonces se tiene que
la probabilidad de que $X$ tome un valor en un intervalo $[c,d]$, con $a\leq c\leq d\leq b$, es
directamente proporcional a la longitud del intervalo.

\begin{prop}
    Sea $X$ una variable aleatoria tal que $X\sim \cc{U}(a,b)$. Su función generatriz de momentos es:
    \begin{equation*}
        M_X(t) = \dfrac{e^{tb} - e^{ta}}{(b-a)t} \quad t\neq 0
    \end{equation*}
    Para $t=0$, $M_X(0) = 1$.
\end{prop}
\begin{proof}
    Veamos en primer lugar el caso $t=0$. Aunque ya esté demostrado en el temario de EDIP, esto es una propiedad
    general de las funciones generatrices de momentos, ya que:
    \begin{equation*}
        M_X(0) = E\left[e^{0X}\right] = E[1] = 1
    \end{equation*}

    Para $t\neq 0$, tenemos que:
    \begin{align*}
        M_X(t) &= E\left[e^{tX}\right] = \int_{a}^{b} e^{tx} \dfrac{1}{b-a}~dx = \dfrac{1}{b-a} \int_{a}^{b} e^{tx}~dx =\\
        &= \dfrac{1}{b-a} \left[ \dfrac{e^{tx}}{t} \right]_{a}^{b} = \dfrac{e^{tb} - e^{ta}}{(b-a)t}
    \end{align*}
\end{proof}

Calculemos ahora los momentos de una variable aleatoria $X$ tal que $X\sim \cc{U}(a,b)$.
Dado $k\in \bb{N}\cup \{0\}$, los momentos no centrados de $X$ son:
\begin{align*}
    m_k = E[X^k] &= \int_{a}^{b} x^k \dfrac{1}{b-a}~dx = \dfrac{1}{b-a} \int_{a}^{b} x^k~dx =\\
    &= \dfrac{1}{b-a} \left[ \dfrac{x^{k+1}}{k+1} \right]_{a}^{b} = \dfrac{b^{k+1} - a^{k+1}}{(k+1)(b-a)}
\end{align*}

Como consecuencia, tenemos que:
\begin{equation*}
    m_1 = E[X] = \dfrac{b^2 - a^2}{2(b-a)} = \dfrac{b+a}{2}
\end{equation*}

Veamos ahora los momentos centrados de $X$:
\begin{align*}
    \mu_k &= E[(X-m_1)^k] = E\left[\left(X-\dfrac{a+b}{2}\right)^k\right] = \int_{a}^{b} \left(x-\dfrac{a+b}{2}\right)^k \dfrac{1}{b-a}~dx =\\
    &= \dfrac{1}{b-a} \int_{a}^{b} \left(x-\dfrac{a+b}{2}\right)^k~dx
    = \dfrac{1}{b-a} \left[ \dfrac{\left(x-\dfrac{a+b}{2}\right)^{k+1}}{k+1} \right]_{a}^{b}
    =\\&= \dfrac{\left(b-\dfrac{a+b}{2}\right)^{k+1} - \left(a-\dfrac{a+b}{2}\right)^{k+1}}{(k+1)(b-a)}
    = \dfrac{\left(\dfrac{b-a}{2}\right)^{k+1} - \left(-\dfrac{b-a}{2}\right)^{k+1}}{(k+1)(b-a)}
\end{align*}

Distinguimos ahora en función de la paridad de $k$:
\begin{itemize}
    \item Si $k$ es impar, entonces $\mu_k = 0$.
    \item Si $k$ es par, entonces $\mu_k = \dfrac{(b-a)^k}{(k+1)2^k}$.
\end{itemize}







Algunos ejemplos de su utilidad son los siguientes:
\begin{itemize}
    \item La distribución uniforme proporciona una representación adecuada para
    redondear las diferencias que surgen al medir cantidades físicas entre los
    valores observados y los reales.
    Por ejemplo, si el peso de una persona se redondea al $kg$ más cercano,
    entonces la diferencia entre el peso observado y el real será algún valor entre
    $-0.5$ y $0.5~kg$. Es común que el error de redondeo siga entonces una distribución
    $\cc{U}(-0.5,0.5)$.
    
    \item La generación de números aleatorios en un intervalo $[a,b]$ debe seguir una distribución
    $\cc{U}(a,b)$.
\end{itemize}