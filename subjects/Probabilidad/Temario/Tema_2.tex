\chapter{Vectores Aleatorios}

Hasta ahora, hemos estudiado variable aleatoria unidimensional.
En este capítulo, vamos a estudiar variables aleatorias multidimensionales, es decir, vectores aleatorios.
Para ello, al igual que como hicimos con las variables aleatorias unidimensionales, hemos de definir en primer lugar la $\sigma-$álgebra de Borel en $\mathbb{R}^n$.
\begin{definicion}
    Sea $\mathbb{R}^n$ el espacio euclídeo de dimensión $n$.
    La $\sigma-$álgebra de Borel en $\mathbb{R}^n$, notada por $\cc{B}^n$, es la $\sigma-$álgebra generada por todos los intervalos de $\bb{R}^n$.
\end{definicion}

En particular, en Análisis Matemático II vimos que esta $\sigma-$álgebra está formada por los intervalos:
\begin{equation*}
    \left]-\infty, x\right] := \left]-\infty, x_1\right] \times \cdots \times \left]-\infty, x_n\right], \quad x = (x_1, \ldots, x_n) \in \mathbb{R}^n.
\end{equation*}

Además, en los presentes apuntes, usaremos la relación parcial de orden en $\mathbb{R}^n$ siguiente.
\begin{notacion}
    Dado $x,y\in \mathbb{R}^n$, notaremos:
    \begin{equation*}
        x\leq y \iff x_i\leq y_i, \quad \forall i=1, \ldots, n.
    \end{equation*}
    Esta es parcial, ya que no podemos comparar ciertos elementos, como $(1, 2)$ y $(2, 1)$.\\

    Gráficamente, en el plano tenemos que $x\leq x'$ si y solo si $x$ está a la izquierda y por debajo de $x'$.
    \begin{figure}[H]
        \centering
        \begin{tikzpicture}
            \begin{axis}[
                axis lines = left,
                xlabel = $x$,
                ylabel = $y$,
                xmin = 0, xmax = 3,
                ymin = 0, ymax = 3,
                xtick = \empty,
                ytick = \empty
            ]   
                \addplot[only marks] coordinates {(2.7,2.2)} node[above]{$x'$};
                \addplot[only marks] coordinates {(1,0.5)} node[above]{$x$};
            \end{axis}
        \end{tikzpicture}
        \caption{Relación de orden en $\mathbb{R}^2$, donde $x\leq x'$.}
    \end{figure}
\end{notacion}

Veamos ahora el equivalente a variable aleatoria en el caso multidimensional.
\begin{definicion}[Vector aleatorio]
    Un vector aleatorio $X=(X_1, \ldots, X_n)$ de un espacio de probabilidad $(\Omega, \mathcal{A}, P)$ se define como una función medible:
    \begin{equation*}
        X~:~(\Omega, \mathcal{A}, P) \to (\mathbb{R}^n, \mathcal{B}^n)
    \end{equation*}
    tal que se cumple que:
    \begin{equation*}
        X^{-1}(B)\in \mathcal{A}, \quad \forall B\in \mathcal{B}^n.
    \end{equation*}
\end{definicion}

Es decir:
\begin{align*}
    X^{-1}(\left]-\infty, x\right]) &= \{\omega\in \Omega \mid X_1(\omega)\leq x_1, \ldots, X_n(\omega)\leq x_n\} \in \mathcal{A}
    \quad \forall x\in \mathbb{R}^n.
\end{align*}

Además, considerando cada una de las componentes por separado, como cada componente de una función medible es medible, se tiene la siguiente caracterización de forma directa.
\begin{teo}
    Sea $X=(X_1, \ldots, X_n): (\Omega, \mathcal{A}, P) \to (\mathbb{R}^n, \mathcal{B}^n)$. Entonces:
    \begin{equation*}
        X \text{ es un vector aleatorio} \iff X_i \text{ es una variable aleatoria } \forall i=1, \ldots, n.
    \end{equation*}
\end{teo}

Introducimos ahora la distribución de probabilidad de un vector aleatorio, que será la función de densidad (o función masa de probabilidad) en el caso unidimensional.
\begin{definicion}[Distribución de probabilidad]
    Sea $X$ un vector aleatorio. La distribución de probabilidad de $X$ es la medida de probabilidad en $\mathbb{R}^n$ definida por:
    \Func{P_X}{\mathcal{B}^n}{[0,1]}{B}{P_X(B) = P(X^{-1}(B)), \quad \forall B\in \mathcal{B}^n.}
\end{definicion}

\begin{notacion}
    Al igual que en el caso unidimensional, dado $B\in \mathcal{B}^n$, tenemos:
    \begin{equation*}
        X^{-1}(B) = \{\omega\in \Omega \mid X(\omega)\in B\}
    \end{equation*}
    Por tanto, denotaremos $P_X(B)$ por $P[X\in B]$.
\end{notacion}

\begin{prop}
    Sea $X$ un vector aleatorio. Entonces, la distribución $P_X$ es una medida de probabilidad sobre $(\mathbb{R}^n, \mathcal{B}^n)$.
\end{prop}
\begin{proof} Veamos que se cumplen las tres propiedades de la Axiomática de Kolmogorov:
    \begin{enumerate}
        \item \ul{No negatividad}: $P_X(B) = P(X^{-1}(B)) \geq 0,\qquad \forall B\in \mathcal{B}^n$ ya que $P$ es una medida de probabilidad.
        \item \ul{Suceso seguro}: $P_X(\mathbb{R}^n) = P(X^{-1}(\mathbb{R}^n)) = P(\Omega) = 1$.
        \item \ul{$\sigma-$aditividad}: Sean $B_1, B_2, \ldots \in \mathcal{B}^n$ disjuntos dos a dos. Entonces, como $X^{-1}(B_1), X^{-1}(B_2), \ldots$ son disjuntos dos a dos, se tiene:
        \begin{align*}
            P_X\left(\bigcup_{i=1}^\infty B_i\right) &= P\left(X^{-1}\left(\bigcup_{i=1}^\infty B_i\right)\right) = P\left(\bigcup_{i=1}^\infty X^{-1}(B_i)\right)\AstIg\\
            &\AstIg \sum_{i=1}^\infty P(X^{-1}(B_i)) = \sum_{i=1}^\infty P_X(B_i).
        \end{align*}
        donde en $(\ast)$ hemos usado la propiedad de $\sigma-$aditividad de la medida de probabilidad $P$.\qedhere
    \end{enumerate}
\end{proof}


Así, tenemos que todo vector aleatorio $X$ transforma el espacio de probabilidad $(\Omega, \mathcal{A}, P)$ en el espacio de probabilidad $(\mathbb{R}^n, \mathcal{B}^n, P_X)$.\\

Al igual que en el caso unidimensional, definimos la función de distribución de un vector aleatorio a partir de la distribución de probabilidad.
\begin{definicion}[Función de distribución]
    Sea $X$ un vector aleatorio. La función de distribución de $X$ es la función:
    \Func{F_X}{\mathbb{R}^n}{[0,1]}{x}{F_X(x) = P[X\leq x] = P_X(\left]-\infty, x\right])}

    Si $X=(X_1, \ldots, X_n)$, entonces denotaremos:
    \begin{equation*}
        F_X(x) = P[X_1\leq x_1, \ldots, X_n\leq x_n].
    \end{equation*}
\end{definicion}

Algunas de las propiedades que cumple esta son:
\begin{enumerate}
    \item Es monótona no decreciente en cada una de sus componentes. Es decir, $\forall~i=1, \ldots, n$ y $\forall~x_1, \dots, x_{i-1}, x_{i+1}, \dots, x_n \in \bb{R}$ se tiene que:
    \begin{equation*}
        x_i \leq x_i'
        \Longrightarrow
        F_X(x_1, \ldots, x_{i-1}, x_i, x_{i+1}, \ldots, x_n) \leq F_X(x_1, \ldots, x_{i-1}, x_i', x_{i+1}, \ldots, x_n).
    \end{equation*}

    \item Es continua por la derecha en cada una de sus componentes. Es decir, $\forall~i=1, \ldots, n$ y $\forall~x_1, \dots, x_{i-1}, x_{i+1}, \dots, x_n \in \bb{R}$ se tiene que:
    \begin{equation*}
        \forall x_i\in \bb{R},\qquad F_X(x_1, \ldots, x_{i-1}, x_i, x_{i+1}, \ldots, x_n) = \lim_{x\to x_i^+} F_X(x_1, \ldots, x_{i-1}, x, x_{i+1}, \ldots, x_n).
    \end{equation*}

    \item $\forall i=1, \ldots, n$ y $\forall x_1, \dots, x_{i-1}, x_{i+1}, \dots, x_n \in \bb{R}$ se tiene que:
    \begin{equation*}
        \lim_{x\to -\infty} F_X(x_1, \ldots, x_{i-1}, x, x_{i+1}, \ldots, x_n) = 0.
    \end{equation*}

    \item Tenemos que:
    \begin{equation*}
        \lim_{\substack{x_i\to +\infty\\i=1, \ldots, n}} F_X(x_1, \ldots, x_n) = 1.
    \end{equation*}

    \item $\forall x_1, \ldots, x_n \in \bb{R}$ y $\forall \veps_1, \ldots, \veps_n\in \bb{R}^+$ se tiene que:
    \begin{align*}
        F_X&(x_1+\veps_1, \ldots, x_n+\veps_n) -\\
        &- \sum_{i=1}^n F_X(x_1 + \veps_1, \ldots, x_{i-1} + \veps_{i-1}, x_i, x_{i+1} + \veps_{i+1}, \ldots, x_n+\veps_n) +\\
        &+ \sum_{\substack{i,j=1\\i<j}}^n F_X(x_1 + \veps_1, \ldots, x_{i-1} + \veps_{i-1}, x_i, x_{i+1} + \veps_{i+1},
        \ldots\\&\hspace{2cm}\ldots, x_{j-1} + \veps_{j-1}, x_j, x_{j+1} + \veps_{j+1}, \ldots, x_n+\veps_n) +\\
        &+\dots+(-1)^n F_X(x_1, \ldots, x_n) \geq 0
    \end{align*}

    % // TODO: Propiedades de la función de distribución multidimensional
    % https://www.ugr.es/~cdpye/CursoProbabilidad/pdf/P_T06_FuncionDistribucion.pdf
\end{enumerate}

Estas propiedades caracterizan la función de distribución de los vectores aleatorios. Es decir,
dada una función que cumple estas propiedades, es la función de distribución de un vector aleatorio.\\

Veamos ahora una interpretación para la última propiedad, que puede ser bastante más compleja. Para el caso de dos variables, tenemos que fórmula queda:
\begin{align*}
    F_X(x_1+\veps_1, x_2+\veps_2) - F_X(x_1,x_2+\veps_2) - F_X(x_1+\veps_1,x_2) + F_X(x_1,x_2) \geq 0.
\end{align*}
Esa fórmula calcula el valor de la función de distribución en el siguiente rectángulo:
\begin{equation*}
    [x_1, x_1+\veps_1]\times [x_2, x_2+\veps_2].
\end{equation*}
Esto tiene sentido, ya que buscamos calcular probabilidades en subconjuntos de $\bb{R}^n$, y dichas probabilidades han de ser no negativas. De forma general, la fórmula calcula la probabilidad del siguiente rectángulo:
\begin{equation*}
    \prod_{i=1}^n [x_i, x_i+\veps_i].
\end{equation*}

Al igual que ocurría con variables aleatorias unidimensionales, puesto que $P_X$ es una medida de probabilidad, podemos calcular de forma sencilla la probabilidad de intervalos bidimensionales.
\begin{itemize}
    \item $P[a < X_1 \leq b, X_2 \in I] = P[X_1 \leq b, X_2 \in I] - P[X_1 \leq a, X_2 \in I]$.
    \item $P[a < X_1 < b, X_2 \in I] = P[X_1 < b, X_2 \in I] - P[X_1 \leq a, X_2 \in I]$.
    \item $P[X_1 \leq b, c < X_2 \leq d] = P[X_1 \leq b, X_2 \leq d] - P[X_1 \leq b, X_2 \leq c]$.
    \item $P[X_1 \leq b, c \leq X_2 < d] = P[X_1 \leq b, X_2 < d] - P[X_1 \leq b, X_2 < c]$.
    % https://www.ugr.es/~cdpye/CursoProbabilidad/pdf/P_T06_IntervalosFDMulti.pdf#[0,{%22name%22:%22Fit%22}]
\end{itemize}



\section{Clasificación de vectores aleatorios}

Al igual que en el caso unidimensional, podemos clasificar los vectores aleatorios en discretos y continuos. Esto se hace en función de la naturaleza de los valores que toma el vector aleatorio.
\begin{definicion}[Recorrido de un vector aleatorio]
    Sea $X=(X_1, \ldots, X_n)$ un vector aleatorio. El recorrido de $X$ es el conjunto de valores que toma el vector aleatorio:
    \begin{equation*}
        E_X = \{x\in \mathbb{R}^n \mid \exists \omega\in \Omega \text{ tal que } X(\omega) = x\}
        = Img(X).
    \end{equation*}
\end{definicion}

Usando el recorrido de una variable aleatoria unidimensional, tenemos que:
\begin{equation*}
    E_X \subset \prod_{i=1}^n E_{X_i}.
\end{equation*}

De forma directa, tenemos este resultado.
\begin{prop}
    Sea $X$ un vector aleatorio sobre el espacio de probabilidad $(\Omega, \mathcal{A}, P)$. Entonces:
    \begin{equation*}
        P[X\in E_X] = 1.
    \end{equation*}
\end{prop}
\begin{proof}
    Tenemos que:
    \begin{equation*}
        P[X\in E_X] = P[X^{-1}(E_X)] = P[\Omega] = 1.
    \end{equation*}
\end{proof}

\begin{comment}
Cuando nos preguntamos si es el único, tenemos el siguiente resultado.
\begin{prop}
    Sea $X$ un vector aleatorio, y sea $A\subset \mathbb{R}^n$. Entonces:
    \begin{equation*}
        P[X\in A] = 1 \iff A = E_X.
    \end{equation*}
\end{prop}
\begin{proof} Demostramos mediante doble implicación.
    \begin{itemize}
        \item[$\Longleftarrow$)] Supongamos que $A = E_X$. Veamos ahora que $P[X\in E_X] = 1$. Tenemos que:
        \begin{equation*}
            P[X\in E_X] = P[X^{-1}(E_X)] = P[\Omega] = 1.
        \end{equation*}

        \item[$\Longrightarrow$)] Supongamos que $P[X\in A] = 1$. Demostramos que $A = E_X$ por doble inclusión.
        \begin{description}
            \item[$\subset$)] Tenemos que:
            \begin{equation*}
                P[X\in A] = P[X^{-1}(A)] = 1 \Longrightarrow X^{-1}(A) = \Omega
            \end{equation*}
            Tomando la imagen de $X$, tenemos que $A=X(\Omega) = E_X$.
            
            \item[$\supset$)] Como $P[X\in E_X]\leq 1$ por definición y, al ser una probabilidad, es una función creciente, tenemos que $E_X\subset A$.
        \end{description}
    \end{itemize}
\end{proof}
\end{comment}


\subsection{Vectores aleatorios discretos}
\begin{definicion}
    Un vector aleatorio $X=(X_1, \ldots, X_n)$ es discreto si $\exists A\subset \mathbb{R}^n$ tal que
    \begin{equation*}
        P[X\in A] = 1.
    \end{equation*}
\end{definicion}

Veamos ahora la siguiente caracterización de vectores aleatorios discretos.
\begin{teo}
    Un vector aleatorio $X=(X_1, \ldots, X_n)$ es discreto si y solo si cada una de sus componentes $X_i$ es discreta.
\end{teo}
\begin{proof} Demostramos por doble implicación.
    \begin{itemize}
        \item[$\Longrightarrow$)] Supongamos que $X$ es discreto con valores en $E_X$. Entonces, Para cada $i=1, \ldots, n$, consideramos la proyección de $X$ en la componente $i$:
        \begin{equation*}
            E_X^i = \{x_i\in \mathbb{R} \mid \exists x\in E_X \text{ tal que } (x)_i = x_i\}.
        \end{equation*}
        Evidentemente, $E_X^i$ es numerable por serlo $E_X$. Veamos ahora que $P[X_i\in E_X^i] = 1$. Tenemos la siguiente inclusión:
        \begin{equation*}
            E_X\subset \bb{R} \times \cdots \times \bb{R}\times E_X^i \times \bb{R}\times \cdots \times \bb{R}.
        \end{equation*}

        Por tanto, como la probabilidad es una función creciente, tenemos que:
        \begin{align*}
            1&= P[X\in E_X] \leq P[X_1\in \bb{R}, \ldots, X_{i-1}\in \bb{R}, X_i\in E_X^i, X_{i+1}\in \bb{R}, \ldots, X_n\in \bb{R}] =\\
            &= P[X_i\in E_X^i].
        \end{align*}

        Por tanto, como toda probabilidad es menor o igual que 1, tenemos que $P[X_i\in E_X^i] = 1$, teniendo que $X_i$ es discreta.

        \item[$\Longleftarrow$)] Supongamos que cada una de las componentes de $X$ es discreta. Es decir, para cada $i=1, \ldots, n$, tenemos que $\exists E_{X_i}\subset \mathbb{R}$ numerable tal que $P[X_i\in E_{X_i}] = 1$.
        
        Consideramos ahora el conjunto $E_{X_1}\times \cdots \times E_{X_n}\subset \mathbb{R}^n$ numerable, y tenemos que:
        \begin{align*}
            P[X\in E_{X_1}\times \cdots \times E_{X_n}] &= P[X_1\in E_{X_1}, \ldots, X_n\in E_{X_n}] = P\left[\bigcap_{i=1}^n X_i\in E_{X_i}\right] \geq \\
            &\geq 1- \sum_{i=1}^n P[X_i\notin E_{X_i}] = 1.
        \end{align*}
        donde hemos usado la desigualdad de Boole. Por tanto, como las probabilidades son menores o iguales que 1, tenemos que $P[X\in E_{X_1}\times \cdots \times E_{X_n}] = 1$, por lo que $X$ es discreto.
    \end{itemize}
\end{proof}

Como en el caso de variables unidimensionales, los vectores de tipo discreto se manejan a partir de su función masa de probabilidad, y el tratamiento de este tipo de vectores es totalmente análogo al de las variables discretas.
\begin{definicion}
    Sea $X=(X_1, \ldots, X_n)$ un vector aleatorio discreto. La función masa de probabilidad de $X$ es la función:
    \Func{p_X}{E_X}{[0,1]}{x}{p_X(x) = P[X=x]}
\end{definicion}

Esta satisface:
\begin{enumerate}
    \item $p_X(x)\geq 0$.
    \item $\sum\limits_{x\in E_X} p_X(x) = 1$.
\end{enumerate}

La función de distribución de un vector aleatorio discreto se define por tanto como:
\begin{equation*}
    F_X(x) = P[X\leq x] = \sum_{\substack{t\in E_X\\t\leq x}} P[X=t]
\end{equation*}



\begin{ejemplo}
    Sea el experimento aleatorio de lanzar un dado, y sean las siguientes variables aleatorias:
    \begin{align*}
        X_1 &= \left\{
        \begin{array}{ll}
            -1 & \text{si sale impar} \\
            1 & \text{si sale par}
        \end{array}
        \right.\\
        X_2 &= \left\{
        \begin{array}{ll}
            -2 & \text{si sale 1, 2, 3} \\
            0 & \text{si sale 4} \\
            3 & \text{si sale 5, 6}
        \end{array}
        \right.
    \end{align*}

    Considerado el vector aleatorio $X=(X_1, X_2)$, se pide:
    \begin{enumerate}
        \item Calcular la función masa de probabilidad de $X$.
        
        Tenemos que:
        \begin{align*}
            E_{X_1} &= \{-1, 1\},\\
            E_{X_2} &= \{-2, 0, 3\},
        \end{align*}

        Por tanto,
        \begin{align*}
            E_X &= E_{X_1} \times E_{X_2} = \{(-1, -2), (-1, 0), (-1, 3), (1, -2), (1, 0), (1, 3)\}.
        \end{align*}

        Tenemos por tanto que:
        \begin{itemize}
            \item $P[X=(-1, -2)] = P[\text{sale impar y 1, 2, 3}] = \nicefrac{2}{6}$.
            \item $P[X=(-1, 0)] = P[\text{sale impar y 4}] = \nicefrac{0}{6}=0$.
            \item $P[X=(-1, 3)] = P[\text{sale impar y 5, 6}] = \nicefrac{1}{6}$.
            \item $P[X=(1, -2)] = P[\text{sale par y 1, 2, 3}] = \nicefrac{1}{6}$.
            \item $P[X=(1, 0)] = P[\text{sale par y 4}] = \frac{1}{6}$.
            \item $P[X=(1, 3)] = P[\text{sale par y 5, 6}] = \nicefrac{1}{6}$.
        \end{itemize}


        Podemos resumir esta información como
        \begin{table}[H]
            \centering
            \begin{tabular}{c | c c c | c }
                \scriptsize{$X_1 \backslash X_2$} & $-2$ & 0 & 3 &\phantom{\scriptsize{$X_1 \backslash X_2$}}\\
                \hline
                $-1$ & \nicefrac{2}{6} & 0 & \nicefrac{1}{6}&\\
                1 & \nicefrac{1}{6} & \nicefrac{1}{6} & \nicefrac{1}{6}&\\
                \hline
                &&&&\\
            \end{tabular}
        \end{table}

        \item Calcular la función de distribución de $X$.
        
        Tenemos que:
        \begin{equation*}
            F_X(x_1, x_2) = \begin{cases}
                0 & x_1 < -1 \text{ o } x_2 < -2 \\
                \nicefrac{2}{6} & x_1 \in \left[-1, 1\right[, x_2 \in \left[-2, 3\right[ \\
                \nicefrac{3}{6} & x_1 \in \left[-1, 1\right], x_2\geq 3 \\
                \nicefrac{3}{6} & x_1\geq 1, x_2 \in \left[-2, 0\right[ \\
                \nicefrac{4}{6} & x_1\geq 1, x_2 \in \left[0, 3\right[ \\
                1 & x_1\geq 1, x_2\geq 3
            \end{cases}
        \end{equation*}
        
        \item Calcular $P[X_1 + X_2 \leq 1]$.
        
        En este caso, los valores de $X_1 + X_2$ que cumplen que $X_1 + X_2 \leq 1$ son:
        \begin{equation*}
            B=\{(-1, -2), (1, -2), (1, 0)\}.
        \end{equation*}

        Por tanto,
        \begin{align*}
            P[X_1 + X_2 \leq 1] &= P[X\in B] = P[X=(-1, -2)] + P[X=(1, -2)] + P[X=(1, 0)] =\\&= \nicefrac{2}{6} + \nicefrac{1}{6} + \nicefrac{1}{6} = \nicefrac{4}{6}.
        \end{align*}
    \end{enumerate}
\end{ejemplo}


\subsection{Vectores aleatorios continuos}

\begin{definicion}
    Un vector aleatorio $X=(X_1, \ldots, X_n)$ es continuo si existe una función integrable no negativa $f_X:\mathbb{R}^n\to \mathbb{R}$ tal que su función de distribución es:
    \begin{equation*}
        F_X(x_1, \ldots, x_n) = \int_{-\infty}^{x_1}\cdots\int_{-\infty}^{x_n} f_X(t_1, \ldots, t_n) d t_n \cdots dt_1,
        \quad \forall x_1, \ldots, x_n \in \mathbb{R}.
    \end{equation*}
    A la función $f_X$ se le llama función de densidad de probabilidad de $X$.
\end{definicion}

Además, si $f_X$ es continua en un punto $x=(x_1, \ldots, x_n)\in \mathbb{R}^n$, entonces la función de distribución $F_X$ es derivable en ese punto y se tiene que:
\begin{equation*}
    \frac{\partial^n F_X}{\partial x_1\cdots \partial x_n}(x) = f_X(x).
\end{equation*}
% // TODO: Función de densidad de un vector aleatorio continuo

Esta función $f_X$, por definición, cumple las siguientes propiedades:
\begin{enumerate}
    \item $f_X(x)\geq 0$.
    \item Es integrable en $\mathbb{R}^n$.
    \item $\int_{\mathbb{R}^n} f_X(x)~d x = 1$.
    \begin{equation*}
        \int_{-\infty}^{+\infty}f_X(t)~d t =
        \lim_{x\to +\infty} \int_{-\infty}^{x} f_X(t) = \lim_{x\to +\infty} F_X(x) \AstIg 1.
    \end{equation*}
    donde en $(\ast)$ hemos usado una de las propiedades de la función de distribución.
\end{enumerate}

La función de densidad determina la función de distribución de un vector aleatorio continuo, y por tanto su distribución de probabilidad.
\begin{equation*}
    P_X(B) = P[X\in B]= \int_B f_X(x)~d x, \quad \forall B\in \mathcal{B}^n.
\end{equation*}
% // TODO: Distribución de probabilidad de un vector aleatorio continuo

Debido a lo estudiado en Análisis Matemático II, sabemos que si $E\subset \mathbb{R}^n$ es un conjunto numerable, entonces $P[X\in E] = 0$.


Al igual que en el caso de vectores discretos, tenemos el siguiente resultado.
\begin{teo} \label{teo:caract_cont}
    Sea vector aleatorio $X=(X_1, \ldots, X_n)$ continuo. Entonces, cada una de sus componentes $X_i$ es continua.
    % https://www.ugr.es/~cdpye/CursoProbabilidad/pdf/P_T06_VectorContinuo.pdf
\end{teo}
\begin{proof}
    Fijemos $i\in \{1, \ldots, n\}$, y sea $F_{X_i}$ la función de distribución de $X_i$. Entonces, tenemos que:
    \begin{align*}
        F_{X_i}(x_i) &= P[X_i\leq x_i] = P[X_1\in \mathbb{R}, \ldots, X_{i-1}\in \mathbb{R}, X_i\leq x_i, X_{i+1}\in \mathbb{R}, \ldots, X_n\in \mathbb{R}].=\\
        &= \int_{\bb{R}} \cdots
        \int_{\bb{R}}\int_{-\infty}^{x_i}\int_{\bb{R}} \cdots
        \int_{\bb{R}}
        f_X(t_1, \ldots, t_n) d t_n \cdots dt_{i+1} dt_i dt_{i-1} \cdots dt_1.
        =\\
        &= \int_{-\infty}^{x_i}\int_{\bb{R}} \cdots
        \int_{\bb{R}}
        f_X(t_1, \ldots, t_n) d t_n \cdots dt_{i+1} dt_{i-1} \cdots dt_1 \cdot dt_i
    \end{align*}
    Definimos por tanto:
    \begin{equation*}
        f_{X_i}(x_i) = \int_{\bb{R}} \cdots
        \int_{\bb{R}}
        f_X(t_1, \ldots, t_n) d t_n \cdots dt_{i+1} dt_{i-1} \cdots dt_1.
    \end{equation*}


    Por tanto, tenemos que:
    \begin{equation*}
        F_{X_i}(x_i) = \int_{-\infty}^{x_i} f_{X_i}(t_i)~d t_i.
    \end{equation*}
    Como $f_i$ es integrable y no negativa, tenemos que es la función de densidad de probabilidad de $X_i$. Por tanto, $X_i$ es una variable aleatoria continua.
\end{proof}



\section{Distribuciones marginales}

Dado un vector aleatorio $X=(X_1, \ldots, X_n)$, podemos estudiar las distribuciones de sus componentes por separado. Estas se conocen como distribuciones marginales.

\begin{definicion}
    Sea $X=(X_1, \ldots, X_n)$ un vector aleatorio. La distribución marginal de $X_i$ es la distribución de probabilidad de la variable aleatoria $X_i$. A la distribución de probabilidad de $X$ se le llama distribución conjunta de $X$.
\end{definicion}

Veamos cómo obtener la función de distribución de una variable aleatoria a partir de la función de distribución de un vector aleatorio.
\begin{prop}
    Sea $X=(X_1, \ldots, X_n)$ un vector aleatorio con función de distribución $F_X$. Entonces, la función de distribución de $X_i$ es:
    \begin{equation*}
        F_{X_i}(x_i) = \lim_{\substack{t_j\to +\infty,\\j\neq i}} F_X(t_1, \ldots, t_{i-1}, x_i, t_{i+1}, \ldots, t_n).
    \end{equation*}
    % https://www.ugr.es/~cdpye/CursoProbabilidad/pdf/P_T06_FDMarginal.pdf
\end{prop}
\begin{proof}
    Esta propiedad se deduce de la continuidad de las funciones de probabilidad (Axiomática de Kolmogorov) y del hecho de que:
    \begin{equation*}
        \bb{R} = \bigcup_{t\in \bb{R}^+} ]-\infty, t].
    \end{equation*}

    Tenemos que:
    \begin{align*}
        F_{X_i}(x_i) &= P[X_i\leq x_i] = P[X_1\in \bb{R}, \ldots, X_{i-1}\in \bb{R}, X_i\leq x_i, X_{i+1}\in \bb{R}, \ldots, X_n\in \bb{R}] \AstIg\\
        &\AstIg
        \lim_{\substack{t_j\to +\infty,\\j\neq i}}
        P_X\left(]-\infty, t_1]\times \ldots \times  ]-\infty, t_{i-1}]\times ]-\infty, x_i] \times ]-\infty, t_{i+1}] \times \ldots \times ]-\infty, t_n]\right) =\\
        &= \lim_{\substack{t_j\to +\infty,\\j\neq i}} F_X(t_1, \ldots, t_{i-1}, x_i, t_{i+1}, \ldots, t_n).
    \end{align*}
    donde en $(\ast)$ hemos usado la propiedad de continuidad de la función de probabilidad.
\end{proof}

\subsubsection{Caso discreto}

En el caso de vectores aleatorios discretos, la función de masa de probabilidad de una variable aleatoria se obtiene a partir de la función de masa de probabilidad del vector aleatorio.

\begin{prop} \label{prop:dist_marginal_disc}
    Sea $X=(X_1, \ldots, X_n)$ un vector aleatorio discreto con función de masa de probabilidad $p_X$. Entonces, la función de masa de probabilidad de $X_i$ es:
    \begin{equation*}
        p_{X_i}(x_i) = \sum_{\substack{t=(t_1,\dots,t_n)\in E_X\\t_i=x_i}} p_X(t).
    \end{equation*}
    % // TODO: Función de masa de probabilidad marginal
\end{prop}

\subsubsection{Caso continuo}

En el caso de vectores aleatorios continuos, la función de densidad de probabilidad de una variable aleatoria se obtiene a partir de la función de densidad de probabilidad del vector aleatorio.

\begin{prop} \label{prop:dist_marginal_cont}
    Sea $X=(X_1, \ldots, X_n)$ un vector aleatorio continuo con función de densidad de probabilidad $f_X$. Entonces, la función de densidad de probabilidad de $X_i$ es:
    \begin{equation*}
        f_{X_i}(x_i) = \int_{\bb{R}^{n-1}} f_X(x_1, \ldots, x_{i-1}, x_i, x_{i+1}, \ldots, x_n)~d x_1 \cdots d x_{i-1} d x_{i+1} \cdots d x_n.
    \end{equation*}
\end{prop}
Notemos que esta demostración se ha hecho en el Teorema~\ref{teo:caract_cont}.


\section{Distribuciones condicionadas}

Dado un vector aleatorio $X=(X_1, \ldots, X_n)$, podemos estudiar la distribución de una de sus componentes condicionada a que otra de sus componentes tome un valor concreto.

\subsubsection{Caso discreto}
\begin{definicion}
    Sea $X=(X_1, \ldots, X_n)$ un vector aleatorio discreto, $X_i$ una de sus componentes y $x_i^\ast\in \bb{R}$ tal que $P[X_i=x_i^\ast]>0$. La distribución condicionada de $(X_1, \ldots, X_{i-1}, X_{i+1}, \ldots, X_n)$ a $X_i=x_i^\ast$ es la distribución con función de masa de probabilidad:
    \begin{align*}
        P&[X_1=x_1, \ldots, X_{i-1}=x_{i-1}, X_{i+1}=x_{i+1}, \ldots, X_n=x_n \mid X_i=x_i^\ast] =\\&\qquad = \frac{P[X_1=x_1, \ldots, X_{i-1}=x_{i-1}, X_i=x_i^\ast, X_{i+1}=x_{i+1}, \ldots, X_n=x_n]}{P[X_i=x_i^\ast]},\\
        &\qquad \forall (x_1, \ldots, x_{i-1}, x_{i+1}, \ldots, x_n)\mid (x_1, \ldots, x_{i-1}, x_i^\ast, x_{i+1}, \ldots, x_n)\in E_X.
    \end{align*}
\end{definicion}

Comprobemos que esta definición efectivamente es una función masa de probabilidad.
\begin{proof}~
    \begin{enumerate}
        \item En primer lugar, toma valores no negativos, puesto que es el cociente de dos valores no negativos.
        \item Veamos ahora que suma $1$. Para ello, por la Proposición~\ref{prop:dist_marginal_disc}, tenemos que la siguiente sumatoria es la distribución marginal de $X_i$:
        \begin{equation*}
            \sum_{\mathclap{\substack{(x_1, \ldots, x_{i-1}, x_{i+1}, \ldots, x_n) \mid \\(x_1, \ldots, x_{i-1}, x_i^\ast, x_{i+1}, \ldots, x_n)\in E_X}}} P[X_1=x_1, \ldots, X_{i-1}=x_{i-1}, X_i=x_i^\ast, X_{i+1}=x_{i+1}, \ldots, X_n=x_n] = P[X_i=x_i^\ast].
        \end{equation*}
    
        Por tanto, tenemos que:
        \begin{multline*}
            \sum_{\mathclap{\substack{(x_1, \ldots, x_{i-1}, x_{i+1}, \ldots, x_n) \mid \\(x_1, \ldots, x_{i-1}, x_i^\ast, x_{i+1}, \ldots, x_n)\in E_X}}} P[X_1=x_1, \ldots, X_{i-1}=x_{i-1}, X_{i+1}=x_{i+1}, \ldots, X_n=x_n \mid X_i=x_i^\ast]= 1
        \end{multline*}
    \end{enumerate}
\end{proof}

\subsubsection{Caso continuo}
\begin{definicion}
    Sea $X=(X_1, \ldots, X_n)$ un vector aleatorio continuo, $X_i$ una de sus componentes y $x_i^\ast\in \bb{R}$ tal que $f_{X_i}(x_i^\ast)>0$. La distribución condicionada de $(X_1, \ldots, X_{i-1}, X_{i+1}, \ldots, X_n)$ a $X_i=x_i^\ast$ es la distribución con función de densidad de probabilidad:
    \begin{align*}
        f_{X_1, \ldots, X_{i-1}, X_{i+1}, \ldots, X_n \mid X_i=x_i^\ast}(x_1, \ldots, x_{i-1}, x_{i+1}, \ldots, x_n) =
        \dfrac{f_X(x_1, \ldots, x_{i-1}, x_i^\ast, x_{i+1}, \ldots, x_n)}{f_{X_i}(x_i^\ast)}.
    \end{align*}
\end{definicion}

Comprobemos que efectivamente dicha función se trata de una función de densidad.
\begin{proof}~
    \begin{enumerate}
        \item $f_{X_1, \ldots, X_{i-1}, X_{i+1}, \ldots, X_n \mid X_i=x_i^\ast}$ es no negativa, por ser cociente de funciones de densidad.
        \item Es integrable (se deja como ejercicio al lector).
        \item Veamos que integra $1$:
        \begin{align*}
            \int_{\bb{R}^{n-1}}& \dfrac{f_X(x_1, \ldots, x_{i-1}, x_i^\ast, x_{i+1}, \ldots, x_n)}{f_{X_i}(x_i^\ast)} 
            = \dfrac{\displaystyle \int_{\bb{R}^{n-1}} f_X(x_1, \ldots, x_{i-1}, x_i^\ast, x_{i+1}, \ldots, x_n)}{f_{X_i}(x_i^\ast)} 
            \AstIg \\ &\AstIg
            \dfrac{f_{X_i}(x_i^\ast)}{f_{X_i}(x_i^\ast)} = 1
        \end{align*}
        donde en $(\ast)$ hemos usado la Proposición~\ref{prop:dist_marginal_cont}, ya que es la función de densidad de la marginal de $X_i$.
    \end{enumerate}
\end{proof}


\section{Cambio de Variable}

Dado un vector aleatorio $X=(X_1, \ldots, X_n)$, podemos estudiar la distribución de otro vector aleatorio $Y=(Y_1, \ldots, Y_n)$ que depende de $X$ mediante una transformación.
\begin{prop}
    Sea $X$ un vector aleatorio $n-$dimensional, y una función $g$ dada por $g:\left(\bb{R}^n,\cc{B}^n\right)\to \left(\bb{R}^m,\cc{B}^m\right)$ una función medible. Entonces, $Y=g(X)$ es un vector aleatorio $m-$dimensional.
\end{prop}
\begin{proof}
    Como la composición de funciones medibles es medible, tenemos que $Y=g(X)$ es medible por serlo $X$ y $g$. Por tanto, $Y$ es un vector aleatorio.
\end{proof}

Veamos ahora cómo se transforma la distribución de probabilidad de un vector aleatorio al aplicarle una transformación.
\begin{prop}
    Sea $X:(\Omega, \cc{A},P) \to (\bb{R}^n, \cc{B}^n)$ un vector aleatorio $n-$dimensional y $g:\bb{R}^n\to \bb{R}^m$ una función medible. Entonces, la distribución de probabilidad de $Y=g(X)$ es:
    \begin{equation*}
        P_Y(B) = P_X(g^{-1}(B)), \quad \forall B\in \cc{B}^m.
    \end{equation*}
\end{prop}
\begin{proof}
    Como $Y=g\circ X$, tenemos que $Y^{-1}=X^{-1}\circ g^{-1}$. Por tanto, tenemos que:
    \begin{equation*}
        P_Y(B) = P[Y^{-1}(B)] = P[X^{-1}(g^{-1}(B))] = P_X(g^{-1}(B)).
    \end{equation*}
\end{proof}

Como resultado inmediato, tenemos que la función de distribución de $Y$ es:
\begin{equation*}
    F_Y(y) = P_Y(\left]-\infty, y\right]) = P_X(g^{-1}(\left]-\infty, y\right]))   \qquad \forall y\in \bb{R}^m.
\end{equation*}

Veamos ahora algunos casos particulares de transformaciones de vectores aleatorios.

\subsection{Discreto a Discreto}

Sea $X=(X_1, \ldots, X_n)$ un vector aleatorio discreto con valores en $E_X$, y sea $g:(\bb{R}^n, \cc{B}^n)\to (\bb{R}^m, \cc{B}^m)$ una función medible. Entonces, $Y=g(X)$ es un vector aleatorio discreto con valores en $E_Y=g(E_X)$, y su función masa de probabilidad es:
\begin{equation*}
    P[Y=y] = \sum_{x\in E_X\cap g^{-1}(y)} P[X=x],\qquad \forall y\in E_Y.
\end{equation*}

% // TODO: Demostración C.V. Discreto


\begin{ejemplo}
    Sea $X=(X_1,X_2)$ un vector aleatorio con función de masa de probabilidad:
    \begin{equation*}
        \begin{array}{c|ccc|}
            X_2\backslash X_1 & 1 & 0 & -1\\
            \hline
            -2 & \nicefrac{1}{6} & \nicefrac{1}{12} & \nicefrac{1}{6}\\
            1 & \nicefrac{1}{6} & \nicefrac{1}{12} & \nicefrac{1}{6}\\
            2 & \nicefrac{1}{12} & 0 & \nicefrac{1}{12}
        \end{array}
    \end{equation*}
    Calcular la función de masa de probabilidad de $Y=(|X_1|, X_2^2)$.\\

    Tenemos que $E_Y=g(E_X)$, que es:
    \begin{equation*}
        E_Y=\{(0,1),(0,4),(1,1),(1,4)\}.
    \end{equation*}

    Por tanto, tenemos que:
    \begin{align*}
        P[Y=(0,1)] &= P[X_1=0, X_2=1] = \nicefrac{1}{12},\\
        P[Y=(0,4)] &= P[X_1=0, X_2=2]+P[X_1=0, X_2=-2] = 0+\nicefrac{1}{12}= \nicefrac{1}{12},\\
        P[Y=(1,1)] &= P[X_1=1, X_2=1]+P[X_1=-1, X_2=1] = \nicefrac{1}{6}+\nicefrac{1}{6}= \nicefrac{1}{3},\\
        P[Y=(1,4)] &= P[X_1=1, X_2=2]+P[X_1=1, X_2=-2]
        + P[X_1=-1, X_2=2]+\\&\hspace{2cm} +P[X_1=-1, X_2=-2] = \nicefrac{1}{12}+\nicefrac{1}{6}+\nicefrac{1}{12}+\nicefrac{1}{6} = \nicefrac{1}{2}.
    \end{align*}

    Por tanto, la función de masa de probabilidad de $Y$ es:
    \begin{equation*}
        \begin{array}{c|cc|}
            Y_2\backslash Y_1 & 0 & 1\\
            \hline
            1 & \nicefrac{1}{12} & \nicefrac{1}{3}\\
            4 & \nicefrac{1}{12} & \nicefrac{1}{2}
        \end{array}
    \end{equation*}
\end{ejemplo}

\subsection{Continuo a Discreto}

Sea $X=(X_1, \ldots, X_n)$ un vector aleatorio continuo con función de densidad $f_X$, y sea $g:(\bb{R}^n, \cc{B}^n)\to (\bb{R}^m, \cc{B}^m)$ una función medible tal que $Y=g(X)$ es un vector aleatorio discreto con valores en $E_Y\subset \bb{R}^m$. Su función masa de probabilidad se obtiene a partir de $f_X$ como:
\begin{equation*}
    P[Y=y] = \int_{g^{-1}(y)} f_X(x)~d x,\qquad \forall y\in E_Y.
\end{equation*}

% // TODO: Demostración C.V. Continuo a Discreto

\begin{ejemplo}
    Sea $X=(X_1,X_2)$ un vector aleatorio con función de densidad, para $\mu,\lm\in \bb{R}^+$:
    \begin{equation*}
        f_X(x_1,x_2)=\begin{cases}
            \lm\mu e^{-\lm x_1-\mu x_2} &
            \text{si } x_1>0, x_2>0,\\
            0 & \text{en otro caso}.
        \end{cases}
    \end{equation*}

    Calcular la función de masa de probabilidad de:
    \begin{equation*}
        Y=\begin{cases}
            1 & \text{si } X_1>X_2 \\
            0 & \text{si } X_1\leq X_2
        \end{cases}
    \end{equation*}
    
    Tenemos que $E_Y=\{0,1\}$, y calculamos cada una de las probabilidades:
    \begin{align*}
        P[Y=1]&=P[X_1>X_2]=\int_{0}^{\infty} \int_{x_2}^{\infty} \lm\mu e^{-\lm x_1-\mu x_2}~d x_1 d x_2
        =\int_{0}^{\infty}\mu e^{-\mu x_2} \int_{x_2}^{\infty} \lm e^{-\lm x_1}~d x_1 d x_2 =
        \\&= \int_{0}^{\infty}\mu e^{-\mu x_2} \left[-e^{-\lm x_1}\right]_{x_2}^{\infty} d x_2
        = \int_{0}^{\infty}\mu e^{-\mu x_2} e^{-\lm x_2} d x_2
        = \int_{0}^{\infty}\mu e^{-(\mu+\lm) x_2} d x_2
        =\\&= \left[-\dfrac{\mu}{\mu+\lm} e^{-(\mu+\lm) x_2}\right]_{0}^{\infty}
        = \dfrac{\mu}{\mu+\lm}.\\
        P[Y=0]&=1-P[Y=1]=1-\dfrac{\mu}{\mu+\lm}=\dfrac{\lm}{\mu+\lm}.
    \end{align*}

    Por tanto, la función de masa de probabilidad de $Y$ es:
    \begin{equation*}
        P[Y=0]=\dfrac{\lm}{\mu+\lm},\quad P[Y=1]=\dfrac{\mu}{\mu+\lm}.
    \end{equation*}
\end{ejemplo}


\subsection{Continuo a Continuo}

Sea $X=(X_1, \ldots, X_n)$ un vector aleatorio continuo con función de densidad $f_X$ y con valores en $E_X\subset \bb{R}^n$. Sea $g=(g_1,\dots,g_n):(\bb{R}^n, \cc{B}^n)\to (\bb{R}^n, \cc{B}^n)$ una función medible tal que:
\begin{itemize}
    \item $\exists g^{-1}=\left(g_1^{\ast},\dots,g_n^{\ast}\right)$.
    \item La inversa es derivable en todas sus componentes:
    \begin{equation*}
        \exists \dfrac{\partial g_i^{\ast}}{\partial y_j}(y_1,\dots,y_n),\quad \forall i,j\in \{1,\dots,n\},\forall y=(y_1,\dots,y_n)\in g(E_X).
    \end{equation*}
    \item El jacobiano de la inversa no es nulo:
    \begin{equation*}
        \det(Jg^{-1}(y))\neq 0 \quad \forall y\in g(E_X).
    \end{equation*}
\end{itemize}

En estas condiciones, la transformación $Y=g(X)$ es un vector aleatorio de tipo continuo, y su función de densidad puede obtenerse a partir de $f_X$ mediante la siguiente relación:
\begin{equation*}
    f_Y(y) = f_X(g^{-1}(y)) \left|\det(Jg^{-1}(y))\right|, \quad \forall y\in g(E_X).
\end{equation*}


\subsection{Distribución del Máximo y del Mínimo}

\begin{definicion}
    Dadas $n$ funciones $f_1$, $f_2$, \ldots $f_n$ definidas sobre un mismo conjunto $A$ y con imagen en un mismo conjunto $B$, definimos las funciones 
    \begin{equation*}
        \min\{f_1,f_2,\ldots,f_n\},\max\{f_1,f_2,\ldots,f_n\}:A\rightarrow B
    \end{equation*}

    dadas por, para cada $x\in A$:
    \begin{align*}
        \min\{f_1,f_2,\ldots,f_n\}(x) &= \min\{f_1(x),f_2(x),\ldots,f_n(x)\} \\
        \max\{f_1,f_2,\ldots,f_n\}(x) &= \max\{f_1(x),f_2(x),\ldots,f_n(x)\}
    \end{align*}
\end{definicion}
Dada una función $F:A^n\rightarrow B$ de $n$ variables, podemos definir $\min F$ (análogamente $\max F$) como la función:
\begin{equation*}
    \min F = \min\{F_1,F_2,\ldots,F_n\}
\end{equation*}

siendo $F_1$, $F_2$, \ldots, $F_n$ las componentes de la función $F$.

\begin{prop}
    Sea $g:(\bb{R}^n, \cc{B}^n)\to (\bb{R}^m, \cc{B}^m)$ una función medible, entonces $\min g$ y $\max g$ son funciones medibles.
\end{prop}

Tenemos que dos cambios de variable frecuentes son los dados por las funciones máximo y mínimo, que sabemos que son medibles.
Sea por tanto $X=(X_1,\dots,X_n)$ un vector aleatorio con función de distribución $F_X$, y buscamos hallar la función de distribución de $Z=\min X$ y $W=\max X$.
Dado $x\in \bb{R}$, tenemos que:
\begin{itemize}
    \item \ul{$Z=\min = \min X$}: $Z=\min X = \min\{X_1,\dots,X_n\}$.
    
    Dado $\omega\in \Omega$, tenemos que:
    \begin{equation*}
        Z(\omega)>x \Longleftrightarrow \min\{X_1(\omega),\dots,X_n(\omega)\}>x \Longleftrightarrow X_1(\omega)>x,\dots,X_n(\omega)>x.
    \end{equation*}

    Por tanto, tenemos que:
    \begin{equation*}
        P[\min \leq x] = 1-P[\min > x] = 1-P[X_1>x,\dots,X_n>x]\qquad \forall x\in \bb{R}.
    \end{equation*}

    \item \ul{$W=\max = \max X$}: $W=\max X = \max\{X_1,\dots,X_n\}$.
    
    Dado $\omega\in \Omega$, tenemos que:
    \begin{equation*}
        W(\omega)<x \Longleftrightarrow \max\{X_1(\omega),\dots,X_n(\omega)\}<x \Longleftrightarrow X_1(\omega)<x,\dots,X_n(\omega)<x.
    \end{equation*}

    Por tanto, tenemos que:
    \begin{equation*}
        P[\max \leq x] = P[X_1\leq x,\dots,X_n\leq x]=P[X\leq (x,\dots,x)]\qquad \forall x\in \bb{R}.
    \end{equation*}
\end{itemize}

Dado ahora $X=(X_1,\dots,X_n)$ un vector aleatorio, consideramos ahora la distribución conjunta:
\begin{equation*}
    (\max X, \min X)
\end{equation*}

Busquemos su función de distribución. Dados $(x,y)\in \bb{R}^2$, tenemos que:
\begin{equation*}
    P[(\max X, \min X)\leq (x,y)] = P[\max X\leq x, \min X\leq y]
\end{equation*}
\begin{itemize}
    \item Si $x\leq y$, como siempre se tiene que $\min X\leq \max X$ y en este caso buscamos que $\max X\leq x$, tenemos que $\min X\leq \max X\leq x\leq y$, luego:
    \begin{equation*}
        P[(\max X, \min X)\leq (x,y)] = P[\max X\leq x, \min X\leq y] = P[\max X\leq x] = F_X(x,\dots,x)
    \end{equation*}

    \item Si $x>y$, entonces:
    \begin{align*}
        P[(\max X, \min X)\leq (x,y)] &= P[\max X\leq x, \min X\leq y] =\\&= P[\max X\leq x] - P[\max X\leq x,\min X> y] =\\&= F_X(x,\dots,x) - P[y<X_1\leq x,\dots,y<X_n\leq x]
    \end{align*}
\end{itemize}

Por tanto, la función de distribución de $(\max X, \min X)$ es:
\begin{equation*}
    F_{(\max X, \min X)}(x,y) = \begin{cases}
        F_X(x,\dots,x) & \text{si } x\leq y,\\
        F_X(x,\dots,x) - P[y<X_1\leq x,\dots,y<X_n\leq x] & \text{si } x>y.
    \end{cases}
\end{equation*}



\section{Esperanza}

Al igual que venimos haciendo en este tema, generalizamos el concepto de esperanza a vectores aleatorios.
\begin{definicion}[Esperanza]
    Sea $X=(X_1,\dots,X_n)$ un vector aleatorio. Entonces:
    \begin{itemize}
        \item $\exists E[X]\Longleftrightarrow \exists E[X_i] \quad \forall i\in \{1,\dots,n\}$.
        \item En tal caso, la esperanza de $X$ es:
        \begin{equation*}
            E[X] := (E[X_1],\dots,E[X_n]).
        \end{equation*}
    \end{itemize}
\end{definicion}


Usando el Teorema de Cambio de Variable en cada uno de los casos, deducimos de forma directa el siguiente teorema:
\begin{teo}
    Sea $X=(X_1,\dots,X_n)$ una variable aleatoria y $g:\bb{R}^n\to \bb{R}$ una función medible. Entonces, suponiendo que dichas esperanzas existen:
    \begin{itemize}
        \item Si $X$ es de tipo discreto con valores en $E_X$:
        \begin{equation*}
            E[g(X)] = \sum_{x\in E_X}g(x)P[X=x]
        \end{equation*}

        \item Si $X$ es de tipo continuo con función de densidad $f_X$:
        \begin{equation*}
            E[g(X)] = \int_{\bb{R}^n} g(x)f_X(x) dx
        \end{equation*}
    \end{itemize}
\end{teo}

\section{Momentos}

\subsection{Momentos No Centrados}

\begin{definicion}[Momento no centrado]
    Sea $X=(X_1,\dots,X_n)$ un vector aleatorio y ($k_1,\dots,k_n)\in (\bb{N}\cup \{0\})^n$. Entonces, el momento no centrado de orden $(k_1,\dots,k_n)$ de $X$ es:
    \begin{equation*}
        m_{k_1,\dots,k_n} := E[X_1^{k_1}\cdots X_n^{k_n}].
    \end{equation*}
    A estos momentos también se les llama momentos centrados en el origen.
\end{definicion}

Haciendo uso de la esperanza de una función de un vector aleatorio, tenemos:
\begin{itemize}
    \item \ul{Caso discreto}:
    \begin{equation*}
        m_{k_1,\dots,k_n}=E[X_1^{k_1}\cdots X_n^{k_n}] = \sum_{x\in E_X} x_1^{k_1}\cdots x_n^{k_n} P[X=x].
    \end{equation*}

    \item \ul{Caso continuo}:
    \begin{equation*}
        m_{k_1,\dots,k_n}=E[X_1^{k_1}\cdots X_n^{k_n}] = \int_{\bb{R}^n} x_1^{k_1}\cdots x_n^{k_n} f_X(x)~d x.
    \end{equation*}
\end{itemize}

Es importante notar que, fijado $i\in \{1,\dots,n\}$, si $k_j=0$ para todo $j\neq i$, entonces se obtienen los momentos de la variable aleatoria $X_i$. Estos se conocen como momentos marginales.

\subsection{Momentos Centrados}

\begin{definicion}[Momento centrado]
    Sea $X=(X_1,\dots,X_n)$ un vector aleatorio y ($k_1,\dots,k_n)\in (\bb{N}\cup \{0\})^n$. Entonces, el momento centrado de orden $(k_1,\dots,k_n)$ de $X$ es:
    \begin{equation*}
        \mu_{k_1,\dots,k_n} := E[(X_1-E[X_1])^{k_1}\cdots (X_n-E[X_n])^{k_n}].
    \end{equation*}

    A estos momentos también se les llama momentos centrados en la media.
\end{definicion}

Haciendo uso de la esperanza de una función de un vector aleatorio, tenemos:
\begin{itemize}
    \item \ul{Caso discreto}:
    \begin{align*}
        \mu_{k_1,\dots,k_n}&=E[(X_1-E[X_1])^{k_1}\cdots (X_n-E[X_n])^{k_n}] =\\&= \sum_{x\in E_X} (x_1-E[X_1])^{k_1}\cdots (x_n-E[X_n])^{k_n}
        P[X=x].
    \end{align*}

    \item \ul{Caso continuo}:
    \begin{align*}
        \mu_{k_1,\dots,k_n}&=E[(X_1-E[X_1])^{k_1}\cdots (X_n-E[X_n])^{k_n}] =\\&= \int_{\bb{R}^n} (x_1-E[X_1])^{k_1}\cdots (x_n-E[X_n])^{k_n} f_X(x)~d x.
    \end{align*}
\end{itemize}

De nuevo, es importante notar que, fijado $i\in \{1,\dots,n\}$, si $k_j=0$ para todo $j\neq i$, entonces se obtienen los momentos centrados de la variable aleatoria $X_i$. Estos se conocen como momentos marginales centrados.\\

Al igual que ocurrió en Estadística Descriptiva Bidimensional, introducimos el concepto de covarianza:
\begin{definicion}[Covarianza]
    Sea $X=(X_1,\dots,X_n)$ un vector aleatorio. Entonces, la covarianza de $X_i$ y $X_j$, con $i\neq j$, es:
    \begin{equation*}
        \Cov(X_i,X_j) = \mu_{0 \dots 0 \, \overset{i)}{1} \, 0 \dots 0 \, \overset{j)}{1} \, 0 \dots 0} = E[(X_i-E[X_i])(X_j-E[X_j])].
    \end{equation*}
\end{definicion}
El siguiente lema técnico nos será de utilidad para el cálculo de la covarianza.
\begin{lema}
    Sean $X,Y$ dos variables aleatorias. Entonces:
    \begin{equation*}
        \Cov(X,Y) = E[XY] - E[X]E[Y].
    \end{equation*}
\end{lema}
\begin{proof}
    Tenemos que:
    \begin{align*}
        \Cov(X,Y) &= E[(X-E[X])(Y-E[Y])] = E[XY - XE[Y] - E[X]Y + E[X]E[Y]] =\\
        &= E[XY] - E[XE[Y]] - E[E[X]Y] + E[E[X]E[Y]] =\\
        &= E[XY] - 2E[X]E[Y] + E[X]E[Y] = E[XY] - E[X]E[Y].
    \end{align*}
    donde hemos usado que $E[X],E[Y]$ son constantes.
\end{proof}

Como consecuencias inmediatas de este lema tenemos que, dadas $X$ e $Y$ dos variables aleatorias unidimensionales:
\begin{itemize}
    \item $\Cov(X,X) = E[X^2] - E[X]^2 = \Var(X)$.
    \item $\Cov(X,Y) = \Cov(Y,X)$.
\end{itemize}

De la definición de la covarianza, se deduce que esta mide la covariación conjunta de dos variables:
\begin{itemize}
    \item Si es positiva nos dará la información de que a valores altos de una de las variable hay una mayor tendencia a encontrar valores altos de la otra variable y a valores bajos de una de las variable, correspondientemente se esperan valores bajos.
    \item Si la covarianza es negativa, la covariación de ambas variables será en sentido inverso: a valores altos le corresponderán bajos, y a valores bajos, altos.
    \item Si la covarianza es cero no hay una covariación clara en ninguno de los dos sentidos.
\end{itemize}

\begin{definicion}[Matriz de Covarianzas]
    Sea $X=(X_1,\dots,X_n)$ un vector aleatorio. Entonces, la matriz de covarianzas de $X$, notada por $\Cov_X$, es la matriz cuadrada de orden $n$ cuyos elementos son las covarianzas de las variables aleatorias:
    \begin{equation*}
        \Cov_X = (\Cov(X_i,X_j))_{i,j}
    \end{equation*}
\end{definicion}
Como consecuencia de las dos propiedades anteriores, tenemos que $\Cov_X$ es simétrica, y sus elementos de la diagonal son las varianzas de las variables aleatorias. En el caso de que $X$ sea un vector aleatorio bidimensional, la matriz de covarianzas se reduce a:
\begin{equation*}
    \Cov_X = \begin{pmatrix}
        \Var(X_1) & \Cov(X_1,X_2)\\
        \Cov(X_2,X_1) & \Var(X_2)
    \end{pmatrix}.
\end{equation*}

\section{Función Generatriz de Momentos}

\begin{definicion}[Función generatriz de momentos]
    Sea $X=(X_1,\dots,X_n)$ un vector aleatorio. Entonces, si $\exists E[e^{t_1X_1+\cdots+t_nX_n}]$ para todo $(t_1,\dots,t_n)\in N$, siendo $N\subset \bb{R}^n$ un entorno del origen, la función generatriz de momentos de $X$ es:
    \Func{M_X}{N}{\bb{R}}{(t_1,\dots,t_n)}{E[e^{t_1X_1+\cdots+t_nX_n}]}.

    Notemos que, usando el producto escalar en $\bb{R}^n$, podemos escribir la función generatriz de momentos como:
    \Func{M_X}{N}{\bb{R}}{t}{E[e^{\langle t,X\rangle}]}.
\end{definicion}

Esta función, si existe, tiene propiedades análogas al caso unidimensional.
\begin{teo}[Unicidad]
    Si existe la función generatriz de momentos de un vector aleatorio, entonces determina la distribución de probabilidad de dicho vector aleatorio de forma unívoca.
\end{teo}

La relación con los momentos viene descrita en el siguiente teorema.
\begin{teo}
    Sea $X=(X_1,\dots,X_n)$ un vector aleatorio. Entonces, si existe la función generatriz de momentos de $X$:
    \begin{enumerate}
        \item $\exists E[X_1^{k_1}\cdots X_n^{k_n}]$ para todo $(k_1,\dots,k_n)\in (\bb{N}\cup \{0\})^n$.
        \item $M_X$ es derivable y se tiene que:
        \begin{equation*}
            \left.\dfrac{\partial^{k_1+\cdots+k_n} M_X(t_1,\dots,t_n)}{\partial t_1^{k_1}\cdots \partial t_n^{k_n}}\right|_{t_1=\dots=t_n=0} = E[X_1^{k_1}\cdots X_n^{k_n}].
        \end{equation*}
    \end{enumerate}
\end{teo}
\begin{proof}
    Supuesta cierta la primera afirmación, tenemos que:
    \begin{align*}
        \left.\dfrac{\partial^{k_1+\cdots+k_n} M_X(t_1,\dots,t_n)}{\partial t_1^{k_1}\cdots \partial t_n^{k_n}}\right|_{t_1=\dots=t_n=0} &= \left.\dfrac{\partial^{k_1+\cdots+k_n} E[e^{t_1X_1+\cdots+t_nX_n}]}{\partial t_1^{k_1}\cdots \partial t_n^{k_n}}\right|_{t_1=\dots=t_n=0} =\\
        &= E\left[\left.\dfrac{\partial^{k_1+\cdots+k_n} e^{t_1X_1+\cdots+t_nX_n}}{\partial t_1^{k_1}\cdots \partial t_n^{k_n}}\right|_{t_1=\dots=t_n=0}\right] =\\
        &= E\left[\left.X_1^{k_1}\dots X_n^{k_n}e^{t_1X_1+\cdots+t_nX_n}\right|_{t_1=\dots=t_n=0}\right] =\\
        &= E\left[X_1^{k_1}\dots X_n^{k_n}e^{0}\right] =\\
        &= E[X_1^{k_1}\cdots X_n^{k_n}].
    \end{align*}
\end{proof}

Por último, introducimos el concepto de función generatriz de momentos marginal. Dado $X=(X_1,\dots,X_n)$ un vector aleatorio con función generatriz de momentos $M_X$ definida en $N$, existe la función generatriz de momentos de cada subvector de $X$ $(X_{i_1},\dots,X_{i_k})$. Esta se calcula como sigue:
\begin{multline*}
    M_{X_{i_1},\dots,X_{i_k}}(t_{i_1},\dots,t_{i_k}) = M_X(0,\dots,0,t_{i_1},0,\dots,0,t_{i_k},0,\dots,0) \\ \forall (t_{i_1},\dots,t_{i_k})\mid (0,\dots,0,t_{i_1},0,\dots,0,t_{i_k},0,\dots,0)\in N.
\end{multline*}
\begin{observacion}
    Notemos que esta notación no es del todo precisa, pero se emplea para no complicar la notación. La función generatriz de momentos de un subvector de $X$ se obtiene evaluando la función generatriz de momentos de $X$ en el punto cuyas componentes son todas nulas, excepto las correspondientes a las variables del subvector.
\end{observacion}
Esto es de demostración inmediata, ya que:
\begin{align*}
    M_{X_{i_1},\dots,X_{i_k}}(t_{i_1},\dots,t_{i_k}) &= E[e^{t_{i_1}X_{i_1}+\cdots+t_{i_k}X_{i_k}}] =\\&= E[e^{0X_1+\cdots+0X_{i_1-1}+t_{i_1}X_{i_1}+0X_{i_1+1}+\cdots+0X_{i_k-1}+t_{i_k}X_{i_k}+0X_{i_k+1}+\cdots+0X_n}] =\\&= M_X(0,\dots,0,t_{i_1},0,\dots,0,t_{i_k},0,\dots,0).
\end{align*}
