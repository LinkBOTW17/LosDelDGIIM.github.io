\section{Esperanza Condicionada}

\begin{ejercicio}
    Sea $X$ una variable aleatoria que se distribuye uniformemente en el intervalo $\left]0,1\right[$. Comprobar si las variables aleatorias $X$ y $|\nicefrac{1}{2}-X|$ son incorreladas.
\end{ejercicio}

\begin{ejercicio}
    Calcular las curvas de regresión y las razones de correlación para las siguientes distribuciones, comentando los resultados.
    \begin{enumerate}
        \item Considerar las distribución conjunta $(X,Y)$ con función de masa de probabilidad dada por:
        \begin{equation*}
            \begin{array}{c|ccc||c}
                X\setminus Y & 10 & 15 & 20 & \\
                \hline
                1 & 0 & \nicefrac{2}{6} & 0 & \nicefrac{2}{6}\\
                2 & \nicefrac{1}{6} & 0 & 0 & \nicefrac{1}{6}\\
                3 & 0 & 0 & \nicefrac{3}{6} & \nicefrac{3}{6}\\
                \hline \hline
                & \nicefrac{1}{6} & \nicefrac{2}{6} & \nicefrac{3}{6} & 1
            \end{array}
        \end{equation*}

        Tras haber calculado las distribuciones marginales, calculamos ahora las distribuciones condicionadas.
        La siguiente tabla muestra la distribución condicionada de $Y$ dado $X$, $P[Y = y\mid X = x]$:
        \begin{equation*}
            \begin{array}{c|ccc}
                X\setminus Y & 10 & 15 & 20 \\
                \hline
                1 & 0 & 1 & 0\\
                2 & 1 & 0 & 0\\
                3 & 0 & 0 & 1
            \end{array}
        \end{equation*}

        La distribución condicionada de $X$ dado $Y$, $P[X = x\mid Y = y]$ viene dada por la misma tabla, ya que en este caso tenemos que:
        \begin{equation*}
            P[X = x\mid Y = y] = P[Y = y\mid X = x] \qquad \forall x, y
        \end{equation*}

        Calculemos ahora las curvas de regresión y las razones de correlación.
        \begin{itemize}
            \item Curva de regresión de $Y$ sobre $X$:
            \begin{equation*}
                \wh{Y}(x) = E[Y\mid X = x] = \sum_{y} y P[Y = y\mid X = x] \qquad \forall x\in E_x
            \end{equation*}
    
            Por tanto, la curva de regresión de $Y$ sobre $X$ es:
            \begin{align*}
                \wh{Y}(1) &= 15\\
                \wh{Y}(2) &= 10\\
                \wh{Y}(3) &= 20
            \end{align*}

            Para calcular la razón de correlación de $Y$ sobre $X$,
            hay dos opciones:
            \begin{description}
                \item[Opción 1.] Método rutinario.
                
                Usamos la fórmula:
                \begin{equation*}
                    \eta^2_{Y/X} = \dfrac{\Var(E[Y\mid X])}{\Var(Y)}
                \end{equation*}
                \begin{itemize}
                    \item Calculemos $E[Y]$:
                    \begin{align*}
                        E[Y] &= \sum_{y} y P[Y = y]\\
                        &= 10 \cdot \nicefrac{1}{6} + 15 \cdot \nicefrac{2}{6} + 20 \cdot \nicefrac{3}{6}\\
                        &= \nicefrac{10}{6} + 5 + 10\\
                        &= \frac{50}{3}
                    \end{align*}

                    \item Calculemos ahora $E[Y^2]$:
                    \begin{align*}
                        E[Y^2] &= \sum_{y} y^2 P[Y = y]\\
                        &= 10^2 \cdot \nicefrac{1}{6} + 15^2 \cdot \nicefrac{2}{6} + 20^2 \cdot \nicefrac{3}{6}\\
                        &= 100 \cdot \nicefrac{1}{6} + 225 \cdot \nicefrac{2}{6} + 400 \cdot \nicefrac{3}{6}\\
                        &= \nicefrac{100}{6} + 75 + 200\\
                        &= \frac{875}{3}
                    \end{align*}

                    \item Calculemos ahora $E[(E[Y\mid X])^2]$:
                    \begin{align*}
                        E[(E[Y\mid X])^2] &= \sum_{x} (E[Y\mid X = x])^2 P[X = x]\\
                        &= 10^2 \cdot \nicefrac{1}{6} + 15^2 \cdot \nicefrac{2}{6} + 20^2 \cdot \nicefrac{3}{6}\\
                        &= \frac{875}{3} = E[Y^2]
                    \end{align*}

                    \item Calculemos ahora $E[E[Y\mid X]]$.
                    \begin{equation*}
                        E[E[Y\mid X]] = E[Y]
                    \end{equation*}
                \end{itemize}

                Por tanto, usando lo anterior, tenemos:
                \begin{align*}
                    \eta^2_{Y/X} &= \dfrac{\Var(E[Y\mid X])}{\Var(Y)}
                    = \dfrac{E[(E[Y\mid X])^2] - E[E[Y\mid X]]^2}{E[Y^2] - E[Y]^2}\\
                    &= \dfrac{E[Y^2] - E[Y]^2}{E[Y^2] - E[Y]^2} = 1
                \end{align*}

                \item[Opción 2.] Razonando por dependencia funcional.
                
                En este caso, vemos que $Y$ es función de $X$. Por tanto:
                \begin{equation*}
                    \eta^2_{Y/X} = 1
                \end{equation*}
            \end{description}

            \item Curva de regresión de $X$ sobre $Y$:
            \begin{equation*}
                \wh{X}(y) = E[X\mid Y = y] = \sum_{x} x P[X = x\mid Y = y] \qquad \forall y\in E_y
            \end{equation*}

            Por tanto, la curva de regresión de $X$ sobre $Y$ es:
            \begin{align*}
                \wh{X}(10) &= 2\\
                \wh{X}(15) &= 1\\
                \wh{X}(20) &= 3
            \end{align*}

            De nuevo, razonando ahora por dependencia funcional, tenemos que:
            \begin{equation*}
                \eta^2_{X/Y} = 1
            \end{equation*}
        \end{itemize}

        Como vemos, en este caso, hay dependencia recíproca entre $X$ e $Y$. Por tanto,
        el ajuste es el idea, ya que $Y=f(X)$ y $X=g(Y)$.
        Cada una explica la totalidad de la variabilidad de la otra.


        \item Considerar las distribución conjunta $(X,Y)$ con función de masa de probabilidad dada por:
        \begin{equation*}
            \begin{array}{c|cccc||c}
                X\setminus Y & 10 & 15 & 20 & 25 &\\
                \hline
                1 & 0 & \nicefrac{3}{7} & 0 & \nicefrac{1}{7} & \nicefrac{4}{7}\\
                2 & 0 & 0 & \nicefrac{1}{7} & 0 & \nicefrac{1}{7}\\
                3 & \nicefrac{2}{7} & 0 & 0 & 0 & \nicefrac{2}{7}\\
                \hline \hline
                & \nicefrac{2}{7} & \nicefrac{3}{7} & \nicefrac{1}{7} & \nicefrac{1}{7} & 1
            \end{array}
        \end{equation*}

        Tras haber calculado las distribuciones marginales, calculamos ahora las distribuciones condicionadas.
        La siguiente tabla muestra la distribución condicionada de $Y$ dado $X$, $P[Y = y\mid X = x]$:
        \begin{equation*}
            \begin{array}{c|cccc}
                X\setminus Y & 10 & 15 & 20 & 25\\
                \hline
                1 & 0 & \nicefrac{3}{4} & 0 & \nicefrac{1}{4}\\
                2 & 0 & 0 & 1 & 0\\
                3 & 1 & 0 & 0 & 0
            \end{array}
        \end{equation*}

        La distribución condicionada de $X$ dado $Y$, $P[X = x\mid Y = y]$ viene dada por la siguiente tabla:
        \begin{equation*}
            \begin{array}{c|ccc}
                X\setminus Y & 10 & 15 & 20\\
                \hline
                1 & 0 & 1 & 0\\
                2 & 0 & 0 & 1\\
                3 & 1 & 0 & 0
            \end{array}
        \end{equation*}

        Calculemos ahora las curvas de regresión y las razones de correlación.
        \begin{itemize}
            \item Curva de regresión de $Y$ sobre $X$:
            \begin{equation*}
                \wh{Y}(x) = E[Y\mid X = x] = \sum_{y} y P[Y = y\mid X = x] \qquad \forall x\in E_x
            \end{equation*}

            Por tanto, la curva de regresión de $Y$ sobre $X$ es:
            \begin{align*}
                \wh{Y}(1) &= 15\cdot \nicefrac{3}{4} + 25\cdot \nicefrac{1}{4} = 17.5\\
                \wh{Y}(2) &= 20\\
                \wh{Y}(3) &= 10
            \end{align*}

            Para calcular la razón de correlación de $Y$ sobre $X$, tenemos que:
            \begin{equation*}
                \eta^2_{Y/X} = \dfrac{\Var(E[Y\mid X])}{\Var(Y)}
            \end{equation*}
            \begin{itemize}
                \item Calculemos $E[Y]$:
                \begin{align*}
                    E[Y] &= \sum_{y} y P[Y = y]\\
                    &= 10 \cdot \nicefrac{2}{7} + 15 \cdot \nicefrac{3}{7} + 20 \cdot \nicefrac{1}{7} + 25 \cdot \nicefrac{1}{7}\\
                    &= \frac{110}{7}
                \end{align*}

                \item Calculemos ahora $E[Y^2]$:
                \begin{align*}
                    E[Y^2] &= \sum_{y} y^2 P[Y = y]\\
                    &= 10^2 \cdot \nicefrac{2}{7} + 15^2 \cdot \nicefrac{3}{7} + 20^2 \cdot \nicefrac{1}{7} + 25^2 \cdot \nicefrac{1}{7}\\
                    &= \frac{1900}{7}
                \end{align*}

                \item Calculemos ahora $E[(E[Y\mid X])^2]$:
                \begin{align*}
                    E[(E[Y\mid X])^2] &= \sum_{x} (E[Y\mid X = x])^2 P[X = x]\\
                    &= 17.5^2 \cdot \nicefrac{4}{7} + 20^2 \cdot \nicefrac{1}{7} + 10^2 \cdot \nicefrac{2}{7}\\
                    &= \frac{1825}{7}
                \end{align*}

                \item Calculemos ahora $E[E[Y\mid X]]$.
                \begin{equation*}
                    E[E[Y\mid X]] = E[Y]
                \end{equation*}
            \end{itemize}

            Por tanto, usando lo anterior, tenemos:
            \begin{align*}
                \eta^2_{Y/X} &= \dfrac{\Var(E[Y\mid X])}{\Var(Y)}
                = \dfrac{E[(E[Y\mid X])^2] - E[E[Y\mid X]]^2}{E[Y^2] - E[Y]^2}\\
                &= \dfrac{E[(E[Y\mid X])^2] - E[Y]^2}{E[Y^2] - E[Y]^2}\\
                &= \dfrac{\dfrac{1825}{7} - \left(\dfrac{110}{7}\right)^2}{\dfrac{1900}{7} - \left(\dfrac{110}{7}\right)^2}\\
                &= \dfrac{9}{16} \approx 0.5625
            \end{align*}

            Por tanto, tenemos que $X$ explica el $56.25\%$ de la variabilidad de $Y$. Tenemos entonces que no es un ajuste ideal.

            \item Curva de regresión de $X$ sobre $Y$:
            
            En este caso, tenemos que $X=f(Y)$, por lo que:
            \begin{align*}
                \wh{X}(10) &= 3\\
                \wh{X}(15) &= 1\\
                \wh{X}(20) &= 2\\
                \wh{X}(25) &= 1
            \end{align*}

            Por tanto, como $X$ es función de $Y$, tenemos que:
            \begin{equation*}
                \eta^2_{X/Y} = 1
            \end{equation*}

            Tenemos que $Y$ explica la totalidad de la variabilidad de $X$, por lo que el ajuste es el ideal.
        \end{itemize}


    \end{enumerate}
\end{ejercicio}

\begin{ejercicio}
    % // TODO: Hacer
    Sea $X$ el número de balanzas e $Y$ el número de dependientes en los puntos de venta de un mercado. Determinar las rectas de regresión y el grado de ajuste a la distribución, si la función masa de probabilidad de $(X,Y)$ viene dada por:
    \begin{equation*}
        \begin{array}{c|cccc}
            X\setminus Y & 1 & 2 & 3 & 4\\
            \hline
            1 & \nicefrac{1}{24} & \nicefrac{2}{24} & 0 & 0\\
            2 & \nicefrac{1}{24} & \nicefrac{2}{24} & \nicefrac{3}{24} & \nicefrac{1}{24}\\
            3 & 0 & \nicefrac{1}{24} & \nicefrac{2}{24} & \nicefrac{6}{24}\\
            4 & 0 & 0 & \nicefrac{2}{24} & \nicefrac{3}{24}
        \end{array}
    \end{equation*}
\end{ejercicio}

\begin{ejercicio}
    Sea $(X,Y)$ un vector aleatorio con valores en $\{(x, y) \in \mathbb{R}^2/0 < x < y < 2\}$ y función de densidad constante. Calcular:
    \begin{enumerate}
        \item Curvas y rectas de regresión de $X$ sobre $Y$ y de $Y$ sobre $X$.
        \item Razones de correlación y coeficiente de correlación lineal.
        \item Error cuadrático medio asociado a cada una de las funciones de regresión.
    \end{enumerate}
\end{ejercicio}

\begin{ejercicio}
    Dada la función masa de probabilidad del vector aleatorio $(X,Y)$
    \begin{equation*}
        \begin{array}{c|cccc}
            X\setminus Y & 0 & 1 & 2 & 3\\
            \hline
            0 & 0.2 & 0.2 & 0.05 & 0\\
            1 & 0.1 & 0.1 & 0.1 & 0.05\\
            2 & 0 & 0.05 & 0.05 & 0.1
        \end{array}
    \end{equation*}
    % // TODO: Hacer
    \begin{enumerate}
        \item Determinar la aproximación lineal mínimo cuadrática de $Y$ para $X = 1$.
        \item Determinar la aproximación mínimo cuadrática de $Y$ para $X = 1$.
    \end{enumerate}
\end{ejercicio}

\begin{ejercicio}
    Dadas las siguientes distribuciones, determinar qué variable, $X$ ó $X'$, aproxima mejor a la variable $Y$:
    \begin{equation*}
        \begin{array}{c|ccc}
            X\setminus Y & 0 & 1 & 2\\
            \hline
            0 & \nicefrac{1}{5} & 0 & 0\\
            2 & 0 & \nicefrac{1}{5} & 0\\
            3 & \nicefrac{1}{5} & 0 & \nicefrac{1}{5}\\
            4 & 0 & 0 & \nicefrac{1}{5}
        \end{array}
        \qquad
        \begin{array}{c|ccc}
            X'\setminus Y & 0 & 1 & 2\\
            \hline
            0 & \nicefrac{1}{5} & 0 & \nicefrac{1}{5}\\
            2 & 0 & \nicefrac{1}{5} & 0\\
            3 & \nicefrac{1}{5} & 0 & 0\\
            4 & 0 & 0 & \nicefrac{1}{5}
        \end{array}
    \end{equation*}
\end{ejercicio}

\begin{ejercicio} \label{ej:4.7}
    Probar que las variables $X = U + V$ e $Y = U - V$ son incorreladas, pero no independientes, si $U$ y $V$ son variables aleatorias con función de densidad conjunta:
    \begin{equation*}
        f_{U,V}(u, v) = \exp(-u-v), \quad u, v > 0.
    \end{equation*}
\end{ejercicio}

\begin{ejercicio}
    % // TODO: Hacer
    Sea $X$ una variable aleatoria con distribución uniforme en el intervalo $[0,1]$, y sea $Y$ una variable aleatoria continua tal que
    \begin{equation*}
        f_{Y\mid X=x}(y) = \begin{cases}
            \nicefrac{1}{x^2} & y \in \left[0, x^2\right]\\
            0 & \text{en caso contrario}
        \end{cases}
    \end{equation*}
    \begin{enumerate}
        \item\label{ej:4.8.a} Calcular la función de densidad de probabilidad conjunta de $X$ e $Y$. Calcular la función de densidad de probabilidad marginal de $Y$.
        \item Calcular $E[X\mid Y = y]$ y $E[Y\mid X = x]$.
        \item Para la misma densidad de probabilidad condicionada del apartado \ref{ej:4.8.a}, considerando ahora que $X$ es una variable aleatoria continua con función de densidad de probabilidad:
        \begin{equation*}
            f_X(x) = \begin{cases}
                3x^2 & x \in \left[0,1\right]\\
                0 & \text{en caso contrario}
            \end{cases}
        \end{equation*}
        Calcular de nuevo la función de densidad de probabilidad conjunta de $X$ e $Y$, y la función de densidad de probabilidad marginal de $Y$, así como $E[X\mid Y = y]$ y $E[Y\mid X = x]$.
    \end{enumerate}
\end{ejercicio}

\begin{ejercicio}
    Sean $X$ e $Y$ variables aleatorias con función de densidad conjunta:
    \begin{equation*}
        f_{(X,Y)}(x, y) = \begin{cases}
            x+y & (x, y) \in [0,1] \times [0,1]\\
            0 & \text{en caso contrario}
        \end{cases}
    \end{equation*}
    \begin{enumerate}
        \item Calcular la predicción mínimo cuadrática de $Y$ a partir de $X$ y el error cuadrático medio asociado.
        \item Si se observa $X = \nicefrac{1}{2}$, qué predicción de $Y$ tiene menor error cuadrático medio? Calcular dicho error.
        \item Supóngase que una persona debe pagar una cantidad $C$ por la oportunidad de observar el valor de $X$ antes de predecir el valor de $Y$, o puede simplemente predecir el valor de $Y$ sin observar $X$. Si la persona considera que su pérdida total es la suma de $C$ y el error cuadrático medio de su predicción, qué valor máximo de $C$ estaría dispuesta a pagar?
    \end{enumerate}
\end{ejercicio}

\begin{ejercicio}
    Sea $(X,Y)$ un vector aleatorio con función de densidad:
    \begin{equation*}
        f_{(X,Y)}(x, y) = \exp(-y), \quad 0 < x < y
    \end{equation*}
    Obtener y representar las rectas y curvas de regresión. Calcular el coeficiente de correlación lineal, las razones de correlación y el error cuadrático medio cometido al predecir cada variable según cada una de las funciones de regresión. Interpretar los resultados.
\end{ejercicio}

\begin{ejercicio}
    Sea $(X,Y)$ un vector aleatorio con función de densidad uniforme sobre el cuadrado unidad. Obtener y representar las rectas y curvas de regresión. Calcular el coeficiente de correlación lineal, las razones de correlación y el error cuadrático medio cometido al predecir cada variable según cada una de las funciones de regresión. Interpretar los resultados.
\end{ejercicio}

\begin{ejercicio}
    Supongamos que $(X,Y)$ tiene función de densidad de probabilidad conjunta dada por:
    \begin{equation*}
        f_{(X,Y)}(x, y) = \begin{cases}
            1, & |y| < x, x \in \left]0,1\right[\\
            0, & \text{en otro caso}
        \end{cases}
    \end{equation*}
    Obtener y representar las rectas y curvas de regresión. Calcular el coeficiente de correlación lineal, las razones de correlación y el error cuadrático medio cometido al predecir cada variable según cada una de las funciones de regresión. Interpretar los resultados.
\end{ejercicio}

\begin{ejercicio}
    Sea $(X,Y)$ un vector aleatorio distribuido uniformemente en el paralelogramo de vértices $(0,0)$; $(2,0)$; $(3,1)$ y $(1,1)$. Calcular el error cuadrático medio asociado a la predicción de $X$ a partir de la variable $Y$ y a la predicción de $Y$ a partir de la variable aleatoria $X$. Determinar la predicción más fiable a la vista de los resultados obtenidos.
\end{ejercicio}

\begin{ejercicio}
    Sea $(X,Y)$ un vector aleatorio con rectas de regresión
    \begin{equation*}
        x+4y = 1 \qquad x+5y = 2
    \end{equation*}
    \begin{enumerate}
        \item Cuál es la recta de regresión de $Y$ sobre $X$?
        \item Calcular el coeficiente de correlación lineal y la proporción de varianza de cada variable que queda explicada por la regresión lineal.
        \item Calcular las medias de ambas variables
    \end{enumerate}
\end{ejercicio}