\chapter{Capa de transporte}

En el presente tema, estudiaremos a fondo la capa de transporte. Recordemos que seguimos el Modelo TCP/IP descrito en la Tabla~\ref{table:_tabla_de_capas}.

\subsubsection{Objetivos}
\begin{itemize}
    \item Comprender las funiconalidades y servicios de la capa de transporte.
        \begin{itemize}
            \item Servicio de \textbf{multiplexación/demultiplexación}.
            \item Servicio \textbf{orientado a conexión} frente a \textbf{no orientado a conexión}.
            \item Cómo conseguir una transferencia de datos \textbf{fiable}.
            \item Cómo proporcionar \textbf{control de flujo}.
            \item Cómo proporcionar \textbf{control de congestión}.
            \item Cómo se han implementado estas funcionalidades en Internet.
        \end{itemize}
\end{itemize}

\section{Introducción}

Tanto la capa de red como la de enlace realizan encaminamiento punto a punto, pero la capa de transporte en cambio se encarga de la comunicación extremo a extremo. Por tanto, solo los dispositivos extremos (normalmente los hosts) cuentan con la capacidad de procesamiento a nivel de transporte. \\

Como vimos en el primer tema, el \acrshort{PDU} de la capa de transporte se denomina ``datagrama'' si se usa el protocolo \acrshort{UDP} y ``segmento'' si se trata de \acrshort{TCP}. El \acrshort{SDU} de esta capa, como es lógico pensar, es el \acrshort{PDU} de la capa de aplicación.\\

Como principales funcionalidades comunes a cualquier protocolo de transporte se encuentrn la comunicación extremo a extremo y la multiplexación/demultiplexación de aplicaciones. Esta segunda consiste en permitir la entrada desde en el origen de muchos paquetes (multiplexación), y que al llegar al destino se distribuyan adecuadamente a los procesos indicados (demultiplexación). Esto se logra mediante los puertos, concepto que introducimos a continuación.
\begin{definicion}[Puertos]
    Un puerto es un número natural que es usado por el Sistema Operativo para saber a qué proceso está destinado cada paquete que llegue por la red. Es decir, cuando un paquete llegue por la red a un equipo, el sistema operativo consultará el puerto para saber a qué proceso corresponde.
\end{definicion}

Los puertos que están por debajo de 1024 están reservados, y el Sistema Operativo los ofrece a los usuarios con privilegios de administrador. Por encima de este número, los puertos están a disposición del desarrollador y no se necesitan permisos de administrador para utilizarlos.
    
Por último, cabe mencionar que los puertos de distintos protocolos son independientes. Esto permite que dos paquetes que se han recibido usando distintos protocolos pero que tengan el mismo número de puerto correspondan, sin problema alguno, a procesos distintos.
\begin{observacion}
    Como curiosidad, en sistemas Linux el archivo \verb|/etc/services| muestra los puertos activos, donde además se muestra el protocolo al que pertenecen.
\end{observacion}


Adicionalmente, cada protocolo de transporte puede implementar funcionalidades adicionales. Los principales protocolos presentes en la actualidad son \acrshort{UDP} y \acrshort{TCP}, aunque existen otros como \acrshort{SCTP}, que trata de ofrecer una mezcla entre los dos anteriores. En la asignatura veremos los dos primeros, cuyas descripciones breves se presentan a continuación.
\begin{description}
    \item [\acrshort{UDP}]~\\
        Es un servicio no orientado a conexión, y por tanto no fiable. Su intención no es esta, sino la de ofrecer una comunicación rápida.
    \item [\acrshort{TCP}]~\\
        Es un servicio fiable,  y por tanto orientado a conexión. Como funcionalidades adicionales, ofrece control de conexión, de errores, de flujo y de congestión. Respecto a los errores, si la red es cableada se asume que son por congestión (pues la tasa de fallo es de 1 entre 1 millón si el medio es cableado), mientras que si es inalámbrica se asume que puede ser por otros motivos (pues la tasa de fallo es del $10\%$).
\end{description}

\section{\acrfull{UDP}}
El protocolo \acrshort{UDP} es un protocolo de la capa de transporte encapsulado sobre \acrshort{IP}.
Este, al igual que \acrshort{IP}, es un protocolo de máximo esfuerzo, ya que intenta hacerlo lo mejor posible pero no se encarga de corregir errores. Esto se debe a que:
\begin{itemize}
    \item Servicio no orientado a conexión.
    
    No hay \textit{hand-shaking}, lo que permite que no haya retardo de establecimiento (aumentando la velocidad de la comunicación). Además, cada \acrshort{TPDU} es totalmente independiente.

    \item Servicio no fiable.
    
    Puede haber pérdidas, por ejemplo debido a que nunca se produzca la conexión. No obstante, esto no significa que no puedan haber aplicaciones fiables sobre \acrshort{UDP}, sino que es la capa de aplicación la que debe encargarse de corregir los errores.

    \item No hay garantías de entrega ordenada.
    
    Como el lector conoce, los paquetes en la capa de red pueden fragmentarse y llegar desordenados. El protocolo \acrshort{UDP} no hace nada para ordenarlo, por lo que debe ser la capa de aplicación la que se encargue de ello.

    \item No hay control de congestión.
    
    Debido a que se busca que la entrega de los datos a las capas adyacentes sean lo más rápida posible, no se implementa control de congestión.
\end{itemize}

Por tanto, las únicas funcionalidades de este protocolo son las comunes a cualquier protocolo de la capa de transporte, la conexión extremo a extremo y la multiplexación/demultiplexación.

Sus principales usos en la actualidad son las aplicaciones multimedia que son tolerantes a fallos y sensibles a retardos, como la voz sobre IP o el streaming.

\subsection{Cabecer \acrshort{UDP}}
En la presente sección profundizaremos en la cabecera \acrshort{UDP}, junto con sus campos. Esta se puede ver en la Tabla~\ref{tab:cabecera_udp}. Como vemos, está organizada en palabras de $32$ bits (4 Bytes), y ocupa $8$ Bytes.
\begin{table}
    \centering
    \begin{tabular}{cccc}
    \hline \rowcolor[HTML]{EFEFEF}
    \multicolumn{1}{|c|}{\cellcolor[HTML]{EFEFEF}\qquad\scriptsize{\textbf{0-7}}\qquad~} &  \multicolumn{1}{c|}{\cellcolor[HTML]{EFEFEF}\qquad\scriptsize{\textbf{8-15}}\qquad~} &  \multicolumn{1}{c|}{\cellcolor[HTML]{EFEFEF}\qquad\scriptsize{\textbf{16-23}}\qquad~}&  \multicolumn{1}{c|}{\cellcolor[HTML]{EFEFEF}\qquad\scriptsize{\textbf{24-31}}\qquad~} \\ \hline \hline
    \multicolumn{2}{|c|}{Puerto Origen}            & \multicolumn{2}{|c|}{Puerto Destino}  \\ \hline
    \multicolumn{2}{|c|}{Longitud UDP}            & \multicolumn{2}{|c|}{Checksum}  \\ \hline \\ \hline
    \rowcolor[HTML]{EFEFEF}
    \multicolumn{4}{|c|}{\cellcolor[HTML]{EFEFEF}\scriptsize{Pseudocabecera}} \\ \hline
    \multicolumn{4}{|c|}{IP Origen}\\ \hline
    \multicolumn{4}{|c|}{IP Destino}\\ \hline
    \multicolumn{1}{|c|}{$0\ldots0$}
    & \multicolumn{1}{|c|}{Protocolo}
    & \multicolumn{2}{|c|}{Longitud UDP}
    \\ \hline
    \end{tabular}
    \caption{Cabecera \acrshort{UDP}.}
    \label{tab:cabecera_udp}
\end{table}

Veamos los campos, en orden, que la componen:
\begin{description}
    \item [Puerto origen:] (16 bits) Puerto en el que escucha el emisor.
    \item [Puerto destino:] (16 bits) Puerto al que está destinado el mensaje, donde se supone que escucha el receptor (aunque no se garantiza pues ser \acrshort{SNOC}).
    \item [Longitud UDP:] (16 bits): en bytes, mide la lontidud total del \acrshort{PDU} (cabecera, junto con datos).
    \item [Checksum:] (16 bits) suma de comprobación calculada mediante el mismo algoritmo que en el caso de la cabecera \acrshort{IP}. Comprueba la cabecera \acrshort{UDP} y una pseudocabecera, que consiste en una parte relevante de la cabecera \acrshort{IP} con datos relevantes para este \acrshort{UDP}. Estos son:
        \begin{itemize}
            \item Dirección IP de origen.
            \item Dirección IP de destino.
            \item Protocolo empleado (en la capa de red).
            \item Longitud UDP.
        \end{itemize}
\end{description}

\subsection{Multiplexación/demultiplexación}

Como se mencionó anteriormente, los puertos con un número menor a $1024$ están preasignados con servicios normalizados, y tan solo se podrán usar con privilegios de administrados. En el caso de \acrshort{UDP}, algunos se muestran en la Tabla~\ref{tab:puertos-udp}.
\begin{table}
    \centering
    \begin{tabular}{|c|c|c|}
        \hline Puerto & Aplicación/Servicio & Descripción\\\hline
        7 & ``Echo'' & ``Echo''\\
        13 & ``Daytime'' & Fecha y Hora\\
        37 & ``Time'' & Fecha y Hora\\
        42 & ``Nameserver'' & Servidor de nombres\\
        53 & ``Domain'' o \acrshort{DNS}  & Servicio de nombres de dominio\\
        69 & \acrshort{TFTP} & Transferencia simple de archivos\\
        123 & \acrshort{NTP} & Protocolo de tiempo de red\\\hline
    \end{tabular}
    \caption{Puertos preasignados en \acrshort{UDP}.}
    \label{tab:puertos-udp}
\end{table}

\section{\acrfull{TCP}}
El protocolo \acrshort{TCP} es un protocolo de la capa de transporte encapsulado sobre \acrshort{IP}. Algunas de sus características son las siguientes:
\begin{itemize}
    \item Servicio orientado a conexión:
    
    Emplea un protocolo\footnote{Aunque se traduce como protocolo, es más bien un intercambio muy específico de mensajes.} de establecimiento de conexión (\textit{handshake}). Es por tanto un servicio punto a punto, y exige un estado común entre el emisor y el receptor. 
    
    \item Es punto a punto (al contrario que \acrshort{UDP}). Por tanto, si se quiere enviar un mensaje mediante la dirección de difusión, se deberá emplear \acrshort{UDP}.
    
    \item La entrega de los datos a la capa de aplicación es ordenada; aunque no necesariamente lo es la llegada de los datos. Este protocolo se encarga de ordenarlos.
    \item Es transmisión full-duplex.
    \item Tiene un mecanismo de detección y recuperación de errores, retransmitiendo si es necesario. Emplea para ello confirmaciones (\acrshort{ACK}).
    % Lo consigue usando confiramaciones, que son positivas (solo confirma lo que ha llegado bien, no se dice nada de lo que ha llegado mal o no ha llegado) y acumulativas (si se ha confirmado hasta cierto byte, entonces todo lo anterior ha llegado bien).
    \item Es un servicio fiable, ya que tiene mecanismos de control de flujo y de congestión.
    \item Usa ``piggybacking'', concepto que consiste en que, al mandar una confirmación (\acrshort{ACK}) se aprovecha y se envían más datos.
\end{itemize}

\subsection{Cabecera TCP}
\begin{itemize}
    \item Puerto origen (16 bits): identifica el puerto del emisor.
    \item Puerto destino (16 bits): identifica el puerto del receptor.
    \item Número de secuencia (32 bits): identifica el byte del flujo de datos enviados por el emisor al receptor que representa el offset del segmento.
    \item Número de acuse de recibo (32 bits): el valor del siguiente número de secuencia que el receptor del segmento espera recibir. De esta forma se confirma todo lo anterior también.
    \item Longitud de cabecera (4 bits): indica el tamaño de la cabecera en palabras de 32 bits. De normal el tamaño es de \textbf{20 bytes}.
    \item Reservado: por si dentro de unos años hacen falta más bits.
    \item Flags:
        \begin{description}
            \item [U:] Urgente. De normal los datos se van introduciendo en el buffer del receptor por la derecha y sacando por la izquierda, buffer circular con ventana deslizante. Pero hay datos urgentes que precisan que este orden no se siga. 
            \item [A:] ACK es una confirmación. Si vale 0 el campo de acuse no es de utilidad.
            \item [P:] Push. En TCP el paquete no se manda a la aplicación hasta que no se llene cierto tamaño. Es más eficiente de esta forma, pero a veces necesitamos que los datos se envíen en un momento preciso y para ello sirve este flag, para decir que se manden los datos.
            \item [R:] Reset. Se resetea la conexión.
            \item [S:] Sincronismo. Esta a 1 en el momento del establecimiento de conexión.
            \item [F:] Fin. Cuando está a 1 es porque quiero terminar la conexión. 
        \end{description}
    \item Ventana ofertada para el control de flujo (16 bits): nos indica cuanto espacio libre le queda al buffer del receptor. 
    \item Comprobación (16 bits): incluye cabecera y datos. 
    \item Puntero de datos urgentes (16 bits): si el flag \textbf{P} está activo, este campo nos indica donde empiezan los datos urgentes, puesto que puede que no todo el segmento sea urgente.
    \item Opciones: son opcionales (por ejemplo las características de las extensiones de TCP).
\end{itemize}

\subsection{Multiplexación/demultiplexación}
Existen puertos preasignados con servicios normalizados:
\begin{figure}[H]
    \centering
    \includegraphics[width=0.6\linewidth]{./images/puertos-tcp.png}
\end{figure}

La conexión TCP se identifica por: puerto e IP origen y puerto e IP destino.
\subsection{Control de conexión}
Como ya hemos comentado, TCP ofrece un servicio orientado a conexión. El intercambio de mensajes tiene tres fases:
\begin{itemize}
    \item Establecimiento de conexión (sincroniza el número de secuencia y se reservan recursos).
    \item Intercambio de datos, full-duplex.
    \item Cierre de conexión, libera recursos.
\end{itemize}

\subsubsection{Establecimiento de conexión}
Se le conoce como ``three-way handshake''. Supongamos que A se quiere comunicar con B. 
\begin{enumerate}
    \item A manda una solicitud a B para activar una conexión, activando para ello el flag de sincronismo y en el campo de secuencia se pone un byte aleatorio X.
    \item Cuando B lo recibe, activa el flag de A (para confirmar el sincronismo) y en el campo de acuse pone X+1 (esto es por convenio). Además, por piggybacking, enviamos el sincronismo en el sentido contrario, activando el bit S y poniendo en el campo de secuencia otro número aleatorio Y.
    \item A recibe esto último y confirma poniendo el flag A a 1 y poniendo en el campo de acuse Y+1. En este mensaje se pueden mandar datos (piggybacking). (Aunque por simplicidad en los ejercicios no lo haremos).
\end{enumerate}
Entonces tenemos que A realiza una \textbf{apertura activa}, siendo el cliente; y B realiza una \textbf{apertura pasiva} siendo el servidor. Los campos que tenemos involucrados son: el bit de sincronismo S, el número de secuencia, el número de acuse, y el bit de ACK A.

La conexión es iniciada siempre por el cliente. Esto se denomina \textbf{apertura activa}. El servidor por su lado siempre está escuchando y cuando le llega una petición hace una \textbf{apertura pasiva}.

\begin{observacion}
    No es posible garantizar un establecimiento de conexión fiable teniendo en cuenta que los mensajes van sobre IP (que no es fiable). Para garantizarlo hay temporizadores y si expiran se reenvían paquetes. 
\end{observacion}

\subsubsection{Número de secuencia}
\begin{itemize}
    \item Es un campo para indicar el orden de los paquetes. Tiene 32 bits. Cuando el número de secuencia llega al máximo ($2^{32}$) se reinicia.
    \item El número de secuencia no empieza normalmente en 0, sino en un valor denominado \acrfull{ISN}, teóricamente aleatorio.
    \item Realmente el ISN es elegido por el SO normalmente. Lo que hace es tener un contador que se va incrementando cada \unit[4]{$\mu s$}. Por lo que tarda en repetirse un ISN casi \unit[5]{horas}.
    \item Este mecanismo de selección de ISN es suficiente para proteger evitar coincidencias, pero no es un mecanismo de protección frente a sabotajes. Es muy fácil averiguar el ISN de una conexión y suplantar a alguno de los participantes.
    \item Se incrementa el número de secuencia de cada segmento según los bytes del segmento anterior. 
    \item Cuando los flags S y F están activados se incrementa en 1 el número de secuencia.
\end{itemize}

Veamos algunos ejemplos de establecimientos de conexión particulares:
\begin{description}
    \item [Establecimiento sin incidencias:]~\\ 
\begin{figure}[H]
    \centering
    \includegraphics[width=0.6\linewidth]{./images/conexion-normal.png}
\end{figure}
    \item [Caso de conexión simultánea:] En este caso simplemente en el segundo mensaje no es necesario el SYN (pues ya se ha mandado antes).
\begin{figure}[H]
    \centering
    \includegraphics[width=0.6\linewidth]{./images/conexion-simul.png}
\end{figure}
    \item [Caso con SYN retrasados y duplicados:] En este caso cuando el emisor recibe el ACK de la petición que ya ha descartado lo que hace es mandar un mensaje para que el receptor resetee la conexión y ambos estén sincronizados.
\begin{figure}[H]
    \centering
    \includegraphics[width=0.6\linewidth]{./images/conexion-retardo.png}
\end{figure}
\end{description}

\subsubsection{Cierre de conexión}
\begin{enumerate}
    \item Se envía un FIN (flag F a 1) y se envía en el número de secuencia el siguiente byte que el otro espera recibir X.
    \item El otro responde con ACK con X+1 y envía un FIN con número de secuencia Y (el siguiente byte que espera recibir el primero).
    \item El primero responde con ACK con Y+1. 
\end{enumerate}

En este caso, al igual que en el establecimiento de conexión, el que inicia el cierre realiza un cierre activo y el otro un cierre pasivo. Dependiendo de la aplicación el cierre activo puede realizarlo tanto el cliente como el servidor.\\

La conexión se cierra, pero para liberar los recursos se deja un tiempo de margen por si tienen que llegar datos aún (suelen ser 2 minutos).

\subsubsection{MSS (Maximum Segment Size)}
El MTU, que es un concepto de capa de enlace (capa 2), especifica la longitud máxima de datos de un paquete de enlace, es decir, cabecera IP + datos IP. \\

MSS es un concepto de la capa de transporte. Indica lo que puede ocupar como máximo los datos de TCP. Por tanto, al MTU le tenemos que quitar lo que ocupa la cabecera IP y la cabecera TCP para calcular el MSS. 

\subsubsection{Diagrama de estados de conexiones TCP}
Un diagrama de estados es un autómata finito de estados TCP desde los cuales puedo hacer una serie de acciones, en las cuales puedo recibir y transmitir datos: a/b equivale a que recibo a y transmito b.

\subsection{Control de errores}
Los campos que tenemos involucrados en el control de errores son:
\begin{itemize}
    \item Número de secuencia.
    \item Campo de acuse.
    \item Bit de ACK.
    \item Campo de checksum (incluye cabecera y datos TCP y pseudocabecera IP). 
\end{itemize}

El sistema que se usa para el control de errores es el de confirmaciones positivas y acumulativas. Si el emisor pierde un ACK tiene que reenviar los datos, independientemente de que se haya perdido el dato o el ACK, tienen el mismo efecto ambos sucesos.\\

Lo que se hace es que el emisor tenga unos timeouts para que si este expira reenviemos el dato si no se ha recibido el ACK. Hay que calcular muy bien los timeouts puesto que si es muy corto se reenviarán datos innecesariamente y si es muy largo tardamos mucho en darnos cuenta del error.\\

Por otra parte tenemos el buffer del receptor. Se va rellenando con los datos que van llegando y se van colocando en orden gracias al número de secuencia, es decir, los datos se introducen por la derecha. Hay que destacar que hay un buffer por cada conexión TCP. Cuando la aplicación pide un dato, el SO saca un paquete de más a la izquierda del buffer. Por esto, decimos que el buffer es una ventana deslilzante, una cola FIFO circular.

\subsubsection{Generación de ACKs}
Vamos a ver situaciones que se dan en el receptor y el comportamiento que sigue a dichas situaciones:   
\begin{enumerate}
    \item Si ocurre una llegada ordenada de segmento, sin discontinuidad, y con todo lo anterior ya confirmado, se retrasa el envío del ACK. Se pone un temporizador a \unit{500}{ms} (este tiempo está estipulado en el correspondiente RFC) y si traspasado ese tiempo no ha llegado otro segmento, en ese momento ya sí se envía el ACK. 
    \item Si tenemos todo en orden, y ocurre una llegada ordenada, sin discontinuidad y hay pendiente un ACK retrasado, se manda inmediatamente el ACK acumulativo. Vemos por tanto que se manda un ACK cada dos segmentos, si va todo bien. 
    \item Supongamos que ahora nos llega un segmento con número de secuencia mayor que el esperado, por lo que tenemos una discontinuidad. En este caso se envía un ACK duplicado, indicando el número de secuencia del siguiente byte esperado.
    \item Supongamos por último que llega un segmento que completa una discontinuidad total (tapa el hueco entero) o parcialmente (tapa parte del hueco). En este caso se manda inmediatamente un ACK con el número de segmento del siguiente byte que se espera.
\end{enumerate}

En el control de flujo veremos alguna situación más que requiere envío de ACKs. 

\subsubsection{Estimación de timeouts}
Dichos timeouts deben adaptarse al \acrlong{RTT}. Este no es un valor fijo pues hay que tener en cuenta el tiempo de transmisión (tiempo que tarda en enviarse un paquete, que depende de la tarjeta), tiempo de propagación (tiempo que tarda desde que se empieza a enviarse el paquete hasta que se empieza a recibir, que depende de la distancia y de la red), tiempo de procesado en un router (depende de la carga de la red). Y todo esto es solo el tiempo de ida, a lo que hay que sumarle el tiempo de vuelta, que es similar. \\

Como enviamos un paquete y recibimos un ACK, podemos medir el \acrshort{RTT}. A esto lo llamamos $RTT_{medido}$. 
\begin{equation*}
    RTT_{nuevo} = \alpha\cdot RTT_{viejo} + (1-\alpha)\cdot RTT_{medido}, \ \alpha \in [0,1]
\end{equation*}
Este es un RTT filtrado, es una media suavizada. 
\begin{equation*}
    Desviacion_{nueva} = (1-x)\cdot Desviacion_{vieja} + x\cdot |RTT_{medido}-RTT_{nuevo}|, \ x \in [0,1]
\end{equation*}
Esta es la desviación instantánea respecto a la media, que se utiliza para procurar cubrir todos los casos. 
\begin{equation*}
    Timeout = RTT_{nuevo} + 4\cdot Desviacion_{nueva}
\end{equation*}

Tenemos un problema con los ACKs repetidos, pero esto se soluciona muy fácilmente (algoritmo de Karn). Se actualiza el RTT solo para los ACKs no ambiguos, pero si hay que retransmitir algún segmento, se duplica el timeout. 

\subsection{Control de flujo}
Es un mecanismo de atrás hacia delante: el receptor le dice al emisor que envíe más o menos datos. Los paquetes que lleguen cuando el buffer está lleno se descartan, lo que supone sobrecargar inútilmente la red. Nuestro objetivo es evitar esto. Es un sistema crediticio, el receptor informa al emisor sobre los bytes autorizados a emitir sin esperar respuesta. \\

Se utiliza el campo de la cabecera ventana, que tiene 16 bits, por lo que esto limita el tamaño de la ventana. 
\begin{equation*}
    ventana \ util \ emisor = ventana \ ofertada \ receptor - bytes \ en \ transito.
\end{equation*}
Es importante que tengamos en cuenta los bytes que ya se han mandado pero de los cuáles no hemos recibido confirmación.\\

Cuando la ventana está llena, el emisor se bloquea hasta recibir un nuevo ACK que confirme que se ha liberado espacio de la ventana. Aquí está la situación que comentábamos antes de la necesidad de envío de ACKs fuera del control de errores.\\

Este ACK es importante, dado que si se pierde el emisor se queda bloqueado. Para evitar esta situación se usa un temporizador de persistencia. Cuando expira dicho temporizador se envía 1 byte para que se fuerce el posible reenvío del ACK. \\

Un problema que puede surgir es el Síndrome de la ventana tonta, que sucede cuando por alguna razón se tiene que mandar un segmento corto, a partir de ahí, lo más probable es que la ventana útil sea similar al tamaño de dicho segmento. Esto hace que se sature la red con muchos segmentos cortos. 

Se puede hacer una posible mejora, usar la ventana optimista, no tomamos la ventana útil ni la ofertada, sino una cosa intermedia. \\ 

Hay dos medios que nos permiten saltarnos el orden:
\begin{itemize}
    \item El bit U (urgente) con el campo puntero.
    \item Solicitar entrega inmediata a la aplicación con el bit P (push).
\end{itemize}

\subsection{Control de congestión}
La velocidad de TCP depende en gran parte de esto. Se manifiesta en pérdidas y/o retrasos de ACKs. Es un problema diferente al control de flujo, involucra la red y los sistemas finales. \\

Tiene una naturaleza adelante-atrás: es el emisor el que decide cuánto se transmite. Por esto, no es necesario ningún campo en la cabecera TCP. 

Lo que se hace es en la fuente limitar de forma adaptable el tráfico generado: reduciendo la velocidad de emisión ante congestiones e incrementándola si todo va bien. \\

Primero vamos a explicar el funcionamiento del control de congestión, y luego pasaremos a juntarlo con el control de flujo, dado que están directamente relacionados.

\begin{description}
    \item [Funcionamiento del control de congestión:]~\\
Hablaremos de varios valores: ventana de congestión, ventana inicial y umbral. Aunque realmente lo que mide es la cantidad de bytes hablaremos de cantidad de segmentos. 

En primer lugar se hace el establecimiento de conexión (siempre en TCP). Ahora bien, tras esto, vamos a tener dos fases:
\begin{description}
    \item [Inicio lento:] Al principio la ventana de congestión está puesta en el valor que estipula la ventana inicial (depende del sistema operativo, suele ser 2 para no tener que esperar los \unit{500}{ms}). Se mandan esa cantidad de paquetes, y se espera los ACKs. \\

        Después de cada ACK recibido se le suma a la ventana de congestión anterior la cantidad de paquetes confirmados en dicho ACK. Es decir, si todo va bien, en cada ACK se aumentará la ventana de congestión en 2. Pero si nos damos cuenta, cada \acrshort{RTT} la ventana duplicará su tamaño. Por tanto, la velocidad aumenta exponencialmente.
        \begin{equation*}
            CW = CW + n^o \ datos \ confirmados
        \end{equation*}
        Siempre debemos tener en cuenta que el número de segmentos que podemos enviar es el que nos permite la ventana de congestión menos los segmentos que hay ya en tránsito (al igual que en el control de flujo). 
        Esto va ocurriendo hasta que llegamos a un umbral, y pasamos a la siguiente fase.
    \item [Prevención de congestión:] En esta fase, después de cada confirmación se aumenta la ventana de la siguiente forma:
        \begin{equation*}
            CW = CW + \frac{1}{CW}
        \end{equation*}
        Entonces, cuando pasa un \acrshort{RTT} aumenta en 1 la ventana de congestión, es decir la velocidad aumenta linealmente. 
    \item [Ocurre un timeout:] esto es por que ha habido algún error, y se asume que es por congestión, por lo que volvemos al valor de la ventana inicial y el umbral se establece en la mitad del valor de la ventana de congestión. 
        \begin{equation*}
            \text{umbral} = \frac{CW}{2}, \qquad CW = CW_{inicial}
        \end{equation*}
        En este caso, la ventana de congestión se va a ir duplicando de nuevo, pero ahora de forma más lenta.
\end{description}

    \item [Funcionamiento del control de flujo y congestión:] habiendo explicado ambos funcionamientos por separado, solo nos queda juntarlo. En realidad no solo vamos a tener una de las dos limitaciones aisladas, sino que las tenemos las dos a la vez, por tanto los bytes permitidos a enviar son el mínimo de las dos ventanas, la de congestión y la del receptor.
        \begin{equation*}
            Ventana \ util = \min\{VentanaCongestion, VentanaReceptor\}
        \end{equation*}
\end{description}

\section{Extensiones TCP}
TCP se define con múltiples ``sabores'' o \textit{flavours} en inglés, que no afectan a la interoperabilidad entre los extremos. 
\begin{itemize}
    \item TCP Tahoe: es el que hemos estudiado.
    \item TCP Reno: es la siguiente versión a TCP Tahoe. Distingue entre los timeout, que opera igual que Tahoe, y ACKs duplicados, que pone a la mitad la ventana de congestión y sigue en prevención de congestión. 
    \item TCP NewReno: la versión anterior tiene un inconveniente. Si se pierden muchos paquetes, en cada uno se reduce la ventana a la mitad, cuando realmente esto no es necesario porque probablemente reduciendo una vez hubiera sido diferente. Esta nueva versión intenta ponerle solución a esto con ACKs parciales. 
    \item TCP Vegas: si el \acrshort{RTT} aumenta se disminuye la ventana, y si el \acrshort{RTT} disminuye se aumenta la ventana de congestión.
    \item TCP Cubic: se usa en cualquier versión de Linux con kernel mayor que la 2.6.19. La ventana de congestión depende de los ACKs y del \acrshort{RTT}. 
    \item TCP Westwood: hay que tener en cuenta que, si bien en redes cableadas suponer que los errores siempre son por congestión es un buen enfoque; en redes inalámbricas no es ni de cerca el mejor, pues el 10\% de los errores son por el medio. Esta versión tiene en cuenta esto, y está pensada para redes inalámbricas.
\end{itemize}

