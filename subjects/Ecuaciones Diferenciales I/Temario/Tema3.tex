\newpage
\chapter{Condición de exactitud y factores integrantes}
Una vez estudiados los principales cambios de variable para resolver ecuaciones diferenciales, cambiamos ahora la forma en la que las resolveremos, procedimiento que describiremos y desarrollaremos a lo largo de este Capítulo.

\begin{notacion}
    Volveremos nuevamente a la notación geométrica, donde notaremos por $x$ a la variable independiente y por $y = y(x)$ a la función incógnita.
\end{notacion}

Ahora, no estaremos interesados en buscar ecuaciones diferenciales en forma normal, sino que buscaremos ecuaciones de la forma
\begin{equation}\label{eq:nueva_forma}
    P(x,y) + Q(x,y)y' = 0
\end{equation}
Y lo que haremos ahora para resolverla será buscar diferenciales exactas, es decir, buscar una función $U$ de forma que la expresión~(\ref{eq:nueva_forma}) se reescriba como
\begin{equation*}
    \dfrac{d}{dx}[U(x,y)] = 0
\end{equation*}
De forma que, bajo unas ciertas condiciones, tendremos que $U(x,y)= c$, $c\in \mathbb{R}$ con lo que tendremos una solución $y=y(x)$ expresada en forma implícita gracias a la función $U$.

\begin{ejemplo}
    Motivaremos lo anteriormente descrito con este ejemplo, en el que trataremos de resolver la ecuación
    \begin{equation}\label{eq:ejemplo_dif_ex}
        \dfrac{dy}{dx} = \dfrac{y-x}{y+x}
    \end{equation}
    buscando para ello una función que al derivarla respecto a $x$ nos de la expresión que tenemos.

    Lo primero para ello será reescribir la ecuación~(\ref{eq:ejemplo_dif_ex}) para que sea de la forma~(\ref{eq:nueva_forma}). Para ello, es suficiente con desplazar todos los términos a la izquierda de la igualdad, obteniendo
    \begin{equation}\label{eq:ejemplo_dif_ex2}
        x-y+(x+y)y' = 0
    \end{equation}
    Por lo que en este caso, tenemos las funciones
    \begin{equation*}
        P(x,y) = x-y \qquad Q(x,y) = x+y
    \end{equation*}
    Reescribiendo la ecuación~(\ref{eq:ejemplo_dif_ex2}) con el objetivo de buscar un diferencial exacto, llegamos a la expresión
    \begin{equation*}
        x+yy' - y+xy' = 0
    \end{equation*}
    donde observamos que la parte de la izquierda de la resta podemos verla como:
    \begin{equation*}
        x+yy' = 0 \Longrightarrow \dfrac{d}{dx}\left(\dfrac{x^2+y^2}{2}\right) = 0
    \end{equation*}
    Si también pudiéramos hacerlo en la derecha (algo que a priori parece más difícil), llegaríamos a una expresión de la forma:
    \begin{equation*}
        \dfrac{d}{dx}\left(\dfrac{x^2+y^2}{2}\right) - \dfrac{d}{dx}[H(x,y)] = 0
    \end{equation*}
    Veremos próximamente que esto es imposible de hacer en este caso.

    Sin embargo, existe un truco que sí nos permite resolver la ecuación~(\ref{eq:ejemplo_dif_ex2}), se basa en dividir la expresión entre $x^2+y^2$ (algo que por ahora parece una idea feliz, pero que cobrará sentido a lo largo del Capítulo, algo que llamaremos \textit{factor integrante}):
    \begin{equation*}
        \dfrac{x-y}{x^2+y^2} + \dfrac{x+y}{x^2+y^2}y' = 0
    \end{equation*}
    Vamos a reorganizar los términos cuidadosamente, para buscar un diferencial exacto:
    \begin{equation*}
        \dfrac{x+yy'}{x^2+y^2} + \dfrac{-y+xy'}{x^2+y^2} = 0
    \end{equation*}
    Es difícil hallar un diferencial exacto a partir de una expresión, pero es fácil comprobar que algo lo sea. Proponemos la siguiente expresión como diferencial exacto y comprobaremos que funciona, por tener por ahora poco manejo en este procedimiento (aunque el término de la izquierda no es difícil de averiguar). Proponemos:
    \begin{equation*}
        \dfrac{d}{dx}\left(\dfrac{1}{2}\ln(x^2+y^2)\right) + \dfrac{d}{dx}\left(\arctg\left(\dfrac{y}{x}\right)\right) = 0
    \end{equation*}
    Es sencillo comprobar que el término de la izquierda se corresponde con lo que queríamos hacer, comprobémoslo ahora en la derecha:
    \begin{equation*}
        \dfrac{d}{dx}\left(\arctg\left(\dfrac{y}{x}\right)\right) = \dfrac{1}{1+{\left(\dfrac{y}{x}\right)}^{2}} \dfrac{xy'-y}{x^2} = \dfrac{xy'-y}{x^2+y^2}
    \end{equation*}
    Finalmente, vemos que:
    \begin{equation*}
        \dfrac{d}{dx}\left(\dfrac{1}{2}\ln(x^2+y^2)+\arctg\left(\dfrac{y}{x}\right)\right) = \dfrac{d}{dx}\left(\dfrac{1}{2}\ln(x^2+y^2)\right) + \dfrac{d}{dx}\left(\arctg\left(\dfrac{y}{x}\right)\right) = 0
    \end{equation*}
    gracias a la linealidad de la derivada, y por ser la función\footnote{En este ejemplo no nos preocupamos por su intervalo de definición, ya que solo queremos mostrar el procedimiento que realizaremos a partir de ahora para resolver las ecuaciones diferenciales.}
    \begin{equation*}
        (x,y) \longmapsto \dfrac{1}{2}\ln(x^2+y^2) + \arctg\left(\dfrac{y}{x}\right)
    \end{equation*}
    de clase $C^1$, concluimos finalmente que
    \begin{equation*}
        \dfrac{1}{2}\ln(x^2+y^2) + \arctg\left(\dfrac{y}{x}\right) = c \qquad c\in \mathbb{R}
    \end{equation*}
\end{ejemplo}
Una vez explicada de forma breve lo que haremos y motivada con el ejemplo anterior, pasaremos ahora al desarrollo teórico de este procedimiento, el cual se divide en dos:
\begin{itemize}
    \item En primer lugar, estudiar una condición necesaria y suficiente para tener la condición de exactitud (esto es, poder encontrar un diferencial exacto) que nos permita obtener la función $U$ anteriormente mencionada.
    \item En caso de que no podemos hacerlo, buscar algo por lo que multiplicar la ecuación original (un factor integrante) para que sí podamos hacerlo, tal y como hicimos en el ejemplo con $x^2+y^2$.
\end{itemize}
Exigiremos varias hipótesis sobres las funciones $P$ y $Q$ de la expresión~(\ref{eq:nueva_forma}) (y sobre otros elementos relacionados con la ecuación diferencial) con el fin de obtener el resultado buscado.

\section{Condición de exactitud}
En todo lo que sigue, trabajaremos en un abierto conexo $\Omega\subseteq \mathbb{R}^2$ y con dos funciones\footnote{Notemos que en el ejemplo anterior, $P$ y $Q$ eran polinomios, por lo que cumplían esta condición.} $P,Q\in C^1(\Omega)$.\\

Si existe $U\in C^1(\Omega)$ una función de dos variables de forma que la ecuación~(\ref{eq:nueva_forma}) se transforme en una de la forma:
\begin{equation*}
    \dfrac{d}{dx}(U(x,y)) = 0
\end{equation*}
Derivando de forma implícita:
\begin{equation*}
    \dfrac{\partial U}{\partial x}(x,y) + \dfrac{\partial U}{\partial y}(x,y)y' = 0
\end{equation*}
Por tanto, lo que buscamos es una función $U$ que cumpla:
\begin{equation*}
    \dfrac{\partial U}{\partial x} = P \qquad \dfrac{\partial U}{\partial y} = Q
\end{equation*}
Veremos a continuación que esto no es posible en general (sin exigir más condiciones). Es decir, no tiene por qué existir una funcion $U$ de forma que sus dos parciales sean las funciones $P$ y $Q$ dadas. Para ello, recuperaremos el ejemplo anterior, introduciendo antes un teorema importante en esta sección\footnote{Se trata de un Teorema que se debería haber visto anteriormente, pero que no se ha hecho por la planificación del doble grado.}.

\begin{teo}[de Clairaut]
    Sea $f:\Omega \rightarrow \mathbb{R}$ una función de dos variables definida en un conjunto abierto $\Omega\subseteq \mathbb{R}^2$, si $f\in C^2(\Omega)$, entonces las derivadas cruzadas de $f$ son iguales, es decir:
    \begin{equation*}
        \dfrac{\partial^2 f}{\partial x\partial y} = \dfrac{\partial^2 f}{\partial y\partial x}
    \end{equation*}
    \begin{proof}
        Supuesto que $(0,0)\in \Omega$, por ser $\Omega$ abierto, existe $h\in \mathbb{R}$ tal que
        \begin{equation*}
            (0,0) \in [0,h]\times [0,h] \subseteq \Omega
        \end{equation*}
        Sea $A = \{h\in \mathbb{R}\mid [0,h]\times [0,h]\subseteq \Omega\}$. Definimos $\Delta:A\rightarrow\mathbb{R}$ una función dada por
        \begin{equation*}
            \Delta(h) = f(h,h) - f(h,0) - f(0,h) + f(0,0) \qquad h\in A
        \end{equation*}
        la demostración se basa en ver cómo es la función $\Delta$:

        Por una parte, fijado un $h\in A$, podemos definir la función $G_h:A\rightarrow\mathbb{R}$ dada por
        \begin{equation*}
            G_h(x) = f(x,h) - f(x,0) \qquad x\in A
        \end{equation*}
        Vemos fácilmente que $G_h\in C^2(A)$ $\forall h\in A$ por serlo $f$, con
        \begin{equation*}
            G_h'(x) = \dfrac{\partial f}{\partial x}(x,h) - \dfrac{\partial f}{\partial x}(x,0) \qquad \forall x\in A
        \end{equation*}
        Podemos ahora usar $G_h$ para ver el comportamiento de $\Delta$:
        \begin{equation*}
            \Delta(h) = G_h(h) - G_h(0) \qquad \forall h\in A
        \end{equation*}
        Aplicando ahora el Teorema del Valor Medio, obtenemos un $\xi_h \in \left]0, h\right[$ tal que
        \begin{equation*}
            \Delta(h) = G_h(h) - G_h(0) = hG_h'(\xi_h) = h \left[\dfrac{\partial f}{\partial x}(\xi_h,h) - \dfrac{\partial f}{\partial x}(\xi_h,0)\right] \qquad \forall h\in A
        \end{equation*}
        Como $f\in C^2(A)$, tenemos que $\frac{\partial f}{\partial x}$ es una función de clase $C^1(A)$. Podemos ahora volver a aplicar el Teorema del Valor Medio en este último término, sobre la función resultado de la composición
        \begin{equation*}
            h \longmapsto (\xi_h, h) \longmapsto \dfrac{\partial f}{\partial x}(\xi_h, h)
        \end{equation*}
        Que es de clase $C^1(A)$ por serlo $\frac{\partial f}{\partial x}$. De esta forma, obtenemos un $\eta_h \in \left]0,h\right[$ tal que
        \begin{equation*}
            \Delta(h) = h \left[\dfrac{\partial f}{\partial x}(\xi_h,h) - \dfrac{\partial f}{\partial x}(\xi_h,0)\right] = h^2 \left[\dfrac{\partial^2 f}{\partial y\partial x}(\xi_h, \eta_h)\right] \qquad \forall h \in A
        \end{equation*}
        Buscamos ahora calcular el siguiente límite
        \begin{equation*}
            \lim_{h\to0}\dfrac{1}{h^2}\Delta(h) = \dfrac{\partial^2 f}{\partial y\partial x}(0,0)
        \end{equation*}
        Donde hemos usado la continuidad de $\frac{\partial^2 f}{\partial y\partial x}$ (por ser $f\in C^2(A)$), ya que:
        \begin{equation*}
            h \rightarrow 0 \Longrightarrow (\xi_h, \eta_h) \rightarrow (0,0) \Longrightarrow \dfrac{\partial^2 f}{\partial y\partial x}(\xi_h,\eta_h)\rightarrow  \dfrac{\partial^2 f}{\partial y\partial x}(0,0)
        \end{equation*}
        De forma totalmente análoga, fijado $h\in A$, podemos ahora definir la función $D_h:A\rightarrow\mathbb{R}$ dada por
        \begin{equation*}
            D_h (y) = f(h,y) - f(0,y) \qquad y\in A
        \end{equation*}
        Función de clase $C^2(A)$ por serlo $f$, con
        \begin{equation*}
            D_h'(y) = \dfrac{\partial f}{\partial y}(h,y) - \dfrac{\partial f}{\partial y}(0,y) \qquad y\in A
        \end{equation*}
        De forma similar a la anterior, podemos aplicar el Teorema del Valor Medio dos veces en la siguiente cadena de igualdades:
        \begin{align*}
            \Delta(h) &= D_h(h) - D_h(0) = h D_h'(\xi_h) = h\left[\dfrac{\partial f}{\partial y}(h,\xi_h) - \dfrac{\partial f}{\partial y}(0,\xi_h)\right] \\
                      &= h^2 \left[\dfrac{\partial^2 f}{\partial x\partial y}(\eta_h,\xi_h)\right] \qquad \xi_h, \eta_h \in \left]0,h\right[ \quad \forall h\in A
        \end{align*}
        De donde obtenemos que
        \begin{equation*}
            \lim_{h\to0}\dfrac{1}{h^2}\Delta(h) = \dfrac{\partial^2 f}{\partial x\partial y}(0,0)
        \end{equation*}
        Y por la unicidad del límite, concluimos que
        \begin{equation*}
            \dfrac{\partial^2 f}{\partial y\partial x}(0,0) = \dfrac{\partial^2 f}{\partial x\partial y}(0,0)
        \end{equation*}
        Una vez probado que las derivadas cruzadas coinciden en el origen (supuesto que $(0,0)\in \Omega$), veamos ahora que coinciden en cualquier $(x,y)\in \Omega$ (ya sin suponer necesariamente que $(0,0)\in \Omega$).

        Sea pues $(x_0,y_0)\in \Omega$, consideramos la traslación $t:\Omega\rightarrow\mathbb{R}^2$ dada por
        \begin{equation*}
            t(x,y) = (x,y) - (x_0,y_0) = (x-x_0,y-y_0) \qquad (x,y)\in \Omega
        \end{equation*}
        Es fácil ver que $t(\Omega)=\Omega_0=\{(x,y)\in \mathbb{R}^2 \mid (x,y)+(x_0,y_0)\in \Omega\}$. Vemos también que $t$ tiene como función inversa $t^{-1}:\Omega_0\rightarrow\Omega$, con
        \begin{equation*}
            t^{-1}(x,y) = (x,y) + (x_0,y_0) = (x+x_0,y+y_0) \qquad (x,y)\in \Omega_0
        \end{equation*}
        Definimos ahora la función $g:\Omega_0\rightarrow\mathbb{R}$ dada por
        \begin{equation*}
            g(x,y) = f(t^{-1}(x,y)) = f(x+x_0, y+y_0) \qquad (x,y)\in \Omega_0
        \end{equation*}
        Por ser $t$ una traslación, se trata de una función continua, luego $t(\Omega) = \Omega_0$ es un abierto de $\mathbb{R}^2$. 
        Además, $t^{-1}\in C^\infty(\Omega_0)$, por lo que $g\in C^2(\Omega_0)$ por serlo también $f$. Finalmente:
        \begin{equation*}
            (x_0,y_0)\in \Omega \Longrightarrow t(x_0,y_0)=(0,0)\in \Omega_0
        \end{equation*}
        Con lo que $g$ cumple todas las hipótesis del Teorema recién demostrado en $(0,0)$, por lo que
        \begin{equation*}
            \dfrac{\partial^2 g}{\partial y\partial x}(0,0) = \dfrac{\partial^2 g}{\partial x\partial y}(0,0)
        \end{equation*}
        Y solo faltará ver la relación entre las parciales de $g$ y de $f$. En primer lugar:
        \begin{align*}
            \dfrac{\partial g}{\partial x}(x,y) &= \dfrac{\partial f}{\partial x}(t^{-1}(x,y))\dfrac{\partial t_1^{-1}}{\partial x}(x,y) + \dfrac{\partial f}{\partial y}(t^{-1}(x,y))\dfrac{\partial t_2^{-1}}{\partial x}(x,y) = \dfrac{\partial f}{\partial x}(t^{-1}(x,y)) \\
            \dfrac{\partial g}{\partial y}(x,y) &= \dfrac{\partial f}{\partial x}(t^{-1}(x,y))\dfrac{\partial t_1^{-1}}{\partial y}(x,y) + \dfrac{\partial f}{\partial y}(t^{-1}(x,y))\dfrac{\partial t_2^{-1}}{\partial y}(x,y) = \dfrac{\partial f}{\partial y}(t^{-1}(x,y)) 
        \end{align*}
        Donde hemos aplicado que:
        \begin{equation*}
            \dfrac{\partial t_1^{-1}}{\partial x}(x,y) = \dfrac{\partial t_2^{-1}}{\partial y}(x,y) = 1 \qquad \dfrac{\partial t_1^{-1}}{\partial y}(x,y) = \dfrac{\partial t_2^{-1}}{\partial x}(x,y) = 0 
        \end{equation*}
        Por tanto:
        \begin{gather*}
            \dfrac{\partial^2 g}{\partial y\partial x}(x,y) = \dfrac{\partial }{\partial y}\left(\dfrac{\partial g}{\partial x}(x,y)\right) = \dfrac{\partial }{\partial y}\left(\dfrac{\partial f}{\partial x}(t^{-1}(x,y))\right) = \dfrac{\partial^2 f}{\partial y\partial x}(t^{-1}(x,y)) \\
            \dfrac{\partial^2 g}{\partial x\partial y}(x,y) = \dfrac{\partial }{\partial x}\left(\dfrac{\partial g}{\partial y}(x,y)\right) = \dfrac{\partial }{\partial x}\left(\dfrac{\partial f}{\partial y}(t^{-1}(x,y))\right) = \dfrac{\partial^2 f}{\partial x\partial y}(t^{-1}(x,y)) 
        \end{gather*}
        De donde:
        \begin{equation*}
            \dfrac{\partial^2 f}{\partial y\partial x}(x_0,y_0) = \dfrac{\partial^2 g}{\partial y\partial x}(0,0) = \dfrac{\partial^2 g}{\partial x\partial y}(0,0) = \dfrac{\partial^2 f}{\partial x\partial y}(x_0, y_0)
        \end{equation*}
        Para cualquier $(x_0,y_0)\in \Omega$ arbitrario, de donde
        \begin{equation*}
            \dfrac{\partial^2 f}{\partial x\partial y} = \dfrac{\partial^2 f}{\partial y\partial x} 
        \end{equation*}
    \end{proof}
\end{teo}

\begin{ejemplo}
    Para las funciones
    \begin{equation*}
        P(x,y) = x-y \qquad Q(x,y) = x+y
    \end{equation*}
    no es posible encontrar una función $U\in C^1(\mathbb{R}^2)$ que cumpla
    \begin{equation*}
        \dfrac{\partial U}{\partial x}(x,y) = P(x,y) \qquad \dfrac{\partial U}{\partial y}(x,y) = Q(x,y) \qquad \forall (x,y)\in \mathbb{R}^2
    \end{equation*}
    \begin{proof}
        Por reducción al absurdo, suponemos que existe una función $U$ de forma que
    \begin{equation*}
        \dfrac{\partial U}{\partial x}(x,y) = P(x,y) = x-y \qquad \dfrac{\partial U}{\partial y}(x,y) = Q(x,y) = x+y \qquad \forall (x,y)\in \mathbb{R}^2
    \end{equation*}
    En dicho caso, entonces $U\in C^2(\mathbb{R}^2)$ (de hecho, $U\in C^\infty(\mathbb{R}^2)$ por tratarse de polinomios). Notemos que:
    \begin{align*}
        \dfrac{\partial^2 U}{\partial x\partial y}(x,y) &= \dfrac{\partial }{\partial x}\left(\dfrac{\partial U}{\partial y}(x,y)\right) = \dfrac{\partial }{\partial x}(Q(x,y)) = 1 \qquad \forall (x,y)\in \mathbb{R}^2 \\
        \dfrac{\partial^2 U}{\partial y\partial x}(x,y) &= \dfrac{\partial }{\partial y}\left(\dfrac{\partial U}{\partial x}(x,y)\right) = \dfrac{\partial }{\partial y}(P(x,y)) = -1 \qquad \forall (x,y)\in \mathbb{R}^2 
    \end{align*}
    Por el Teorema de Clairaut, llegamos a que:
    \begin{equation*}
        1 = \dfrac{\partial^2 U}{\partial x\partial y}(x,y) = \dfrac{\partial^2 U}{\partial y\partial x}(x,y) = -1 \qquad \forall (x,y)\in \mathbb{R}^2
    \end{equation*}
    Contradicción, con lo que no existe dicha función $U$.
    \end{proof}
\end{ejemplo}

En general, dadas dos funciones de clase $C^1$ no podemos encontrar una tercera función de clase $C^1$ de forma que sus derivadas parciales sean las dos primeras funciones. Notemos que en el caso unidimensional, el Teorema Fundamental del Cálculo nos asegura que esto sí que es cierto, cosa que no pasa en varias variables.\\

Buscamos ahora una condición que nos permita encontrar una función $U\in C^1(\Omega)$ de forma que podamos escribir
\begin{equation*}
    \dfrac{\partial U}{\partial x} = P \qquad \dfrac{\partial U}{\partial y} = Q 
\end{equation*}
Para dos funciones $P$ y $Q$ de clase $C^1(\Omega)$. Veamos primero un resultado que nos da una condición necesaria:

\begin{prop}[Condición necesaria]\label{prop:condicion_necesaria}
    Dadas dos funciones $P,Q\in C^1(\Omega)$, si existe una función $U\in C^1(\Omega)$ tal que 
\begin{equation*}
    \dfrac{\partial U}{\partial x}(x,y) = P(x,y) \qquad \dfrac{\partial U}{\partial y}(x,y) = Q(x,y) \qquad \forall (x,y)\in \mathbb{R}^2
\end{equation*}
Entonces, se ha de cumplir la \textbf{condición de exactitud}:
    \begin{equation*}
        \dfrac{\partial P}{\partial y}(x,y) = \dfrac{\partial Q}{\partial x}(x,y) \qquad \forall (x,y)\in \mathbb{R}^2
    \end{equation*}
    \begin{proof}
        Recuperando parte de la demostración del ejemplo anterior, si existiera dicha función $U$, esta sería de clase $C^2(\Omega)$, luego aplicando el Teorema de Clairaut:
        \begin{equation*}
            \dfrac{\partial Q}{\partial x} = \dfrac{\partial }{\partial x}\left(\dfrac{\partial U}{\partial y}\right)= \dfrac{\partial^2 U}{\partial x\partial y} = \dfrac{\partial^2 U}{\partial y \partial x} = \dfrac{\partial}{\partial y}\left(\dfrac{\partial U}{\partial x}\right) = \dfrac{\partial P}{\partial y}
        \end{equation*}
    \end{proof}
\end{prop}

Sin embargo, la condición de exactitud no se trata de una condición suficiente para poder encontrar dicha función $U$, sino que dependerá de la topología de $\Omega$ de que esto pueda hacerse o no. Para ver este resultado, es necesario introducir previamente un concepto ya visto en otras asignaturas.

\begin{definicion}[Forma de estrella]
    Diremos que $\Omega$ tiene forma de estrella (o que es estrellado\footnote{Tal y como se desarrolló en los apuntes de Topología I.}) si existe $z_\ast \in \Omega$ tal que 
    \begin{equation*}
        [z,z_\ast] \subseteq  \Omega \qquad \forall z\in \Omega
    \end{equation*}

    Es decir, que el segmento de extremos $z$ y $z_\ast$ esté contenido en $\Omega$:
    \begin{equation*}
        (1-t)z + tz_\ast \in \Omega \qquad \forall t\in [0,1], z\in \Omega
    \end{equation*}
\end{definicion}

Notemos que la condición de ser estrellado se trata de una condicion geométrica. Ejemplos de conjuntos estrellados son:
\begin{equation*}
    \mathbb{R}^2 \qquad [0,1]\times [0,1] \qquad \mathbb{S}^1
\end{equation*}
Todos estos son convexos. Sin embargo, existen conjuntos con forma de estrella que no son convexos, como el conjunto de la Figura~\ref{fig:Estrellado}.
\begin{figure}[H]
    \centering
    \begin{tikzpicture}[scale=0.4]
        % Dibujo de una estrella
        \coordinate (A) at (0,8);
        \coordinate (B) at (2,3);
        \coordinate (C) at (7,3);
        \coordinate (D) at (3,0);
        \coordinate (E) at (4,-6);
        \coordinate (F) at (0,-3);
        \coordinate (G) at (-4,-6);
        \coordinate (H) at (-3,0);
        \coordinate (I) at (-7,3);
        \coordinate (J) at (-2,3);

        \draw (A) -- (B) -- (C) -- (D) -- (E) -- (F) -- (G) -- (H) -- (I) -- (J) -- cycle;

        \coordinate (X) at (0,0);
        \coordinate (P) at (3,2);
        \coordinate (Q) at (-2,-3);

        % Marca cada punto
        \fill (X) circle (4pt) node[anchor=south east]{$z_\ast$};
        \fill (P) circle (2pt);
        \fill (Q) circle (2pt);

        % Dibujo de los segmentos
        \draw[dashed] (X) -- (P);
        \draw[dashed] (X) -- (Q);
    \end{tikzpicture}
    \caption{Conjunto estrellado desde $z_\ast$.}
    \label{fig:Estrellado}
\end{figure}

\begin{definicion}[Convexo]
    Diremos que un conjunto $\Omega\subseteq \mathbb{R}^2$ es convexo si dados cualesquiera dos puntos $\alpha,\beta\in \Omega$, se tiene que 
    \begin{equation*}
        [\alpha,\beta] \subseteq \Omega \qquad \forall \alpha,\beta\in \Omega
    \end{equation*}
    Es decir, que el segmento de extremos $\alpha$ y $\beta$ esté contenido en $\Omega$:
    \begin{equation*}
        (1-t)\alpha+t\beta \in \Omega \qquad \forall t\in [0,1] \quad \alpha,\beta\in \Omega
    \end{equation*}
\end{definicion}
De esta forma, vemos que un conjnto convexo es un conjunto estrellado desde cualquier punto, algo que se pondrá de manifiesto en la siguiente proposición.
La propiedad de que un conjunto sea convexo se trata de una propiedad geométrica, concepto que ya se trató en Topología I y en Geometría III\@.

\begin{prop}
    Sea $\Omega$ un conjunto convexo, entonces es estrellado.
    \begin{proof}
        Sea $z_\ast \in \Omega$, entonces $[z_\ast, \alpha]\subseteq \Omega$ $\forall \alpha\in \Omega$, por ser $\Omega$ convexo.
    \end{proof}
\end{prop}

\noindent
Recordando la Proposición~\ref{prop:condicion_necesaria}, mostramos ahora el siguiente teorema, el cual nos proporciona la otra implicación que venimos buscando para tener una condición necesaria y \underline{suficiente}.
\begin{teo}\label{teo:condicion_suficiente}
    Si $\Omega\subseteq \mathbb{R}^2$ es abierto y tiene forma de estrella, sean $P,Q\in C^1(\Omega)$ funciones que cumplen la condición de exactitud, es decir, que:
    \begin{equation*}
        \dfrac{\partial P}{\partial y}(x,y) = \dfrac{\partial Q}{\partial x}(x,y) \qquad \forall (x,y)\in \mathbb{R}^2
    \end{equation*}
    Entonces, existe una función $U\in C^2(\Omega)$ tal que 
    \begin{equation*}
        \dfrac{\partial U}{\partial x}(x,y) = P(x,y) \qquad \dfrac{\partial U}{\partial y}(x,y) = Q(x,y) \qquad \forall (x,y)\in \mathbb{R}^2
    \end{equation*}
\end{teo}
\noindent
En realidad, obtenemos un teorema mucho más general exigiendo solo que $\Omega$ sea simplemente conexo\footnote{Noción que no hemos visto todavía. Intuitivamente, un conjunto es simplemente conexo si no tiene agujeros.}.\\

Para realizar la demostración, es necesario recordar previamente un concepto ya visto en Análisis Matemático II\@, las integrales dependientes de un parámetro.
\subsection{Integrales dependientes de un parámetro}
Sabemos que si tenemos una función continua $f$ definida en un intervalo $I$, entonces si definimos
\begin{equation*}
    F(y) = \int_{y_0}^{y} f(\xi)~d\xi  \qquad y_0\in I, \forall y\in I
\end{equation*}
Sabemos por el Teorema Fundametal del Cálculo que $F\in C^1(I)$, con $F'(y) = f(y)$.\\

Sin embargo, nos podemos encontrar funciones definidas por integrales de diversas formas, como una función dada por la integral de una función de dos variables integrando solo una de ellas. Sea $f:J\times I\rightarrow\mathbb{R}$ una función y $a,b\in J$, definimos $F:I\rightarrow\mathbb{R}$ por
\begin{equation*}
    F(y) = \int_{a}^{b} f(x,y)~dx  \qquad \forall y\in I
\end{equation*}
Las funciones obtenidas de esta forma decimos que son funciones obtenidas mediante integrales dependientes de un parámetro (en este caso, el parámetro es $y$).\\

Antes de ver cómo podemos derivar este tipo de funciones, pensaremos en ``el caso discreto''. Es decir, dada una sucesión de funciones ${\{f_n\}}_{n\in \mathbb{N}}$ todas ellas definidas en un cierto intervalo $I$ y dado $N\in \mathbb{N}$, podemos definir una función $F:I\rightarrow\mathbb{R}$ dada por
\begin{equation*}
    F(y) = \sum_{n=1}^{N} f_n(y) \qquad \forall y\in I
\end{equation*}
De esta forma, sabemos ya derivar la función $F$:
\begin{equation*}
    \dfrac{dF}{dy}(y) = \dfrac{d}{dy}\left(\sum_{n=1}^{N}f_n(y)\right) = \sum_{n=1}^{N}\left(\dfrac{df_n}{dy}(y)\right) \qquad \forall y\in I
\end{equation*}

gracias a la linealidad de la derivada. Resulta que esto se mantiene al pasar al ``caso continuo'', tal y como veremos en el siguiente teorema.\\

Veremos una versión más débil del teorema visto en Análisis Matemático II, que cuenta con las consecuencias justas para demostrar el Teorema~\ref{teo:condicion_suficiente}.
\begin{teo}[Integral dependiente de un parámetro]
    Sea $G\subseteq \mathbb{R}^d$ un conjunto abierto, dada una aplicación $f:G\times [a,b]\rightarrow\mathbb{R}$ de clase $C^1(G\times [a,b])$, definimos una función $F:G\rightarrow\mathbb{R}$ dada por
\begin{equation*}
    F(\xi_1, \xi_2, \ldots, \xi_d) = \int_{a}^{b} f(\xi_1, \xi_2, \ldots, \xi_d, t)~dt
\end{equation*}
Entonces, $F\in C^1(G)$ y 
\begin{equation*}
    \dfrac{\partial F}{\partial \xi_i}(\xi_1, \xi_2, \ldots, \xi_d) = \int_{a}^{b} \dfrac{\partial f}{\partial \xi_i}(\xi_1, \xi_2, \ldots, \xi_d, t)~dt \qquad \forall i \in \{1,\ldots, d\}
\end{equation*}
\end{teo}

\noindent
Como consecuencia del teorema, la función $F$ anteriormente definida como
\begin{equation*}
    F(y) = \int_{a}^{b} f(x,y)~dx \qquad \forall y\in I
\end{equation*}
Si $I$ era un intervalo abierto y $f$ era de clase\footnote{Notemos que el teorema se anunció pensando que los parámetros de la función serían los primeros, pero ahora tenemos el parámetro al final, es una situación totalmente análoga.} $C^1([a,b]\times I)$, entonces $F\in C^1(I)$, y tenemos que 
\begin{equation*}
    F'(y) = \int_{a}^{b} \dfrac{\partial f}{\partial y}(x,y)~dx  \qquad \forall y\in I
\end{equation*}

\begin{ejemplo}
    Dada la función
    \begin{equation*}
        F(y) = \int_{0}^{1} e^x \sen(x+y^2)~dx \qquad \forall y\in I
    \end{equation*}
    Gracias al teorema de integrales dependientes de un parámetro, sabemos que la derivada de esta función es:
    \begin{equation*}
        F'(y) = \int_{0}^{1} 2ye^x \cos(x+y^2)~dx = 2y\int_{0}^{1} e^x \cos(x+y^2)~dx \qquad \forall y\in \mathbb{R}
    \end{equation*}
\end{ejemplo}

Una vez terminado el repaso de integrales dependientes de un parámetro, estamos ya preparados para proceder con la demostracion del Teorema~\ref{teo:condicion_suficiente}, el cual volvemos a enunciar:
\begin{teo}
    Si $\Omega\subseteq \mathbb{R}^2$ es abierto y tiene forma de estrella, sean $P,Q\in C^1(\Omega)$ funciones que cumplen la condición de exactitud, es decir, que:
    \begin{equation*}
        \dfrac{\partial P}{\partial y}(x,y) = \dfrac{\partial Q}{\partial x}(x,y) \qquad \forall (x,y)\in \mathbb{R}^2
    \end{equation*}
    Entonces, existe una función $U\in C^2(\Omega)$ tal que 
    \begin{equation*}
        \dfrac{\partial U}{\partial x}(x,y) = P(x,y) \qquad \dfrac{\partial U}{\partial y}(x,y) = Q(x,y) \qquad \forall (x,y)\in \mathbb{R}^2
    \end{equation*}
    \begin{proof}
        La demostración la haremos pensando que el punto $z_\ast$ de $\Omega$ que nos da la condición de que tenga forma de estrella sea $z_\ast = (0,0)$ y la demostración en el caso general se deja como ejercicio para el lector.

        En dicho caso, definimos una función $U:\Omega\rightarrow\mathbb{R}$ dada por
        \begin{equation*}
            U(x,y) = x\int_{0}^{1} P(\lm x,\lm y)~d\lm + y\int_{0}^{1} Q(\lm x,\lm y)~d\lm  \qquad \forall (x,y)\in \Omega
        \end{equation*}
        Notemos que $U$ está bien definida, ya que: 
        \begin{itemize}
            \item En primer lugar, como $\Omega$ tiene forma de estrella desde $z_\ast = (0,0)$, entonces el segmento que une cualquier punto $(x,y)$ con $z_\ast$ estará en $\Omega$, luego si $(x,y)\in \Omega$, entonces $(\lm x,\lm y)\in \Omega$ $\forall \lm\in [0,1]$.
            \item Ademś, $P$ y $Q$ son funciones continuas, luego integrables en cualquier conjunto compacto (como lo es $[0,1]$), luego podemos calcular dichas integrales.
        \end{itemize}
        Como las funciones resultantes de las composiciones siguientes
        \begin{gather*}
            (x,y,\lm) \longmapsto (x\lm, y\lm) \longmapsto P(x\lm, y\lm) \\
            (x,y,\lm) \longmapsto (x\lm, y\lm) \longmapsto Q(x\lm, y\lm) 
        \end{gather*}
        son de clase $C^1(\Omega\times [0,1])$, podemos aplicar dos veces el teorema de las integrales dependientes de un parámetro, obteniendo que $U\in C^1(\Omega)$ y que:
        \begin{align*}
            \dfrac{\partial U}{\partial x}(x,y) &= \int_{0}^{1} P(\lm x,\lm y)~d\lm  + x\int_{0}^{1} \lm \dfrac{\partial P}{\partial x}(\lm x,\lm y)~d\lm  + y\int_{0}^{1} \lm\dfrac{\partial Q}{\partial x}(\lm x,\lm y)~d\lm  \\
                                                &\AstIg \int_{0}^{1} P(\lm x,\lm y)~d\lm  + x\int_{0}^{1} \lm \dfrac{\partial P}{\partial x}(\lm x,\lm y)~d\lm  + y\int_{0}^{1} \lm\dfrac{\partial P}{\partial y}(\lm x,\lm y)~d\lm  
        \end{align*}
        Donde en $(\ast)$ hemos usado que $P$ y $Q$ cumplen la condición de exactitud. Podemos ahora escribirla como una diferencial exacta (compruébese), obteniendo que
        \begin{equation*}
            \dfrac{\partial U}{\partial x}(x,y) = \int_{0}^{1} P(\lm x,\lm y)~d\lm  + \int_{0}^{1} \lm\dfrac{d}{d\lm}[P(\lm x,\lm y)]~d\lm 
        \end{equation*}
        Que podemos volver a escribir como una diferencial exacta (vuélvase a comprobar), llegando a que
        \begin{equation*}
            \dfrac{\partial U}{\partial x}(x,y) = \int_{0}^{1} \dfrac{d}{d\lm}[\lm P(\lm x,\lm y)]~d\lm
        \end{equation*}
        donde podemos aplicar la Regla de Barrow:
        \begin{equation*}
        \dfrac{\partial U}{\partial x}(x,y) = \int_{0}^{1} \dfrac{d}{d\lm}[\lm P(\lm x,\lm y)]~d\lm = {\left[\lm P(\lm x,\lm y)\right]}_{\lm = 0}^{\lm = 1} = P(x,y)
        \end{equation*}
        Por un razonamiento análogo, llegamos a que:
        \begin{equation*}
            \dfrac{\partial U}{\partial y}(x,y) = Q(x,y)
        \end{equation*}
        Finalmente, como las dos derivadas parciales de $U$ son de clase $C^1(\Omega)$, concluimos que $U\in C^2(\Omega)$.
    \end{proof}
\end{teo}

\subsection{Interpretación de la demostración}
Pese a haber demostrado el Teorema~\ref{teo:condicion_suficiente}, la demostración no es gratificante, ya que hemos obtenido de forma ``mágica'' una función $U$ que cumplía lo que queríamos, y no sabemos de dónde proviene dicha fórmula. Trataremos en esta sección de dar sentido a esta, usando para ello la física.\\

\noindent
En física, un campo vectorial en el plano es una aplicación que a cada punto $z=(x,y)$ le hace corresponder un vector (una flecha), $F(z) = (F_1(x,y), F_2(x,y))$.\\

De esta forma, un campo vectorial para nosotros será una aplicación $F\in C^1(G, \mathbb{R}^2)$ con $G\subseteq \mathbb{R}^2$ un conjunto abierto.
Pensaremos en este campo vectorial como en un campo de fuerzas (es decir, el vector $F(z)$ nos indicará cómo es la fuerza que se sufre al estar en el punto $z$).

\begin{definicion}[Campo de fuerzas conservativo]
    Diremos que un campo de fuerzas $F$ es conservativo si existe un potencial, es decir, una función $U:G\rightarrow\mathbb{R}$ de clase $C^1$ tal que 
    \begin{equation*}
        \nabla U = F
    \end{equation*}

    Es decir:
    \begin{equation*}
        \dfrac{\partial U}{\partial x} = F_1 \qquad \dfrac{\partial U}{\partial y} = F_2
    \end{equation*}
\end{definicion}
\begin{observacion}
    El lector estará acostumbrado a ver en física el gradiente notado por $-\nabla V$ (con $V = -U$). Sin embargo, en esta sección trabajaremos con el gradiente refiriéndonos a $\nabla U$.
\end{observacion}

\begin{ejemplo}
    Dado el campo de fuerzas
    \begin{equation*}
        F(x_1,x_2) = \dfrac{1}{2}(x_1,x_2) \qquad \forall (x_1,x_2)\in \mathbb{R}^2
    \end{equation*}
    Que podemos pensar como una homotecia o como un campo vectorial:
    \begin{itemize}
        \item En el origen, tenemos el vector 0.
        \item Dado un punto $(x,y)$, tenemos que dibujar el vector fuerza (gradiente) como la mitad del vector de posición.
    \end{itemize}
    Notemos que se trata de un campo repulsor, de forma que el vector fuerza se mantiene constante en circunferencias de un determinado radio, con dirección perpendicular a los radios de la misma. Conforme nos alejamos del origen, la fuerza se incrementa.\\

    Resulta que $F$ es un campo de fuerzas conservativo, ya que podemos encontrar un potencial para dicho campo, es decir, una función $U\in C^1(\mathbb{R}^2)$ dada por
    \begin{equation*}
        U(x_1,x_2) = \dfrac{x_1^2 + x_2^2}{4} \qquad \forall (x_1,x_2)\in \mathbb{R}^2
    \end{equation*}

    de forma que
    \begin{equation*}
        \dfrac{\partial U}{\partial x}(x_1,x_2) = \dfrac{x_1}{2}= F_1(x_1,x_2) \qquad \dfrac{\partial U}{\partial y}(x_1,x_2) = \dfrac{x_2}{2} = F_2(x_1,x_2) \qquad \forall (x_1,x_2) \in \mathbb{R}^2
    \end{equation*}
\end{ejemplo}

\begin{ejemplo}
    Un ejemplo de campo no conservativo es
    \begin{equation*}
        F(x_1,x_2) = (-x_2, x_1)
    \end{equation*}
    Se trata de un giro de 90º en sentido antihorario, un campo de fuerzas que describe el comportamiento de un vórtice (como hace el agua cuando se cuela en un sumidero). Se trata de un campo no conservativo, ya que no podemos encontrar un potencial, debido a que no se cumple la condición de exactitud.
\end{ejemplo}

En un campo de fuerzas no hay necesariamente energía (ya que puede no ser conservativo), pero lo que siempre hay es trabajo.

\begin{definicion}[Trabajo]
    Dado un conjunto abierto $G\subseteq \mathbb{R}^2$, un campo de fuerzas en $G$ y un camino en $G$, es decir, una función $\gamma\in C^1([a,b], G)$, el trabajo de $F$ a lo largo de $\gamma$ se define como
    \begin{equation*}
        \int_{a}^{b} \langle F(\gamma(t)), \gamma'(t) \rangle~dt 
    \end{equation*}
\end{definicion}

A continuación, podemos reformular el Teorema~\ref{teo:condicion_suficiente} en términos físicos, obteniendo el siguiente teorema:

\begin{teo}
    Si $G\subseteq \mathbb{R}^2$ es abierto y tiene forma de estrella, sea $F\in C^1(G,\mathbb{R}^2)$ un campo de fuerzas para el cual se cumple la condición de exactitud:
    \begin{equation*}
        \dfrac{\partial F_1}{\partial x_2} = \dfrac{\partial F_2}{\partial x_1}
    \end{equation*}
    Entonces, $F$ es conservativo.
\end{teo}

Finalmente, notemos que si tenemos dos caminos distintos con los mismos extremos, el trabajo por cada uno de ellos no tiene por qué coincidir. Sin embargo, esto sucede si el campo es conservativo:
\begin{align*}
    \int_{a}^{b} \langle F(\gamma(t)), \gamma'(t) \rangle~dt  &= \int_{a}^{b} \left[F_1(\gamma(t))\gamma_1'(t) + F_2(\gamma(t))\gamma_2'(t)\right]~dt   \\
                                                              &= \int_{a}^{b} \left[\dfrac{\partial U}{\partial x_1}(\gamma(t))\gamma_1'(t) + \dfrac{\partial U}{\partial x_2}(\gamma(t))\gamma_2'(t)\right]~dt   \\
                                                              &= \int_{a}^{b} \dfrac{d}{dt}[U(\gamma(t))]~dt \AstIg U(\gamma(b)) - U(\gamma(a))
\end{align*}
Usando la regla de Barrow en $(\ast)$, concluimos que el trabajo para ir de un punto a otro por un camino $\gamma$ es la diferencia del potencial entre los dos puntos.\\

\noindent
Para entender ahora de dónde proviene la fórmula de la función $U$ del Teorema~\ref{teo:condicion_suficiente}:
\begin{equation*}
    U(x,y) = x\int_{0}^{1} P(\lm x,\lm y)~d\lm + y\int_{0}^{1} Q(\lm x,\lm y)~d\lm  \qquad (x,y)\in \Omega
\end{equation*}
Lo que hacemos es pensar que tenemos un campo de fuerzas $F:\Omega\rightarrow\mathbb{R}^2$ dado por
\begin{equation*}
    F(x,y) = (P(x,y),Q(x,y)) \qquad (x,y)\in \mathbb{R}^2
\end{equation*}
Y resulta que este campo de fuerzas es conservativo, y como el trabajo en un campo conservativo es independiente del camino elegido para calcular dicho trabajo, podemos elegir cualquier camino. Observamos ahora que la expresión de $U$ es simplemente el trabajo a lo largo del camino dado por el segmento $[(0,0),(x,y)]$ para cualquier $(x,y)\in \Omega$. Es decir, sea $(x,y)\in \Omega$, obtenemos el camino $\gamma:[0,1]\rightarrow\mathbb{R}^2$ dado por
\begin{equation*}
    \gamma(\lm) = (\lm x,\lm y) \qquad \lm \in [0,1]
\end{equation*}

resulta que $\gamma\in C^1([0,1])$, con
\begin{equation*}
    \gamma'(\lm) = (x,y) \qquad \forall \lm\in [0,1]
\end{equation*}
Y si ahora escribimos el trabajo de $F$ a lo largo de $\gamma$:
\begin{equation*}
    \int_{0}^{1} \langle F(\gamma(t)),\gamma'(t) \rangle~dt = \int_{0}^{1} [P(\lm x,\lm y)x+Q(\lm x,\lm y)y]~d\lm  = U(x,y)
\end{equation*}
Además, puede probarse que la función $U$ que nos da el Teorema~\ref{teo:condicion_suficiente} es única salvo una constante aditiva\footnote{De aquí que en los problemas de física podíamos poner el origen de potencial en el punto que queramos.}. Lo que hicimos en la definición de $U$ era fijar el origen de potencial en el origen, por lo que teníamos
\begin{equation*}
    U(0,0) = 0
\end{equation*}
Una vez que se conoce la existencia de dicho potencial (gracias al Teorema~\ref{teo:condicion_suficiente}), no es necesario aplicar la fórmula para calcularlo, sino que podemos hacerlo por un procedimiento más práctico, el cual ilustramos en el siguiente ejemplo.

\begin{ejemplo}
    Dadas las funciones
    \begin{align*}
        P(x,y) &= 7x^6+6x^5y+3x^2y^3  \\
        Q(x,y) &= x^6+3x^3y^2 -4y^3
    \end{align*}
    se pide calcular un potencial para el campo de fuerzas $F=(P,Q)$.\\

    Por una parte, sabemos que $P,Q\in C^1(\mathbb{R}^2)$ por tratarse de polinomios, con lo que nuestro dominio $\Omega$ en este caso será $\mathbb{R}^2$, que sabemos que es estrellado por ser convexo: sean $\alpha,\beta\in \mathbb{R}^2$, entonces:
    \begin{equation*}
        (1-t)\alpha + t\beta \in \mathbb{R}^2 \qquad \forall t\in [0,1]
    \end{equation*}
    Falta comprobar la condición de exactitud para poder aplicar el Teorema~\ref{teo:condicion_suficiente}, que nos provee de la existencia de un potencial para el campo $F$:
    \begin{align*}
        \dfrac{\partial P}{\partial y}(x,y) &= 6x^5+9x^2y^2 \\
        \dfrac{\partial P}{\partial x}(x,y) &= 6x^5+9x^2y^2
    \end{align*}
    Aplicando el Teorema, sabemos que existe un potencial $U\in C^2(\mathbb{R}^2)$, el cual pasamos a calcular de forma práctica:

    Estamos buscando una función $U$ de forma que:
    \begin{equation*}
        \dfrac{\partial U}{\partial x}(x,y) = P(x,y) = 7x^6+6x^5y+3x^2y^3
    \end{equation*}
    Por tanto, integraremos en $x$ pensando que la $y$ es fija:
    \begin{equation*}
        U(x,y) = \int (7x^6+6x^5y+3x^2y^3)~dx = x^7+x^6y+x^3y^3 + \phi(y)
    \end{equation*}
    Es decir, por cada $y\in \mathbb{R}$, tenemos una primitiva a buscar, la cual tendrá una constante aditiva $c\in \mathbb{R}$. Si ahora juntamos todas las primitivas encontradas para cada $y$, la constante aditiva de cada $y$ ahora será una función dependiente de $y$, ya que por cada valor de $y$ habíamos encontrado una constante. Dicha función es la $\phi$ que hemos usado anteriormente. 

    Para terminar de buscar dicha $\phi$ (para determinar correctamente $U$), lo que hacemos es establecer la otra condición que teníamos de $U$, en relación a la función $Q$, que se pone de manifiesto en $(\ast)$:
    \begin{equation*}
        \dfrac{\partial U}{\partial y}(x,y) = x^6+3x^3y^2 + \phi'(y) \AstIg x^6+3x^2y^2 -4y^3 = Q(x,y)
    \end{equation*}
    De donde $\phi'(y) = -4y^3$, por lo que $\phi(y) = -y^4$. Finalmente:
    \begin{equation*}
        U(x,y) = x^7+x^6y+x^3y^3 -y^4
    \end{equation*}
    Notemos que podíamos haber escogido $\phi(y)=-y^4 + c$ con cualquier $c\in \mathbb{R}$. Esto se debe a que como habíamos comentado antes, $U$ es única salvo constante aditiva, lo que nos permite fijar el origen del potencial en el punto que queramos.
\end{ejemplo}

Veamos ahora un ejemplo donde no se puede buscar $U$ porque el dominio que consideramos no tiene forma de estrella\footnote{Con la intuición de que tenemos que buscar un conjunto que no sea simplemente conexo, buscamos un conjunto con un agujero.}.
\begin{ejemplo}
    Tomaremos como dominio
    \begin{equation*}
        \Omega = \left\{(x,y)\in \mathbb{R}^2 \mid \dfrac{1}{4}<x^2+y^2 < 4\right\}
    \end{equation*}
    Es decir, el anillo formado por los puntos que están entre una circunferencia de radio $\sqrt{\nicefrac{1}{4}}=\nicefrac{1}{2}$ y radio $\sqrt{4}=2$, tal y como vemos en la Figura~\ref{fig:anillo_ejm}.

    \begin{figure}[H]
    \centering
    \begin{tikzpicture}
        % Colorear el área entre los círculos
        \fill[blue!20, even odd rule] (0,0) circle (2) (0,0) circle (0.5);

        % Dibujar los círculos
        \draw[thick] (0,0) circle (2);      % Círculo externo de radio 2
        \draw[thick] (0,0) circle (0.5);    % Círculo interno de radio 1/2

        % Dibujar los ejes coordenados
        \draw[-Stealth] (-2.5,0) -- (2.5,0) node[right] {$x$};
        \draw[-Stealth] (0,-2.5) -- (0,2.5) node[above] {$y$};
    \end{tikzpicture}
    \caption{Dominio $\Omega$.}
    \label{fig:anillo_ejm}
    \end{figure}
    Sean:
    \begin{equation*}
        P(x,y) = \dfrac{y}{x^2+y^2} \qquad Q(x,y) = \dfrac{-x}{x^2+y^2}
    \end{equation*}
    Estas funciones no pueden definirse en $\mathbb{R}^2$ (por tener una singularidad en el origen), pero sí en $\Omega$, donde son $C^1(\Omega)$, con:
    \begin{align*}
        \dfrac{\partial P}{\partial y}(x,y) &= \dfrac{x^2+y^2 - y(2y)}{{(x^2+y^2)}^{2}} = \dfrac{x^2-y^2}{{(x^2+y^2)}^{2}} \\
        \dfrac{\partial Q}{\partial x}(x,y) &= \dfrac{-x^2-y^2+2x^2}{{(x^2+y^2)}^{2}} = \dfrac{x^2-y^2}{{(x^2+y^2)}^{2}}
    \end{align*}
    con lo que tenemos la condición de exactitud en un ejemplo en el que $\Omega$ no es estrellado. Para ver que no existe el potencial, lo razonaremos por el trabajo, buscando un camino cerrado en el que el trabajo no sea nulo, ya que si existiera un potencial $U$, entonces tendríamos que
    \begin{align*}
        \int_{a}^{b} \langle F(\gamma(t)),\gamma'(t) \rangle~dt  &= \int_{a}^{b} \langle \nabla U(\gamma(t)), \gamma'(t) \rangle~dt   \\
                                                                 &= \int_{a}^{b} \dfrac{d}{dt}U(\gamma(t))~dt  = U(\gamma(b)) - U(\gamma(a))
    \end{align*}
    Y si cogemos un camino cerrado, entonces $\gamma(a)=\gamma(b)$, con lo que obtendríamos trabajo nulo.

    Cogeremos entonces el camino que recorre la circunferencia de radio 1 (a poco que se piense, para que el camino sea bueno tiene que pasar al otro lado del agujero del anillo\footnote{Ya que si no podríamos coger un dominio menor que contenga al camino y sí sea estrellado o simplemente conexo, con lo que sí existiría un potencial.}). Cogemos por tanto el camino $\gamma:[0,2\pi]\rightarrow\mathbb{R}^2$ dado por
    \begin{equation*}
        \gamma(\theta) = (\cos\theta, \sen\theta) \qquad \theta \in [0,2\pi]
    \end{equation*}

    que es de clase $C^1([0,2\pi], \mathbb{R}^2)$, con
    \begin{equation*}
        \gamma'(\theta) = (-\sen\theta,\cos\theta) \qquad \forall \theta \in [0,2\pi]
    \end{equation*}
    Vemos representado el camino escogido en la Figura~\ref{fig:camino_ejm}.

    \begin{figure}[H]
        \centering
        \begin{tikzpicture}
            % Colorear el área entre los círculos
            \fill[blue!20, even odd rule] (0,0) circle (2) (0,0) circle (0.5);

            % Dibujar los círculos
            \draw[thick] (0,0) circle (2);          % Círculo externo de radio 2
            \draw[thick] (0,0) circle (0.5);        % Círculo interno de radio 1/2
            \draw[dashed, thick] (0,0) circle (1);  % Círculo discontinuo de radio 1

            % Dibujar la flecha en el punto (1,0)
            \draw[-Stealth, thick] (1,0) -- (1,0);

            % Dibujar los ejes coordenados
            \draw[-Stealth] (-2.5,0) -- (2.5,0) node[right] {$x$};
            \draw[-Stealth] (0,-2.5) -- (0,2.5) node[above] {$y$};
        \end{tikzpicture}
        \caption{Camino $\gamma$.}
        \label{fig:camino_ejm}
    \end{figure}

    Con lo que el trabajo del campo $F=(P,Q)$ será:
    \begin{multline*}
        \int_{0}^{2\pi } \langle F(\gamma(\theta)),\gamma'(\theta) \rangle~d\theta = \int_{0}^{2\pi} [-P(\cos\theta,\sen\theta)\sen\theta + Q(\cos\theta,\sen\theta)\cos\theta]~d\theta  = \\
        = \int_{0}^{2\pi } [-\sen^2\theta-\cos^2\theta]~d\theta  = -2\pi \neq 0
    \end{multline*}
\end{ejemplo}
Tenemos ya un ejemplo en el que no se cumple la condición de exactitud y no podemos encontrar potencial y otro ejemplo en el que el dominio no es estrellado y tampoco podemos encontrar un potencial, con lo que parece que las condiciones de exactitud y dominio estrellado son ambas necesarias como hipótesis del Teorema~\ref{teo:condicion_suficiente}.\\

Antes de pasar a la siguiente sección y con el objetivo de asentar todos los conceptos desarrollados en esta, realizaremos el siguiente ejercicio, el cual asentará conceptos importantes viéndolos de forma práctica.

\begin{ejercicio*}
    Sea $F:\mathbb{R}\times\mathbb{R}^+\rightarrow\mathbb{R}^2$ un campo de fuerzas dado por:
    \begin{equation*}
        F(x,y) = \left(\dfrac{2x}{y}, \dfrac{-x^2}{y^2}\right) \qquad (x,y)\in \mathbb{R}\times\mathbb{R}^+
    \end{equation*}
    ¿Admite $F$ potencial? Calcular el trabajo a lo largo de la curva $\gamma:[0,\pi]\rightarrow\mathbb{R}$ dada por:
    \begin{equation*}
        \gamma(\theta) = (\cos\theta, 1+\sen\theta) \qquad \theta\in [0,\pi]
    \end{equation*}~\\

    En primer lugar, definimos por comodidad $\Omega=\mathbb{R}\times\mathbb{R}^+$, así como nuestras funciones $P,Q:\Omega\rightarrow\mathbb{R}$ dadas por:
    \begin{equation*}
        P(x,y) = \dfrac{2x}{y} \qquad Q(x,y) = \dfrac{-x^2}{y^2} \qquad (x,y)\in \Omega
    \end{equation*}
    de clase $C^1(\Omega)$, siendo $F=(P,Q)$. Y lo primero para ver si $F$ admite un potencial será comprobar si $P$ y $Q$ cumplen con la condición de exactitud:
    \begin{equation*}
        \dfrac{\partial P}{\partial y}(x,y) = \dfrac{-2x}{y^2} = \dfrac{\partial Q}{\partial x}(x,y) \qquad \forall (x,y)\in \Omega
    \end{equation*}
    Efectivamente, por lo que solo faltará ver que $\Omega$ es estrellado para estar en las hipótesis del Teorema~\ref{teo:condicion_suficiente}, que nos asegura de la existencia de un potencial para $F$.\\

    Para ello, demostremos que $\Omega$ es convexo: sean $(x,y),(u,v)\in \Omega$, entonces ${x,u\in \mathbb{R}}$ y $y,v\in \mathbb{R}^+$. Sea ahora $(\alpha,\beta)\in [(x,y),(u,v)]$, entonces:
    \begin{equation*}
        (\alpha,\beta) = t(x,y) + (1-t)(u,v) \qquad t\in [0,1]
    \end{equation*}

    y tendremos que:
    \begin{align*}
        \left.\begin{array}{rl}
            \alpha &= tx + (1-t)u \in \mathbb{R} \\
            \beta &= ty + (1-t)v \in \mathbb{R}^+
        \end{array}\right\} \Longrightarrow (\alpha,\beta)\in \Omega
    \end{align*}

    por ser $t\leq 1$, $y,v\in \mathbb{R}^+$. Concluimos que $\Omega$ es convexo, luego tiene forma de estrella. Por tanto, sí, $F$ admite un potencial $U\in C^2(\Omega)$.\\

    Con vistas a calcular el trabajo a lo largo de la curva $\gamma$, calcularemos primero los puntos inicial y final de dicho recorrido:
    \begin{equation*}
        \gamma(0) = (1,1) \qquad \gamma(\pi) = (-1,1)
    \end{equation*}
    En este caso son puntos distintos, pero si hubiera dado la casualidad de ser iguales, como nos encontramos en un campo de fuerzas $F$ conservativo (por admitir un potencial), podríamos directamente concluir que el trabajo a lo largo de la curva es 0. Como esto no ha sucedido, tenemos ahora dos posibilidades:
    \begin{itemize}
        \item Calcular el trabajo directamente a partir de su definición.
        \item Calcular cuál es el potencial $U$ y aplicar que el trabajo en un campo conservativo es la diferencia de los potenciales final e inicial.
    \end{itemize}
    Nos decantamos por la segunda opción, por tener cálculos más sencillos.\\

    Una vez conocida la existencia de un potencial $U$, pasamos a calcularlo, sabiendo que es una función $U:\Omega\rightarrow\mathbb{R}$, $U\in C^2(\Omega)$ de forma que:
    \begin{equation*}
        \dfrac{\partial U}{\partial x}(x,y) = P(x,y) \qquad \dfrac{\partial U}{\partial y}(x,y) = Q(x,y) \qquad \forall (x,y)\in \Omega
    \end{equation*}
    De la primera igualdad, tenemos que:
    \begin{equation*}
        \dfrac{\partial U}{\partial x}(x,y) = P(x,y) = \dfrac{2x}{y}
    \end{equation*}
    
    con lo que para hallar $U$, fijamos un $y\in \mathbb{R}^+$ y calculamos una primitiva de la función real de variable real (por fijar el $y$) $P(x,y)$:
    \begin{equation*}
        U(x,y) = \int P(x,y)~dx  = \int \dfrac{2x}{y}~dx  = \dfrac{x^2}{y} + \phi(y)
    \end{equation*}

    donde para cada $y\in \mathbb{R}^+$, $\phi(y)$ es la constante de integración que obtenemos en cada caso. Si aplicamos ahora la segunda igualdad, tenemos que:
    \begin{equation*}
        \dfrac{\partial U}{\partial y}(x,y) = \dfrac{-x^2}{y^2} + \phi'(y) = \dfrac{-x^2}{y^2} = Q(x,y)
    \end{equation*}

    por lo que concluimos que $\phi'(y) = 0$ $\forall y\in \mathbb{R}^+$, con lo que como función $\phi$ podemos coger cualquier función de la forma $\phi(y) = c$ con $c\in \mathbb{R}$. Elegiremos por comodidad $c=0$, con lo que tenemos $\phi(y) = 0$ $\forall y\in \mathbb{R}^+$.\\

    Llegamos finalmente a que:
    \begin{equation*}
        U(x,y) = \dfrac{x^2}{y} + \phi(y) = \dfrac{x^2}{y} \qquad \forall (x,y)\in \Omega
    \end{equation*}
    Y ya sí que podemos calcular el trabajo a lo largo de la curva $\gamma$:
    \begin{equation*}
        U(\gamma(\pi)) - U(\gamma(0)) = U(-1,1) - U(1,1) = 0
    \end{equation*}
\end{ejercicio*}
Además de tener interés práctico el ejercicio superior, hemos visto que el recíproco de ``si tenemos un camino cerrado en un campo conservativo, entonces el trabajo a lo largo de dicho camino es 0'' es falso, porque hemos visto un ejemplo de trabajo nulo en un campo conservativo a lo largo de un camino que no es cerrado.

\section{Ecuaciones exactas}
Las ecuaciones exactas son ecuaciones diferenciales de la forma
\begin{equation}\label{eq:exacta}
    P(x,y)+Q(x,y)y' = 0
\end{equation}

Con $P,Q\in C^1(\Omega)$ definidas en $\Omega\subseteq \mathbb{R}^2$, un conjunto abierto y conexo en el que se cumple la \textbf{condición de exactitud}:
\begin{equation*}
    \dfrac{\partial P}{\partial y}(x,y) = \dfrac{\partial Q}{\partial x}(x,y) \qquad \forall (x,y)\in \Omega
\end{equation*}
Las ecuaciones exactas no son una familia de ecuaciones que sea fácil de detectar. Lo recomendable es, dada una ecuación diferencial, observar si se trata de algún tipo de ecuaciones de las descritas en el Capítulo 2. En caso contrario, posiblemente estemos ante una ecuación exacta (o que se pueda convertir fácilmente a exacta, como veremos en la siguiente sección).\\

Sin embargo, una vez detectado que una ecuación es exacta, resolverla es un proceso muy sencillo, por lo que podemos decir que lo más difícil de las ecuaciones exactas es darnos cuenta de que son exactas. La Proposición~\ref{prop:resolver_exactas} nos mostrará cómo podemos resolver una ecuación diferencial exacta.

\begin{prop}[Resolución de ecuaciones exactas]\label{prop:resolver_exactas}
    Dada una ecuación exacta, es decir, una ecuación de la forma~(\ref{eq:exacta}) definida en un conjunto abierto y conexo $\Omega\subseteq \mathbb{R}^2$ con $P,Q\in C^1(\Omega)$ de forma que se cumpla la condición de exactitud:\\

    Si fijamos un punto $(x_0,y_0)\in \Omega$ en el que $Q(x_0,y_0)\neq 0$, entonces existirá una solución $y:I\rightarrow\mathbb{R}$ para dicha ecuación diferencial definida en un intervalo abierto $I\subseteq \mathbb{R}$ en la que $y(x_0)=y_0$.
    \begin{proof}
        La primera dificultad de la demostración es que no hemos exigido nada sobre $\Omega$ (no hemos exigido que tenga forma de estrella), con lo que la condición de exactitud no es suficiente para asegurarnos la existencia de un potencial en $\Omega$.\\

        Sin embargo, dado que $\Omega$ es abierto, sí que podremos tomar un conjunto estrellado en cada punto $(x,y)$ de $\Omega$ que esté contenido en el mismo conjunto. Tenida en cuenta esta dificultad, pasamos ya con la demostración:\\

        Por ser $\Omega$ abierto, $\exists \veps > 0$ de forma que podemos tomar un cuadrado\footnote{Podríamos tomar también una bola centrada en $(x_0,y_0)$, o incluso cualquier conjunto estrellado que no se salga de $\Omega$ y contenga al punto $(x_0,y_0)$, con lo que la demostración sería análoga.} que contenga a $(x_0,y_0)$ y no se salga de $\Omega$:
        \begin{equation*}
            (x_0,y_0) \in [x_0-\veps, x_0+\veps] \times [y_0-\veps,y_0+\veps] \subseteq \Omega
        \end{equation*}
        Llamamos a dicho cuadrado $R = [x_0-\veps, x_0+\veps] \times [y_0-\veps,y_0+\veps]$.

        Por ser $R$ un cuadrado, es fácil ver que es convexo (hágase), luego tiene forma de estrella, por lo que sabemos que existe un potencial: $\exists U\in C^2(R)$ de forma que:
        \begin{equation*}
            \dfrac{\partial U}{\partial x}(x,y) = P(x,y) \qquad \dfrac{\partial U}{\partial y}(x,y) = Q(x,y) \qquad \forall (x,y)\in R
        \end{equation*}
        Usando estas igualdades, podemos ahora reescribir la ecuación~(\ref{eq:exacta}), obteniendo que esta se puede reescribir como la derivada exacta de una función:
        \begin{equation*}
            P(x,y)+Q(x,y)y' = \dfrac{\partial U}{\partial x}(x,y) + \dfrac{\partial U}{\partial y}(x,y)y' \AstIg \dfrac{d}{dx}[U(x,y)] = 0
        \end{equation*}
        Donde en $(\ast)$ hacemos un abuso de notación\footnote{¡No tiene sentido considerar la derivada de una función de dos variables!}, entendiendo que $y$ es una función que depende de $x$ y lo que hacemos es derivar la función resultado de la composición:
        \begin{equation*}
            x \longmapsto (x,y(x)) \longmapsto U(x,y(x))
        \end{equation*}
        Que es una función de una variable. Por ser esta composición una función de clase $C^1(\pi_1(R))$ (donde aplicamos que la composición de funciones de clase $C^1$ es de clase $C^1$), y ser su derivada constantemente igual a 0, existirá por tanto una constante $c\in \mathbb{R}$ de forma que:
        \begin{equation*}
            U(x,y) = c \qquad \forall (x,y)\in R
        \end{equation*}
        Sin embargo, como no estamos interesados en encontrar todas las soluciones en $R$, sino solo aquella que contenga al punto $(x_0,y_0)$, podemos tomar $c=U(x_0,y_0)$, con lo que el potencial será una función definida en $R$ y:
        \begin{equation*}
            U(x,y) = U(x_0,y_0) \qquad \forall (x,y)\in R
        \end{equation*}
        Para concluir, lo que hacemos es buscar una función $y$ definida en un intervalo abierto $I$ de $\mathbb{R}$ de forma que:
        \begin{enumerate}
            \item $x_0\in I$.
            \item $y(x_0)=y_0$.
            \item $(x,y(x))\in R$ $\forall x\in I$.
            \item $U(x,y(x))=U(x_0,y_0)$ $\forall x\in I$.
        \end{enumerate}
        Es evidente que lo que tenemos que hacer ahora es busar aplicar el Teorema de la Función Implícita. Para ello, sea $F:R\rightarrow\mathbb{R}$ una función dada por
        \begin{equation*}
            F(x,y) = U(x,y) - U(x_0,y_0) \qquad (x,y)\in R
        \end{equation*}
        se trata de una función $F\in C^1(R,\mathbb{R})$, que cumple que $F(x_0,y_0)=0$ y que:
        \begin{equation*}
            \dfrac{\partial F}{\partial y}(x_0,y_0) = \dfrac{\partial U}{\partial y}(x_0,y_0) = Q(x_0,y_0) \neq 0
        \end{equation*}
        Por lo que podemos aplicar el Teorema de la Función Implícita, con lo que existe una función $y:I\rightarrow\mathbb{R}$ definida en un intervalo abierto $I\subseteq \mathbb{R}$, $y\in C^1(I)$ que verifica todos los puntos de la enumeración anterior, con lo que la función $y$ es solución de la ecuación diferencial~(\ref{eq:exacta}).
    \end{proof}
\end{prop}~\\

\noindent
Notemos que la intuición tras la condición $Q(x,y)\neq 0$ sobre la ecuación~(\ref{eq:exacta}) significa que podemos despejar $y'$ de forma que podamos expresar dicha ecuación en forma normal:
\begin{equation*}
    y' = \dfrac{-P(x,y)}{Q(x,y)}
\end{equation*}
Como hemos comentado anteriormente, no será difícil resolver ecuaciones diferenciales exactas. De hecho, como mostramos en la demostración, el procedimiento para resolverlas será:
\begin{enumerate}
    \item Darnos cuenta de que estamos ante una ecuación diferencial exacta (tendremos que comprobar principalmente que cumple la condición de exactitud).
    \item Calcular la función potencial de dicha ecuación diferencial de forma práctica (algo que ya aprendimos a hacer en un ejemplo), que consiste en calcular la una primitiva y ajustar el valor de una función $\phi$.
    \item Finalmente, aplicar el Teorema de la Función Implícita sobre un punto que nos interese tener en el dominio de la solución a escoger (la condición inicial que nos habrán exigido sobre la solución a encontrar).
\end{enumerate}
Este procedimiento lo mostramos en el siguiente ejemplo, en el que resolvemos una ecuación diferencial exacta.

% // TODO: Seguir por aquí

\begin{ejemplo}
    Se pide resolver la ecuación
    \begin{equation}\label{eq:exacta_ejm}
        y^2 + 2x+(5y^4 + 2xy)y' = 0 \qquad y(0) = 3
    \end{equation}
    Dado que estamos en la sección de Ecuaciones Exactas, probablemente sea una ecuación exacta, comprobémoslo:

    Sean $P,Q:\mathbb{R}^2\rightarrow\mathbb{R}$ dadas por
    \begin{equation*}
        P(x,y) = y^2 + 2x \qquad Q(x,y) = 5y^4 + 2xy \qquad (x,y)\in \mathbb{R}^2
    \end{equation*}

    tenemos que $P,Q\in C^1(\mathbb{R}^2)$, veamos si cumplen la condición de exactitud:
    \begin{equation*}
        \dfrac{\partial P}{\partial y}(x,y) = 2y = \dfrac{\partial Q}{\partial x}(x,y) \qquad \forall (x,y)\in \mathbb{R}^2
    \end{equation*}
    Por tanto, la ecuación~(\ref{eq:exacta_ejm}) es una ecuación exacta, definida en $\Omega=\mathbb{R}^2$. Como nos interesará que el punto $(0,3)$ esté en la solución particular a encontrar, comprobemos el valor de $Q(0,3)$:
    \begin{equation*}
        Q(0,3) = 5\cdot 3^4 = 405 \neq 0
    \end{equation*}
    De esta forma, nos encontramos en las hipótesis de la Proposición~\ref{prop:resolver_exactas}, con lo que ya sabemos la existencia de una función $y:I\rightarrow\mathbb{R}$ con $I\subseteq \mathbb{R}$ un intervalo abierto que es solución de~(\ref{eq:exacta_ejm}) con $y(0)=3$. Sin embargo, dado que no conocemos nada sobre dicha función $y$, nos disponemos a calcular el potencial $U$, para al menos conocer $y$ de forma implícita mediante una ecuación.

    Calculamos dicho potencial de forma práctica, tal y como hicimos en un ejemplo anterior. Primero, recordemos que buscamos una función $U:R\rightarrow\mathbb{R}$ de forma que:
    \begin{equation*}
        \dfrac{\partial U}{\partial x}(x,y) = P(x,y) =  y^2 + 2x \qquad \forall (x,y)\in R
    \end{equation*}
    Con lo que integramos en $x$, pensando que $y$ es una constante fija:
    \begin{equation*}
        U(x,y) = \int (y^2 + 2x)~dx  = y^2 x + x^2 + \varphi(y)
    \end{equation*}
    Donde en cada $y$ obtenemos una constante de integración $\varphi(y)$ que puede ser distinta en cada caso. Si ahora calculamos la derivada parcial de esta expresión respecto a $y$, imponiendo que dicha parcial debe coincidir con la función $Q$:
    \begin{equation*}
        \dfrac{\partial U}{\partial y}(x,y) = 2xy + \varphi'(y) = 5y^4 + 2xy = Q(x,y) \qquad \forall (x,y)\in R
    \end{equation*}

    llegamos a que $\varphi'(y) = 5y^4$ y podemos tomar, por ejemplo, $\varphi(y)=y^5$.

    Tenemos finalmente que:
    \begin{equation*}
        U(x,y) = y^2x+x^2+\varphi(y)= y^2x+x^2+y^5 \qquad \forall (x,y)\in \mathbb{R}^2
    \end{equation*}
    Y sabemos (gracias a la Proposición~\ref{prop:resolver_exactas}) que la ecuación~(\ref{eq:exacta_ejm}) podemos ponerla como la dericada de una función de una variable igualada a 0. Por tanto, sabemos que las soluciones pueden escribirse como:
    \begin{equation*}
        U(x,y) = c  \qquad c\in \mathbb{R}
    \end{equation*}
    Sin embargo, como no queremos todas las soluciones $y=y(x)$ de~(\ref{eq:exacta_ejm}), nos quedamos con aquella que cumple $3=y(0)$, con lo que:
    \begin{equation*}
        U(x,y) = U(x_0,y_0) = U(0,3) = 3^2\cdot 0 + 0^2 + 3^5 = 3^5 = 243
    \end{equation*}
    Y como anteriormente comprobamos que $Q(0,3) = 405 \neq 0$, no hace falta aplicar el Teorema de la Función Implícita, ya que la Proposición~\ref{prop:resolver_exactas} ya nos garantiza la existencia de dicha función $y$, de la que conocemos que:
    \begin{align*}
            y^2x + x^2 + y^5 &= 243 \\
            y(0) &= 3
    \end{align*}
    Que sospechamos que no puede ponerse en forma explícita, ya que requiere averiguar las raíces de un polinomio de grado 5.
\end{ejemplo}
Como acabamos de ver en el ejemplo superior, lo más difícil es darnos cuenta de que la ecuación diferencial que nos solicitan sea o no exacta, ya que el procedimiento que realizamos posteriormente para resolverla es muy mecánico y similar en todos los casos. Sin embargo, no hay que olvidar que la sencillez de resolución de este tipo de soluciones es gracias a la teoría que venimos desarrollando durante todo este Capítulo.\\

Cabe destacar que la idea para resolver ecuaciones exactas es totalmente distinta a la idea que teníamos en el Capítulo anterior para resolver ecuaciones diferenciales, usando para ello cambios de variable. En este caso, ha sido necesario anteriormente probar un resultado muy útil en Análisis y en muchos otros campos que se salen de la Matemática (como la Física), que es la existencia de un potencial para un campo de fuerzas dado bajo unas condiciones.

Sin embargo, desde el punto de vista de las ecuaciones diferenciales se trata (por ahora) de un resultado muy pobre, ya que para que una ecuación diferencial sea exacta ha de cumplir la condición de exactitud, una condición muy rígida y que cumplen poquísimas ecuaciones diferenciales.\\

A pesar de ello, resulta que dada cualquier ecuación diferencial, es posible siempre encontrar una función que al multiplicarla por nuestra ecuación diferencial la convierta en una ecuación exacta, la cual ya sabemos (y es sencillo hacerlo) resolver. Dicha función que usamos para convertir una ecuación en exacta se trata del \textbf{factor integrante}, y es lo que nos mantendrá ocupados durante la siguiente sección.

\section{Factor integrante}
Como hemos comentado anteriormente (y motivamos al inicio del Capítulo), un factor integrantes es una función ``misteriosa'' que tiene la cualidad de convertir cualquier\footnote{Este resultado no es objetivo de Ecuaciones Diferenciales I, aunque merece ya ser conocido.} ecuación diferencial que tratemos resolver en una ecuación exacta, las cuales sabemos resolver.\\

El nombre de ``factor integrante'' proviene de la notación clásica, donde era frecuente decir ``integrar una ecuación diferencial'' para indicar que esta se estaba resolviendo, con lo que la función que usamos para resolverla es el ``factor'' que nos permite integrarla.\\

Veamos primero un ejemplo que motive el uso y la definición del mismo:
\begin{ejemplo}
    Dada la ecuación:
    \begin{equation}\label{eq:factori_ejm}
        y' + y = 0
    \end{equation}
    Sabemos desde el inicio de este documento que sus soluciones son funciones de la familia
    \begin{equation*}
        y(x) = ke^{-x} \qquad k\in \mathbb{R}, \quad x\in \mathbb{R}
    \end{equation*}
    Y resulta que~(\ref{eq:factori_ejm}) no es una ecuación exacta, ya que sean $P,Q:\mathbb{R}^2\rightarrow\mathbb{R}$ dadas por:
    \begin{equation*}
        P(x,y) = y \qquad Q(x,y) = 1 \qquad \forall (x,y)\in \mathbb{R}^2
    \end{equation*}

    tenemos que $P,Q\in C^1(\mathbb{R}^2)$, con:
    \begin{equation*}
        \dfrac{\partial P}{\partial y}(x,y) = 1 \neq 0 = \dfrac{\partial Q}{\partial x}(x,y) \qquad \forall (x,y)\in \mathbb{R}^2
    \end{equation*}
    Con lo que~(\ref{eq:factori_ejm}) no cumple la condición de exactitud, por lo que no es una ecuación exacta.\\
    Sin embargo, podemos encontrar distintas funciones que al multiplicarlas por~(\ref{eq:factori_ejm}) nos conviertan dicha ecuación en una ecuación exacta:
    \begin{enumerate}
        \item En primer lugar, sea $\mu_1:\mathbb{R}\rightarrow\mathbb{R}$ dada por $\mu_1(x)=e^x$, veamos que nos transforma la ecuación~(\ref{eq:factori_ejm}) en una ecuación exacta al multiplicar por $\mu_1$:
            \begin{equation*}
                \mu_1(x)(y+y') = e^x(y+y') = e^{x}y + e^{x}y' = 0
            \end{equation*}

            en efecto, ahora la ecuación es exacta (compruébese), teniendo que:
            \begin{equation*}
                e^{x}y + e^{x}y' = \dfrac{d}{dx}(e^x y) = 0
            \end{equation*}
            donde pensamos en $y$ como función de $x$, con lo que soluciones suyas son funciones $y=y(x)$ dadas de forma implícita por:
            \begin{equation*}
                e^x y = c \qquad c\in \mathbb{R}
            \end{equation*}

            con lo que fijando $c\in \mathbb{R}$ obtenemos una solución:
            \begin{equation*}
                y(x) = c\cdot e^{-x} \qquad x\in \mathbb{R}
            \end{equation*}
            Que tiene la forma que ya conocíamos. De esta forma, vemos que $\mu_1$ es un factor integrante para~(\ref{eq:factori_ejm}).
        \item De otra forma, sea $\mu_2:\mathbb{R}^+\rightarrow\mathbb{R}$ dada por $\mu_2(y) = \nicefrac{1}{y}$, al multiplicar $\mu_2$ por~(\ref{eq:factori_ejm}):
            \begin{equation*}
                \mu_2(y)(y+y') = \dfrac{y+y'}{y} = 1 + \dfrac{y'}{y} = 0 \qquad y>0
            \end{equation*}
            que vuelve a ser una ecuación exacta (compruébese), teniendo que:
            \begin{equation*}
                1 + \dfrac{y'}{y} = \dfrac{d}{dx}(x+\ln y) = 0 \qquad y>0
            \end{equation*}
            De esta forma y análogamente, soluciones de~(\ref{eq:factori_ejm}) son funciones $y=y(x)$ dadas de forma implícita por la familia de ecuaciones:
            \begin{equation*}
                x + \ln y = d \qquad d\in \mathbb{R}
            \end{equation*}
        \item Notemos que tomando $\mu_3:\mathbb{R}^-\rightarrow\mathbb{R}$ dada por $\mu_3(y) = \nicefrac{1}{y}$ obtenemos el resto de soluciones que nos faltaron en el punto anterior, salvo la solución $y(x) = 0$ $\forall x\in \mathbb{R}$.
    \end{enumerate}
\end{ejemplo}

Como hemos visto anteriormente, un ``factor integrante'' (todavía no sabemos lo que es) es una función que en algunos casos puede venir dado en función de $x$, otras veces en función de $y$, \ldots, y que puede estar definida en unos dominios muy grandes (como $\mu_1$) o en otros más restringidos que nos dan parte de las soluciones (como $\mu_2$ y $\mu_3$).\\

Cabe destacar que si los factores integrantes cuentan con singularidades o puntos en los que se anulan, en dichos puntos estaremos perdiendo información sobre la ecuación, con lo que nos interesarán factores integrantes con un mayor dominio de definición.

\begin{definicion}[Factor integrante]
    Dada una ecuación diferencial definida en un conjunto $D$. Sea $\Omega\subseteq D$, un factor integrante para dicha ecuación es una función $\mu:\Omega\rightarrow\mathbb{R}$ de clase $C^1(\Omega)$ de forma que:
    \begin{enumerate}[label=\arabic*)]
        \item Se verifique que
            \begin{equation}\label{eq:condicion_fi}
                \dfrac{\partial (\mu P)}{\partial y}(x,y) = \dfrac{\partial (\mu Q)}{\partial x}(x,y) \qquad \forall (x,y)\in \Omega
            \end{equation}
            Es decir, que si tenemos una ecuación de la forma~(\ref{eq:exacta}) y la multiplicamos por $\mu(x,y)$, entonces obtenemos una ecuación exacta.
        \item$\mu(x,y)\neq 0$ $\forall (x,y)\in \Omega$, para no perder información.
    \end{enumerate}
\end{definicion}

\noindent
De esta forma, dada una ecuación diferencial, un factor integrante para la misma será cualquier función definida en un subconjunto del conjunto de definición de la ecuación que no se anule y que al multiplicarla por nuestra ecuación obtengamos una ecuación exacta.\\

Como el factor integrante no se anula en ningún punto, las soluciones de la ecuación diferencial exacta que obtenemos al multiplicar por el factor integrante son las mismas que las soluciones para la ecuación diferencial que teníamos de partida, restringida a $\Omega$.

\begin{ejemplo}
    Como hemos visto en el ejemplo superior, ejemplos de factores integrantes distintos para la ecuación 
    \begin{equation*}
        y + y' = 0
    \end{equation*}

    definida en $D=\mathbb{R}^2$ son:
    \begin{enumerate}
        \item Tomando $\Omega=\mathbb{R}^2$:
            \begin{equation*}
                \mu_1(x,y) = e^x
            \end{equation*}
        \item Tomando $\Omega=\mathbb{R}\times\mathbb{R}^+$ o $\Omega=\mathbb{R}\times \mathbb{R}^-$:
            \begin{equation*}
                \mu_2(x,y) = \dfrac{1}{y} \qquad \mu_3(x,y) = \dfrac{1}{y}
            \end{equation*}
    \end{enumerate}
\end{ejemplo}

\begin{observacion}
    Notemos que si tenemos una ecuación diferencial que ya es exacta, cualquier función constantemente igual a un número real (salvo 0) será un factor integrante para la misma:
    \begin{equation*}
        \mu_c(x,y) = c \qquad c\neq 0, \quad (x,y)\in \Omega
    \end{equation*}
\end{observacion}

\subsection{Métodos de búsqueda de un factor integrante}
Dada una ecuación diferencial, nos ponemos a buscar un factor integrante que sirva para la misma. Lo que haremos será partir de lo único que conocemos de los factores integrantes, que es su definición, con lo que buscamos una función que no se anule y que cumpla la ecuación~(\ref{eq:condicion_fi}) en un subconjunto del conjunto de definición de la ecuación diferencial que tenemos.\\

La idea para buscar dicho factor integrante será ver la ecuación~(\ref{eq:condicion_fi}) como una ecuación en derivadas parciales con incógnita $\mu$. Esta podemos reescribirla usando la fórmula de la derivación de un producto:
\begin{align*}
    \dfrac{\partial (\mu P)}{\partial y}(x,y) &= \dfrac{\partial (\mu Q)}{\partial x}(x,y) \\
    \dfrac{\partial \mu}{\partial y}(x,y)P(x,y) + \mu(x,y)\dfrac{\partial P}{\partial y}(x,y) &= \dfrac{\partial \mu}{\partial x}(x,y)Q(x,y) + \mu(x,y) \dfrac{\partial Q}{\partial x}(x,y) \\
    \dfrac{\partial \mu}{\partial y}(x,y)P(x,y) - \dfrac{\partial \mu}{\partial x}(x,y)Q(x,y) &= \mu(x,y)\left(\dfrac{\partial Q}{\partial x}(x,y)-\dfrac{\partial P}{\partial y}(x,y)\right)
\end{align*}
Obtenemos una expresión muy engorrosa que podemos ahora reescribir, donde notaremos por $f_x$ a la parcial de la función $f$ respecto a $x$ y análogamente con $y$. Además, quitaremos la dependencia de las variables $(x,y)$:
\begin{align*}
    (\mu P)_y &= (\mu Q)_x \\
    \mu_y P + \mu P_y &= \mu_x Q + \mu Q_x \\
    \mu_y P - \mu_x Q &= \mu (Q_x - P_y)
\end{align*}
Con lo que obtenemos una ecuación en derivadas parciales del factor integrante $\mu$.\\

Aunque no sea objetivo de esta asignatura, comentaremos que las soluciones de las ecuaciones en derivadas parciales son familias de funciones que dependen de infinitas constantes, por lo que su espacio de soluciones tiene dimensión infinita.

Sin embargo, no necesitaremos encontrar todas las soluciones, sino sólamente una, que será la que usemos como factor integrante. Recordamos que este no puede anularse.\\

Para buscar dicha solución, lo que haremos será que el factor integrante en realidad será una función que dependerá de una única variable, la cual puede ser a su vez función de $x$ y de $y$. Es decir, podemos buscar factores integantes que dependan de:
\begin{itemize}
    \item \makebox[8cm][l]{solo $x$:} $\mu(x,y) = m(x)$.
    \item \makebox[8cm][l]{solo $y$:} $\mu(x,y) = m(y)$.
    \item \makebox[8cm][l]{de la suma de $x$ e $y$:} $\mu(x,y) = m(x+y)$.
    \item \makebox[8cm][l]{del producto de $x$ e $y$:} $\mu(x,y) = m(x\cdot y)$.
    \item \makebox[8cm][l]{del cuadrado de la norma del vector $(x,y)$:} $\mu(x,y) = m(x^2+y^2)$.
\end{itemize}
En general, dada cualquier\footnote{Cualesquiera funciones $f$ y $m$ que tras realizar la composición nos permitan tener que $\mu$ sea un factor integrante.} función $f:\mathbb{R}^2\rightarrow\mathbb{R}$ y una función $m:\mathbb{R}\rightarrow\mathbb{R}$, podemos tomar como factor integrante la función $\mu:\mathbb{R}^2\rightarrow\mathbb{R}$ dada como resultado de la composición:
\begin{gather*}
    \mu = m \circ f  \\
    (x,y) \stackrel{f}{\longmapsto} f(x,y) \stackrel{m}{\longmapsto} m(f(x,y))
\end{gather*}
Sin embargo, los de la lista anterior son los más comunes y los más útiles en los problemas a resolver, aunque podríamos también encontrarnos un problema que se resuelva con un factor integrante de la forma $\mu(x,y) = m(47x^8 + 27y^2 - 4)$, por ejemplo.\\

\begin{observacion}
    Las 4 primeras ``formas'' de posibles factores integrantes pueden parecer tener sentido por la sencillez de sus fórmulas. Sin embargo, la quinta de ellas parece ser más rara. Resulta que en el siglo XIX había muchos problemas geométricos que planteaban ecuaciones diferenciales a resolver, y dichos problemas ahora han sido olvidados pero se han mantenido las ecuaciones diferenciales en diversos libros.

    De esta forma, en muchos de esos problemas intervenía la distancia de un punto al origen, fórmula que se haya en la expresión $\mu(x,y)=m(x^2+y^2)$.\\

    Recomendamos probar primero con las 4 ``formas'' de factores integantes de la lista superior y si en algún caso nos atrancamos con una ecuación, buscar un factor integrante de la última ``forma''.
\end{observacion}~\\
Cabe destacar que en la notación clásica se llama a la función de una variable que usamos para definir $\mu$ (es decir, $m$), también como $\mu$, notación que no usamos por ser confusa.

\begin{ejemplo}
    Veamos varios ejemplos de distintos factores integrantes, con la finalidad de que nos quede claro cómo es que se definien estos, para entender completamente los factores integrantes:
    \begin{enumerate}
        \item En primer lugar, discutimos el caso del factor integrante
            \begin{equation*}
                \mu(x,y) = e^x
            \end{equation*}
            Resulta que lo que hacíamos era tomar la función 
            \begin{equation*}
                m(\xi) = e^\xi
            \end{equation*}
            Y quedarnos con la función resultado de la composición
            \begin{equation*}
                \begin{array}{ccccc}
                    \mathbb{R}^2 & \longrightarrow & \mathbb{R} & \longrightarrow & \mathbb{R}\\
                    (x,y) & \stackrel{\pi_1}{\longmapsto} & x \\
                          & & \xi & \stackrel{m}{\longmapsto} & e^\xi
                \end{array}
            \end{equation*}
        \item Si ahora consideramos:
            \begin{equation*}
                \mu(x,y) = \sen(x+y)
            \end{equation*}
            Lo que hacemos es tomar la función
            \begin{equation*}
                m(\xi) = \sen(\xi)
            \end{equation*}
            Y tomar $\mu$ como resultado de la composición
            \begin{equation*}
                \begin{array}{ccccc}
                    \mathbb{R}^2 & \longrightarrow & \mathbb{R} & \longrightarrow & \mathbb{R}\\
                    (x,y) & \stackrel{\phi}{\longmapsto} & x+y \\
                          & & \xi & \stackrel{m}{\longmapsto} & \sen(\xi)
                \end{array}
            \end{equation*}
            donde hemos usado la función $\phi:\mathbb{R}^2\rightarrow\mathbb{R}$ dada por $\phi(x,y)=x+y$.
        \item Análogamente, si consideramos ahora 
            \begin{equation*}
                \mu(x,y) = \dfrac{1}{x^2+y^2}
            \end{equation*}
            Podemos tomar
            \begin{equation*}
                m(\xi) = \dfrac{1}{\xi}
            \end{equation*}
            Y tomar $\mu$ como resultado de la composición
            \begin{equation*}
                \begin{array}{ccccc}
                    \mathbb{R}^2 & \longrightarrow & \mathbb{R} & \longrightarrow & \mathbb{R}\\
                    (x,y) & \stackrel{\psi}{\longmapsto} & x^2+y^2 \\
                          & & \xi & \stackrel{m}{\longmapsto} & \dfrac{1}{\xi}
                \end{array}
            \end{equation*}
            donde hemos usado la función $\psi:\mathbb{R}^2\rightarrow\mathbb{R}$ dada por $\psi(x,y)=x^2+y^2$.
    \end{enumerate}
\end{ejemplo}~\\

Finalmente, para cada ``forma'' de factor integrante tenemos que ver qué condiciones ha de cumplir la ecuación diferencial de partida para ver si es o no posible buscar un factor de dicha forma que nos permita resolver la ecuación.

\subsubsection{Factor integrante que solo depende de $x$}
Ahora, buscaremos qué condición deben cumplir las ecuaciones diferenciales para poder ser resueltas por un factor integrante del tipo $\mu(x,y)=m(x)$.\\

\noindent
Anteriormente, vimos que la fórmula~(\ref{eq:condicion_fi}) podía traducirse (haciendo un abuso de la notación) en
\begin{equation*}
    \mu_y P -\mu_x Q = \mu(Q_x - P_y)
\end{equation*}
y que lo que teníamos que hacer era resolver dicha ecuación en derivadas parciales, buscando una función $\mu$. En este caso, estamos buscando una función de la forma $\mu(x,y)=m(x)$, con lo que:
\begin{equation*}
    \dfrac{\partial \mu}{\partial x}(x,y) = m'(x) \qquad \dfrac{\partial \mu}{\partial y}(x,y) = 0 \qquad \forall (x,y)\in \Omega
\end{equation*}
Y podemos ya sustituir en la ecuación en derivadas parciales, obteniendo que:
\begin{equation*}
    -m'(x) Q = m(x) (Q_x-P_y)
\end{equation*}
despejando para dejar a un lado lo que depende de $m$ y al otro lo que depende de $P$ y $Q$ (este paso hace necesario suponer que $Q(x,y)\neq 0$ $\forall (x,y)\in \Omega$):
\begin{equation*}
    \dfrac{m'(x)}{m(x)} = \dfrac{P_y-Q_x}{Q}
\end{equation*}
Con lo que podremos encontrar un factor integrante de la forma $\mu(x,y)=m(x)$ si y solo si la ecuación diferencial dada cumple que el cociente:
\begin{equation*}
    \dfrac{P_y-Q_x}{Q} = \dfrac{\dfrac{\partial P}{\partial y}(x,y)-\dfrac{\partial Q}{\partial x}(x,y)}{Q(x,y)}
\end{equation*}
sea una expresión que solo dependa de $x$ en todo $\Omega$, a la que notamos por $f(x)$ (además, es necesario que $Q(x,y)\neq 0$ $\forall (x,y)\in \Omega$). En cuyo caso, estaremos ante una ecuación diferencial lineal homogénea:
\begin{equation*}
    m' = m\cdot f
\end{equation*}

con lo que sus soluciones son de la forma:
\begin{equation*}
    m(\xi) = e^{F(\xi)}
\end{equation*}

siendo $F$ una primitiva de $f$, y ya podemos calcular $\mu$ como $m\circ \pi_1$.

\begin{ejemplo}
    Consideremos la ecuación lineal completa:
    \begin{equation*}
        b(t) + a(t)x - x' = 0
    \end{equation*}

    Siendo $a,b:J\rightarrow\mathbb{R}$ funciones continuas en un intervalo abierto $J\subseteq \mathbb{R}$.

    De esta forma, tenemos funciones $P,Q\in C^1(\mathbb{R}^2)$ dadas por:
    \begin{equation*}
        P(t,x) = b(t) + a(t)x \qquad Q(t,x) = -1
    \end{equation*}
    La condición de exactitud con esta nueva notación queda ahora como:
    \begin{equation*}
        \dfrac{\partial P}{\partial x}(t,x) = a(t) \neq 0 = \dfrac{\partial Q}{\partial t}(t,x) \qquad \forall (t,x)\in \mathbb{R}^2
    \end{equation*}
    Con lo que una ecuación lineal completa cualquier no es exacta, pero veamos que sí que acepta un factor integrante del tipo $\mu(t,x)=m(t)$. Como hemos visto anteriormente, esto pasará si (tenemos que $Q(t,x)=-1\neq 0$ $\forall (t,x)\in J\times \mathbb{R}$):
    \begin{equation*}
        \dfrac{P_x-Q_t}{Q} = f(t)
    \end{equation*}
    Es decir, si dicho cociente es función únicamente de $t$. Sustituyendo:
    \begin{equation*}
        \dfrac{a(t)}{-1} = f(t)
    \end{equation*}
    Obtenemos un cociente que es función de $t$, con lo que por la teoría vista, sabemos que existe el factor integrante $\mu$, que sólo depende de $t$, cuya función $m$ vendrá dada por:
    \begin{equation*}
        m(\xi) = e^{-A(\xi)}
    \end{equation*}
    Siendo $A$ una primitiva de $a$. De esta forma, podemos multiplicar la ecuación lineal completa de partida por $\mu(t,x) = e^{-A(t)}$, obteniendo una ecuación exacta:
    \begin{equation*}
        e^{-A(t)}b(t) - e^{-A(t)}(a(t)x - x') = b(t)e^{-A(t)} - \dfrac{d}{dt}\left(e^{-A(t)}x\right) = 0
    \end{equation*}
\end{ejemplo}

\subsubsection{Factor integrante que solo depende de $x^2+y^2$}
De la misma forma que hicimos para $\mu(x,y)=m(x)$, razonamos ahora de forma análoga para buscar qué condición es la que tiene que cumplir una ecución diferencial para admitir un factor integrante de la forma $\mu(x,y)=m(x^2+y^2)$.

Para ello, al igual que hicimos en la sección anterior, calcularemos primero las derivadas parciales de $\mu$:
\begin{equation*}
    \dfrac{\partial \mu}{\partial x}(x,y) = 2xm'(x^2+y^2) \qquad \dfrac{\partial \mu}{\partial y}(x,y) = 2ym'(x^2+y^2) \qquad \forall (x,y)\in \Omega
\end{equation*}
Y podemos usar estas fórmulas en la ecuación
\begin{equation*}
    \mu_y P - \mu_x Q = \mu(Q_x-P_y)
\end{equation*}

obteniendo que:
\begin{equation*}
    [2yP-2xQ]m'(x^2+y^2) = m(x^2+y^2)[Q_x-P_y]
\end{equation*}
y si ahora dejamos a un lado todo lo que depende de $m$ y todo lo que depende de $P$ y $Q$ (este paso nos hace suponer que $yP(x,y)-xQ(x,y)$ no puede anularse, para cualquier $(x,y)\in \Omega$): 
\begin{equation*}
    \dfrac{m'(x^2+y^2)}{m(x^2+y^2)} = \dfrac{Q_x-P_y}{2yP-2xQ}
\end{equation*}
Con lo que podremos encontrar un factor integrante de la forma $\mu(x,y)=m(x^2+y^2)$ si y solo si la ecuación diferencial dada cumple que el cociente:
\begin{equation*}
     \dfrac{Q_x-P_y}{2yP-2xQ} = \dfrac{\dfrac{\partial Q}{\partial x}(x,y)-\dfrac{\partial P}{\partial y}(x,y)}{2yP(x,y)-2xQ(x,y)} 
\end{equation*}
sea una expresión que solo dependa de $x^2+y^2$ en todo $\Omega$, a la que denotaremos por $f(x^2+y^2)$ (además, $yP(x,y)-xQ(x,y)\neq 0$ $\forall (x,y)\in \Omega$). En cuyo caso, volveremos a estar ante una ecuación diferencial lineal homogénea:
\begin{equation*}
    m' = m\cdot f
\end{equation*}

con lo que sus soluciones serán de la forma:
\begin{equation*}
    m(\xi) = e^{F(\xi)}
\end{equation*}

siendo $F$ una primitiva de $f$, y ya podemos calcular $\mu$ como:
\begin{equation*}
    \mu = m \circ \phi
\end{equation*}
Siendo $\phi:\mathbb{R}^2\rightarrow\mathbb{R}$ una función dada por
\begin{equation*}
    \phi(x,y) = x^2+y^2 \qquad \forall (x,y)\in \mathbb{R}^2
\end{equation*}

\begin{ejemplo}
    Volviendo al ejemplo de la espiral logarítmica:
    \begin{equation*}
        x-y+(y+x)y' = 0
    \end{equation*}
    Este vuelve a ser un ejemplo de ecuación diferencial que no es exacta:

    Sean $P,Q:\mathbb{R}^2\rightarrow\mathbb{R}$ dadas por
    \begin{equation*}
        P(x,y) = x-y \qquad Q(x,y) = y+x \qquad \forall (x,y)\in \mathbb{R}^2
    \end{equation*}

    se tiene que $P,Q\in C^1(\mathbb{R}^2)$, y si comprobamos la condición de admisibilidad:
    \begin{equation*}
        \dfrac{\partial P}{\partial y}(x,y) = -1 \neq 1 = \dfrac{\partial Q}{\partial x}(x,y) \qquad \forall (x,y)\in \mathbb{R}^2
    \end{equation*}

    vemos que no se cumple.\\

    Veamos si esta ecuación admite un factor integrante de la forma ${\mu(x,y)=m(x^2+y^2)}$. Para ello, calculamos el cociente que hemos visto en este apartado, de forma que si está en función de $x^2+y^2$, entonces sí será posible calcular dicho factor integrante. Trabajando en\footnote{Para hallar $\Omega$ lo que hemos hecho ha sido calcular primero el cociente, calcular luego dónde no se anula el denominador de dicho cociente y, para que quede bonito, decir el dominio antes de calcular el cociente.} $\Omega=\mathbb{R}^2\setminus\{(0,0)\}$:
    \begin{equation*}
        \dfrac{Q_x-P_y}{2yP-2xQ} = \dfrac{1+1}{2y(x-y)-2x(y+x)} = \dfrac{1}{xy-y^2-xy-x^2} = \dfrac{-1}{x^2+y^2}
    \end{equation*}
    Y llegamos a un cociente que depende de $x^2+y^2$:
    \begin{equation*}
        f(x^2+y^2) = \dfrac{-1}{x^2+y^2}
    \end{equation*}
    De esta forma, tomamos $m$ como (gracias a la teoría desarrollada):
    \begin{equation*}
        m(\xi) = e^{-\ln \xi} = \dfrac{1}{\xi}
    \end{equation*}
    Con lo que el factor integante para este caso será:
    \begin{equation*}
        \mu(x,y) = \dfrac{1}{x^2+y^2}
    \end{equation*}
    Y si multiplicamos la ecuación de la espiral logarítmica por $\mu$ obtendremos una ecuación exacta (compruébese).
\end{ejemplo}

