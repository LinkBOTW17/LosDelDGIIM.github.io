\documentclass[12pt]{article}

\input{../../_assets/preambulo.tex}


\begin{document}

    % 1. Foto de fondo
    % 2. Título
    % 3. Encabezado Izquierdo
    % 4. Color de fondo
    % 5. Coord x del titulo
    % 6. Coord y del titulo
    % 7. Fecha

    
    \input{../../_assets/portada}
    \portadaExamen{ffccA4.jpg}{Ecuaciones\\Diferenciales I\\Examen XVIII}{Ecuaciones Diferenciales I. Examen XVIII}{MidnightBlue}{-8}{28}{2024-2025}{Arturo Olivares Martos}

    \begin{description}
        \item[Asignatura] Ecuaciones Diferenciales I
        \item[Curso Académico] 2016-17.
        % \item[Grado] Doble Grado en Ingeniería Informática y Matemáticas.
        \item[Grupo] A.
        \item[Profesor] Rafael Ortega Ríos.
        \item[Descripción] Parcial C.
        \item[Fecha] 1 de Junio de 2017.
        %\item[Duración] 60 minutos.
    
    \end{description}
    \newpage

    \begin{ejercicio}
        Encuentra la solución del problema
        \[
            x'' + 9x = t^2, \quad x(0) = 0, \quad x'(0) = 0
        \]

        Busquemos una solución particular de la forma $x_p(t) = \alpha t^2+\beta t + \gamma$.
        Tenemos que:
        \begin{align*}
            x_p'(t) &= 2\alpha t + \beta, \\
            x_p''(t) &= 2\alpha.
        \end{align*}

        Por tanto, como buscamos que sea solución, hemos de imponer:
        \[
            2\alpha + 9(\alpha t^2 + \beta t + \gamma) = t^2
            \Longrightarrow 
            9\alpha t^2 + 9\beta t + 9\gamma + 2\alpha = t^2
            \Longrightarrow
            \left\{
                \begin{aligned}
                    9\alpha &= 1, \\
                    9\beta &= 0, \\
                    9\gamma + 2\alpha &= 0.
                \end{aligned}
            \right\}
            \Longrightarrow
            \left\{
                \begin{aligned}
                    \alpha &= \nicefrac{1}{9}, \\
                    \beta &= 0, \\
                    \gamma &= \nicefrac{-2}{81}.
                \end{aligned}
            \right\}
        \]

        Por tanto, una solución particular del problema es:
        \[
            x_p(t) = \frac{t^2}{9} - \frac{2}{81}\qquad t\in \bb{R}.
        \]

        Busquemos ahora la solución de la homogénea. Sus valores propios son:
        \[
            \lambda^2 + 9 = 0 \Longrightarrow \lambda = \pm 3i.
        \]

        Trabajando con el valor propio $\lambda = 3i$, tenemos que una solución compleja de la homogénea es:
        \begin{equation*}
            x(t)=e^{3i}=\cos(3t)+i\sen(3t)\qquad t\in \bb{R}.
        \end{equation*}

        Por tanto, la solución general de la homogénea es:
        \[
            x(t) = c_1\cos(3t) + c_2\sen(3t)\qquad t\in \bb{R}.
        \]

        Por tanto, la solución general del problema es:
        \[
            x(t) = c_1\cos(3t) + c_2\sen(3t) + \frac{t^2}{9} - \frac{2}{81}\qquad t\in \bb{R}.
        \]

        Imponiendo las condiciones iniciales, tenemos que:
        \begin{align*}
            x(0) &= c_1 - \frac{2}{81} = 0 \Longrightarrow c_1 = \frac{2}{81}, \\
            x'(t) &= -3c_1\sen(3t) + 3c_2\cos(3t) + \frac{2t}{9}, \\
            x'(0) &= 3c_2 = 0 \Longrightarrow c_2 = 0.
        \end{align*}

        Por tanto, la solución del problema es:
        \[
            x(t) = \frac{2}{81}\cos(3t) + \frac{t^2}{9} - \frac{2}{81}\qquad t\in \bb{R}.
        \]
    \end{ejercicio}

    \begin{ejercicio}
        Sea $Z$ el espacio de soluciones del sistema $x' = Ax$ donde $A$ es la matriz $2\times 2$
        \[
            A=\begin{pmatrix}
                0 & 1 \\
                0 & 0
            \end{pmatrix}
        \]
        Consideramos la aplicación lineal $\Psi : Z \to \bb{R}^2$, $\Psi(x) = (x_1(0), x_2(1))$. Encuentra $\ker \Psi$.\\

        Tenemos que:
        \begin{align*}
            \ker \Psi &= \{x\in Z : \Psi(x) = 0\}
            = \{x\in Z : x_1(0) = 0, x_2(1) = 0\}.
        \end{align*}

        El sistema podemos escribirlo como:
        \begin{align*}
            x_1' &= x_2, \\
            x_2' &= 0.
        \end{align*}

        Por tanto, tenemos que toda solución $x_2(t)$, al ser de clase $1$ en $\bb{R}$ y tener derivada nula, es constante. Por la condición inicial, tenemos que:
        \[
            x_2(t) = x_2(1) = 0\qquad t\in \bb{R}.
        \]

        De igual forma, tenemos que:
        \begin{equation*}
            x_1'=0\Longrightarrow
            x_1(t)=x_1(0)=0\qquad t\in \bb{R}.
        \end{equation*}

        Por tanto, tenemos que:
        \[
            \ker \Psi = \{x\in Z : x_1(t) = 0, x_2(t) = 0\} = \{0\}.
        \]
    \end{ejercicio}

    \begin{ejercicio}
        Demuestra que la función
        \[
            \chi(t) = \begin{vmatrix}
                t^2+1 & t^2+2 & t^2+3 & \dots & t^2+n \\
                t^3+1 & t^3+2 & t^3+3 & \dots & t^3+n \\
                \vdots & \vdots & \vdots & \ddots & \vdots \\
                t^{n}+1 & t^{n}+2 & t^{n}+3 & \dots & t^{n}+n \\
                t^{n+1}+1 & t^{n+1}+2 & t^{n+1}+3 & \dots & t^{n+1}+n
            \end{vmatrix}
        \]
        es derivable y calcula $\chi'(0)$.

        Como cada componente de la matriz es un polinomio en $t$, cada componente es derivable en todo $\bb{R}$, luegp $\chi$ es derivable en todo $\bb{R}$, con derivada:
        \[
            \chi'(t) = \begin{vmatrix}
                2t & 2t & 2t & \dots & 2t \\
                3t^2 & 3t^2 & 3t^2 & \dots & 3t^2 \\
                \vdots & \vdots & \vdots & \ddots & \vdots \\
                nt^{n-1} & nt^{n-1} & nt^{n-1} & \dots & nt^{n-1} \\
                (n+1)t^{n} & (n+1)t^{n} & (n+1)t^{n} & \dots & (n+1)t^{n}
            \end{vmatrix}
        \]

        Por tanto, evaluando en el punto $t=0$, tenemos que:
        \[
            \chi'(0) = \begin{vmatrix}
                0 & 0 & 0 & \dots & 0 \\
                0 & 0 & 0 & \dots & 0 \\
                \vdots & \vdots & \vdots & \ddots & \vdots \\
                0 & 0 & 0 & \dots & 0 \\
                0 & 0 & 0 & \dots & 0
            \end{vmatrix} = 0.
        \]
    \end{ejercicio}

    \begin{ejercicio}
        Demuestra que la sucesión de funciones $\{f_n\}$ converge uniformemente en el intervalo $[0,1]$ si $f_n: \bb{R} \to \bb{R}$ está definida por las fórmulas recursivas
        \[
            f_0(t) = 7, \quad f_{n+1}(t) = 7 + \int_0^t \sqrt{s^2+t^2}f_n(s)ds.
        \]

        Para ello, usaremos el Test de Weierstrass. Veamos que:
        \begin{align*}
            |f_{1}(t)-f_0(t)|
            &= \left|\int_0^t \sqrt{s^2+t^2}f_0(s)ds\right| \\
            &= \left|7\int_0^t \sqrt{s^2+t^2}ds\right|
            \leq 7\left|\int_0^t \sqrt{2t^2}ds\right| \\
            &= 7\sqrt{2}\cdot t^2\leq 7\sqrt{2}.\\
            |f_2(t)-f_1(t)|
            &= \left|\int_0^t \sqrt{s^2+t^2}(f_1(s)-f_0(s))ds\right| \\
            &\leq 7\sqrt{2}\left|\int_0^t \sqrt{s^2+t^2}ds\right|
            \leq 7(\sqrt{2})^2\left|\int_0^t t ds\right|	
            \leq 7(\sqrt{2})^2 \cdot \left|\int_0^t ds\right|
            = 7(\sqrt{2})^2t.\\
            |f_3(t)-f_2(t)|
            &= \left|\int_0^t \sqrt{s^2+t^2}(f_2(s)-f_1(s))ds\right| \\
            &\leq 7(\sqrt{2})^2\left|\int_0^t \sqrt{s^2+t^2}s ds\right|
            \leq 7(\sqrt{2})^3 \cdot \left|\int_0^t sds\right|
            = 7(\sqrt{2})^3\frac{t^2}{2}.
        \end{align*}

        Demostremos por inducción que:
        \[
            |f_{n+1}(t)-f_n(t)|\leq 7(\sqrt{2})^{n+1}\frac{t^{n}}{n!}.
        \]
        \begin{itemize}
            \item Para $n=0$, tenemos que:
            \[
                |f_{1}(t)-f_0(t)|\leq 7(\sqrt{2})^{1}\frac{t^{0}}{0!}.
            \]

            \item Supongamos cierto para $n$, y veamos que es cierto para $n+1$. Tenemos que:
            \begin{align*}
                |f_{n+2}(t)-f_{n+1}(t)|
                &= \left|\int_0^t \sqrt{s^2+t^2}(f_{n+1}(s)-f_n(s))ds\right| \\
                &\leq 7(\sqrt{2})^{n+1}\left|\int_0^t \sqrt{s^2+t^2}s ds\right|
                \leq 7(\sqrt{2})^{n+2} \cdot \left|\int_0^t \frac{s^n}{n!}ds\right|
                =\\&= 7(\sqrt{2})^{n+2}\frac{t^{n+1}}{(n+1)!}.
            \end{align*}
        \end{itemize}

        Por tanto, tenemos que:
        \[
            |f_{n+1}(t)-f_n(t)|\leq 7(\sqrt{2})^{n+1}\frac{t^{n}}{n!}\leq
            7\sqrt{2}\cdot \frac{(\sqrt{2})^{n}}{n!}\qquad t\in [0,1].
        \]

        Definimos entonces la sucesión de números reales:
        \[
            M_n = 7\sqrt{2}\cdot \frac{(\sqrt{2})^{n}}{n!}\qquad n\in \bb{N}.
        \]

        Veamos ahora que la serie $\sum\limits_{n=0}^{\infty} M_n$ converge. Para ello, usando el desarrollo en serie de Taylor de la función exponencial, tenemos que:
        \[
            \sum_{n=0}^{\infty} M_n = 7\sqrt{2}\sum_{n=0}^{\infty} \frac{(\sqrt{2})^{n}}{n!} = 7\sqrt{2}e^{\sqrt{2}} < \infty.
        \]

        Por tanto, por el Test de Weierstrass, la sucesión de funciones $\{f_n\}$ converge uniformemente en el intervalo $[0,1]$.
    \end{ejercicio}

    \begin{ejercicio}
        Dado un sistema lineal y homogéneo $x' = A(t)x$ con $A: I \to \bb{R}^{N\times N}$ continua, se considera una matriz solución $\Phi: I \to \bb{R}^{N\times N}$. Demuestra que el rango de la matriz $\Phi(t)$ es independiente de $t$.\\

        Sea $\Phi=(\phi_1\mid \dots\mid \phi_N)$, con $\phi_i$ la columna $i$-ésima de $\Phi$ una solución del sistema. Veamos que el rango de $\Phi(t)$ es el número de soluciones linealmente independientes de $\Phi$, y que por tanto no depende de $t$.\\

        Sea $Z$ el espacio de soluciones del sistema. Consideramos el subespacio vectorial de las combinaciones lineales de las columnas de $\Phi$:
        \begin{equation*}
            V=\left\{\sum_{i=1}^{N}c_i\phi_i\mid c_i\in \bb{R}~\forall i\in 1=1,\dots,n\right\}.
        \end{equation*}
        de esta forma, $\dim V$ es el número de soluciones linealmente independientes de $\Phi$.\\

        Fijado $t_0\in I$, consideramos el isomorfismo dado por:
        \Func{\Phi_{t_0}}{Z}{\bb{R}^N}{x=\begin{pmatrix} x_1 \\ \vdots \\ x_N \end{pmatrix}}{x(t_0)=\begin{pmatrix} x_1(t_0) \\ \vdots \\ x_N(t_0) \end{pmatrix}}

        Por ser $\Phi_{t_0}$ lineal, tenemos que:
        \begin{equation*}
            \Phi_{t_0}(V)=\left\{\sum_{i=1}^{N}c_i\Phi_{t_0}(\phi_i)\mid c_i\in \bb{R}~\forall i\in 1=1,\dots,n\right\}.
        \end{equation*}

        De esta forma, tenemos que:
        \begin{equation*}
            \Phi(t_0)=\left(\Phi_{t_0}(\phi_1)\mid \dots\mid \Phi_{t_0}(\phi_N)\right)
            \Longrightarrow
            \operatorname{rg}(\Phi(t_0))=\operatorname{rg}(\Phi_{t_0}(\phi_1)\mid \dots\mid \Phi_{t_0}(\phi_N))
        \end{equation*}

        La matriz $\left(\Phi_{t_0}(\phi_1)\mid \dots\mid \Phi_{t_0}(\phi_N)\right)$ ya es una matriz en cuyas columnas hay vectores de $\bb{R}^N$, por lo que su rango es el número de columnas linealmente independientes, y como $\Phi_{t_0}(V)$ es el espacio vectorial formado por las combinaciones lineales de los vectores de dicha matriz, tenemos que:
        \begin{equation*}
            \operatorname{rg}(\Phi(t_0))=\operatorname{rg}(\Phi_{t_0}(\phi_1)\mid \dots\mid \Phi_{t_0}(\phi_N))
            = \dim \Phi_{t_0}(V)
        \end{equation*}

        No obstante, como $\Phi_{t_0}$ es un isomorfismo, tenemos que $\dim \Phi_{t_0}(V)=\dim V$, y por tanto:
        \begin{equation*}
            \operatorname{rg}(\Phi(t_0))=\dim V
        \end{equation*}

        Como $t_0$ es arbitrario, tenemos que:
        \begin{equation*}
            \operatorname{rg}(\Phi(t))=\dim V\qquad \forall t\in I.
        \end{equation*}
        Por lo que hemos demostrado que es independiente de $t$.
    \end{ejercicio}
\end{document}
