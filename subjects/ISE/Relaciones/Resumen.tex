\chapter{Resumen de fórmulas}
Este apartado trata de ser un resumen de la mayoría de las fórmulas vistas en cada tema de la asignatura, está pensado para recordar de forma rápida las fórmulas vistas en la asignatura, y no debe usarse como medio de estudio.

\section{Introducción a la Ingeniería de Servidores}
Los dos conceptos más importantes del tema son:
\begin{itemize}
    \item Tiempo de respuesta (latencia).
    \item Productividad (ancho de banda).
\end{itemize}
Si queremos comparar dos dispositivos $A$ y $B$ con tiempos $t_A$ y $t_B$, la ganancia en velocidad de $A$ respecto a $B$ viene dada por:
\begin{equation*}
    S_B(A) = \dfrac{t_A}{t_B}
\end{equation*}
Si tenemos un dispositivo que tarda en ejecutar una tarea un tiempo $T_0$ y mejoramos dicho dispositivo sustituyendoo un compoente que se usa durante una fracción de tiempo $f\in [0,1]$ de forma que mejoramos dicho componentes $k$ veces, el nuevo tiempo vendrá dado por:
\begin{equation*}
    T_M = (1-f)T_0 + \dfrac{fT_0}{k}
\end{equation*}
Bajo las mismas condiciones, la Ley de Amdahl nos dice que:
\begin{equation*}
    S = \dfrac{T_0}{T_M} = \dfrac{T_0}{(1-f)T_0 + \dfrac{fT_0}{k}} = \dfrac{1}{1-f+\dfrac{f}{k}}
\end{equation*}

\setcounter{section}{3}
\section{Análisis comparativo del rendimiento}
Si sabemos las instrucciones de un programa ($NI$), cuántas de ellas son en coma flotante ($FL$) y el tiempo que tarda un dispositivo en ejecutar el programa ($t$), podremos calcular:
\begin{align*}
    \text{MIPS} &= \dfrac{NI}{t\cdot 10^6} \\
    \text{MFLOPS} &= \dfrac{FL}{t\cdot 10^6}
\end{align*}
Si para un cierto programa conocemos el número de instrucciones necesarias para su ejecución ($NI$), el número medio de ciclos por instrucción de la CPU ($CPI$) y la frecuencia del procesador ($f$), podremos calcular el tiempo que tarda la CPU en ejecutar el programa, mediante:
\begin{equation*}
    T_{CPU} = NI\cdot CPI \cdot \dfrac{1}{f}
\end{equation*}
Si al ejecutar un benchmark de $n$ programas obtenemos las puntuaciones $t_1,t_2,\ldots,t_n$ y las puntuaciones de referencia eran $t_{REF_1}, t_{REF_2}, \ldots, t_{REF_n}$, podemos calcular el índice SPEC mediante:
\begin{equation*}
    SPEC = \sqrt[n]{\dfrac{t_{REF_1}}{t_1} \cdot \dfrac{t_{REF_2}}{t_2} \cdot \ldots \cdot \dfrac{t_{REF_n}}{t_n}}
\end{equation*}

\subsection{Distribución t-Student}
Si extraemos $n$ muestras de ejecución de varios programas por dos dispositivos o programas distintos y consideramos la diferencia de los datos obtenidos: $d_1,d_2,\ldots,d_n$, estamos interesados en calcular si las dos muestras tienen diferencias significativas con un grado de significatividad mayor al $95\%$. Para ello, lo que haremos será suponer la hipótesis nula $H_0$:
\begin{center}
    Las dos máquinas/programas tienen rendimientos equivalentes
\end{center}
Definimos:
\begin{itemize}
    \item La media de las diferencias:
        \begin{equation*}
            \ol{d} = \dfrac{1}{n}\sum_{i=1}^{n}d_i
        \end{equation*}
    \item La desviación típica muestral:
        \begin{equation*}
            s = \sqrt{\dfrac{\sum\limits_{i=1}^{n}{(d_i - \ol{d})}^{2}}{n-1}}
        \end{equation*}
    \item El error estándar:
        \begin{equation*}
            \dfrac{s}{\sqrt{n}}
        \end{equation*}
\end{itemize}
Supuesta la hipótesis nula $H_0$, tras un estudio podremos rechazar la hipótesis nula (por lo que los datos no son significativamente distintos) o no podremos rechazarla. Este estudio se puede realizar de 3 formas distintas. Fijado un grado de significatividad usualmente de $\alpha=0.5$ (para el $95\%$):
\begin{enumerate}
    \item Una vez calculados $\ol{d},s$ y el error estándar, calculamos:
        \begin{equation*}
            t_{exp} = \dfrac{\ol{d}}{\nicefrac{s}{\sqrt{n}}}
        \end{equation*}
        Tras lo cual podemos calcular el $p-$value:
        \begin{equation*}
            P(|t| \geq |t_{exp}|)
        \end{equation*}
        Donde consideramos la distribución de probabilidad de $t-$Student de $n-1$ grados de libertad. Si $P(|t|\geq |t_{exp}|) < \alpha$, entonces podremos rechazar $H_0$.
    \item Conocidos $\alpha$ y $n$, si calculamos $t_{\frac{\alpha}{2},n-1}$ que cumple:
        \begin{equation*}
            P(|t| \geq |t_{\frac{\alpha}{2},n-1}|) = \alpha
        \end{equation*}
        Para una distribución de $t-$Student de $n-1$ grados de libertad, si calculamos $t_{exp}$ y:
        \begin{equation*}
            t_{exp} \notin \left[-t_{\frac{\alpha}{2},n-1}, t_{\frac{\alpha}{2},n-1}\right]
        \end{equation*}
        Entonces podremos rechazar $H_0$.
    \item Si calculamos $t_{\frac{\alpha}{2},n-1}$, si:
        \begin{equation*}
            0\notin \left[\ol{d}-\frac{s}{\sqrt{n}} \cdot t_{\frac{\alpha}{2},n-1},~\ol{d}+\frac{s}{\sqrt{n}} \cdot t_{\frac{\alpha}{2},n-1}\right]
        \end{equation*}
        Entonces podremos rechazar $H_0$.
\end{enumerate}

\section{Optimización del rendimiento}
En un servidor con $K$ dispositivos o estaciones, para cada uno registraremos los siguientes parámetros (estarán marcados con subíndice $i$, ya que harán referencia al $i-$ésimo dispositivo, con $i \in \{1,\ldots,K\}$), donde $T$ es el tiempo total durante el que observamos el servidor:
\begin{itemize}
    \item $A_i$, número de trabajos solicitados a la estación.
    \item $C_i$, número de trabajos completados por la estación.
    \item $B_i$, tiempo que el dispositivo ha estado en uso.
    \item $S_i$, tiempo medio de servicio:
        \begin{equation*}
            S_i = \dfrac{B_i}{C_i}
        \end{equation*}
    \item $W_i$, tiempo medio de espera en cola.
    \item $R_i$, tiempo medio de respuesta del dispositivo:
        \begin{equation*}
            R_i = W_i + S_i
        \end{equation*}
    \item $\lm_i$, tasa media de llegada (cuántos trabajos por segundo llegan):
        \begin{equation*}
            \lm_i = \dfrac{A_i}{T}
        \end{equation*}
    \item $X_i$, productividad media (cuántos trabajos se completan por segundo):
        \begin{equation*}
            X_i = \dfrac{C_i}{T}
        \end{equation*}
    \item $U_i$, utilización media (porcentaje de tiempo durante el cual el dispositivo ha estado en uso):
        \begin{equation*}
            U_i = \dfrac{B_i}{T}
        \end{equation*}
    \item $Q_i$, número medio de trabajos en cola.
    \item $N_i$, número medio de trabajos siendo servidos por el dispositivo:
        \begin{equation*}
            N_i = Q_i + U_i
        \end{equation*}
\end{itemize}
Si vemos el servidor como un dispositivo, podemos generalizar estos parámetros para el mismo, los cuales denotaremos con subíndice $0$, y nos importarán especialmente:
\begin{equation*}
    A_0,\quad C_0,\quad R_0,\quad \lm_0 = \dfrac{A_0}{T},\quad X_0 = \dfrac{C_0}{T},\quad N_0 = \sum_{i} N_i
\end{equation*}
Estos parámetros nos permiten considerar un par más de parámetros de dispositivos:
\begin{itemize}
    \item $V_i$, la razón media de visita (número medio de veces que un trabajo visita al dispositivo $i-$ésimo durante su visita al servidor):
        \begin{equation*}
            V_i = \dfrac{C_i}{C_0}
        \end{equation*}
    \item $D_i$, la demanda media del servicio (cantidad media de tiempo que el dispositivo dedica a cada trabajo que abandona el servidor):
        \begin{equation*}
            D_i = \dfrac{B_i}{C_0} = V_i\cdot S_i
        \end{equation*}
\end{itemize}

Los parámetros esenciales en un servidor son su productividad $X_0$ y tiempo de respuesta, $R_0$, y siempre tratraremos de aumentar la productividad y de reducir el tiempo de respuesta, algo que se pondrá de manifiesto más adelante.

\subsection{Leyes operacionales}
El valor de las variables anteriores depende obviamente del tiempo de observación $T$, pero existen algunas relaciones entre variables que son ciertas independientemente de dicho tiempo $T$, lo que se denominan leyes operacionales.

\begin{definicion}
    Supuesto que $T$ es suficientemente grande (en relación con $R_0$), decimos que el servidor está en equilibrio de flujo si el número de trabajos que este completa coincide de forma aproximada con el número de trabajos solicitados al mismo, es decir, si:
    \begin{equation*}
        A_0\approx C_0
    \end{equation*}
    En dicho caso, también tendremos que $X_0\approx \lm_0$, lo que puede tomarse como una definición equivalente.
\end{definicion}

A continuación mostraremos las distintas leyes operacionales que manejamos en este curso. Muchas de ellas no necesitan la hipótesis de que el servidor esté en equilibrio de flujo. Sin embargo, si en estas aparece $X_0$, por cada fórmula podemos obtener otra equivalente, suponiendo que el servidor está en equilibrio de flujo y sustituyendo $X_0$ por $\lm_0$.

\begin{prop}[Ley de la utilización]
    Podemos relacionar la utilización media de un dispositivo con el número de trabajos que completa por unidad de tiempo (es decir, con su productividad) y con el tiempo medio que le dedica a cada uno de ellos:
    \begin{equation*}
        U_i = X_i \cdot S_i
    \end{equation*}
    Y si está en equilibrio de flujo: $U_i = \lm_i \cdot S_i$.
    \begin{proof}
        \begin{equation*}
            S_i = \dfrac{B_i}{C_i} = \dfrac{\dfrac{B_i}{T}}{\dfrac{C_i}{T}} = \dfrac{U_i}{X_i} \Longrightarrow U_i = X_i\cdot S_i
        \end{equation*}
    \end{proof}
\end{prop}

\begin{prop}[Ley del flujo forzado]
    Los flujos de salida de cada estación de servicio han de ser proporcionales a la productividad global del servidor:
    \begin{equation*}
        X_i = X_0\cdot V_i
    \end{equation*}
    En caso de equilibrio de flujo: $X_i = X_0 \cdot V_i = \lm_0\cdot V_i = \lm_i$.
    \begin{proof}
        \begin{equation*}
            V_i = \dfrac{C_i}{C_0} = \dfrac{\dfrac{C_i}{T}}{\dfrac{C_0}{T}} = \dfrac{X_i}{X_0} \Longrightarrow X_i = X_0\cdot V_i
        \end{equation*}
    \end{proof}
\end{prop}

\begin{prop}[Relación utilización-demanda de servicio]
    Las utilizaciones de cada servicio son proporcionales a las demandas de servicio del mismo, siendo la constante de proporcionalidad la productividad del servidor:
    \begin{equation*}
        U_i = X_0 \cdot D_i
    \end{equation*}
    En caso de equilibrio de flujo: $U_i = \lm_0 \cdot D_i$.
    \begin{proof}
        \begin{equation*}
            D_i = \dfrac{B_i}{C_0} = \dfrac{\dfrac{B_i}{T}}{\dfrac{C_0}{T}} = \dfrac{U_i}{X_0} \Longrightarrow U_i = X_0\cdot D_i
        \end{equation*}
    \end{proof}
\end{prop}

\begin{prop}[Ley de Little]
    Si el sistema está en equilibrio de flujo\footnote{En otro caso la Ley de Little no es cierta.}:
    \begin{equation*}
        N_i = \lm_i \cdot R_i = X_i\cdot R_i
    \end{equation*}
    También puede aplicarse a la cola de un dispositivo:
    \begin{equation*}
        Q_i = \lm_i \cdot W_i = X_i\cdot W_i
    \end{equation*}
\end{prop}

\begin{prop}[Ley general del tiempo de respuesta]
    El tiempo medio de respuesta que experimenta una petición en un servidor en equilibrio de flujo teniendo en cuenta que cada una de ellas ha visitado $V_i$ veces el dispositivo $i-$ésimo, donde ha permanecido $R_i$ segundos de media:
    \begin{equation*}
        R_0 = \sum_{i=0}^{K} V_i \cdot R_i
    \end{equation*}
    \begin{proof}
        Tenemos que:
        \begin{equation*}
            N_0 = \sum_{i=0}^{K}N_i
        \end{equation*}
        Y si aplicamos la Ley de Little:
        \begin{equation*}
            X_0 \cdot R_0 = \sum_{i=0}^{K}X_i\cdot R_i
        \end{equation*}
        Si usamos la Ley del flujo forzado:
        \begin{equation*}
            X_0 \cdot R_0 = \sum_{i=0}^{K}X_0\cdot V_i\cdot R_i
        \end{equation*}
        De donde:
        \begin{equation*}
            R_0 = \sum_{i=0}^{K}V_i\cdot R_i
        \end{equation*}
    \end{proof}
\end{prop}

Antes de ver la siguiente ley cabe mencionar que las redes cerradas siempre están en equilibrio de flujo, ya que supondremos que sus colas son suficientemente grandes como para alvergar la cantidad de trabajos $N_T$ en estas redes.

\begin{prop}[Ley del tiempo de respuesta interactivo]
    En una red cerrada:
    \begin{equation*}
        R_0 = \dfrac{N_T}{X_0} - Z
    \end{equation*}
    \begin{proof}
        Sabemos que $N_T = N_Z + N_0$ y si aplicamos la Ley de Little a ambos:
        \begin{equation*}
            N_T = N_Z + N_0 = X_0 \cdot Z + X_0\cdot R_0 = X_0(Z+R_0) \Longrightarrow R_0 = \dfrac{N_T}{X_0}-Z
        \end{equation*}
    \end{proof}
\end{prop}

\begin{prop}
    Si suponemos que $W_i = N_i\cdot S_i$ y que el servidor está en equilibrio de flujo, entonces:
    \begin{equation*}
        R_i = \dfrac{S_i}{1-U_i}
    \end{equation*}
    \begin{proof}
        Aplicando que $R_i = W_i + S_i$ y la hipótesis, tenemos que:
        \begin{equation*}
            R_i - S_i = W_i = N_i\cdot S_i 
        \end{equation*}
        Si a la derecha usamos la Ley de Little, $N_i = \lm_i \cdot R_i$:
        \begin{equation*}
            R_i - S_i = N_i \cdot S_i = \lm_i \cdot R_i \cdot S_i \AstIg X_i\cdot R_i \cdot S_i
        \end{equation*}
        Donde en $(\ast)$ hemos usado que el servidor se encuentra en equilibrio de flujo, por lo que $\lm_i = X_i$. Si usamos ahora la Ley de la utilización: $U_i = X_i\cdot S_i$:
        \begin{equation*}
            R_i - S_i = X_i\cdot R_i\cdot S_i = U_i \cdot R_i
        \end{equation*}
        Y nos falta finalmente despejar $R_i$, para concluir que:
        \begin{equation*}
            R_i = \dfrac{S_i}{1-U_i}
        \end{equation*}
    \end{proof}
\end{prop}

En resumen:
\begin{itemize}
    \item Ley de la Utilización.
        \begin{equation*}
            U_i = X_i \cdot S_i
        \end{equation*}
    \item Ley del flujo forzado.
        \begin{equation*}
            X_i = X_0\cdot V_i
        \end{equation*}
    \item Relación de la utilización-demanda.
        \begin{equation*}
            U_i = X_0\cdot D_i
        \end{equation*}
    \item Ley de Little (solo en equilibrio de flujo).
        \begin{equation*}
            N_i = \lm_i \cdot R_i
        \end{equation*}
    \item Ley general del tiempo de respuesta.
        \begin{equation*}
            R_0 = \sum_{i=1}^{k} V_i\cdot R_i
        \end{equation*}
    \item Ley del tiempo de respuesta interactivo (para redes cerradas).
        \begin{equation*}
            R_0 = \dfrac{N_T}{X_0}-Z
        \end{equation*}
\end{itemize}

\subsection{Limites del tiempo de respuesta y de la productividad}
\begin{definicion}
    Decimos que un dispositivo es el cuello de botella de un servidor si es el que primero llega a saturarse (es decir, a tener el porcentaje de utilización al $100\%$). Si llamamos $b$ al índice del dispositivo del cuello de botella, como:
    \begin{equation*}
        U_b = X_0 \cdot D_b
    \end{equation*}
    Tenemos que una definición equivalente de dispositivo de cuello de botella es aquel con mayor tiempo de demanda.
\end{definicion}
Por esta definición, tenemos que:
\begin{align*}
    U_b &= \max_{i = 1, \ldots, k}\{U_i\} = V_b\cdot S_b\\
    D_b &= \max_{i = 1, \ldots, k}\{D_i\} = X_0\cdot U_b
\end{align*}

\begin{definicion}
    Diremos que el servidor está saturado si el dispositivo que es el cuello de botella del servidor lo está, es decir, si $U_b = 1$.
\end{definicion}

Estudiaremos ahora cómo determinar los límites de productividad máxima $X_0^{\text{max}}$ y tiempo de respuesta mínimo $R_0^{\text{min}}$ de un servidor, que dependerá si trabajamos en una red abierta o cerrada:

\subsubsection{Redes abiertas}
\begin{itemize}
    \item Para el cálculo de la productividad máxima $X_0^{\text{max}}$ parece lógico pensar que esta se dé cuando el servidor esté saturado, ya que en dicho caso estará atendiendo la máxima cantidad de trabajos por segundo, puesto que al terminar una tarea en un dispositivo este volverá nuevamente a estar ocupado por otra tarea, al estar su cola no vacía. Por tanto, si suponemos que $U_b = 1$ y aplicamos la ley de relación de utilización-demanda, vemos que:
        \begin{equation*}
            U_b = X_0 \cdot D_b \Longrightarrow X_0 = \dfrac{U_b}{D_b}
        \end{equation*}
        Y como estábamos suponiendo que $U_b = 1$ para conseguir la mayor productividad, tenemos que:
        \begin{equation*}
            X_0^{\text{max}} = \dfrac{1}{D_b}
        \end{equation*}
    \item Para el cálculo del tiempo de respuesta mínimo $R_0^{\text{min}}$, parece lógico pensar lo contrario: el tiempo de respuesta mínimo se dará cuando todas las colas estén vacías y llegue un proceso a la cola. En dicho caso, el tiempo de respuesta en cada cola será despreciable, quedando solo el tiempo que tarde el trabajo en cada dispositivo que visita. De esta forma:
        \begin{equation*}
            R_0 = \sum_{i=1}^{k} V_i\cdot R_i = \sum_{i=1}^{k} V_i\cdot (W_i + U_i) \AstIg \sum_{i=1}^{k} V_i \cdot U_i = \sum_{i=1}^{k} D_i
        \end{equation*}
        Donde en $(\ast)$ hemos usado que como todas las colas están vacías, $W_i = 0$ para todo $i = 1,\ldots,k$. Si definimos:
        \begin{equation*}
            D := \sum_{i=1}^{k}D_i
        \end{equation*}
        Tendremos que:
        \begin{equation*}
            R_0^{\text{min}} = D
        \end{equation*}
\end{itemize}

\subsubsection{Redes cerradas}
Como en redeces cerradas siempre tenemos equilibrio de flujo, nunca podrá estar el servidor saturado, por lo que hemos de distinguir casos con el fin de calcular la productividad máxima y tiempo de respuesta mínimo:

\begin{itemize}
    \item \underline{Suponiendo que hay muchos trabajos en la red ($N_T$ grande)}, entonces el servidor no llegará a estar saturado, pero podemos pensar que no le falta mucho para ello. Intuitivamente, podemos tomar $U_b \to 1$, por lo que estamos en un caso similar a la saturación en redes abiertas, y tendremos que:
        \begin{equation*}
            X_0 \to \dfrac{1}{D_b}
        \end{equation*}
        Para el tiempo de respuesta mínimo, recordamos que teníamos en redes cerradas que:
        \begin{equation*}
            R_0 = \dfrac{N_T}{X_0} - Z
        \end{equation*}
        Y como $N_T$ y $Z$ son fijos, vemos que el tiempo mínimo de respuesta se alcanza cuando se alcanza la productividad máxima del sistema, por lo que:
        \begin{equation*}
            R_0 = \dfrac{N_T}{X_0}-Z \to D_b\cdot N_T- Z
        \end{equation*}
    \item \underline{Suponiendo que hay pocos trabajos en la red ($N_T$ pequeño)}, entonces las colas del servidor estarán relativamente vacías, por lo que podemos pensar en que $W_i \to 0$ para $i = 1,\ldots,k$. En dicho caso:
        \begin{equation*}
            R_0 = \sum_{i=1}^{k} V_i\cdot (W_i+U_i) \to \sum_{i=1}^{k}V_i \cdot U_i = D
        \end{equation*}
        Y como es una red cerrada, seguimos teniendo que:
        \begin{equation*}
            R_0 = \dfrac{N_T}{X_0} - Z \Longrightarrow X_0 = \dfrac{N_T}{R_0 + Z}
        \end{equation*}
        De donde al igual que antes, la productividad máxima se obtendrá cuando el tiempo de respuesta sea mínimo, por lo que:
        \begin{equation*}
            X_0 = \dfrac{N_T}{R_0 + Z} \to \dfrac{N_T}{D+Z}
        \end{equation*}
\end{itemize}

Finalmente, como buscábamos cotas inferiores y cotas superiores, tendremos que:
\begin{align*}
    X_0^\text{max} &\leq \min\left\{\dfrac{1}{D_b}, \dfrac{N_T}{D+Z}\right\} \\
    R_0^\text{min} &\geq \max\{D_b\cdot N_T-Z, D\}
\end{align*}
Además, podremos pensar en el punto de equilibrio entre todos estos valores, es decir, cuando:
\begin{equation*}
    D = D_b\cdot N_T - Z \Longrightarrow N_T = \dfrac{D+Z}{D_b}
\end{equation*}
Al que llamaremos \underline{punto teórico de saturación del servidor}.
