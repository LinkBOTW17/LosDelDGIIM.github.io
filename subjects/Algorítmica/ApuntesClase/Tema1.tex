\chapter{Eficiencia de Algoritmos}
La asignatura se centrará en eficiencia basada en el tiempo de ejecución (no en la eficiencia en cuanto espacio, memoria usada por el programa).

Para calcular la eficiencia de un algoritmo, tenemos tres métodos:
\begin{itemize}
    \item Método empírico: donde se mide el tiempo real.
    \item Método teórico: donde se mide el tiempo esperado.
    \item Método híbrido: tiempo teórico evitando las constantes mediante resultados empíricos.
\end{itemize}

\begin{prop}[Principio de Invarianza]
Dadas dos implementaciones $I1$, $I2$ de un algoritmo, el tiempo de ejecución para una misma instancia de tamaño $n$, $T_{I1}(n)$ y $T_{I2}(n)$, no diferirá en más de una constante multiplicativa. Es decir, $\exists K > 0$ que verifica: 
\begin{equation*}
T_{I1}(n) \leq K \cdot T_{I2}(n)
\end{equation*}

\end{prop}principio
Por lo que podremos despreciar las constantes.
En un principio, se asumiriá que operaciones básicas como sumas, multiplicaciones, $\ldots$ serán de tiempo constante, salvo excepciones (por ejemplo, multiplicaciones de números de 100000 dígitos).

\begin{definicion}[Notación O]
Se dice que un algoritmo $A$ es de orden $O(f(n))$, donde $f$ es una función $f:\mathbb{N}\rightarrow \mathbb{R}^{+}$, cuando existe una implementación del mismo tamaño cuyo tiempo de ejecución $T_A(n)$ es menor igual que $K \cdot f(n)$, donde $K$ es una constante real positiva a partir de un tamaño grande $n_0$. Formalmente:
\begin{equation*}
A \text{\ es\ } O(f(n)) \Leftrightarrow \exists K \in \mathbb{R}^{+}, \exists n_0 \in \mathbb{N} \mid T_A(n) \leq K \cdot f(n)\quad\forall n \geq n_0
\end{equation*}
\end{definicion}
La notación $O$ nos permite conocer cómo se comportará el algoritmo en términos de eficiencia en instancias del caso pero del problema, como mucho, sabemos que el algoritmo no tardará más de $K \cdot f(n)$ en ejecutarse, en el peor de los casos.

Al decir que el algoritmo $A$ es de orden $O(f(n))$, decimos que siempre podemos encontrar una constante positiva $K$ que para valores muy grandes del caso $n$ (a partir de un $n_0$), el tiempo de ejecución del algoritmo siempre será inferior a $K \cdot f(n)$:
\begin{equation*}
T_A(n) \leq K \cdot f(n)
\end{equation*}

Ejemplos de órdenes de eficiencia son:
\begin{itemize}
    \item Constante, $O(1)$.
    \item Logarítmico, $O(\log(n))$.
    \item Lineal, $O(n)$.
    \item Cuadrático, $O(n^2)$.
    \item Exponencial, $O(a^n)$.
    \item $\vdots$
\end{itemize}

\begin{prop}[Principio de comparación]\label{prop:comparacion}
Para saber si dos órdenes $O(f(n))$ y $O(g(n))$ son equivalentes o no, aplicamos las siguientes reglas:
\begin{gather*}
O(f(n)) \equiv O(g(n)) \Leftrightarrow \lim_{n \to \infty} \dfrac{f(n)}{g(n)} \rightarrow K \in \mathbb{R}^{+}\\
O(f(n)) > O(g(n)) \Leftrightarrow \lim_{n \to \infty} \dfrac{f(n)}{g(n)} \rightarrow \infty\\
O(f(n)) < O(g(n)) \Leftrightarrow \lim_{n \to \infty} \dfrac{f(n)}{g(n)} \rightarrow 0
\end{gather*}
Entendiendo que un órden es menor que otro si es mejor, es decir, más rápido en el caso asintótico.
\end{prop}

\begin{ejemplo}
Si tenemos dos algoritmos $A$ y $B$ con órdenes de eficiencia $O(n^2)$ y $O((4n+1)^2+n)$ respectivamente, tratamos de ver qué algoritmos es más eficiente:
\begin{equation*}
\lim_{n\to \infty} \dfrac{f(n)}{g(n)} = \lim_{n\to\infty}\dfrac{n^2}{(4n+1)^2+n)} = \lim_{n\to\infty}\dfrac{n^2}{(16n^2 +1+2\cdot 4n\cdot 1)+n} = \lim_{n\to\infty}\dfrac{1}{16}
\end{equation*}
Gracias a la Proposición~\ref{prop:comparacion}, tenemos que los algoritmos $A$ y $B$ son equivalentes.
\end{ejemplo}

\begin{ejemplo}
En esta ocasión, tenemos a dos algoritmos $A$ y $B$ con órdenes de eficiencia de $O(2^n)$ y $O(3^n)$, respectivamente.
\begin{equation*}
\lim_{n\to\infty}\dfrac{f(n)}{g(n)} = \lim_{n\to\infty}\dfrac{2^n}{3^n}=\lim_{n\to\infty}\left(\dfrac{2}{3}\right)^n = 0
\end{equation*}
Por la Proposición~\ref{prop:comparacion}, $A$ es más eficiente que $B$.
\end{ejemplo}

\begin{ejemplo}
El algoritmo $A$ tiene una eficiencia $O(n)$ y el algoritmo $B$ tiene una eficiencia de $O(n\log(n))$. Buscamos cuál es más eficiente.
\begin{equation*}
\lim_{n\to\infty}\dfrac{f(n)}{g(n)}=\lim_{n\to\infty}\dfrac{n}{n\log(n)}=\lim_{n\to\infty}\dfrac{1}{\log(n)} = 0
\end{equation*}
Por lo que $A$ es más eficiente que $B$, por la Proposción~\ref{prop:comparacion}.
\end{ejemplo}

\begin{ejemplo}
Disponemos de dos algoritmos, $A$ y $B$ con órdenes de eficiencia $O((n^2+29)^2)$ y $O(n^3)$ respectivamente. Intuimos que $B$ es más eficiente que $A$ pero queremos probarlo.
\begin{equation*}
\lim_{n\to\infty}\dfrac{f(n)}{g(n)} = \lim_{n\to\infty}\dfrac{(n^2+29)^2}{n^3} = \infty
\end{equation*}
Gracias a la Proposción~\ref{prop:comparacion}, hemos probado lo que esperábamos; $B$ es más eficiente que $A$.
\end{ejemplo}

\begin{ejemplo}
Se quiere probar que $O(\log(n))$ es más eficiente que $O(n)$.
\begin{equation*}
\lim_{n\to\infty}\dfrac{f(n)}{g(n)} = \lim_{n\to\infty}\dfrac{n}{\log(n)} = \lim_{n\to\infty}\dfrac{10^n}{n} = \infty
\end{equation*}
Por la Proposción~\ref{prop:comparacion}, lo acabamos de probar.
\end{ejemplo}

\begin{ejemplo}
Se quiere dar un ejemplo de que el órden de eficiencia de los logaritmos es equivalente sin importar la base de este. Podemos ver qué sucede con $O(\log_2(n))$ y con $O(\log_3(n))$:
\begin{equation*}
\lim_{n\to\infty}\dfrac{\log_3(n)}{\log_2(n)} = \lim_{n\to\infty}\dfrac{\ln(2)}{\ln(3)}
\end{equation*}
Por lo que ambos algoritmos tienen el mismo órden de eficiencia.
\end{ejemplo}

\begin{definicion}[Notación Omega]
Se dice que un algoritmo $A$ es de orden $\Omega(f(n))$, donde $f$ es una función $f:\mathbb{N}\rightarrow \mathbb{R}^{+}$, cuando existe una implementación del mismo tamaño cuyo tiempo de ejecución $T_A(n)$ es mayor igual que $K \cdot f(n)$, donde $K$ es una constante real positiva a partir de un tamaño grande $n_0$. Formalmente:
\begin{equation*}
A \text{\ es\ } \Omega(f(n)) \Leftrightarrow \exists K \in \mathbb{R}^{+}, \exists n_0 \in \mathbb{N} \mid T_A(n) \geq K \cdot f(n)\quad\forall n > n_0
\end{equation*}
La notación $\Omega$ nos permite conocer cómo se comportará el algoritmo en términos de eficiencia en instancias del caso mejor del problema.
Como poco, sabemos que el algoritmo no t ardará menos de $K\cdot f(n)$ en ejecutarse, en el mejor de los casos.
\end{definicion}

\begin{definicion}[Notación Theta]
Se dice que un algoritmo $A$ es de orden exacto $\theta(f(n))$, donde $f$ es una función $f:\mathbb{N}\rightarrow \mathbb{R}^{+}$, cuando existe una implementación del mismo tamaño cuyo tiempo de ejecución $T_A(n)$ es igual que $K \cdot f(n)$, donde $K$ es una constante real positiva a partir de un tamaño grande $n_0$. En este caso, el algoritmo es simultáneamente de orden $O(f(n))$ y $\Omega(g(n))$.
\begin{equation*}
A \text{\ es\ } \theta(f(n)) \Leftrightarrow \exists K \in \mathbb{R}^{+}, \exists n_0 \in \mathbb{N} \mid T_A(n) = K \cdot f(n)\quad\forall n > n_0
\end{equation*}
\end{definicion}

\subsubsection{Propiedades}
A continuación, vemos algunas propiedades de las notaciones anteriormente vistas:
\begin{description}
    \item Reflexiva.
\begin{equation*}
f(n) \in O(f(n))
\end{equation*}
También para las notaciones $\Omega$ y $\theta$.

\item Simétrica.
\begin{equation*}
f(n) \in \theta(g(n)) \Leftrightarrow g(n) \in \theta(f(n))
\end{equation*}

\item Suma.

Si $T_1(n) \in O(f(n))$ y $T_2(n) \in O(g(n))$. Entonces:
\begin{equation*}
T_1(n) + T_2(n) \in O(\max(f(n), g(n)))
\end{equation*}

\item Producto.

Si $T_1(n) \in O(f(n))$ y $T_2(n) \in O(g(n))$. Entonces:
\begin{equation*}
T_1(n) \cdot T_2(n) \in O(f(n) \cdot g(n))
\end{equation*}

\item Regla del máximo.
\begin{equation*}
O(f(n)+g(n)) = \max(O(f(n)), O(g(n)))
\end{equation*}

\item Regla de la suma.
\begin{equation*}
O(f(n)+g(n)) = O(f(n))+O(g(n))
\end{equation*}

\item Regla del producto.
\begin{equation*}
O(f(n)\cdot g(n)) = O(f(n))\cdot O(g(n))
\end{equation*}

\end{description}

Puede suceder que el tamaño del problema no depende de una única variable $n$, sino de varias.
En estos casos, se analiza de igual forma que en el caso de una variable, pero con una función de varias variables. Conocida una función $f:\mathbb{N}\times\mathbb{N}\rightarrow \mathbb{R}^{+}$:
\begin{equation*}
A \text{\ es\ } O(f(n,m)) \Leftrightarrow \exists K \in \mathbb{R}^{+} \mid T_A(n,m) \leq K \cdot f(n,m)\quad \forall n,m\in \mathbb{N}
\end{equation*}

\begin{ejemplo}
El órden de eficiencia del algoritmo canónico (el que todos conocemos) de suma de matrices $n\times m$ es de órden $O(n\cdot m)$.
\end{ejemplo}

\section{Análisis de algoritmos}
El primer paso a la hora de determinar la eficiencia de un algoritmo es identificar qué parámetro determina el tamaño del problema ($n$).
Posteriormente, tenemos que tener claro como se analiza cada estructura del código:
\begin{enumerate}
    \item Operaciones elementales.
    \item Secuencias de sentencias.
    \item Sentencias condicionales.
    \item Sentencias repetitivas.
    \item Llamadas a funciones no recursivas.
    \item Llamadas a funciones recursivas.
\end{enumerate}

\subsubsection{Sentencias simples u operaciones elementales}
Son aquellas instrucciones cuya ejecución no depende del tamaño del caso, como por ejemlo:
\begin{itemize}
\item Operaciones matemáticas básicas (sumas, multiplicaciones, $\ldots$).
\item Comparaciones.
\item Operaciones booleanas.
\end{itemize}

Su tiempo de ejecución está acotado superiormente por una constante. Su órden es $O(1)$.

\subsubsection{Secuencias de sentencias}
Constan de la ejecución de secuencias de bloques de sentencias:
\begin{listing}
    \begin{minted}[linenos,xleftmargin=2cm]{c++}
Sentencia_1;
Sentencia_2;
// etc
Sentencia_r;
    \end{minted}
\end{listing}

Suponiendo que cada sentencia $i$ tiene eficiencia $O(f_i(n))$, la eficiencia de la secuencia se obtiene mediante las reglas de la suma y del máximo:
\begin{equation*}
O(f_1(n) + f_2(n) + \cdots + f_r(n)) = \max\left[O(f_1(n)), O(f_2(n)), \ldots, O(f_r(n))\right]
\end{equation*}

\begin{ejemplo}
Un ejemplo que puede parecer confuso es el siguiente:
\begin{listing}
    \begin{minted}[linenos,xleftmargin=2cm]{c++}
if(n == 10){
    for(int i = 0; i < n; i++){
        cout << "Hola" << endl;
    }
}
    \end{minted}
\end{listing}

En este caso, se trata de un código de orden $O(1)$, ya que es para un valor fijo de $n$, $10$. 
\end{ejemplo}
