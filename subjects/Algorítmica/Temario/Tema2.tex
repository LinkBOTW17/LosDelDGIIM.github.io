\chapter{Algoritmos Divide y Vencerás}
Dado un problema $P$, lo dividimos en subproblemas que han de ser del mismo tipo: $P = \{P_i\}_{i\in I}$. Encontramos las soluciones de todos estos problemas: $S_i \mid i \in I$ y con estas, las juntamos de forma adecuada para obtener la solución al problema $P$: $S = \{S_i\}_{i \in I}$. Notemos que podemos hacerlo de forma recursiva, podemos aplicar la técnica de divide y vencerás a los subproblemas. Debemos fijar un caso base, donde el problema sea suficientemente pequeño como para resolverlo.

Ejemplos de algoritmos que implementan la búsqueda binaria son Quicksort, Mergesort, Búsqueda Binaria, $\ldots$

Problemas como el de las Torres de Hanoi pueden resolverse mediante esta técnica de resolución de problemas.

Tratamos cuestiones importantes:
\begin{itemize}
    \item Cómo descomponer un problema en subproblemas.
    \item Cómo resolver subproblemas.
    \item Cómo combinar las soluciones.
    \item ¿Mereció la pena aplicar esta técnica?
\end{itemize}

Para responder al último punto observemos el siguiente ejemplo, que trata un problema de forma genérica.
\begin{ejemplo}
    Supongamos un problema $P$ de tamaño $n$ que sabemos que puede resolverse con un algoritmo (básico) $A$, con:
    \begin{equation*}
        t_A(n) \leq cn^2 
    \end{equation*}

    Dividimos $P$ en 3 subproblemas de tamaño $\frac{n}{2}$, isneod cada uno de ellos del mismo tipo que $A$ y consumiendo un tiempo lineal la combinación de sus soluciones: $t(n) \leq dn$.
    Tenemos, por tanto, un nuevo algoritmo $B$, Divide y Vencerás, que consumirá un tiempo de:
    \begin{equation*}
        t_B(n) = 3t_A\left(\dfrac{n}{2}\right)+t(n) \leq 3t_A\left(\dfrac{n}{2}\right) + dn \leq \left(\dfrac{3c}{4}\right)n^2 + dn
    \end{equation*}
    $B$ tiene un tiempo de ejecución mejor que el algoritmo $A$, ya que reduce la constante oculta.

    Si volvemos a reducir el tamaño del subproblema, obtenemos un nuevo algoritmo $C$, que tendría un tiempo:
    \begin{equation*}
        t_c(n) = \left\{ \begin{array}{ll}
            t_A(n) & \text{si\ } n \leq n_0 \\
            3t_C\left(\dfrac{n}{2}\right) + t(n) & \text{si\ } n > n_0
        \end{array}\right.
    \end{equation*}
    $C$ es mejor en eficiencia que los algoritmos $A$ y $B$ ($t_c(n) \leq bn^{1.58}$). 
\end{ejemplo}
Al valor $n_0$ se le denomina umbral y al algoritmo que se ejecuta debajo de este umbral, \verb|ad hoc| son fundamentales para que la técnica funcione bien.

Requisitos lógicos para usar Divide y Vencerás:
\begin{itemize}
    \item El problema se tiene que poder reducir a subproblemas del mismo tipo.
    \item Los subproblemas han de poder resolverse de manera independiente.
    \item Las soluciones de los subproblemas no deben afectar entre sí, no debe existir solapamiento entre subproblemas.
    \item Ha de poderse juntar las soluciones de los subproblemas para resolver el problema.
\end{itemize}
Una forma matemática de entender el punto 3 es decir que los subproblemas deben formar una \ul{partición} del problema.

Para que la técnica sea eficiente:
\begin{itemize}
    \item Selección cuidadosa de cuando usar el algoritmo \verb|ad hoc|.
    \item El número de subproblemas debe ser razonablemente pequeño (para no reducir mucho la eficiencia).
    \item Los subproblemas deben tener el menor tamaño posible.
\end{itemize}

Normalmente, al aplicar Divide y Vencerás nos encontraremos con eficiencias del estilo:
\begin{equation*}
    T(n) = \left\{ \begin{array}{ll}
            t(n) & \text{si\ } n \leq n_0\\
            IT\left(\dfrac{n}{b}\right) + G(n) & \text{si\ }n > n_0
    \end{array}\right.
\end{equation*}
Donde $I$ es el número de subproblemas, $\dfrac{n}{b}$ el tamaño de estos y:
\begin{equation*}
    G(n) = D(n) + C(n)
\end{equation*}
Con $D(n)$ el tiempo de dividir el problema en subproblemas y $C(n)$ el tiempo de combinación.
$t(n)$ era el tiempo del algoritmo \verb|ad hoc|.


\begin{ejemplo}
    Dado un vector de elementos, determinar la posición que ocupa el máximo del mismo.

    Proponemos como solución el siguiente código:

\begin{listing}[H]
    \begin{minted}[xleftmargin=2cm]{c++}
        int Maximo(int* v, int inf, int sup){
            if(sup == inf) return v[inf];
            else{
                int med = (inf+sup)/2;
                int izda = Maximo(v, inf, med);
                int dcha = Maximo(v, med+1, sup);

                return max(izda, dcha);
            }
        }
    \end{minted}
\end{listing}

Con un tiempo de ejecución de:
\begin{equation*}
    T(n) = 2T\left(\dfrac{n}{2}\right) +1 \in O(n)
\end{equation*}

Otra solución sería:
\begin{listing}[H]
    \begin{minted}[xleftmargin=2cm]{c++}
        int Maximo2(int* v, int inf, int sup){
            if(sup == inf) return v[inf];
            else{
                int izda = Maximo2(v, inf, sup);

                return max(izda, sup);
            }
        }
    \end{minted}
\end{listing}

En este caso:
\begin{equation*}
    T(n) = T(n-1)+1 \in O(n)
\end{equation*}

Los dos del mismo orden, pero encontramos un problema entre uno y otro: el número de llamadas recursivas:
\begin{itemize}
    \item \verb|Maximo2| Realiza $n$ llamadas recursivas, pero el tamaño de la pila ocupado es de $n$.
    \item \verb|Maximo| Realiza $n$ llamadas recursivas, pero el tamaño de la pila es $\log n$.
\end{itemize}
El número de los elementos de la pila de \verb|Maximo| puede razonarse dibujándolo con un árbol.

Por tanto, el primer algoritmo que planteamos era mejor ya que usa menos pila (evitando su desbordamiento).

\end{ejemplo}
\begin{observacion}
    Notemos que este ejemplo ha sido un caso instructivo, es más eficiente resolverlo de la forma canónica que aplicando Divide y Vencerás.
\end{observacion}

\begin{ejercicio*}
    Un camión va desde Granada a Moscú siguiendo una ruta determinada. La capacidad del tanque de combustible es $C$ y conocemos el consumo por kilómetros del camión. Conocemos las gasolineras que se encuentran en la ruta y la distantica entre ellas. Se pide minimizar el número de paradas que hace el conductor.
\end{ejercicio*}

\section{Ejemplos de Divide y Vencerás}
\subsection{Multiplicación de Enteros Grandes}
Comprobar si un número es primo requiere muchas multiplicaciones de enteros grandes (desde dos millones de dígitos). Útil en criptografía. Para resolver este problema, debemos implementar algoritmos efiientes capaces de trabajar con estos valores. Nos encontramos con:
\begin{itemize}
    \item Método clásico (el que aprendimos en infantil).
    \item Método basado en Divide y Vencerás.
\end{itemize}

\begin{description}
    \item [Método clásico]~\\
Multiplicar dos dígitos de $n$ entre sí por el método clásico tiene un costo de ($n\cdot n = n^2$ multiplicaciones más $n$ desplazamientos más $n\cdot 2n$ sumas) $n^2 + n + 2n^2$. Tratamos de reducir su costo mediante Divide y Vencerás.

    \item [Divide y Vencerás sencillo]~\\
    Aplicando Divide y Vencerás, obtenemos el siguiente algoritmo:

    Dados dos números $X = 12345678$ e $Y = 24680135$, consideramos:
    \begin{gather*}
        x_i = 1234 \qquad x_d = 5678 \\
        X = x_i \cdot 10^4 + x_d
    \end{gather*}
    \begin{gather*}
        y_i = 2468 \qquad y_d = 0135 \\
        Y = y_i \cdot 10^4 + y_d
    \end{gather*}
    Y combinamos:
    \begin{align*}
        X \cdot Y &= (x_i \cdot 10^4 + x_d)(y_i \cdot 10^4 + y_d)\\
        &= x_i \cdot y_i \cdot 10^8 + (x_i \cdot y_d + x_d \cdot y_i) \cdot 10^4 + x_d \cdot y_d
    \end{align*}

    Que, de forma general:
    \begin{align*}
        X &= x_i \cdot 10^{\nicefrac{n}{2}} + x_d\\
        Y &= y_i \cdot 10^{\nicefrac{n}{2}} + y_d\\
        X \cdot Y &= (x_i \cdot y)\cdot 10^n + (x_i \cdot y_d + x_d \cdot y_i) \cdot 10^{\nicefrac{n}{2}} + x_d \cdot y_d
    \end{align*}

    De eficiencia:
    \begin{equation*}
        T(n) = 4T\left(\dfrac{n}{2}\right) + cn \in O\left(n^{\log_2 4}\right) = O\left(n^2\right)
    \end{equation*}

    Este lo vemos en el siguiente pseudocódigo:
        \begin{listing}[H]
            \begin{minted}[xleftmargin=2cm]{c++}
Funcion DVbasico(X, Y, n){
    if P chico return X * Y;
    else{
        // Dividir
        Obtener xi, xd, yi, yd;

        z1 = DVbasico(xi, yi, n/2);
        z2 = DVbasico(xi, yd, n/2);
        z3 = DVbasico(xd, yi, n/2);
        z4 = DVbasico(xd, yd, n/2);

        // Combinar
        aux = Sumar(z2, z3);
        z1 = DesplazarDcha(z1, n);
        aux = DesplazarDcha(aux, n/2);
        z = Sumar(z1, aux, z4);

        return z;
    }
}
            \end{minted}
        \end{listing}


    Sin embargo, podemos seguir mejorando el algoritmo.

    \item [Divide y Vencerás mejorado]~\\
        Observemos que el cuello de botella del algoritmo anterior está en el número de multiplicaciones, que es de tamaño $\nicefrac{n}{2}$. Por tanto, para mejorar la eficiencia, necesitamos reducir el número de multiplicaciones que hacemos. Podemos plantear el siguiente algoritmo, donde dados dos números $X$ e $Y$ y divididos entre $x_i$, $x_d$, $y_i$ e $y_d$; definimos:
        \begin{align*}
            r &= (x_i + x_d) \cdot (y_i + y_d) = (x_i \cdot y_i) + (x_i \cdot y_d + x_d \cdot y_i) + x_d \cdot y_d \\
            p &= x_i \cdot y_i \\
            q &= x_d \cdot y_d
        \end{align*}

        Luego se tiene que:
        \begin{equation*}
            x_i \cdot y_d + x_d \cdot y_i = r - p - q
        \end{equation*}
        
        Y podemos calcular que:
        \begin{equation*}
            X \cdot Y = p \cdot 10^n + (r-p-q) \cdot 10^{\nicefrac{n}{2}} + q
        \end{equation*}

        Donde tenemos una multiplicación de tamaño $n$. Podemos verlo en pseudocódigo:
        \begin{listing}[H]
            \begin{minted}[xleftmargin=2cm]{c++}
FuncionDV (X, Y, n){
    if P chico return X * Y;
    else{
        // Dividir
        Obtener xi, xd, yi yd;

        s1 = Sumar(xi, xd);
        s2 = Sumar(yi, yd);
        p = DV (xi, yi, n/2);
        q = DV (xd, yd, n/2);
        r = DV (s1, s2, n/2);
        
        // Combinar
        aux = Sumar(r, -p, -q);
        p = DesplazarDcha(p, n);
        aux = DesplazarDcha(aux, n/2);
        z = Sumar(p, aux, q);

        return z;
    }
}
            \end{minted}
        \end{listing}

        De eficiencia:
        \begin{equation*}
            T(n) = 3T\left(\dfrac{n}{2}\right) + O(n) \in O\left(n^{\log_2 3}\right) \approx O(n^{1.585})
        \end{equation*}
\end{description}

\subsection{Búsqueda binaria}
La búsqueda binaria es un algoritmo de búsqueda de un elemento en un vector \emph{ordenado} de tamaño $n$. Esta consiste en coger el elemento del medio del vector (supongamos que está en la posición $k$) y comprobar si es o no el elemento deseado. Si lo es, hemos terminado; si no lo es:
\begin{itemize}
    \item Si el elemento del medio es menor que el deseado, repetimos el procedimiento con el subvector que va desde $k+1$ hasta $n$.
    \item Si el elemento del medio es mayor que el deseado, repetimos el procedimiento con el subvector que va desde $0$ hasta $k-1$.
\end{itemize}
Se trata de un algoritmo de eficiencia $O(\log n)$.

\begin{ejercicio*}
    Hágase la demostración del orden de eficiencia de la búsqueda binaria.
\end{ejercicio*}

\subsection{Multiplicación de matrices}
Dadas dos matrices $A = (a_{ij})_{ij}$ y $B = (b_{ij})_{ij}$ del mismo tamaño, $n \times m$, tratamos de multiplicar $A$ por $B$ para obtener una nueva matriz $C = (c_{ij})_{ij}$. La multiplicación de matrices se define como:
\begin{equation*}
    c_{ij} = \sum_{k = 1}^n \left( a_{ik} \cdot b_{kj} \right)
\end{equation*}
Para todo índice $(i,j)$ de cada elemento de la matriz $C$ de tamaño $n \times m$.

Implementando la fórmula, se puede ver claramente que es de orden (considerando $n = m$) $O(n^3)$. Para aplicar Divide y Vencerás, vamos a proceder como con la multiplicación de enteros:
\begin{equation*}
    \begin{pmatrix}
        r & s \\
        t & u
        \end{pmatrix} = C = A \cdot B = \begin{pmatrix}
        a & b \\
        c & d
        \end{pmatrix} \begin{pmatrix}
        e & g \\
        f & h
        \end{pmatrix} = \begin{pmatrix}
        ae+bf & ag+bh \\
        ce + df & cg + dh
    \end{pmatrix}
\end{equation*}

Esta fórmula también es cierta cuando $a, \ldots, h$ son matrices. Por tanto, mediante esta fórmula podemos dividir el producto de dos matrices $n \times n$ en 8 subproblemas de tamaños $\nicefrac{n}{2}$. Por lo que tendríamos una eficiencia de tamaño (recordemos que la suma de matrices es de orden $n^2$):
\begin{equation*}
    T(n) = 8T\left(\dfrac{n}{2}\right) + cn^2 \in O\left(n^{\log_2 8}\right) = O(n^3)
\end{equation*}

\subsubsection{Algoritmo de Strassen}
Dado el problema anterior:
\begin{equation*}
    \begin{pmatrix}
        r & s \\
        t & u
        \end{pmatrix} = C = A \cdot B = \begin{pmatrix}
        a & b \\
        c & d
        \end{pmatrix} \begin{pmatrix}
        e & g \\
        f & h
        \end{pmatrix} = \begin{pmatrix}
        ae+bf & ag+bh \\
        ce + df & cg + dh
    \end{pmatrix}
\end{equation*}

Ahora, definimos:
\begin{align*}
    P &= (a+d)(e+h) \\
    Q &= (c+d)e \\
    R &= a(g-h) \\
    S &= d(f-e) \\
    T &= (a+b)h \\
    U &= (c-a)(e+g) \\
    V &= (b-d)(f+h)
\end{align*}

De esta forma se tiene que:
\begin{align*}
    r &= P + S - T + V \\
    s &= R + T \\
    t &= Q + S \\
    u &= P + R - Q + U
\end{align*}
Y sólo se necesitan 7 multiplicaciones y 18 sumas y restas, en lugar de 8 multiplicaciones y 4 sumas.

La eficiencia de este algoritmo es de:
\begin{equation*}
    T(n) = 7T\left(\dfrac{n}{2}\right) + cn^2 \in O\left(n^{\log_2 7}\right) \approx O(n^{2.81})
\end{equation*}

\section{Umbrales}
Por el método de Divide y Vencerás es natural que queramos ejecutar algoritmos de mayor orden de eficiencia para tamaños de problema pequeños (porque rinden mejor) y que para el resto de tamaños se ejecute un algoritmo de mayor eficiencia asintótica. Este tamaño límite (el último tamaño en el que se ejecuta el algoritmo de orden de eficiencia mayor) recibe el nombre de \ul{umbral}. De esta forma, el algoritmo que se ejecuta para tamaños del problema ($n$) menores que el umbral ($n \leq n_0$), se denomina algoritmo \verb|ad hoc|.

Lo más difícil relativo al umbral es su elección: es difícil hablar del umbral $n_0$ si no tratamos con implementaciones, ya que gracias a ellas conocemos las constantes ocultas que nos permiten afinar el cálculo de dicho valor. No hay restricciones sobre el tamaño que debe tener el umbral: puede que el mejor umbral sea tal que siempre se ejecute el algoritmo \verb|ad hoc|; o puede que el umbral sea tal que siempre se ejecute el algoritmo de mejor orden asintótico. 

\subsection{Selección de umbrales}
Podemos encontrar el umbral de un algoritmo en el que vamos a usar Divide y Vencerś y el \verb|ad hoc| de distintos métodos:

\subsubsection{Método empírico}
Implementamos ambos algoritmos, el básico (o \verb|ad hoc|) y el Divide y Vencerás. Ejecutamos el problema para varios valores de $n$, obteniendo las gráficas de los dos algoritmos. Fijarnos en el valor de la abscisa del punto de corte de las gráficas y dicho valor será el umbral. Posteriormente, eligiremos obviamente a cada lado del umbral los algoritmos de menor tiempo de ejecución.

\subsubsection{Método teórico}
El método es similar: obtenemos las expresiones de los tiempos de ambos algoritmos (sin despreciar constantes) y analizamos las gráficas, buscando algún punto de corte que será el umbral.

\subsubsection{Método híbrido}
Calculamos las constantes ocultas mediante el enfoque empírico. Calculamos el umbral igualando teóricamente ambas gráficas. Tenemos ya candidado a umbral. Finalmente, probamos valores alrededor de dicho umbral, para determinar el umbral óptimo.

\section{Algoritmos de ordenación}
A la hora de clasificar los algoritmos de ordenación, encontramos:
\begin{enumerate}
    \item Algoritmos lentos (de orden $\Theta(n^2)$ y ordenación por cambio):
        \begin{enumerate}
            \item Burbuja.
            \item Inserción.
            \item Selección.
        \end{enumerate}
        Se trata e algoritmos más sencillos cuyo comportamiento es malo para tamaños muy grandes.
    \item Algoritmos rápidos (de orden $\Theta(n\log n)$):
        \begin{enumerate}
            \item Heapsort.
            \item Mergesort.
            \item Shellsort.
            \item Quicksort.
        \end{enumerate}
        Son algoritmos más complejos que se coomportan bien cuando el tamaño del problema es grande.
\end{enumerate}

% // TODO: especificar cada algoritmo

\subsection{Burbuja} 
Burbuja (\emph{Bubble sort}) es un algoritmo que trata de ordenar los elementos de un vector de la siguiente forma: compara los dos primeros elementos del vector.
\begin{itemize}
    \item Si están ordenados, pasa a la siguiente pareja de elementos del vector (formada por el segundo y tercer elemento).
    \item Si no están ordenados, los intercambia y pasa a la siguiente pareja de elementos del vector (formada por el segundo y tercer elemento).
\end{itemize}
Se repite este procedimiento hasta llegar a los dos últimos elementos del vector. Una vez realizado este procedimiento, volvemos a repetirlo sobre el vector, hasta que este esté ordenado (sabremos que el vector está ordenado cuando al recorrerlo mediante este procedimiento, no se realice ningún intercambio).
    \begin{minted}[xleftmargin=1cm]{c++}
void bubbleSort(int* v, int N){
    int temp;
    bool ordenado = false;

    int i = 1; 
    while(!ordenado && i < N){
        ordenado = true;

        for(int j = 0; j < N - i; j++){
            if(v[j] > v[j+1]){
                temp = v[j];
                v[j] = v[j+1];
                v[j+1] = temp;

                ordenado = false;
            }
        }

        i++;
    }
}
    \end{minted}

\subsection{Inserción} 
Inserción (\emph{Insertion sort}) es un algoritmo de ordenación que trata de ordenar los elementos de un vector de una forma natural para el ser humano. El procedimiento es el siguiente. Se toma un elemento del vector (por ejemplo, el primero), al ser sólo un elemento, se trata de un conjunto ordenado. Continuamos cogiendo otro elemento del vector (el segundo):
\begin{itemize}
    \item Si es mayor que el primer elemento, lo colocamos detrás.
    \item Si es menor que el primer elemento, lo colocamos delante de este.
\end{itemize}
Continuamos con el siguiente elemento del vector (el tercero):
\begin{itemize}
    \item Si es mayor que el segundo, lo colocamos detrás.
    \item Si es menor que el segundo y mayor que el primero, lo colocamos en medio. 
    \item Si es menor que ambos, lo colocamos al inicio.
\end{itemize}
Repitiendo los pasos, consiste en construir un subconjunto del vector de tamaño $k$ de elementos ordenados, de forma que cogemos un nuevo elemento del vector y tratamos de colocarlo en el conjunto de tamaño $k$, obteniendo un subconjunto ordenado de tamaño $k+1$ y repetir el proceso hasta llegar a $n$.
    \begin{minted}[xleftmargin=1cm]{c++}
void insertionSort(int* v, int N){
    int i, j, temp;

    for(i = 1; i < N; i++){
        temp = v[i];
        j = i - 1;

        while(j >= 0 && temp <= v[j]){
            v[j+1] = v[j];
            j--;
        }

        v[j+1] = temp;
    }
}
    \end{minted}

\subsection{Selección} 
Selección (\emph{Selection sort}) es otro algoritmo de ordenación que junto con Inserción constituyen los dos algoritmos más intuitivos (más naturales) del ser humano. Dado un vector de $n$ elementos, buscamos el mínimo del vector. Posteriormente, colocamos el mínimo en la posición inicial y, dado un vector de $n-1$ elementos restantes (todos salvo el primero), buscmos el mínimo y lo colocamos detrás del mínimo anterior. Repetimos el proceso $n-1$ veces y obtenemos un vector ordenado.
    \begin{minted}[xleftmargin=1cm]{c++}
void selectionSort(int* v, int N){
    int i, j, pos_min, temp;

    for(i = 0; i < N - 1; i++){
        // buscamos el mínimo
        pos_min = i;
        for(j = i + 1; j < N; j++){
            if(v[j] < v[pos_min]){
                pos_min = j;
            }
        }

        // intercambiamos con el primero
        temp = v[pos_min];
        v[pos_min] = v[i];
        v[i] = temp;
    }
}
    \end{minted}

\subsection{Mergesort}
O también llamado ordenación por mezcla, consiste en dado un vector de $n$ componentes, dividirlo en dos vectores de $\nicefrac{n}{2}$, de forma que ordenamos los dos subvectores y combinamos ambos en un único vector (el vector ya ordenado), sabiendo que los dos subvectores ya se encuentran ordenados (cosa que sabemos hacer). Este proceso puede hacerse de forma recursiva, aplicándolo varias veces sobre el mismo vector.

Podemos encontrar variaciones de este algoritmo, como no dividir por $\nicefrac{n}{2}$, sino por cualquier otro tamaño dependiente de $n$. Por ejemplo, $\nicefrac{n}{k}$ con $k$ entero.

\section{Ejercicios}
\subsection{Mediana de un vector}
\begin{ejercicio*}
    ¿Cómo calculamos la mediana de un vector algorítmicamente?

    % Usar partición de quicksort
\end{ejercicio*}

\subsection{Problema de los puntos más cercanos}
\begin{ejercicio*}
    Tenemos un vector con una secuencia de valores y queremos saber los dos valores más cercanos.

    \begin{enumerate}
        \item Una primera aproximación es calcular para cada valor del vector las distancias y buscar la mínima. Eficiencia $O(n^2)$.
        \item Otra solución es ordenar los datos y ahora recorrer linealmente el vector para buscar la distancia mínima. Eficiencia $O(n\log n)$.
        \item Mediante la técnica divide y vencerás sobre el vector del primer punto no vemos cómo resolverlo.
        \item Si aplicamos divide y vencerás sobre el vector ordenado, sí que podemos resolver el problema (elegimos o la menor distancia a la izquierda del corte, o la menor a al derecha, o justo los que separamos a cortar). Tenemos un coste de $T(n) = 2T(\nicefrac{n}{2})+1$. Otra vez eficiencia $O(n\log n)$.
    \end{enumerate}
\end{ejercicio*}

\begin{ejercicio*}
    Tenemos un conjunto de puntos repartidos a lo largo de un plano y queremos saber cuales son los dos puntos que equidistan entre sí menos que cualquier dos otros.

    \begin{enumerate}
        \item Una primera aproximación es calcular para cada valor del vector de puntos las distancias y buscar la mínima. Eficiencia $O(n^2)$.
        \item Otra aproximación es utilizando divide y vencerás: Buscamos una forma de partir los puntos en subproblemas. Nos damos cuenta de que si partimos por la mitad del plano obtenemos una distribución no muy buena de los puntos. Para una mejor aproximación, tratamos de dejar todos los puntos con ordenada menor que el valor medio de las ordenadas de todos los puntos y el resto a otro lado. De esta forma acabamos de dividir el problema en dos subproblemas del mismo tamaño. 

            Una vez resueltos los dos subproblemas, nos queda a un lado una distancia mínima de $a$ y al otro una distancia mínima de $b$. Lo que hacemos es coger $c = \min\{a, b\}$ y considerar una banda que definimos como: coger de los puntos de la derecha el punto más a la izquierda y poner una tolerancia de $c$ a la izquierda y del punto de la izquierda más a la derecha, poner una tolerancia de $c$ a la derecha.

        \begin{enumerate}
            \item A su vez, dentro de esta banda podemos compararlos todos con todos. Orden de $O(n^2)$.
            \item También, podemos ordenarlos en la otra coordenada y establecer otra tolerancia, una especie de bola donde estudiar qué puntos son los más cercanos. Orden de $O(n\log^2 n)$.
                Estos dos órdenes de eficiencia no son satisfactorios, buscamos uno mejor.
        \end{enumerate}
        \item Otra aproximación de Divide y Vencerás es:
            \begin{enumerate}
                \item Ordenar por las dos coordenadas todos los puntos en dos vectores. 
                \item Separar por una coordenada (como $x$) ambos conjuntos, obteniendo directamente $L_x$ y $R_x$ (izquierda según $x$ y derecha según $x$) y en orden lineal $L_y$ y $R_y$: que son respectivamente los puntos en $L_x$ y $R_x$ ordenados por coordenada $y$.
            \end{enumerate}
        \end{enumerate}
\end{ejercicio*}

\begin{ejercicio*}
    Dada una secuencia de números, definimos \ul{pico} al valor $i$ tal que $x[i-1] < x[i] > x[i+1]$ y \ul{valle} al valor $j$ tal que $x[j-1]>x[j]<x[j+1]$. Un pico $i$ es consecutivo a un valle $j$ si ningún valor entre $i$ y $j$ es pico o valle.

    \begin{enumerate}
        \item Dado un vector de enteros que primero es estrictamente creciente y luego estrictamente decreciente, encontrar el máximo del vector.

            Para ello, planteamos cortar por el del centro del vector y ver a sus vecinos: si el vecino de la derecha, aplicamos otra vez el algoritmo de la derecha (y si es por la izquierda, aplicarlo a la izquierda); hasta tener al menos 3 elementos.
    \end{enumerate}
\end{ejercicio*}
