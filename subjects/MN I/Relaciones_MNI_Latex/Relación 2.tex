\section{Resolución de Sistemas de Ecuaciones Lineales}

\begin{ejercicio}
   Determina el número de operaciones necesario para resolver un sistema de $n$ ecuaciones lineales con $n$ incógnitas mediante los siguientes métodos:

   \begin{enumerate}
       \item \underline{La regla de Cramer}

       \item \underline{El método de Gauss (sin elección de pivotes).}
   \end{enumerate}
\end{ejercicio}

\begin{ejercicio}
    Sea pretende resolver el sistema $Ax=b$ donde $A$ es la matriz
    $$A=\left( \begin{array}{ccc}
        -3 & a & -3 \\
         -4 & 3 & -4 \\
         2 & 7 & -4
    \end{array}\right)$$
    y $b=(a,3,1)^T$, donde $A\in \bb{R}$ es un parámetro.

    \begin{enumerate}
        \item Determina para qué valores del parámetro $a$ se puede resolver el sistema usando el método de Gauss sin intercambio de filas.

        \begin{multline*}
        \left(\begin{array}{ccc|c}
            -3 & a & -3 & a\\
             -4 & 3 & -4  & 3\\
             2 & 7 & -4 & 1
        \end{array}
        \right) \xrightarrow[m_{2,1}=-\frac{-4}{-3}]{F'_2=m_{2,1}F_1 + F_2}
        \left(\begin{array}{ccc|c}
            -3 & a & -3 & a\\
             0 & -\frac{4a}{3}+3 & 0 & -\frac{4a}{3}+3\\
             2 & 7 & -4 & 1
        \end{array}
        \right) \\
        \xrightarrow[m_{3,1}=-\frac{2}{-3} = \frac{2}{3}]{F'_3=m_{3,1}F_1 + F_3}
        \left(\begin{array}{ccc|c}
            -3 & a & -3 & a\\
             0 & -\frac{4a}{3}+3 & 0 & -\frac{4a}{3}+3\\
             0 & \frac{2a}{3}+7 & -6 & \frac{2a}{3}+1
        \end{array}
        \right) \\
        \xrightarrow[m_{3,2}=-\frac{\frac{2a}{3}+7}{-\frac{4a}{3}+3} = \frac{2a+21}{4a-9}]{F'_3=m_{3,2}F_2 + F_3}
        \left(\begin{array}{ccc|c}
            -3 & a & -3 & a\\
             0 & -\frac{4a}{3}+3 & 0 & -\frac{4a}{3}+3\\
             0 & 0 & -6 & -6
        \end{array}
        \right) 
    \end{multline*}

    Por tanto, el sistema se puede resolver con Gauss sin intercambiar filas si y solo si:
    $$-\frac{4a}{3}+3 \neq 0 \Longleftrightarrow 4a \neq 9 \Longrightarrow a\neq \frac{9}{4}$$

    \item Resuelve el sistema para cualquier valor del parámetro $a$:
    \begin{itemize}
        \item \underline{Para $a=\frac{9}{4}$}:
            \begin{equation*}
                \left(\begin{array}{ccc|c}
                    -3 & \frac{9}{4} & -3 & \frac{9}{4}\\
                     0 & 0 & 0 & 0\\
                     0 & \frac{17}{2} & -6 & \frac{5}{2}
                \end{array}
                \right)
            \end{equation*}
            Por tanto, la solución es $x=(-\frac{8\lambda+9}{17}, \frac{5+12\lambda}{17}, \lambda)^T$:
            \begin{equation*}
                x_3 = \lambda\in \bb{R} \qquad x_2 = \frac{\frac{5}{2}+6\lambda}{\frac{17}{2}} = \frac{5+12\lambda}{17} \qquad x_1 = \frac{\frac{9}{4}+3\lambda -\frac{9}{4}\frac{5+12\lambda}{17}}{-3} = -\frac{8\lambda+9}{17}
            \end{equation*}

        \item \underline{Para $a\neq\frac{9}{4}$}:
            La solución es $x=(-1,1,1)^T$:
            \begin{equation*}
                x_3 = 1 \qquad x_2 = 1 \qquad x_1 = \frac{a+3-a}{-3} = -1
            \end{equation*}
            
    \end{itemize}

    \item Para $a=0$ resuelve el sistema utilizando el método de Gauss con pivote parcial.
    \begin{multline*}
        \left(\begin{array}{ccc|c}
            -3 & 0 & -3 & 0\\
             -4 & 3 & -4  & 3\\
             2 & 7 & -4 & 1
        \end{array}
        \right) \xrightarrow{F_1 \Longleftrightarrow F_2}
        \left(\begin{array}{ccc|c}
            -4 & 3 & -4  & 3\\
            -3 & 0 & -3 & 0\\
             2 & 7 & -4 & 1
        \end{array}
        \right)
        \xrightarrow[F'_3=\frac{1}{2}F_1 + F_3]{F'_2=-\frac{3}{4}F_1 + F_2} \\
        \longrightarrow \left(\begin{array}{ccc|c}
            -4 & 3 & -4  & 3\\
             0 & -\frac{9}{4} & 0 & -\frac{9}{4}\\
             0 & \frac{17}{2} & -6 & \frac{5}{2}
        \end{array}
        \right)
        \xrightarrow{F_2 \Longleftrightarrow F_3}
        \left(\begin{array}{ccc|c}
            -4 & 3 & -4  & 3\\
            0 & \frac{17}{2} & -6 & \frac{5}{2} \\
             0 & -\frac{9}{4} & 0 & -\frac{9}{4}       
        \end{array}
        \right) \\
        \xrightarrow{F'_3=\frac{9}{34}F_2 + F_3}
        \left(\begin{array}{ccc|c}
            -4 & 3 & -4  & 3\\
            0 & \frac{17}{2} & -6 & \frac{5}{2} \\
             0 & 0 & -\frac{27}{17} & -\frac{27}{17}
        \end{array}
        \right) 
    \end{multline*}
    La solución es $x=(-1, 1, 1)^T$:
    \begin{equation*}
        x_3 = 1 \qquad x_2 = \frac{\frac{5}{2}+6}{\frac{17}{2}} = \frac{5+12}{17} = 1 \qquad x_1 = \frac{3+4-3}{-4} = -1
    \end{equation*}

    \item Para $a=0$ resuelve el sistema utilizando el método de Gauss con pivote total.
    \begin{multline*}
        \left(\begin{array}{ccc|c}
            -3 & 0 & -3 & 0\\
             -4 & 3 & -4  & 3\\
             2 & 7 & -4 & 1
        \end{array}
        \right) \xrightarrow[C_2 \Longleftrightarrow C_1]{F_1 \Longleftrightarrow F_3}
        \left(\begin{array}{ccc|c}
              7 & 2 & -4 & 1 \\
              3 & -4 & -4  & 3\\
              0 & -3 & -3 & 0
        \end{array}
        \right)
        \xrightarrow{F'_2=-\frac{3}{7}F_1 + F_2} \\
        \longrightarrow \left(\begin{array}{ccc|c}
              7 & 2 & -4 & 1 \\
              0 & -\frac{34}{7} & -\frac{16}{7}  & \frac{18}{7}\\
              0 & -3 & -3 & 0
        \end{array}
        \right)
        \xrightarrow{F'_3 = -\frac{21}{34}F_2 + F_3}
        \left(\begin{array}{ccc|c}
            7 & 2 & -4  & 1\\
            0 & -\frac{34}{7} & -\frac{16}{7} & \frac{18}{7} \\
             0 & 0 & -\frac{27}{17} & -\frac{27}{17}
        \end{array}
        \right)
    \end{multline*}
    La solución, recordando que se han intercambiado la primera y segunda variable, es $x=(-1, 1, 1)^T$:
    \begin{equation*}
        x_3 = 1 \qquad x_1 = \frac{\frac{18+16}{7}}{\frac{-34}{7}} = -1 \qquad x_2 = \frac{1+4+2}{7} = 1
    \end{equation*}
    
    \end{enumerate}
\end{ejercicio}

\begin{ejercicio} Usa el método de Gauss (sin intercambio de filas), sustitución hacia atrás y aritmética exacta para resolver, si es posible, los sistemas lineales siguientes:
    \begin{enumerate}
        \item
        $ \displaystyle \left.
            \begin{array}{rrrrrrr}
                x_1 & - & x_2 & + & 3x_3 & = & 2  \\
                3x_1 & - & 3x_2 & + & x_3 & = & -1  \\
                x_1 & + & x_2 &  &  & = & 3  \\
            \end{array}
        \right\} $

        \begin{equation*}
        \left(\begin{array}{ccc|c}
            1 & -1 & 3 & 2\\
            3 & -3 & 1 & -1 \\
            1 & 1 & 0 & 3
        \end{array}
        \right) \xrightarrow[F'_3=-F_1 + F_3]{F'_2=-3F_1 + F_2}
        \left(\begin{array}{ccc|c}
            1 & -1 & 3 & 2\\
            0 & 0 & -8 & -7 \\
            0 & 2 & -3 & 1
        \end{array}
        \right)
        \end{equation*}

        Por tanto, como $a_{22}^{(2)} = 0$, no es posible resolverlo sin intercambio de filas.

        \item
        $ \displaystyle \left.
            \begin{array}{rrrrrrrrr}
                x_1 & - & \frac{1}{2}x_2 & + & x_3 & & & = & 4  \\
                2x_1 & - & x_2 & - & x_3 & + & x_4 & = & 5  \\
                x_1 & + & x_2 &  &  & & & = & 2  \\
                x_1 & - & \frac{1}{2}x_2 & + & x_3 & + & x_4 & = & 5  \\
            \end{array}
        \right\} $

        \begin{equation*}
        \left(\begin{array}{cccc|c}
            1 & -\frac{1}{2} & 1 & 0 & 4\\
            2 & -1 & -1 & 1 & 5\\
            1 & 1 & 0 & 0 & 2\\
            1 & -\frac{1}{2} & 1 & 1 & 5\\
        \end{array}
        \right) \xrightarrow[\begin{array}{c}	
             \scriptstyle F'_3=-F_1 + F_3 \\
             \scriptstyle F'_4=-F_1 + F_4 
        \end{array}]{F'_2=-2F_1 + F_2}
        \left(\begin{array}{cccc|c}
            1 & -\frac{1}{2} & 1 & 0 & 4\\
            0 & 0 & -3 & 1 & -3\\
            0 & \frac{3}{2} & -1 & 0 & -2\\
            0 & 0 & 0 & 1 & 1\\
        \end{array}
        \right)
        \end{equation*}

        Por tanto, como $a_{22}^{(2)} = 0$, no es posible resolverlo sin intercambio de filas.
        
    \end{enumerate}
\end{ejercicio}

\begin{ejercicio}
    ¿Es posible aplicar el método de Gauss (sin intercambio de filas) al siguiente sistema de ecuaciones lineales? ¿Por qué?
    \begin{equation*}
        \left( \begin{array}{cccc}
            1 & 2 & 3 & 4 \\
            2 & 4 & 5 & 1 \\
            3 & 5 & 1 & 2 \\
            4 & 6 & 3 & 1
        \end{array}\right) \left( \begin{array}{c}
            x_1 \\
            x_2 \\
            x_3 \\
            x_4
        \end{array}\right) = \left( \begin{array}{c}
            10 \\
            12 \\
            11 \\
            14
        \end{array}\right)
    \end{equation*}

    \begin{equation*}
        \left(\begin{array}{cccc|c}
            1 & 2 & 3 & 4 & 10 \\
            2 & 4 & 5 & 1 & 12\\
            3 & 5 & 1 & 2 & 11\\
            4 & 6 & 3 & 1 & 14
        \end{array}
        \right) \xrightarrow{F'_2=-2F_1 + F_2}
        \left(\begin{array}{cccc|c}
            1 & 2 & 3 & 4 & 10 \\
            0 & 0 & 1 & -7 & 2\\
            3 & 5 & 1 & 2 & 11\\
            4 & 6 & 3 & 1 & 14
        \end{array}
        \right)
        \end{equation*}

        Por tanto, como $a_{22}^{(2)} = 0$, no es posible resolverlo sin intercambio de filas.
\end{ejercicio}

\begin{ejercicio}
    Sea la matrz $A\in \mathcal{M}_4(\bb{R})$
    $$A = \left( \begin{array}{cccc}
        2 & -2 & -4 & 2 \\
        -1 & 3 & 0 & -5 \\
        -2 & 1 & 7 & -2 \\
        1 & -3 & -1 & 8
    \end{array}\right)$$
    
    \begin{enumerate}
        \item Determina la factorización LU en su forma de Crout de la matriz $A$.

        \begin{equation*}\begin{split} A & = \left(
        \begin{array}{cccc}
            2 & -2 & -4 & 2 \\
            -1 & 3 & 0 & -5 \\
            -2 & 1 & 7 & -2 \\
            1 & -3 & -1 & 8
        \end{array}\right)
        = \left(
        \begin{array}{cccc}
            l_{11} & 0 & 0 & 0\\
            l_{21} & l_{22} & 0 & 0\\
            l_{31} & l_{32} & l_{33} & 0\\
            l_{41} & l_{42} & l_{43} & l_{44}
        \end{array}\right) \left(
        \begin{array}{cccc}
            1 & u_{12} & u_{13} & u_{14}\\
            0 & 1 & u_{23} & u_{24}\\
            0 & 0 & 1 & u_{34}\\
            0 & 0 & 0 & 1
        \end{array}\right) \\ &
        = \left(
        \begin{array}{cccc}
            l_{11} & l_{11}u_{12} & l_{11}u_{13} & l_{11}u_{14}\\
            l_{21} & l_{21}u_{12}+l_{22} & l_{21}u_{13}+l_{22}u_{23} & l_{21}u_{14} + l_{22}u_{24}\\
            l_{31} & l_{31}u_{12}+l_{32} & l_{31}u_{13}+l_{32}u_{23} + l_{33} & l_{31}u_{14}+l_{32}u_{24} + l_{33}u_{34}\\
            l_{41} & l_{41}u_{12}+l_{42} & l_{41}u_{13} + l_{42}u_{23} + l_{43} & l_{41}u_{14} + l_{42}u_{24} + l_{43}u_{34} + l_{44}
        \end{array}\right)
    \end{split}\end{equation*}
    
    Igualando componentes:
    \begin{equation*}
    \left\{ \begin{array}{l}
         l_{11} = 2 \\ 
         l_{21} = -1 \\
         l_{31} = -2 \\
         l_{41} = 1 \\
         l_{11}u_{12} = -2 \longrightarrow u_{12}=-1 \\
         l_{21}u_{12} + l_{22} = 3 \longrightarrow l_{22}=2\\
         l_{31}u_{12} + l_{32} = 1 \longrightarrow l_{32}=-1 \\
         l_{41}u_{12} + l_{42} = -3 \longrightarrow l_{42}=-2 \\
         l_{11}u_{13} = -4 \longrightarrow u_{13}=-2 \\
         l_{21}u_{13} + l_{22}u_{23} = 0 \longrightarrow u_{23} = -1\\
         l_{31}u_{13} + l_{32}u_{23} + l_{33} = 7 \longrightarrow l_{33} = 2 \\
         l_{41}u_{13} + l_{42}u_{23} + l_{43} = -1 \longrightarrow l_{43} = -1 \\
         l_{11}u_{14} = 2 \longrightarrow u_{14}=1 \\
         l_{21}u_{14} + l_{22}u_{24} = -5 \longrightarrow u_{24}=-2\\
         l_{31}u_{14} + l_{32}u_{24} + l_{33}u_{34} = -2 \longrightarrow u_{34} = -1 \\
         l_{41}u_{14} + l_{42}u_{24} + l_{43}u_{34} + l_{44} = 8 \longrightarrow l_{44} = 2\\
    \end{array}\right.
    \end{equation*}

    Por tanto, y tras igualar componentes,
    \begin{equation*}
        A = \left(
        \begin{array}{cccc}
            2 & -2 & -4 & 2 \\
            -1 & 3 & 0 & -5 \\
            -2 & 1 & 7 & -2 \\
            1 & -3 & -1 & 8
        \end{array}\right)
        = \left(
        \begin{array}{cccc}
            2 & 0 & 0 & 0\\
            -1 & 2 & 0 & 0\\
            -2 & -1 & 2 & 0\\
            1 & -2 & -1 & 2
        \end{array}\right) \left(
        \begin{array}{cccc}
            1 & -1 & -2 & 1\\
            0 & 1 & -1 & -2\\
            0 & 0 & 1 & -1\\
            0 & 0 & 0 & 1
        \end{array}\right) = LU
    \end{equation*}

    \item Resuelve a partir de esta factorización el sistema que tiene a esta matriz por matriz de coeficientes y por vector de términos independientes $(0, 2, -1, -2)^T$.

    Sea la solución $x\in\bb{R}^4$.
    \begin{equation*}
        Ax = (0, 2, -1, -2)^T \Longrightarrow LUx = (0, 2, -1, -2)^T
    \end{equation*}
    Sea $Ux = y \in \bb{R}^4$. Resuelvo en primer lugar el sistema $Ly=(0, 2, -1, -2)^T$
    \begin{equation*}
        \left(
        \begin{array}{cccc}
            2 & 0 & 0 & 0\\
            -1 & 2 & 0 & 0\\
            -2 & -1 & 2 & 0\\
            1 & -2 & -1 & 2
        \end{array}\right) \left(\begin{array}{c}
            y_1 \\
            y_2 \\
            y_3 \\
            y_4
        \end{array} \right)       
        =\left( \begin{array}{c}
             0 \\
             2 \\
             -1 \\
             -2
        \end{array}\right) \Longrightarrow y = (0, 1, 0, 0)^T
    \end{equation*}

    Resuelvo ahora el sistema $Ux=y$
    \begin{equation*}
        \left(
        \begin{array}{cccc}
            1 & -1 & -2 & 1\\
            0 & 1 & -1 & -2\\
            0 & 0 & 1 & -1\\
            0 & 0 & 0 & 1
        \end{array}\right) \left(\begin{array}{c}
            x_1 \\
            x_2 \\
            x_3 \\
            x_4
        \end{array} \right)       
        =\left( \begin{array}{c}
             0 \\
             1 \\
             0 \\
             0
        \end{array}\right) \Longrightarrow x = (1, 1, 0, 0)^T
    \end{equation*}
    Por tanto, la solución del sistema es $x = (1, 1, 0, 0)^T$.   
    
    \end{enumerate}
    
\end{ejercicio}


\begin{ejercicio}
    Dada la matriz
    $$A = \left( \begin{array}{cccc}
        2 & -2 & -4 & -2 \\
        2 & 0 & -6 & -6 \\
        4 & -2 & -8 & -10 \\
        2 & 2 & -6 & -10 \\
    \end{array}\right)$$
    y los vectores
    \begin{equation*}
        b_1 = \left(\begin{array}{c}
            -8 \\ -12 \\ -20 \\ -14
        \end{array}\right), \qquad
        b_2 = \left( \begin{array}{c}
            -4 \\ -10 \\ -14 \\ -14
        \end{array}\right), \qquad
        b_3 = \left( \begin{array}{c}
            -2 \\ -4 \\ -8 \\ -6
        \end{array}\right), \qquad
        b_4 = \left( \begin{array}{c}
            -4 \\ -4 \\ -6 \\ -2
        \end{array}\right)
    \end{equation*}
    resuelve los cuatro sistemas lineales $Ax=b_i,\quad i=1,2,3,4$, mediante el método que considere más eficiente. ¿Puede usarse esa misma técnica para calcular la inversa de una matriz?\\

    El método más eficiente es la factorización LU, ya que al tener la matriz $A$ factorizada, este resultado se puede emplear para los 4 valores de $b_i$. En el caso en el que hubiésemos elegido Gauss, habríamos tenido que obtener la matriz triangular en 4 casos distintos.

    Calculo por tanto la factorización LU de la matriz $A$ mediante el método de Doolittle.
    \begin{equation*}
        A = \left( \begin{array}{cccc}
            2 & -2 & -4 & -2 \\
            2 & 0 & -6 & -6 \\
            4 & -2 & -8 & -10 \\
            2 & 2 & -6 & -10 \\
        \end{array}\right)
        = \left( \begin{array}{cccc}
            1 & 0 & 0 & 0 \\
            l_{21} & 1 & 0 & 0 \\
            l_{31} & l_{32} & 1 & 0 \\
            l_{41} & l_{42} & l_{43} & 1 \\
        \end{array}\right)
        \left( \begin{array}{cccc}
            u_{11} & u_{12} & u_{13} & u_{14} \\
            0 & u_{22} & u_{23} & u_{24} \\
            0 & 0 & u_{33} & u_{34} \\
            0 & 0 & 0 & u_{44} \\
        \end{array}\right)
    \end{equation*}
    Por tanto, igualando componente a componente,
    \begin{equation*}
        A = \left( \begin{array}{cccc}
            2 & -2 & -4 & -2 \\
            2 & 0 & -6 & -6 \\
            4 & -2 & -8 & -10 \\
            2 & 2 & -6 & -10 \\
        \end{array}\right)
        = \left( \begin{array}{cccc}
            1 & 0 & 0 & 0 \\
            1 & 1 & 0 & 0 \\
            2 & 1 & 1 & 0 \\
            1 & 2 & 1 & 1 \\
        \end{array}\right)
        \left( \begin{array}{cccc}
            2 & -2 & -4 & -2 \\
            0 & 2 & -2 & -4 \\
            0 & 0 & 2 & -2 \\
            0 & 0 & 0 & 2 \\
        \end{array}\right) = LU
    \end{equation*}
    \begin{enumerate}
        \item Resuelvo en primer lugar $Ax_1 = b_1$.\\
        Como solución del sistema $Ly_1 = b_1$, obtenemos $y_1 = (-8, -4, 0, 2)^T$.

        Por tanto, la solución del sistema $Ax_1 = b_1$ equivale a $Ux_1 = y_1$. Por tanto, $x_1 = (0,1,1,1)^T$.

        \item Resuelvo en primer lugar $Ax_2 = b_2$.\\
        Como solución del sistema $Ly_2 = b_2$, obtenemos $y_2 = (-4, -6, 0, 2)^T$.

        Por tanto, la solución del sistema $Ax_2 = b_2$ equivale a $Ux_2 = y_2$. Por tanto, $x_2 = (1,0,1,1)^T$.

        \item Resuelvo en primer lugar $Ax_3 = b_3$.\\
        Como solución del sistema $Ly_3 = b_3$, obtenemos $y_3 = (-2, -2, -2, 2)^T$.

        Por tanto, la solución del sistema $Ax_3 = b_3$ equivale a $Ux_3 = y_3$. Por tanto, $x_3 = (1,1,0,1)^T$.

        \item Resuelvo en primer lugar $Ax_4 = b_4$.\\
        Como solución del sistema $Ly_4 = b_4$, obtenemos $y_4 = (-4, 0, 2, 0)^T$.

        Por tanto, la solución del sistema $Ax_4 = b_4$ equivale a $Ux_4 = y_4$. Por tanto, $x_4 = (1,1,1,0)^T$.
        
    \end{enumerate}
    

    Para calcular $A^{-1}$, se puede calcular la columna $i$-ésima de $A^{-1}$ resolviendo el sistema igualando a $e_i$ en cada caso. Por tanto, resolviendo 4 sistemas LU se puede calcular la inversa de $A$.
\end{ejercicio}

\begin{ejercicio}
    Sea $A\in \mathcal{M}_n(\bb{R})$ regular y tridiagonal.
    \begin{equation*}
        A_n = \left( \begin{array}{cccccc}
            a_1 & c_1 & 0 & 0 & \dots & 0 \\
            b_2 & a_2 & c_2 & 0 & \dots & 0 \\
            0 & b_3 & a_3 & c_3 & \dots & 0 \\
            \vdots & \vdots & \ddots & \ddots & \ddots & \vdots \\
            0 & 0 & \dots & b_{n-1} & a_{n-1} & c_{n-1} \\
            0 & 0 & \dots & 0 & b_n & a_n
        \end{array} \right)
    \end{equation*}
    Supongamos que $A$ admite una factorización LU tipo Doolittle. Prueba que las correspondientes matrices triangulares adoptan la forma
    \begin{equation*}
        L_n = \left( \begin{array}{cccccc}
            1 & 0 & 0 & 0 & \dots & 0 \\
            l_2 & 1 & 0 & 0 & \dots & 0 \\
            0 & l_3 & 1 & 0 & \dots & 0 \\
            \vdots & \vdots & \ddots & \ddots & \ddots & \vdots \\
            0 & 0 & \dots & l_{n-1} & 1 & 0 \\
            0 & 0 & \dots & 0 & l_n & 1
        \end{array} \right), \qquad
        U_n = \left( \begin{array}{cccccc}
            d_1 & c_1 & 0 & 0 & \dots & 0 \\
            0 & d_2 & c_2 & 0 & \dots & 0 \\
            0 & 0 & d_3 & c_3 & \dots & 0 \\
            \vdots & \vdots & \ddots & \ddots & \ddots & \vdots \\
            0 & 0 & \dots & 0 & d_{n-1} & c_{n-1} \\
            0 & 0 & \dots & 0 & 0 & d_n
        \end{array} \right)
    \end{equation*}
    con $d_1 = a_1$ y para $i=2,\dots,n$ se verifica $l_i=\frac{b_i}{d_{i-1}},\;d_i=a_i - l_ic_{i-1}$.

\end{ejercicio}

\begin{ejercicio}
    Decide razonadamente si la matriz
    $$A = \left( \begin{array}{cccc}
        1 & 1 & 2 & 1 \\
        1 & 5 & 4 & 5 \\
        2 & 4 & 6 & 5 \\
        1 & 5 & 5 & 10
    \end{array} \right)$$
    es o no definida positiva y utiliza tu razonamiento para resolver el sistema de ecuaciones lineales $Ax = b$ donde $b=(-1,5,1,9)^T$.\\

    Para que sea definida positiva, es necesario que todos sus menores principales sean positivos.
    \begin{equation*}
        |1| = 1, \qquad
        \left| \begin{array}{cc}
            1 & 1 \\
            1 & 5
        \end{array} \right| = 5-1=4,\qquad
        \left| \begin{array}{ccc}
            1 & 1 & 2\\
            1 & 5 & 4\\
            2 & 4 & 6
        \end{array} \right|=4
    \end{equation*}
    \begin{multline*}
    |A| = \left| \begin{array}{cccc}
        1 & 1 & 2 & 1 \\
        1 & 5 & 4 & 5 \\
        2 & 4 & 6 & 5 \\
        1 & 5 & 5 & 10
    \end{array} \right| = \left| \begin{array}{cccc}
        0 & 1 & 2 & 1 \\
        -4 & 5 & 4 & 5 \\
        -2 & 4 & 6 & 5 \\
        -4 & 5 & 5 & 10
    \end{array} \right| = \left| \begin{array}{cccc}
        0 & 1 & 2 & 1 \\
        0 & 0 & -1 & -5 \\
        -2 & 4 & 6 & 5 \\
        -4 & 5 & 5 & 10
    \end{array} \right| = 
    \left| \begin{array}{cccc}
        0 & 1 & 2 & 1 \\
        0 & 0 & -1 & -5 \\
        -2 & 4 & 6 & 5 \\
        0 & -3 & -7 & 0
    \end{array} \right| =  \\
    = -2 \left| \begin{array}{ccc}
        1 & 2 & 1 \\
        0 & -1 & -5 \\
        -3 & -7 & 0
    \end{array} \right| = -2 \cdot -8 = 16
    \end{multline*}

    Por tanto, como sus $4$ menores principales son positivos, es definida positiva. Además, como es simétrica, admite factorización de tipo \emph{Cholesky}.
    \begin{multline*}
        A = \left( \begin{array}{cccc}
        1 & 1 & 2 & 1 \\
        1 & 5 & 4 & 5 \\
        2 & 4 & 6 & 5 \\
        1 & 5 & 5 & 10
    \end{array} \right) = \left( \begin{array}{cccc}
        l_{11} & 0 & 0 & 0 \\
        1_{21} & l_{22} & 0 & 0 \\
        l_{31} & l_{32} & l_{33} & 0 \\
        l_{41} & l_{42} & l_{43} & l_{44}
    \end{array} \right)
    \left( \begin{array}{cccc}
        l_{11} & l_{21} & l_{31} & l_{41} \\
        0 & l_{22} & l_{32} & l_{42} \\
        0 & 0 & l_{33} & l_{43} \\
        0 & 0 & 0 & l_{44}
    \end{array} \right) = \\
    = \left( \begin{array}{cccc}
        l_{11}^2 & l_{11}l_{21} & l_{11}l_{31} & l_{11}l_{41} \\
        1_{21}l_{11} & l_{21}^2+l_{22}^2 & l_{21}l_{31}+l_{22}l_{32} & l_{21}l_{41} + l_{22}l_{42} \\
        l_{31}l_{11} & l_{31}l_{21} + l_{32}l_{22} & l_{31}^2 + l_{32}^2 + l_{33}^2 & l_{31}l_{41} + l_{32}l_{42} l _{33}l_{43} \\
        l_{41}l_{11} & l_{41}l_{21} + l_{42}l_{22} & l_{41}l_{31} + l_{42}l_{32} + l_{43}l_{33} & l_{41}^2 + l_{42}^2 + l_{43}^2 + l_{44}^2
    \end{array} \right)
    \end{multline*}

    Por tanto, igualando componentes y quedándome con los valores positivos de las potencias,
    
    \begin{equation*}
            A = \left( \begin{array}{cccc}
        1 & 1 & 2 & 1 \\
        1 & 5 & 4 & 5 \\
        2 & 4 & 6 & 5 \\
        1 & 5 & 5 & 10
    \end{array} \right) = \left( \begin{array}{cccc}
        1 & 0 & 0 & 0 \\
        1 & 2 & 0 & 0 \\
        2 & 1 & 1 & 0 \\
        1 & 2 & 1 & 2
    \end{array} \right)
    \left( \begin{array}{cccc}
        1 & 1 & 2 & 1 \\
        0 & 2 & 1 & 2 \\
        0 & 0 & 1 & 1 \\
        0 & 0 & 0 & 2
    \end{array} \right) = LU
    \end{equation*}

    Por tanto, el sistema $Ax=b$ se queda como $LUx = b$. Sea $Ux = y \in \bb{R}^4$. Resuelvo en primer lugar el sistema $Ly=b$.
    \begin{equation*}
        \left( \begin{array}{cccc}
        1 & 0 & 0 & 0 \\
        1 & 2 & 0 & 0 \\
        2 & 1 & 1 & 0 \\
        1 & 2 & 1 & 2
    \end{array} \right)
    \left( \begin{array}{c}
        y_1 \\ y_2 \\ y_3 \\y_4
    \end{array} \right) =
    \left( \begin{array}{c}
        -1 \\ 5 \\ 1 \\9
    \end{array} \right) \Longrightarrow y = (-1, 3, 0, 2)^T
    \end{equation*}

    Resuelvo ahora $Ux=y$
    \begin{equation*}
        \left( \begin{array}{cccc}
        1 & 1 & 2 & 1 \\
        0 & 2 & 1 & 2 \\
        0 & 0 & 1 & 1 \\
        0 & 0 & 0 & 2
    \end{array} \right)
    \left( \begin{array}{c}
        x_1 \\ x_2 \\ x_3 \\x_4
    \end{array} \right) =
    \left( \begin{array}{c}
        -1 \\ 3 \\ 0 \\2
    \end{array} \right) \Longrightarrow x = (-1,1,-1,1)^T
    \end{equation*}

    Por tanto, la solución es $x = (-1,1,-1,1)^T$.
\end{ejercicio}

\begin{ejercicio}
    Se considera el sistema de ecuaciones
    $$\left\{ \begin{array}{rrrrr}
        6x & + & 11y & = & 3 \\
        13x & + & 22y & = & 71
    \end{array} \right.$$

    \begin{enumerate}
        \item Resuelve el sistema de ecuaciones por el método de Gauss, utilizando aritmética finita de cuatro dígitos por redondeo.
        \begin{equation*}
        \left(\begin{array}{cc|c}
            6 & 11 & 3\\
            13 & 22 & 71 \\
        \end{array}
        \right) \xrightarrow[m_{2,1} = -\frac{13}{6} \approx -2.167]{F'_2=m_{2,1}F_1 + F_2}
        \left(\begin{array}{cc|c}
            6 & 11 & 3\\
            0 & -1.84 & 64.50 \\
        \end{array}
        \right)
        \end{equation*}
        Por tanto,
        $$y=\frac{64.50}{-1.84} \approx -35.05$$
        $$x=\frac{3-11y}{6} \approx \frac{3+385.6}{6} = \frac{388.6}{6} = 64.77$$

        \item Resuelve de nuevo el sistema por el método de Gauss con pivote parcial, utilizando aritmética finita de cuatro dígitos por redondeo.
        \begin{equation*}
        \left(\begin{array}{cc|c}
            6 & 11 & 3\\
            13 & 22 & 71 \\
        \end{array}
        \right) \xrightarrow{F_1 \Longleftrightarrow F_2}
        \left(\begin{array}{cc|c}
            13 & 22 & 71 \\
            6 & 11 & 3\\
        \end{array}
        \right) \xrightarrow[m_{2,1} = -\frac{6}{13} \approx -0.4615]{F'_2=m_{2,1}F_1 + F_2}
        \left(\begin{array}{cc|c}
            13 & 22 & 71 \\
            0 & 0.85 & -29.77
        \end{array}
        \right)
        \end{equation*}
        Por tanto,
        $$y=\frac{-29.77}{0.85} \approx -35.02$$
        $$x=\frac{71-22y}{13} \approx \frac{71+770.4}{13} = \frac{841.4}{13} = 64.72$$
        
        \item Comenta los resultados obtenidos en los apartados anteriores.

        Como podemos ver, al usar el pivote parcial los resultados son más precisos.

        \item Resuelve el sistema utilizando la factorización $LU$ de Crout.
        \begin{equation*}
            \left(\begin{array}{cc}
            6 & 11\\
            13 & 22
            \end{array}\right) =
            \left(\begin{array}{cc}
            l_{11} & 0\\
            l_{21} & l_{22}
            \end{array}\right)
            \left(\begin{array}{cc}
            1 & u_{12}\\
            0 & 1
            \end{array}\right) = 
            \left(\begin{array}{cc}
            l_{11} & l_{11}u_{12}\\
            l_{21} & l_{21}u_{12} + l_{22}
            \end{array}\right)
        \end{equation*}

        Por tanto, igualando componentes:
        \begin{equation*}
            \left(\begin{array}{cc}
            6 & 11\\
            13 & 22
            \end{array}\right) =
            \left(\begin{array}{cc}
            6 & 0\\
            13 & -\frac{11}{6}
            \end{array}\right)
            \left(\begin{array}{cc}
            1 & \frac{11}{6}\\
            0 & 1
            \end{array}\right) = LU
        \end{equation*}

        Para resolver el sistema $Ar=(3,71)^T = LUr$, resuelvo en primer lugar $Ls=(3,71)^T$.
        \begin{equation*}
            \left(\begin{array}{cc}
            6 & 0\\
            13 & -\frac{11}{6}
            \end{array}\right)
            \left(\begin{array}{c}
            s_1 \\ s_2
            \end{array}\right) =
            \left(\begin{array}{c}
            3 \\ 71
            \end{array}\right) \Longrightarrow
            s = \left(\frac{1}{2},-\frac{387}{11}\right)^T
        \end{equation*}

        Resuelvo ahora el sistema $Ur=s$
        \begin{equation*}
            \left(\begin{array}{cc}
            1 & \frac{11}{6}\\
            0 & 1
            \end{array}\right)
            \left(\begin{array}{c}
            r_1 \\ r_2
            \end{array}\right) =
            \left(\begin{array}{c}
            0.5 \\ -\frac{387}{11}
            \end{array}\right) \Longrightarrow
            r = \left(65 ,-\frac{387}{11} \right)^T
        \end{equation*}

        Por tanto, $x=65$ e $y=-\frac{387}{11}$.
        
    \end{enumerate}
\end{ejercicio}

\begin{ejercicio}
    Demuestra que toda matriz simétrica $A\in \mathcal{S}_n(\bb{K})$ cuyos menores principales son no nulos admite una factorización en la forma $A = LDL^t$, donde $D$ es una matriz diagonal regular y $L$ es una matriz triangular inferior unitaria, es decir, con unos en la diagonal principal.

    \begin{proof}
        Al ser sus menores principales no nulos, admite una factorización LU sin intercambio de filas. $$A=LU$$

        Como $A$ es simétrica, $$A=A^t \Longrightarrow LU = (LU)^t = U^tL^t$$
    
        Despejando, $U=L^{-1}U^tL^t$. Por tanto,
        $$A=LU=LL^{-1}U^tL^t$$
    
        Veamos ahora que $L^{-1}U^t = D$ es un matriz diagonal regular.
        
        Es fácil ver que $D^{-1}=(U^t)^{-1}L$, por lo que $D$ es regular. \\
        
        Veamos ahora que $D$ es diagonal.
        En primer lugar, sabemos que la inversa de una triangular inferior es triangular inferior. Por tanto, $L^{-1}$ es triangular inferior.
        Además, $U$ es triangular superior, por lo que $U^t$ es triangular inferior.
        Como el producto de triangulares inferiores es triangular inferior, sabemos que $D$ es triangular inferior.
    
        Veamos ahora que $D$ es diagonal. Para ver que es diagonal, y sabiendo que es diagonal inferior, veamos si es simétrica.
        $$D = L^{-1}U^t = L^{-1}(L^{-1}U^tL^t)^t = L^{-1}LU(L^{-1})^t = U(L^{-1})^t = D^t$$
        
        Por tanto, como $D=D^t$, $D$ es simétrica y, por tanto, es diagonal.
    \end{proof}
    
\end{ejercicio}

\begin{ejercicio}
    Demuestra que la función definida en $\bb{R}^n$ por
    $$||x||_n = \sum_{i=1}^n |x_i|$$
    realmente es una norma vectorial.

    \begin{proof} Ha de cumplir las tres propiedades:
    \begin{itemize}
        \item $||x||_1 = |x_1| + \dots + |x_n| \geq 0$, ya que es la suma de elementos positivos.
        
        Además, es necesario ver que $||x||_1 = 0 \Longleftrightarrow x = 0$.
        \begin{multline*}
            ||x||_1 = 0 \Longleftrightarrow |x_1| + \dots + |x_n| = 0 \Longleftrightarrow |x_1| = \dots = |x_n| = 0 \\
            \Longleftrightarrow x_1 = \dots = x_n = 0 \Longleftrightarrow x = 0
        \end{multline*}

        \item Veamos si $||cx||_1 = |c| ||x||_1$
        \begin{equation*}
            ||cx||_1 = |cx_1| + \dots + |cx_n| = |c|(|x_1| + \dots + |x_n|) = |c|||x||_1
        \end{equation*}

        \item Veamos la desigualdad triangular.
        \begin{multline*}
            ||x+y||_1 = |x_1+y_1| + \dots + |x_n+y_n| \leq |x_1| + |y_1| + \dots + |x_n| + |y_n| = ||x||_1 + ||y||_1
        \end{multline*}
    \end{itemize}
    \end{proof}
\end{ejercicio}

\begin{ejercicio} Demuestra que para todo $x\in \bb{R}^n$ se verifica:
    \begin{enumerate}
        \item  $ ||x||_\infty \leq ||x||_2 \leq ||x||_1 $ \qquad y que las igualdades pueden darse, incluso para vectores no nulos.
        \begin{proof}
            Demuestro en primer lugar la primera desigualdad.
            $$ ||x||_\infty = \max_{i=1,\dots,n} |x_i|$$
            Supongamos que el máximo se alcanza en $i=k$, es decir, $||x||_\infty = |x_k|$
            $$||x||_\infty = \max_{i=1,\dots,n} |x_i| = |x_k| = \sqrt{|x_k|^2}\leq \sqrt{\sum_{i=1}^n |x_i|^2} = ||x||_2$$

            Demuestro ahora la segunda desigualdad.
            $$||x||_2 = \sqrt{\sum_{i=1}^n |x_i|^2} \stackrel{(\ast)}{\leq} \sqrt{\left(\sum_{i=1}^n |x_i|\right)^2} = \left|\sum_{i=1}^n |x_i|\right| \stackrel{(\ast \ast)}{\leq} \sum_{i=1}^n |x_i| = ||x||_1$$

            donde en $(\ast)$ se da la desigualdad ya que la suma de cuadrados es menor que el cuadrado de la suma, y en $(\ast \ast)$ se da ya que, al ser $|x_i \geq 0$, la suma también es $\geq 0$.

            Además, se puede dar la igualdad oara vectores no nulos. por ejemplo, es el caso de $e_k$.
            $$ ||e_k||_\infty = ||e_k||_2 = ||e_k||_1 = 1 $$
        \end{proof}

        \item $||x||_1 \leq n||x||_\infty$

        \begin{proof}
            Sea $||x||_\infty = \max_{i=1,\dots,n}|x_i|$. Supongamos que el máximo se alcanza en $i=k$, es decir, $||x||_\infty = |x_k|$.
            $$||x||_1 = \sum_{i=1}^n |x_i| \leq \sum_{i=1}^n |x_k| = n|x_k| = n||x||_\infty$$
    
            donde la desigualdad se da ya que, por la definición de $|x_k|$, $|x_k|\geq |x_i| \; \forall i$
        \end{proof}

        \item $||x||_2 \leq \sqrt{n}||x||_\infty$

        \begin{proof}
            Sea $||x||_\infty = \max_{i=1,\dots,n}|x_i|$. Supongamos que el máximo se alcanza en $i=k$, es decir, $||x||_\infty = |x_k|$.
            $$||x||_2 = \sqrt{\sum_{i=1}^n |x_i|^2} \leq \sqrt{\sum_{i=1}^n |x_k|^2} = \sqrt{n |x_k|^2} = \sqrt{n}|x_k| = \sqrt{n}||x||_\infty$$
            donde la desigualdad se da ya que, por la definición de $|x_k|$, $|x_k|\geq |x_i| \; \forall i$
        \end{proof}
    \end{enumerate}
\end{ejercicio}

\begin{ejercicio}
    Demuestra que el número de condición, $\kappa(A)$, para toda matriz $A$ verifica:
    \begin{enumerate}
        \item $\kappa(A)\geq 1$
        \begin{proof}
            \begin{equation*}
                \kappa(A) = ||A||||A^{-1}|| \geq ||AA^{-1}|| = ||I||
            \end{equation*}
            Por tanto, para ver que $\kappa(A)\geq 1$, es necesario ver que $||I|| \geq 1$. Hay dos opciones:
            \begin{enumerate}
                \item Opción 1\\
                Sabemos que $||I||_1 = 1$, pero podría ser que existiese otra norma matricial en la que su norma fuese menor que $1$. Sin embargo, esto no es posible, ya que como $\rho (I) = 1 \nless 1 \Longrightarrow \nexists ||\cdot||_M \text{ t.q. } ||I||_M < 1$.

                \item Opción 2\\
                \begin{equation*}
                    \forall\;||\cdot|| \qquad ||A||=||AI|| \leq ||A||\cdot ||I|| \Longrightarrow ||I||\geq \frac{||A||}{||A||} = 1
                \end{equation*}
            \end{enumerate}
            
            Por tanto, $||I||\geq 1$, por lo que:
            $$\kappa(A) \geq ||I|| \geq 1$$
        \end{proof}

        \item $\kappa(\alpha A) = \kappa(A)$ para cualquier escalar $\alpha \in \bb{R}^\ast$.
        \begin{proof}
            \begin{multline*}
                \kappa(\alpha A) = ||\alpha A||||(\alpha A)^{-1}|| = ||\alpha A||||\alpha^{-1} A^{-1}|| = |\alpha|||A||\cdot |\alpha^{-1}|||A^{-1}|| =\\= ||A||||A^{-1}|| = \kappa(A)
            \end{multline*}
        \end{proof}
    \end{enumerate}
\end{ejercicio}

\begin{ejercicio}
    El sistema de ecuaciones
    \begin{equation*}\left.
        \begin{array}{r}
             x+y=0  \\
             x+0.999999y=1 
        \end{array}\right\}
    \end{equation*}
    tiene como solución exacta $x=10^6,\;y=-10^6$. Encuentra la solución exacta del sistema
    \begin{equation*}\left.
        \begin{array}{r}
             x+y=0  \\
             x+1.000001y=1 
        \end{array}\right\}
    \end{equation*}
    Comenta los resultados.\\

    Resuelvo haciendo uso de que $-x=y$:
    $$x-1.000001x = 1 \Longrightarrow x=\frac{1}{-0.000001} = -10^6$$
    Por tanto, $x=-10^6,\;y=10^6$. Estos resultados totalmente contrarios se deben a que es una matriz mal condicionada. Calculemos el número de condición de $A = \left( \begin{array}{cc}
        1 & 1 \\
        1 & 0.999999
    \end{array} \right)$:
    \begin{equation*}
        \kappa(A) =
        \left|\left|\left(\begin{array}{cc}
            1 & 1 \\
            1 & 0.999999
        \end{array}\right)\right|\right|
        \left|\left|\left(\begin{array}{cc}
            1 & 1 \\
            1 & 0.999999
        \end{array}\right)^{-1}\right|\right|
        \left|\left|\left(\begin{array}{cc}
            1 & 1 \\
            1 & 0.999999
        \end{array}\right)\right|\right|
        \left|\left|\left(\begin{array}{cc}
            -10^6 & 10^6 \\
            10^6 & -10^6
        \end{array}\right)\right|\right|
    \end{equation*}

    Haciendo uso de la norma 1, $\kappa_1(A) = 2\cdot 2\cdot 10^6 = 4\cdot 10^6 \ggg1$. Por tanto, se han perdido aproximadamente 6 cifras significantes.
\end{ejercicio}

\begin{ejercicio}
    La matriz de Hilbert $H_n=(h_{ij})_{n\times n}$ definida por $h_{ij}=\frac{1}{i+j-1},\;1\leq i,j\leq n$ es un importante ejemplo en el álgebra lineal numérica. Encuentra la matriz $H_4$, demuestra que
    \begin{equation*}
        H_4^{-1} = \left( \begin{array}{cccc}
            16 & -120 & 240 & -140 \\
            -120 & 1200 & -2700 & 1680 \\
            240 & -2700 & 6480 & -4200 \\
            -140 & 1680 & -4200 & 2800
        \end{array} \right)
    \end{equation*}
    y calcula $\kappa_\infty(H_4)$. ¿Qué puede esperarse al resolver una ecuación en la forma $H_4x=b$?\\

    En primer lugar, obtengo $H_4$:
    \begin{equation*}
        H_4 = \left( \begin{array}{cccc}
            1 & 0.5 & \frac{1}{3} & 0.25 \\
            0.5 & \frac{1}{3} & 0.25 & 0.2 \\
            \frac{1}{3} & 0.25 & 0.2 & \frac{1}{6} \\
            0.25 & 0.2 & \frac{1}{6} & \frac{1}{7}
        \end{array} \right)
    \end{equation*}

    Efectivamente, la matriz dada es $H^{-1}_4$, ya que $H^{-1}_4 H = I_4$.
    \begin{equation*}
        ||H_4||_\infty = \frac{25}{12} \qquad  ||H_4^{-1}||_\infty = \max \{516,5700,13620,8820\} = 13620
    \end{equation*}

    Por tanto, $\kappa_\infty (H_4) = ||H_4||_\infty ||H_4^{-1}||_\infty = \frac{25}{12} 13620 = 28375 > 10^4 \ggg 1$.

    Por tanto, es una matriz mal condicionada y al resolverse un sistema lineal será poco fiable, ya que frente a pequeñas variaciones variará en grandes medidas.
    
\end{ejercicio}

\begin{ejercicio}
    Consideremos la matriz
    $$A=\left( \begin{array}{cc}
        2 & 3 \\
        1 & 4
    \end{array} \right)$$
    Comprueba que la matriz $A$ no es estrictamente diagonal dominante (por filas), pero que los métodos iterativos de Jacobi y Gauss-Seidel convergen, para resolver cualquier sistema $Ax = b$.\\

    Como $|2| \ngtr |3|$, no es E.D.D. 

    Veamos si el método de Jacobi es convergente. En este método, se toma como matriz de descomposición $Q=D$.
    $$D=\left( \begin{array}{cc}
        2 & 0 \\
        0 & 4
    \end{array} \right)
    \qquad \qquad
    D^{-1}=\left( \begin{array}{cc}
        \frac{1}{2} & 0 \\
        0 & \frac{1}{4}
    \end{array} \right)$$
    Por tanto, el método iterativo de Jacobi queda como:
    $$x^{(k+1)} = (I-D^{-1}A)x^{(k)} + D^{-1}b 
    =Bx^{(k)} + D^{-1}b
    \quad \text{ con } B=I-D^{-1}A$$
    $$B=I-\left( \begin{array}{cc}
        1 & \frac{3}{2} \\
        \frac{1}{4} & 1
    \end{array} \right)
    = \left( \begin{array}{cc}
        0 & -\frac{3}{2} \\
        -\frac{1}{4} & 0
    \end{array} \right)$$

    Por tanto, como $P_B(\lambda) = \lambda^2 -\frac{3}{8} \Longrightarrow \rho(B) = \sqrt{\frac{3}{8}} < 1$. Como $\rho(B)<1$, el método iterativo de Jacobi converge.

    Veamos si el método de Gauss-Seidel es convergente. En este método, se toma como matriz de descomposición $Q=D+L$.
    $$Q=\left( \begin{array}{cc}
        2 & 0 \\
        1 & 4
    \end{array} \right)
    \qquad \qquad
    Q^{-1}=\frac{1}{8}\left( \begin{array}{cc}
        4 & 0 \\
        -1 & 2
    \end{array} \right)=
    \left( \begin{array}{cc}
        \frac{1}{2} & 0 \\
        -\frac{1}{8} & \frac{1}{4}
    \end{array} \right)$$
    Por tanto, el método iterativo de Gauss-Seidel queda como:
    $$x^{(k+1)} = (I-Q^{-1}A)x^{(k)} + Q^{-1}b 
    =Bx^{(k)} + Q^{-1}b
    \quad \text{ con } B=I-Q^{-1}A$$
    $$B=I-\left( \begin{array}{cc}
        1 & \frac{3}{2} \\
        0 & \frac{5}{8}
    \end{array} \right)
    = \left( \begin{array}{cc}
        0 & -\frac{3}{2} \\
        0 & \frac{3}{8}
    \end{array} \right)$$

    Por tanto, como $P_B(\lambda) = \lambda^2 -\frac{3}{8}\lambda \Longrightarrow \rho(B) = {\frac{3}{8}} < 1$. Como $\rho(B)<1$, el método iterativo de Gauss-Seidel converge.
\end{ejercicio}

\begin{ejercicio}
    Demuestre que para la matriz
    $$A=\left( \begin{array}{ccc}
        1 & 0 & 1 \\
        -1 & 1 & 0 \\
        1 & 2 & -3 \\
    \end{array} \right)$$
    las iteraciones del método de Jacobi convergen y las del método de Gauss-Seidel no lo hacen.\\

    Trabajemos primero con el método de Jacobi.
    $$Q=\left( \begin{array}{ccc}
        1 & 0 & 0 \\
        0 & 1 & 0 \\
        0 & 0 & -3 \\
    \end{array} \right)
    \qquad \qquad
    Q^{-1}=\left( \begin{array}{ccc}
        1 & 0 & 0 \\
        0 & 1 & 0 \\
        0 & 0 & -\frac{1}{3} \\
    \end{array} \right)
    $$
    Por tanto, el método iterativo de Jacobi queda como:
    $$x^{(k+1)} = (I-Q^{-1}A)x^{(k)} + Q^{-1}b 
    =Bx^{(k)} + Q^{-1}b
    \quad \text{ con } B=I-Q^{-1}A$$
    $$B=I-\left( \begin{array}{ccc}
        1 & 0 & 1 \\
        -1 & 1 & 0 \\
        -\frac{1}{3} & -\frac{2}{3} & 1 \\
    \end{array} \right)
    = \left( \begin{array}{ccc}
        0 & 0 & -1 \\
        1 & 0 & 0 \\
        \frac{1}{3} & \frac{2}{3} & 0 \\
    \end{array} \right)$$
    $$P_B(\lambda)=\left|\begin{array}{ccc}
        -\lambda & 0 & -1 \\
        1 & -\lambda & 0 \\
        \frac{1}{3} & \frac{2}{3} & -\lambda \\
    \end{array} \right|= -\lambda^3 -\frac{2}{3} - \frac{1}{3}\lambda$$

    Las soluciones son:
    \begin{equation*}
        \begin{split}
            \lambda_0&  = 0.75 \\
            \lambda_1 & = 0.37 \pm 0.87i \Longrightarrow |\lambda_1| = 0.89
        \end{split}
    \end{equation*}
     
     Por tanto, $\rho(B)<1$, por lo que el método iterativo de Jacobi converge.

    Veamos ahora para el método de Gauss-Seidel.
    $$Q=\left( \begin{array}{ccc}
        1 & 0 & 0 \\
        -1 & 1 & 0 \\
        1 & 2 & -3 \\
    \end{array} \right)
    \qquad \qquad
    Q^{-1}=\left( \begin{array}{ccc}
        1 & 0 & 0 \\
        1 & 1 & 0 \\
        1 & \frac{2}{3} & -\frac{1}{3} \\
    \end{array} \right)
    $$
    Por tanto, el método iterativo de Gauss-Seidel queda como:
    $$x^{(k+1)} = (I-Q^{-1}A)x^{(k)} + Q^{-1}b 
    =Bx^{(k)} + Q^{-1}b
    \quad \text{ con } B=I-Q^{-1}A$$
    $$B=I-\left( \begin{array}{ccc}
        1 & 0 & 1 \\
        0 & 1 & 1 \\
        0 & 0 & 2 \\
    \end{array} \right)
    = \left( \begin{array}{ccc}
        0 & 0 & -1 \\
        0 & 0 & -1 \\
        0 & 0 & -1 \\
    \end{array} \right)$$
    $$P_B(\lambda)=-\lambda^2(\lambda+1) \Longrightarrow \rho(B)=1$$

    Como $\rho(B)\nless 1 \Longrightarrow$ el método de Gauss-Seidel, en este caso, no converge para cualquier valor de $x^{(0)}$.
\end{ejercicio}

\begin{ejercicio}
    Considera el sistema
    $$\left\{\begin{array}{cc}
        2x+y+z &=4  \\
        x+2y+z &=4  \\
        x+y+2z &=4  \\
    \end{array}\right.$$
    \begin{enumerate}
        \item Comprueba que la matriz de coeficientes del sistema no es estrictamente diagonal dominante (por filas).\\
        En la primera fila, $2\ngtr2$, por lo que no es $E.D.D.$ (por filas).

        \item Partiendo de $x^{(0)} = (0.8,0.8,0.8)^T$, muestra que las iteraciones del método de Jacobi oscilan entre los valores $(1.2,1.2,1.2)^T$ y $(0.8,0.8,0.8)^T$.\\
        $$Q=2I
        \qquad \qquad
        Q^{-1}=\frac{1}{2}I
        $$
        Por tanto, el método iterativo de Jacobi queda como:
        $$x^{(k+1)} = (I-Q^{-1}A)x^{(k)} + Q^{-1}b
        =Bx^{(k)} + c$$
        con $B=I-Q^{-1}A = I-\frac{1}{2}A$ y $c=Q^{-1}b = \frac{1}{2}b = (2,2,2)^T$
        $$B=I-\frac{1}{2}A = -\frac{1}{2}\left( \begin{array}{ccc}
            0 & 1 & 1 \\
            1 & 0 & 1 \\
            1 & 1 & 0 \\
        \end{array} \right)
        \qquad \qquad
        c=\left( \begin{array}{c}
            2 \\ 2 \\ 2
        \end{array} \right)$$
        Por tanto,
        \begin{equation*}
            \begin{split}
                x^{(0)} &= (0.8,0.8,0.8)^T \\
                x^{(1)} &= Bx^{(0)} + c = -\frac{2\cdot (0.8,0.8,0.8)^T}{2} +(2,2,2)^T =  (1.2,1.2,1.2)^T \\
                x^{(2)} &= Bx^{(1)} + c = -\frac{2\cdot (1.2,1.2,1.2)^T}{2} +(2,2,2)^T =  (0.8,0.8,0.8)^T \\
            \end{split}
        \end{equation*}
        Por tanto, es fácil ver que:
        \begin{equation*}
            \begin{array}{rl}
                x^{(2n)}&= (0.8,0.8,0.8)^T\\
                x^{(2n-1)}&= (1.2,1.2,1.2)^T \\
            \end{array} \quad \forall n \in \bb{N}\cup \{0\}
        \end{equation*}

        \item Muestra que las iteraciones del método de Gauss-Seidel convergen a la solución $x=(1,1,1)^T$, calculando iteraciones hasta que $||x^{(k)}-x^{(k-1)}||_\infty < 10^{-3}$.
        $$Q=\left( \begin{array}{ccc}
            2 & 0 & 0 \\
            1 & 2 & 0 \\
            1 & 1 & 2 \\
        \end{array} \right)
        \qquad \qquad
        Q^{-1}=\frac{1}{8}\left( \begin{array}{ccc}
            4 & 0 & 0 \\
            -2 & 4 & 0 \\
            -1 & -2 & 4 \\
        \end{array} \right)
        $$
        Por tanto, el método iterativo de Gauss-Seidel queda como:
        $$x^{(k+1)} = (I-Q^{-1}A)x^{(k)} + Q^{-1}b 
        =Bx^{(k)} +c$$
        
        con $B=I-Q^{-1}A$ y $c=Q^{-1}b$
        $$B=I-Q^{-1}A =\left( \begin{array}{ccc}
            0 & -\frac{1}{2} & -\frac{1}{2} \\
            0 & \frac{1}{4} & -\frac{1}{4} \\
            0 & \frac{1}{8} & \frac{3}{8} \\
        \end{array} \right)
        \qquad \qquad
        c=\left( \begin{array}{c}
            2 \\ 1 \\ \frac{1}{2}
        \end{array} \right)$$
        Por tanto, las iteraciones son:
        \begin{equation*}
            \begin{array}{c|l}
                k & x^{(k)} \\ \hline
                0 & \displaystyle(0,0,0)^T \\
                1 & \displaystyle\left(2,1,\frac{1}{2}\right)^T \\
                2 & \displaystyle\left(\frac{5}{4},\frac{9}{8},\frac{13}{16}\right)^T \\
                3 & \displaystyle\left(\frac{33}{32},\frac{69}{64},\frac{121}{128}\right)^T \\
                4 & \displaystyle\left(\frac{253}{256},\frac{529}{512},\frac{1013}{1024}\right)^T \\
                5 & \displaystyle\left(\frac{2025}{2048},\frac{4141}{4096},\frac{8193}{8192}\right)^T \\
                6 & \displaystyle\left(\frac{16293}{16384},\frac{32857}{32768},\frac{65629}{65536}\right)^T \\
                7 & \displaystyle\left(\frac{130801}{131072},\frac{262229}{262144},\frac{524745}{524288}\right)^T  \approx (0.9979,1.0003,1.0009)^T\\
                8 & \displaystyle\left(\frac{1047949}{1048576},\frac{2096865}{2097152},\frac{4195845}{4194304}\right)^T \approx (0.9994,0.9999,1.0004)^T \\
                9 & \displaystyle\left(\frac{8387641}{8388608},\frac{16775101}{16777216},\frac{33558481}{33884432}\right)^T \approx (0.9999,0.9999,1.0001)^T\\
            \end{array}
        \end{equation*}
        \begin{observacion}
            Como $A$ es simétrica y definida positivamente, podemos confirmar que el método de Gauss-Seidel converge.
            Sea $\left\{x^{(k)}\right\}\longrightarrow L=(x,y,z)^T\in \bb{R}^3$. Como $x^{(k+1)}=Bx^{(k)} +c$, como toda parcial de una sucesión convergente converge al mismo límite, y usando también la unicidad del límite,
            $$L=BL + c \Longrightarrow (I-B)L=c \Longrightarrow L=(I-B)^{-1}c = \mathbf{(1,1,1)^T=(x,y,z)^T}$$
        \end{observacion}

        \item ¿Se mantienen los resultados de convergencia de los métodos de Jacobi y Gauss-Seidel si intercambiamos las ecuaciones segunda y tercera?\\

        No tiene por qué, ya que sus valores propios son distintos y, por tanto, su radio espectral también lo es. Veámoslo.

        Trabajemos primero con el método de Jacobi.
        $$Q=\left( \begin{array}{ccc}
            2 & 0 & 0 \\
            0 & 1 & 0 \\
            0 & 0 & 1 \\
        \end{array} \right)
        \qquad \qquad
        Q^{-1}=\left( \begin{array}{ccc}
            \frac{1}{2} & 0 & 0 \\
            0 & 1 & 0 \\
            0 & 0 & 1 \\
        \end{array} \right)
        $$
        Por tanto, el método iterativo de Jacobi queda como:
        $$x^{(k+1)} = (I-Q^{-1}A)x^{(k)} + Q^{-1}b 
        =Bx^{(k)} + Q^{-1}b
        \quad \text{ con } B=I-Q^{-1}A$$
        $$B=I-\left( \begin{array}{ccc}
            1 & \frac{1}{2} & \frac{1}{2} \\
            1 & 1 & 2 \\
            1 & 2 & 1 \\
        \end{array} \right)
        = \left( \begin{array}{ccc}
            0 & -\frac{1}{2} & -\frac{1}{2} \\
            -1 & 0 & -2 \\
            -1 & -2 & 0 \\
        \end{array} \right)$$
        \begin{multline*}
            P_B(\lambda)=
            \left|\begin{array}{ccc}
                -\lambda & -\frac{1}{2} & -\frac{1}{2} \\
                -1 & -\lambda & -2 \\
                -1 & -2 & -\lambda
            \end{array} \right|
            =\left|\begin{array}{ccc}
                -\lambda & -\frac{1}{2} & 0 \\
                -1 & -\lambda & -2+\lambda \\
                -1 & -2 & 2-\lambda
            \end{array} \right|
            =\left|\begin{array}{ccc}
                -\lambda & -\frac{1}{2} & 0 \\
                -2 & -2-\lambda & 0 \\
                -1 & -2 & 2-\lambda
            \end{array} \right|
            =\\=
            (2-\lambda)q(\lambda) \Longrightarrow \rho(B)\geq 2
        \end{multline*}
        Por tanto, como $\rho(B)\geq 2$, el método de Jacobi tampoco converge en este caso independientemente del valor de $x^{(0)}$.

        Trabajemos ahora con el método de Gauss-Seidel.
        $$Q=\left( \begin{array}{ccc}
            2 & 0 & 0 \\
            1 & 1 & 0 \\
            1 & 2 & 1 \\
        \end{array} \right)
        \qquad \qquad
        Q^{-1}=\left( \begin{array}{ccc}
            \frac{1}{2} & 0 & 0 \\
            - \frac{1}{2} & 1 & 0 \\
             \frac{1}{2} & -2 & 1 \\
        \end{array} \right)
        $$
        Por tanto, el método iterativo de Gauss-Seidel queda como:
        $$x^{(k+1)} = (I-Q^{-1}A)x^{(k)} + Q^{-1}b 
        =Bx^{(k)} + Q^{-1}b
        \quad \text{ con } B=I-Q^{-1}A$$
        $$B=I-\left( \begin{array}{ccc}
            1 & \frac{1}{2} & \frac{1}{2} \\
            0 &  \frac{1}{2} &  \frac{3}{2} \\
            0 &  \frac{1}{2} &  -\frac{5}{2} \\
        \end{array} \right)
        = \left( \begin{array}{ccc}
            0 & -\frac{1}{2} & -\frac{1}{2} \\
            0 &  \frac{1}{2} &  -\frac{3}{2} \\
            0 &  -\frac{1}{2} &  \frac{7}{2} \\
        \end{array} \right)$$
        \begin{multline*}
            P_B(\lambda)=
            \left|\begin{array}{ccc}
               -\lambda & -\frac{1}{2} & -\frac{1}{2} \\
                0 &  \frac{1}{2}-\lambda &  -\frac{3}{2} \\
                0 &  -\frac{1}{2} &  \frac{7}{2}-\lambda \\
            \end{array} \right|
            = -\lambda\left(\lambda^2 - 4\lambda + 1\right)
            = -\lambda(\lambda-2-\sqrt{3})(\lambda-2+\sqrt{3})
        \end{multline*}
        Por tanto, como $\rho(B)= 2+\sqrt{3}\geq 1$, el método de Gauss-Seidel no converge en este caso.        
    \end{enumerate}
\end{ejercicio}

\begin{ejercicio}
    Determina el número de operaciones necesario para resolver un sistema de $n$ ecuaciones lineales con $n$ incógnitas mediante los siguientes métodos:
    \begin{enumerate}
        \item La factorización LU en la forma de Doolittle.
        \item La factorización de Choslesky (suponiendo que la matriz de coeficientes es simétrica y definida positiva).
    \end{enumerate}
\end{ejercicio}


\begin{ejercicio} \textbf{Ejercicio Examen 21/22}\\
     Se considera una norma vectorial $||\cdot||$ en $\bb{R}^n$ y la correspondiente norma matricial inducida $||\cdot||$. Dada una matriz cuadrada regular $S$ de orden $n$, se define la norma vectorial $||\cdot||_S$ por:
     $$||x||_S = ||Sx||$$

     \begin{enumerate}
         \item Prueba que así definida es una norma en $\bb{R}^n$
         \begin{itemize}
             \item $||x||_S = ||Sx|| \geq 0$ por ser $||\cdot||$ una norma vectorial. Además, se comprueba que $||x||_S = 0 \Longleftrightarrow x=0$
             $$||x||_S = 0 \Longleftrightarrow ||Sx|| = 0 \Longleftrightarrow Sx = 0 \Longleftrightarrow x = S^{-1}\cdot 0 = 0$$

             \item $||cx||_S = ||S(cx)|| = ||c(Sx)|| = |c|\cdot ||Sx|| = |c| \cdot ||x||_S$

             \item $||x+y||_S = ||S(x+y)|| = ||Sx + Sy|| \leq ||Sx|| + ||Sy|| = ||x||_S + ||y||_S$
         \end{itemize}

         \item Prueba que la norma matricial inducida es
         $$||A||_S = ||SAS^{-1}||$$
         \begin{proof}
             \begin{multline*}
                 ||A||_S = \max_{x\neq 0} \frac{||Ax||_S}{||x||_S}
                 = \max_{x\neq 0} \frac{||SAx||}{||Sx||}
                 = \max_{x\neq 0} \frac{||SAS^{-1}Sx||}{||Sx||}
                 =\\ \stackrel{(\ast)}{=}
                 \max_{Sx\neq 0} \frac{||SAS^{-1}Sx||}{||Sx||} = ||SAS^{-1}||
             \end{multline*}
             Donde en $(\ast)$ he usado que, por ser $S$ regular,
             $$\{x\in \bb{R}^n \mid x\neq 0\} = \{x\in \bb{R}^n \mid Sx\neq 0\}$$
             Como ambos conjuntos son los mismos, el máximo se alcanzará en el mismo valor.
        \end{proof}

         \item Si denotamos por $\kappa(A)$ y $\kappa_S(A)$ el número de condición de la matriz $A$ respecto de las normas $||\cdot||$ y $||\cdot||_S$ respectivamente, prueba que:
         $$\kappa_S (A) \leq \kappa(S)^2\kappa(A)$$
         \begin{proof}
             \begin{multline*}
                 \kappa_S(A) = ||A||_S ||A^{-1}||_S = ||SAS^{-1}||\cdot ||SA^{-1}S^{-1}||
                 \leq \\ \leq
                 ||S||^2 ||S^{-1}||^2 ||A||||A^{-1}|| = \kappa(S)^2 \kappa(A)
             \end{multline*}
         \end{proof}
     \end{enumerate}
\end{ejercicio}

\begin{ejercicio} \textbf{Ejercicio Examen 21/22}\\
    Dadas las matrices
    $$A=\left( \begin{array}{cc}
        -2 & 1/2 \\
        -1/2 & -2
    \end{array}\right)
    \qquad \qquad
    b=\left( \begin{array}{c}
        8\\32
    \end{array}\right)$$
    se pretende resolver el sistema $Ax=b$.

    \begin{enumerate}
        \item ¿Se puede garantizar la convergencia de los métodos de Jacobi y Gauss-Seidel? Justifica la respuesta.\\
        
        Sí, ya que la matriz $A$ es E.D.D., ya que $2>1/2$ y $2>1/2$.\\

        Alternativamente, y solo para el caso del método de Jacobi, se demuestra de manera general.
        
        La matriz de descomposición del método de Jacobi es:
        $$Q=D=\left( \begin{array}{cc}
            -2 & 0 \\
            0 & -2
        \end{array}\right) = -2I$$
        Por tanto, el sistema de punto fijo de Jacobi $x=B_J x + c$  tiene como $B_J$ a la matriz:
        $$B_J = I-Q^{-1}A = I+\frac{1}{2}A=I + \left( \begin{array}{cc}
            -1 & 1/4 \\
            -1/4 & -1
        \end{array}\right)
        = \left( \begin{array}{cc}
            0 & 1/4 \\
            -1/4 & 0
        \end{array}\right)$$

        Por tanto, como $||B_J||_1 < 1 \Longrightarrow $ este método iterativo converge.

        \item Escribe las ecuaciones de los métodos y realiza dos iteraciones del método de Gauss-Seidel partiendo de $x^{(0)}=(0,0)$.\\

        Las ecuaciones del método de Jacobi son:
        \begin{equation*}
            \left\{\begin{array}{l}
                x_1^{(k+1)} = -\frac{1}{2}\left( -\frac{1}{2}x_2^{(k)} + 8 \right) = \frac{1}{4}x_2^{(k)} - 4 \\
                x_2^{(k+1)} = -\frac{1}{2}\left( \frac{1}{2}x_1^{(k)} + 32 \right) =  -\frac{1}{4}x_1^{(k)} - 16\\
            \end{array} \right.
        \end{equation*}
        
        Las ecuaciones del método de Gauss-Seidel son:
        \begin{equation*}
            \left\{\begin{array}{l}
                x_1^{(k+1)} = \frac{1}{4}x_2^{(k)} - 4 \\
                x_2^{(k+1)} = -\frac{1}{4}x_1^{(k+1)} - 16\\
            \end{array} \right.
        \end{equation*}

        Realizamos ahora dos iteraciones del método de Gauss-Seidel:
        \begin{equation*}
            \begin{array}{c|c|c}
                k & x_1^{(k)} & x_2^{(k)} \\ \hline
                0 & 0 & 0 \\
                1 & -4 & -15 \\
                2 & -\frac{31}{4} & -\frac{225}{16} \\
            \end{array}
        \end{equation*}


        \item Se propone el método iterativo
        $$x^{k+1} = (I-\omega A)x^{(k)} + \omega b$$
        Prueba que para $\omega=-\frac{1}{2}$ el método converge a la solución del sistema para cualquier valor inicial $x^{(0)}$. ¿Que debe cumplir $\omega$ para que el método sea convergente? Indica algún otro valor para el que así sea.

        \begin{equation*}
            I-\omega A = \left( \begin{array}{cc}
                1+2\omega & -\frac{\omega}{2} \\
                \frac{\omega}{2} & 1+2\omega
            \end{array}\right)
        \end{equation*}

        \begin{equation*}
            P_{I-\omega A}(\lambda) = \lambda^2 - (2+4\omega)\lambda + (1+2\omega)^2 + \frac{\omega^2}{4}
        \end{equation*}

        Los valores propios de dicha matriz son: $$\lambda\in \bb{R} \mid \lambda^2 - (2+4\omega)\lambda + (1+2\omega)^2 + \frac{\omega^2}{4} =0$$
        \begin{equation*}\begin{split}
            \lambda &= \frac{2+4\omega \pm \sqrt{(2+4\omega)^2 -4(1+2\omega)^2 - \omega^2}}{2}\\
            &= \frac{2+4\omega \pm \sqrt{\cancel{2^2(1+2\omega)^2} \cancel{-4(1+2\omega)^2} - \omega^2}}{2} \\
            &= 1+2\omega \pm \frac{|\omega|}{2}i = 1 + 2\omega \pm \frac{\omega}{2}i
        \end{split}\end{equation*}

        Por tanto, los valores propios son: $\left\{1 + 2\omega \pm \frac{\omega}{2}i\right\}$. Para que el método iterativo converga, necesitamos que
        $$\max \left\{\left|1 + 2\omega + \frac{\omega}{2}i\right| ,\left| 1 + 2\omega - \frac{\omega}{2}i\right| \right\} < 1$$

        Como $\left| 1 + 2\omega - \frac{\omega}{2}i\right| = \left| 1 + 2\omega + \frac{\omega}{2}i\right|$, la inecuación a resolver es:
        \begin{multline*}
            \left| 1 + 2\omega - \frac{\omega}{2}i\right| < 1 \Longleftrightarrow \sqrt{(1+2\omega)^2 + \frac{\omega^2}{4}} < 1 \Longleftrightarrow 1 + 4\omega + 4\omega^2 + \frac{\omega^2}{4} < 1 
            \Longleftrightarrow \\ \Longleftrightarrow
            \omega\left(4 + 4\omega + \frac{\omega}{4}\right) < 0
        \end{multline*}

        Esta última desigualdad se cumple solo si uno de los dos términos es negativos.
        \begin{equation*}
            \omega < 0 \hspace{3cm} 4 + 4\omega + \frac{\omega}{4} = 4 + \frac{17}{4}\omega < 0 \Longleftrightarrow \omega < \frac{-16}{17}
        \end{equation*}

        Por tanto, el método iterativo converge si: $$\omega \in \left]-\frac{16}{17},0\right[$$
    \end{enumerate}

\end{ejercicio}