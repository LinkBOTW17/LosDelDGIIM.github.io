\documentclass[12pt]{article}

\input{assets/preambulo.tex}


\begin{document}

    % 1. Foto de fondo
    % 2. Título
    % 3. Encabezado Izquierdo
    % 4. Color de fondo
    % 5. Coord x del titulo
    % 6. Coord y del titulo
    % 7. Fecha

    
    \include{assets/portada}
    \portadaExamen{ffccA4.jpg}{MN I\\Examen I}{MN I. Examen I}{MidnightBlue}{-8}{28}{2023}{Arturo Olivares Martos}

    \begin{description}
        \item[Asignatura] Métodos Numéricos I.
        \item[Curso Académico] 2021-22.
        \item[Grado] Doble Grado en Ingeniería Informática y Matemáticas.
        \item[Grupo] Único.
        \item[Profesor] Lidia Fernández Rodríguez.
        \item[Descripción] Prueba 1. Temas 1 y 2.
        %\item[Fecha] 10 de noviembre de 2023.
        %\item[Duración] 60 minutos.
    
    \end{description}
    \newpage
    
    \begin{ejercicio} [\textbf{1.5 puntos}]
    Dado el sistema de ecuaciones lineales
    \begin{equation*}
        \left\{ \begin{array}{rrrrrrr}
            2x_1 & + & x_2 & + & 3x_3 &=& 1  \\
            6x_1 & + & \alpha x_2 & + & 10x_3 &=&  5 \\
            4x_1 & + & 6x_2 & + & 8x_3 &=&  5
        \end{array}\right.
    \end{equation*}
    ¿Qué debe cumplir el parámetro $\alpha$ para que se pueda resolver el sistema usando el método de Gauss sin intercambio de filas?\\

    Como este método es equivalente a la descomposición LU, basta con que todos sus menores principales sean no nulos.
    \begin{equation*}
        |2|=2\neq 0 \qquad \left|\begin{array}{cc}
            2 & 1 \\
            6 & \alpha
        \end{array} \right| = 2\alpha-6 \neq 0 \Longrightarrow \alpha \neq 3
    \end{equation*}
    \begin{equation*}
        \left|\begin{array}{ccc}
            2 & 1 & 3\\
            6 & \alpha & 10 \\
            4 & 6 & 8    
        \end{array} \right| = 16\alpha +40 +108-12\alpha-120-48 = 4\alpha -20 \neq 0 \Longrightarrow \alpha\neq 5
    \end{equation*}

    Por tanto, se puede resolver siempre que $\alpha \neq \{3,5\}$. 
    
    Alternativamente, se puede siempre que $a_{kk}^{(k)} \neq 0$. Veamos:
    \begin{multline*}
        \left(\begin{array}{ccc|c}
            2 & 1 & 3 & 1\\
            6 & \alpha & 10 & 5 \\
            4 & 6 & 8 & 5   
        \end{array} \right)
        \xrightarrow[F'_3=F_3-2F1]{F'_2=F_2-3F_1}
        \left(\begin{array}{ccc|c}
            2 & 1 & 3 & 1\\
            0 & \alpha-3 & 1 & 2 \\
            0 & 4 & 2 & 3   
        \end{array} \right)
        \longrightarrow \\
        \xrightarrow[F'_3=F_3+m_{3,2}F_2]{m_{3,2}=\frac{-4}{\alpha-3}}
        \left(\begin{array}{ccc|c}
            2 & 1 & 3 & 1\\
            0 & \alpha-3 & 1 & 2 \\
            0 & 0 & 2-\frac{4}{\alpha-3} & 3-\frac{8}{\alpha-3}
        \end{array} \right)
    \end{multline*}

    $a_{11}^{(1)}=2\neq 0$
    
    $a_{22}^{(2)}=\alpha- 3\neq 0 \Longleftrightarrow \alpha \neq 3$
    
    $a_{33}^{(3)}=2-\frac{4}{\alpha-3}\neq 0 \Longleftrightarrow 2\alpha-6\neq 4 \Longleftrightarrow \alpha\neq 5$\\
    
    Podemos ver que, efectivamente, se cumple que se puede resolver si $\alpha\neq \{3,5\}$
\end{ejercicio}


\begin{ejercicio} [\textbf{2 puntos}]
    Resuelve el sistema
    \begin{equation*}
        \left\{ \begin{array}{rrrrr}
            0.0300x_1 & + & 58.9x_2 &=& 59.2  \\
            5.31x_1 & - & 6.10 x_2 &=&  47.0 \\
        \end{array}\right.
    \end{equation*}
    utilizando el método de Gauss con pivote parcial y aritmética de tres dígitos. Realiza los cálculos uno a uno indicando claramente el redondeo a tres dígitos en cada paso.
    \begin{multline*}
        \left( \begin{array}{cc|c}
            0.03 & 58.9 & 59.2 \\
            5.31 & -6.10 & 47.0
        \end{array}\right)
        \xrightarrow{F_1 \Longleftrightarrow F_2}
        \left( \begin{array}{cc|c}
            5.31 & -6.10 & 47.0\\
            0.03 & 58.9 & 59.2 \\
        \end{array}\right)
        \longrightarrow \\
        \xrightarrow[m_{2,1} = -\frac{0.03}{5.31}\approx -0.00565]{F'_2 = F_2 + m_{2,1}F_1}
        \left( \begin{array}{cc|c}
            5.31 & -6.10 & 47.0\\
            0 & 58.9 & 58.9
        \end{array}\right)
    \end{multline*}
    \begin{equation*}
        x_2 \approx \frac{58.9}{58.9} =1 \qquad \qquad x_1 \approx \frac{47+6.1x_2}{5.31} \approx \frac{47+6.1}{5.31} \approx \frac{53.1}{5.31} =10
    \end{equation*}
\end{ejercicio}

\begin{ejercicio} [\textbf{1.5 puntos}]
     Pon un ejemplo de matriz simétrica que admita factorización de Cholesky y otra que no la admita. Justifica tu respuesta.
     \begin{equation*}
         A = \left( \begin{array}{ccc}
             2 & 1 & 1 \\
             1 & 2 & 1 \\
             1 & 1 & 2
         \end{array}\right)
         \qquad \qquad
         B = \left( \begin{array}{ccc}
             -2 & 1 & 1 \\
             1 & 2 & 1 \\
             1 & 1 & 2
         \end{array}\right)
     \end{equation*}

     Una condición necesaria y suficiente para que una matriz admita factorización de Cholesky es que sea simétrica y definida positiva. Como $A$ y $B$ son simétricas, una de ellas debe ser definida positiva y la otra no.

     Es fácil ver que $A$ es definida positiva, ya que:
     \begin{equation*}
         |2|=2 \qquad \left| \begin{array}{cc}
             2 & 1 \\
             1 & 2 \\
         \end{array}\right| = 3 \qquad |A|=10-6=4
     \end{equation*}

     Por tanto, $A$ sí admite factorización de Cholesky. Sin embargo, $B$ no es definida positiva ya que su menor principal de orden 1 es negativo, por lo que $B$ no admite factorización de Cholesky.
\end{ejercicio}

\begin{ejercicio} [\textbf{1.5 puntos}]
      Se considera una norma vectorial $||\cdot||$ en $\bb{R}^n$ y la correspondiente norma matricial inducida $||\cdot||$. Dada una matriz cuadrada regular $S$ de orden $n$, se define la norma vectorial $||\cdot||_S$ por:
     $$||x||_S = ||Sx||$$

     \begin{enumerate}
         \item Prueba que así definida es una norma en $\bb{R}^n$
         \begin{itemize}
             \item $||x||_S = ||Sx|| \geq 0$ por ser $||\cdot||$ una norma vectorial. Además, se comprueba que $||x||_S = 0 \Longleftrightarrow x=0$
             $$||x||_S = 0 \Longleftrightarrow ||Sx|| = 0 \Longleftrightarrow Sx = 0 \Longleftrightarrow x = S^{-1}\cdot 0 = 0$$

             \item $||cx||_S = ||S(cx)|| = ||c(Sx)|| = |c|\cdot ||Sx|| = |c| \cdot ||x||_S$

             \item $||x+y||_S = ||S(x+y)|| = ||Sx + Sy|| \leq ||Sx|| + ||Sy|| = ||x||_S + ||y||_S$
         \end{itemize}

         \item Prueba que la norma matricial inducida es
         $$||A||_S = ||SAS^{-1}||$$
         \begin{proof}
             \begin{multline*}
                 ||A||_S = \max_{x\neq 0} \frac{||Ax||_S}{||x||_S}
                 = \max_{x\neq 0} \frac{||SAx||}{||Sx||}
                 = \max_{x\neq 0} \frac{||SAS^{-1}Sx||}{||Sx||}
                 =\\ \stackrel{(\ast)}{=}
                 \max_{Sx\neq 0} \frac{||SAS^{-1}Sx||}{||Sx||} = ||SAS^{-1}||
             \end{multline*}
             Donde en $(\ast)$ he usado que, por ser $S$ regular,
             $$\{x\in \bb{R}^n \mid x\neq 0\} = \{x\in \bb{R}^n \mid Sx\neq 0\}$$
             Como ambos conjuntos son los mismos, el máximo se alcanzará en el mismo valor.
        \end{proof}

         \item Si denotamos por $\kappa(A)$ y $\kappa_S(A)$ el número de condición de la matriz $A$ respecto de las normas $||\cdot||$ y $||\cdot||_S$ respectivamente, prueba que:
         $$\kappa_S (A) \leq \kappa(S)^2\kappa(A)$$
         \begin{proof}
             \begin{multline*}
                 \kappa_S(A) = ||A||_S ||A^{-1}||_S = ||SAS^{-1}||\cdot ||SA^{-1}S^{-1}||
                 \leq \\ \leq
                 ||S||^2 ||S^{-1}||^2 ||A||||A^{-1}|| = \kappa(S)^2 \kappa(A)
             \end{multline*}
         \end{proof}
     \end{enumerate}
\end{ejercicio}

\begin{ejercicio}\textbf{[3 puntos]}
    Dadas las matrices
    $$A=\left( \begin{array}{cc}
        -2 & 1/2 \\
        -1/2 & -2
    \end{array}\right)
    \qquad \qquad
    b=\left( \begin{array}{c}
        8\\32
    \end{array}\right)$$
    se pretende resolver el sistema $Ax=b$.

    \begin{enumerate}
        \item ¿Se puede garantizar la convergencia de los métodos de Jacobi y Gauss-Seidel? Justifica la respuesta.\\
        
        Sí, ya que la matriz $A$ es E.D.D., ya que $2>1/2$ y $2>1/2$.\\

        Alternativamente, y solo para el caso del método de Jacobi, se demuestra de manera general.
        
        La matriz de descomposición del método de Jacobi es:
        $$Q=D=\left( \begin{array}{cc}
            -2 & 0 \\
            0 & -2
        \end{array}\right) = -2I$$
        Por tanto, el sistema de punto fijo de Jacobi $x=B_J x + c$  tiene como $B_J$ a la matriz:
        $$B_J = I-Q^{-1}A = I+\frac{1}{2}A=I + \left( \begin{array}{cc}
            -1 & 1/4 \\
            -1/4 & -1
        \end{array}\right)
        = \left( \begin{array}{cc}
            0 & 1/4 \\
            -1/4 & 0
        \end{array}\right)$$

        Por tanto, como $||B_J||_1 < 1 \Longrightarrow $ este método iterativo converge.

        \item Escribe las ecuaciones de los métodos y realiza dos iteraciones del método de Gauss-Seidel partiendo de $x^{(0)}=(0,0)$.\\

        Las ecuaciones del método de Jacobi son:
        \begin{equation*}
            \left\{\begin{array}{l}
                x_1^{(k+1)} = -\frac{1}{2}\left( -\frac{1}{2}x_2^{(k)} + 8 \right) = \frac{1}{4}x_2^{(k)} - 4 \\
                x_2^{(k+1)} = -\frac{1}{2}\left( \frac{1}{2}x_1^{(k)} + 32 \right) =  -\frac{1}{4}x_1^{(k)} - 16\\
            \end{array} \right.
        \end{equation*}
        
        Las ecuaciones del método de Gauss-Seidel son:
        \begin{equation*}
            \left\{\begin{array}{l}
                x_1^{(k+1)} = \frac{1}{4}x_2^{(k)} - 4 \\
                x_2^{(k+1)} = -\frac{1}{4}x_1^{(k+1)} - 16\\
            \end{array} \right.
        \end{equation*}

        Realizamos ahora dos iteraciones del método de Gauss-Seidel:
        \begin{equation*}
            \begin{array}{c|c|c}
                k & x_1^{(k)} & x_2^{(k)} \\ \hline
                0 & 0 & 0 \\
                1 & -4 & -15 \\
                2 & -\frac{31}{4} & -\frac{225}{16} \\
            \end{array}
        \end{equation*}


        \item Se propone el método iterativo
        $$x^{k+1} = (I-\omega A)x^{(k)} + \omega b$$
        Prueba que para $\omega=-\frac{1}{2}$ el método converge a la solución del sistema para cualquier valor inicial $x^{(0)}$. ¿Que debe cumplir $\omega$ para que el método sea convergente? Indica algún otro valor para el que así sea.

        \begin{equation*}
            I-\omega A = \left( \begin{array}{cc}
                1+2\omega & -\frac{\omega}{2} \\
                \frac{\omega}{2} & 1+2\omega
            \end{array}\right)
        \end{equation*}

        \begin{equation*}
            P_{I-\omega A}(\lambda) = \lambda^2 - (2+4\omega)\lambda + (1+2\omega)^2 + \frac{\omega^2}{4}
        \end{equation*}

        Los valores propios de dicha matriz son: $$\lambda\in \bb{R} \mid \lambda^2 - (2+4\omega)\lambda + (1+2\omega)^2 + \frac{\omega^2}{4} =0$$
        \begin{equation*}\begin{split}
            \lambda &= \frac{2+4\omega \pm \sqrt{(2+4\omega)^2 -4(1+2\omega)^2 - \omega^2}}{2}\\
            &= \frac{2+4\omega \pm \sqrt{\cancel{2^2(1+2\omega)^2} \cancel{-4(1+2\omega)^2} - \omega^2}}{2} \\
            &= 1+2\omega \pm \frac{|\omega|}{2}i = 1 + 2\omega \pm \frac{\omega}{2}i
        \end{split}\end{equation*}

        Por tanto, los valores propios son: $\left\{1 + 2\omega \pm \frac{\omega}{2}i\right\}$. Para que el método iterativo converga, necesitamos que
        $$\max \left\{\left|1 + 2\omega + \frac{\omega}{2}i\right| ,\left| 1 + 2\omega - \frac{\omega}{2}i\right| \right\} < 1$$

        Como $\left| 1 + 2\omega - \frac{\omega}{2}i\right| = \left| 1 + 2\omega + \frac{\omega}{2}i\right|$, la inecuación a resolver es:
        \begin{multline*}
            \left| 1 + 2\omega - \frac{\omega}{2}i\right| < 1 \Longleftrightarrow \sqrt{(1+2\omega)^2 + \frac{\omega^2}{4}} < 1 \Longleftrightarrow 1 + 4\omega + 4\omega^2 + \frac{\omega^2}{4} < 1 
            \Longleftrightarrow \\ \Longleftrightarrow
            \omega\left(4 + 4\omega + \frac{\omega}{4}\right) < 0
        \end{multline*}

        Esta última desigualdad se cumple solo si uno de los dos términos es negativos.
        \begin{equation*}
            \omega < 0 \hspace{3cm} 4 + 4\omega + \frac{\omega}{4} = 4 + \frac{17}{4}\omega < 0 \Longleftrightarrow \omega < \frac{-16}{17}
        \end{equation*}

        Por tanto, el método iterativo converge si: $$\omega \in \left]-\frac{16}{17},0\right[$$
    \end{enumerate}
\end{ejercicio}
\end{document}