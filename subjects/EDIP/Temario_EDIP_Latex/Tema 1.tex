\chapter{Estadística descriptiva unidimensional}

\section{Definiciones}

\begin{itemize}
    \item \textbf{Fenómenos determinísticos:} Los que dan lugar al mismo resultado si se hacen bajo condiciones idénticas.
    \item \textbf{Fenómenos aleatorios:} los resultados pueden variar incluso si el estudio se realiza con las mismas condiciones iniciales.
    \item \textbf{Población:} Conjunto de unidades con al menos una característica en común sobre la que se desea obtener cierta información.
    \item \textbf{Muestra:} Subconjunto de la población elegido en términos de representatividad.
    \item \textbf{Carácter:} Propiedad a ser estudiada, puede ser cualitativa o cuantitativa.
    \item \textbf{Modalidad:} Valores que se han presentado al medir una variable con una cierta escala.

          \begin{itemize}
              \item Principio de incompatibilidad: Un individuo sólo puede tomar valor en una modalidad.
              \item Principio de exhaustividad: Todos los individuos deben tomar al menos un valor.
          \end{itemize}

    \item \textbf{Variable} Ente matemático capaz de captar las diferentes modalidades que puede tomar una característica a medir en una población. Se suelen relacionar con valores cuantitativos.
    \begin{itemize}
        \item \textbf{Variables discretas:} Si el paso de un valor al siguiente representa un salto.
        \item \textbf{Variables continuas:} Si se puede tomar cualquier valor entre dos valores dados.
    \end{itemize}
\end{itemize}

\begin{notacion}
    Supongamos que tenemos una población de tamaño $n$ de la cual obtenemos una muestra para realizar un estudio. Queremos medir el carácter $X$ sobre dicha muestra. A cada modalidad le asignaremos un valor $x_{i}$. De esta forma, al número de individuos que nos responda que presentan la modalidad $x_{i}$ acerca del carácter $X$ lo notaremos $n_{i}$.
\end{notacion}

\section{Escalas de medida}

Cuando realizamos un estudio estadístico debemos identificar de forma precisa las modalidades y asignarles símbolos o números
a dichas modalidades. Eso se denomina la medición del carácter.

\begin{itemize}
    \item \textbf{Escala nominal:} Las modalidades sólo pueden ser iguales o diferentes y no se puede determinar un órden en estas. Un ejemplo son las modalidades de verdadero/falso
          o los colores de pelo.
    \item \textbf{Escala ordinal:} Las modalidades pueden ser iguales o diferentes y además se puede establecer un orden de mayor que. Esta escala es válida tanto para carácteres cualitativos y cuantitativos.
          Ejemplo: niveles de aceptación.
    \item \textbf{Escala de intervalo:} Existen diferencias, luego podemos introducir el término de resta pero no existe un cero absoluto. Un ejemplo son las tallas de ropa.
    \item \textbf{Escala de razón:} Aquella en la que podemos dividir y decir que una modalidad es $a$ veces otra modalidad. Existe el cero absoluto.
\end{itemize}

\begin{ejercicio*} Da ejemplos de cada una de las escalas de medida. Para cada ejemplo, indica el carácter, si es cuantitativo o cualitativo, y la población.
\begin{enumerate}

    \item \textbf{Escala nominal}
    \begin{enumerate}
        \item \underline{Ser hijo único} Es cualitativo y la población son las personas. Las modalidades son ser hijo único o no.
        \item \underline{Sexo al nacer} Es cualitativo y la población son las personas. Las modalidades son ser hombre o mujer.
        \item \underline{Ser funcionario} Es cualitativo y la población es la población activa. Las modalidades son ser o no funcionario.
        \item \underline{Consumir estupefacientes} Es cualitativo y la población son las personas. Las modalidades son consumirlas o no.
        \item \underline{Provincia de origen de los estudiantes del DGIIM} Es cualitativo y la población son los estudiantes. Las modalidades son las distintas provincias.
        \item \underline{Grupo Sanguíneo} Es cualitativo y la población son las personas. Las modalidades son A+, A-, B+, B-, AB+, AB-, 0+ y 0-.
    \end{enumerate}

    \item \textbf{Escala ordinal}
    \begin{enumerate}
        \item \underline{Nivel de Estudios} Es cualitativo y la población son las personas. Las modalidades son analfabetismo, EP, ESO, FP, Universidad, etc.
        \item \underline{Rango en el ejército} Es cualitativo y la población son los militares. Las modalidades son los distintos rangos.
    \end{enumerate}

    \item \textbf{Escala de intervalo}
    \begin{enumerate}
        \item \underline{La temperatura en $^\circ C$} Es cuantitativo y la población son los distintos lugares del mundo. Es un carácter continuo.
        \item \underline{Inteligencia} Es cuantitativo y la población son las personas. Es un carácter continuo y se mide según el coeficiente intelectual $(CI)$.
        \item \underline{Tallaje de la ropa} Es cuantitativo y la población son las prendas de ropa. Es un carácter discreto y las modalidades son las distintas tallas.
        \item \underline{Grado de satisfacción de los políticos españoles}\footnote{Ejemplo de escala de \emph{Likert}} Es cualitativo y la población son los españoles. Las modalidades son los distintos gustos.
    \end{enumerate}

    \item \textbf{Escala de razón}
    \begin{enumerate}
        \item \underline{Notas de 1$^\circ$ del DGIIM} Es cuantitativo y la población son los estudiantes de dicha clase. Es un carácter continuo.
        \item \underline{Número de hermanos} Es cuantitativo y la población son las personas. Es un carácter discreto, y las modalidades son $\mathbb{N} \cup \{0\}$.
        \item \underline{Número de segundos que tarda un coche en llegar a los $100 km/h$} Es cuantitativo y la población son los coches. Es un carácter continuo.
        \item \underline{Salario bruto anual} Es cuantitativo y la población es la población activa. Es un carácter continuo.
        \item \underline{El tamaño de la RAM de un PC} Es cuantitativo y la población son los ordenadores. Es un carácter discreto.
        \item \underline{Estatura} Es cuantitativo y la población son las personas. Es un carácter continuo.
    \end{enumerate}
\end{enumerate}

\end{ejercicio*}

\section{Distribución de frecuencias}

En una población de $n$ individuos medimos la característica $X$, que puede adoptar las modalidades $x_{1}, x_{2}, ..., x_{k}$. Se denomina:
\begin{itemize}
    \item \textbf{Frecuencia absoluta de $x_{i}$:} Número total de individuos en la población que representa dicho valor $x_{i}$. Se denota $n_{i}$. Además, se verifica que $\sum\limits_{i = 1}^{k} n_{i} = n$.

    \item \textbf{Frecuencia relativa de $x_{i}$:} Es la proporción de individuos que presenta dicha modalidad: $f_{i} = \dfrac{n_{i}}{n}$. Además, se verifica que $\sum\limits_{i = 1}^{k} f_{i} = 1$.
\end{itemize}

Si las modalidades se pueden ordenar, supuesto $x_{1} < x_{2} < \ldots~< x_{i} < \ldots < x_{k}$:
\begin{itemize}
    \item \textbf{Frecuencia absoluta acumulada:} Es el número de individuos que presentan una modalidad menor o igual que $x_{i}$: $N_{i} = \sum\limits_{j=1}^{i}n_{j}$.
    \item \textbf{Frecuencia relativa acumulada:} Es la proporción de individuos que presentan una modalidad menor o igual que $x_{i}$: $F_{i} = \dfrac{N_{i}}{n}$.
\end{itemize}


Llamaremos \textbf{distribución de frecuencias} de una variable al conjunto formado por cada uno de los valores modales junto con sus frecuencias:
\begin{itemize}
    \item Distribución de frecuencias absolutas: $\{x_i, n_i\}_{i=1, \dots, k}$
    \item Distribución de frecuencias relativas: $\{x_i, f_i\}_{i=1, \dots, k}$
    \item Distribución de frecuencias absolutas acumuladas: $\{x_i, N_i\}_{i=1, \dots, k}$
    \item Distribución de frecuencias relativas acumuladas: $\{x_i, F_i\}_{i=1, \dots, k}$
\end{itemize}


Si las modalidades son intervalos, llamaremos a estos límites intervalos de clases: $[e_{0}, e_{1}], ]e_{1}, e_{2}], ]e_{2}, e_{3}], \ldots, ]e_{k-1}, e_{k}]$ y definimos nuevos conceptos:
\begin{itemize}
    \item \textbf{Marca de clase:} Es la media de los límites de cada intervalo: $x_{i}~=~\dfrac{e_{i-1}+e_{i}}{2}$.
    \item \textbf{Amplitud de clase:} $a_{i} = e_{i} - e_{i-1}$.
    \item \textbf{Densidad de frecuencia de modalidad i de variable X:} $h_{i}~=~d_{i}~=~\dfrac{n_{i}}{a_{i}}$. También se calcula a veces con la frecuencia relativa.
\end{itemize}


Cuando comencemos el estudio de una variable, indicaremos:\\
\emph{
    Sea $X$ una variable estadística con población $n$ y modalidades $x_1, \dots, x_k$ con \emph{distribución de frecuencias}:
        $$\{x_i, n_i\}_{i=1, \dots, k}$$
}

\section{Representaciones gráficas de una variable estadística unidimensional}

\subsection{Variables cualitativas o atributos}
\begin{itemize}
    \item \textbf{Diagrama de sectores}.\\
    Es un círculo dividido en tantos sectores circulares como modalidades tenga el carácter, siendo el área de cada uno proporcional a la frecuencia absoluta o relativa de la modalidad.
    
    \item \textbf{Diagrama de rectángulos o barras}.\\
    Consiste en varios rectángulos (uno por modalidad) de base constante y alturas proporcionales a las frecuencias (absolutas o relativas) de cada modalidad.
    
    \item \textbf{Pictograma}.\\
    Se dibujan figuras, normalmente alusivas al carácter que se está estudiando, bien una para cada modalidad con tamaño proporcional a su frecuencia, o bien repitiendo la figura tantas veces como requieran las frecuencias.
\end{itemize}

\subsection{Variables discretas}
\begin{itemize}
    \item \textbf{Diagramas de barras}.\\
    Similar al de atributos: en un sistema de ejes cartesianos se representa en el eje de abcisas los valores de la variable, y se trazan barras verticales con longitudes proporcionales a sus frecuencias (absolutas o relativas).
    
    \item \textbf{Función / Curva de distribución o acumulativa}:

          $$F: \R \mapsto \R \mid F(x) = \left\{
              \begin{array}{cl}
                  0   & \mbox{si } x < x_1              \\
                  F_i & \mbox{si } x_i \leq x < x_{i+1} \\
                  1   & \mbox{si } x \geq x_k
              \end{array}\right.
          $$

          Función definida en todo $\R$, no decreciente y continua por la derecha.

\end{itemize}

\subsection{Variables continuas}
 \textbf{Histogramas:}

De los más utilizados.
La base de los rectángulos son las diferentes clases o intervalos de la variable y la altura de estos son las densidades de frecuencia $h_i = \frac{f_i}{a_i}$ (o $h_i = \frac{n_i}{a_i}$). \\


Calculamos el área de los rectángulos de la siguiente forma en los histogramas:
$$Area = a_i \cdot \dfrac{f_i}{a_i} = f_i \ \ \ Area = a_i \cdot \dfrac{n_i}{a_i} = n_i$$


\textbf{Poligonal de frecuencias:} Poligonal resultante de unir los puntos correspondientes a los techos de las marcas de clase de los intervalos en el histograma.\\


\textbf{Curva acumulativa o de distribución:} Es la proporción de individuos en la población cuyo valor de la
variable es inferior o igual a cada modalidad. Esta función se conoce únicamente para los valores de $x$ que son
cota superior de cada intervalo. Asumiendo que los datos son equidistantes en el intervalo, podemos unir dichos puntos.

$$F(e_i)=\sum_{j=1}^i f_j$$

Se trata de una función monótona no decreciente.

\section{Características unidimensionales}

Resúmenes cuantitativos de la información de los datos.

Propiedades deseables (Propiedades de Yule):
\begin{itemize}
    \item Deben definirse de manera objetiva.
    \item Deben usar todas las observaciones.
    \item Deben tener un significado concreto, para ser de rápida y fácil interpretación.
    \item Deben ser sencillas de calcular.
    \item Deben prestarse fácilmente al cálculo algebraico.
    \item Deben ser poco sensibles a fluctuaciones muestrales, sin mucho cambio cuando alteramos las medidas de los extremos.
\end{itemize}

Pueden ser de varios tipos:

\begin{itemize}
    \item \textbf{Medidas de posición:} permiten situar una distribucion en la recta real. Las más importantes son las de centralización o tendencia central,
          denominadas promedios (proporcionan un valor central representativo alrededor del cual se agrupan los datos) y cuantiles (que proporcionan valores representativos
          de parte de la distribución).
    \item \textbf{Medidas de dispersión:} Miden el grado de esparcimiento de los datos de una distribución.
    \item \textbf{Medidas de forma:} Caracterizan de manera precisa la forma de una distribución sin tener que llevar a cabo una representación gráfica.
\end{itemize}

\subsection{Medidas de posición}
\begin{observacion}
    Promediar es dar la media aritmética, mediana y moda.
\end{observacion}

\subsubsection{Media aritmética}

Nos sirve para tener un valor alrededor del cual se sitúan los valores, actuando como centro de gravedad de la distribución.

$$\overline{x}=\dfrac{1}{n} \sum_{i=1}^{k}n_i x_i = \sum_{i=1}^{k}f_i x_i$$

Si los datos están distribuidos en intervalos, se usan las marcas de clase.\\

\begin{prop}
    La media de una variable unidimensional está acotada.
\end{prop}
\begin{proof}
    Es inmediata, ya que $x_1 \leq \overline{x} \leq x_k$.
\end{proof}

\begin{prop}
    La media aritmética de las desviaciones de los datos respecto de la media aritmética es igual a $0$:
    \begin{equation*}
        \sum^k_{i=1} f_i(x_i-\bar{x})=0
    \end{equation*}
\end{prop}
\begin{proof}
    \begin{equation*}
        \sum^k_{i=1} f_i(x_i-\bar{x}) = \sum^k_{i=1}(f_i x - f_i\bar{x}) = \sum^k_{i=1}f_ix - \bar{x}\sum^k_{i=1}f_i = \bar{x} - 1\bar{x} = 0 
    \end{equation*}
\end{proof}

\begin{prop}\label{prop:1.3}
    Si se somete una variable $X$ a una transformación lineal afín, la media aritmética de la nueva variable es la imagen de la media de $X$ por la misma transformación:
    \begin{equation*}
        Y=aX+b \Longrightarrow \bar{Y} = a \bar{x} + b
    \end{equation*}
\end{prop}
\begin{proof}
    \begin{multline*}
        \bar{Y} = \sum^k_{i=1}f_iy_i = \sum^k_{i=1}f_i(ax_i+b) = \sum^k_{i=1}[f_i(ax_i)+f_ib] = \\
        = a\sum^k_{i=1}f_ix_i + b\sum^k_{i=1}f_i = a\bar{x} + 1b = a\bar{x} + b 
    \end{multline*}
\end{proof}

\begin{prop}\label{prop:1.4}
    La media aritmética de los cuadrados de las desviaciones respecto a la media aritmética es mínima:
    \begin{equation*}
        \sum^k_{i=1} f_i(x_i-\bar{x})^2 < \sum^k_{i=1} f_i(x_i-a)^2, \quad \forall a \neq \bar{x}
    \end{equation*}
\end{prop}
\begin{proof}
    Se trata de minimizar una parábola con coeficiente líder positivo, por lo que el valor que anule la primera derivada será el mínimo absoluto.
    \begin{equation*}
        \frac{\partial}{\partial a} \sum^k_{i=1} f_i(x_i-a)^2 =  -2\sum_{i=1}^k (f_ix_i - f_ia) = -2\bar{x} +2\sum_{i=1}^k f_ia = 0 \Longleftrightarrow a=\bar{x}
    \end{equation*}
\end{proof}

\noindent Test de Yule:
\begin{itemize}
    \item Es objetiva.
    \item Usa todas las observaciones.
    \item Representa el centro de gravedad de la distribución.
    \item Sencillo de calcular.
    \item Se presta a hacer cálculos para compararla.
    \item (Contra) Es sensible a fluctuaciones en los extremos.
\end{itemize}

\subsubsection{Media geométrica}

Se usa cuando las variables sufren variaciones acumuladas (como en porcentajes), se usa cuando se desea promediar
datos de una variable que tiene efectos multiplicativos acumulativos.

$$G=\sqrt[n]{x_1^{n_1} x_2^{n_2} \ldots x_k^{n_k}} = \sqrt[n]{\prod_{i=1}^{k}x_i^{n_i}}$$

Si se trata de una variable continua, la calculamos con las marcas de clase.

\begin{prop}
    El logaritmo de la media geométrica	es la media aritmética de los logaritmos de los valores de la variable.
\end{prop}
\begin{proof}
    $$\log G = \log \sqrt[n]{\prod_{i=1}^k x_i^{n_i}} = \dfrac{1}{n} \sum_{i=1}^k n_i \log x_i = \sum_{i=1}^k f_i \log x_i $$
\end{proof}

\begin{observacion}
    Si algún valor de la variable es 0 $\Rightarrow G=0$, luego esta media no nos será de mucha utilidad.
\end{observacion}

\noindent Test de Yule:
\begin{itemize}
    \item Es objetiva.
    \item Usa todas las observaciones.
    \item (Contra) Tiene significado concreto pero no es sencillo de interpretar.
    \item (Contra) Complicada de calcular.
    \item (Contra) Sufre también a fluctuaciones pero menos que la aritmética.
\end{itemize}

\subsubsection{Media armónica}

Se usa para promediar datos de magnitudes que son cocientes de dos magnitudes; esto es, magnitudes relativas
(su unidad de medida es referida a una unidad de otra variable). Por ejemplo, para promedir velocidades,
rendimientos o productividades, etc.

Se define como la inversa de la media aritmética de los valores inversos de la variable.

$$H = \dfrac{n}{\dfrac{n_1}{x_1} + \dfrac{n_2}{x_2} + \ldots + \dfrac{n_k}{x_k}} = \dfrac{n}{\sum\limits_{i=1}^k \dfrac{n_i}{x_i}}$$

Tenemos el mismo problema con la geométrica, cuando algún $x_i$ vale $0$ difícilmente vamos a poder realizar
dicha media. Además, no se recomienda realizarla cuando sea cercano a 0, ya que nos dispararía la media,
sensible para valores pequeños.\\

\noindent Test de Yule:
\begin{itemize}
    \item Es objetiva.
    \item Usa todos los datos.
    \item (Contra) Tiene un significado, pero es difícil de manejar.
    \item (Contra) No es sencilla de calcular.
\end{itemize}


\subsubsection{Media cuadrática}

Es la menos utilizada y, fundamentalmente, su uso se reduce al cálculo de promedios sobre superficies.
Se define como la raíz cuadrada de la media aritmética de los cuadrados de los valores de la variable.

$$Q = \sqrt{\sum_{i=1}^k f_i x_i^2}$$


\subsubsection{Moda}

La moda de una distribución es el valor de mayor frecuencia (absoluta o relativa), el que más se repite.

\begin{itemize}
    \item \underline{Variables discretas}: La moda es el valor $x_i \mid n_i \geq n_j$ o $f_i \geq f_j \ \forall j \in \{1, \ldots, k\}$.

    Si en variables discretas todas las variables $x_i$ se repiten $n_i$ veces con $n_i = n_j \ \forall i,j \mid i \neq j$ entonces diríamos que no hay moda.
    Si la moda se repite varias veces, hablamos de una moda plurimodal.
    
    \item \underline{Variables continuas}: La moda está en el denominado intervalo modal, el de mayor densidad de frecuencia $h_i = \frac{f_i}{a_i}$, es decir, el de mayor altura en el histograma.
    
    La moda en variables continuas se calcula haciendo interpolación y semejanza de triángulos: 
    
    La distancia de la moda desde el intervalo que más se repite es inversamente proporcional a la frecuencia de los intervalos contiguos.


    Calculamos la moda sabiendo que:
    
    $$\dfrac{h_i - h_{i-1}}{M_o - e_{i-1}} = \dfrac{h_i - h_{i+1}}{e_i - M_o} = \dfrac{(h_i - h_{i-1}) + (h_i - h_{i+1})}{a_i}$$
    
    Despejando:
    $$M_o = \dfrac{a_i (h_i - h_{i-1})}{2h_i- h_{i-1} - h_{i+1}} + e_{i-1}$$
\end{itemize}


\subsubsection{Mediana}

Como la media aritmética se presta a variaciones extremas, surge la mediana: Aquel valor que separa la distribución en dos efectivos de igual tamaño (supuestos ordenados por valor creciente de carácter).

Se puede calcular para variables discretas y para variables continuas.

La mediana también se puede calcular para características cualitativas pero han de estar en escala ordinal.

La mediana es la solución a la siguiente ecuación: 
$$F(x) = \dfrac{1}{2} \hspace{1cm} \left(\text{Equivalentemente}, N(x) = \dfrac{n}{2}\right)$$

\begin{itemize}
    \item \underline{Variables discretas}:
    Se busca $x_i \mid N_{i-1} < \frac{n}{2} \leq N_i$.
    \begin{itemize}
        \item Si $N_i > \frac{n}{2} \Rightarrow Me = x_i$.
        \item Si $N_i = \frac{n}{2} \Rightarrow Me = \dfrac{x_i + x_{i+1}}{2}$.
    \end{itemize}

    \item \underline{Variables continuas}:
    Se busca $I_i = (e_{i-1}, e_i] \mid N_{i-1} < \dfrac{n}{2} \leq N_i$ ó $F_{i-1} < \dfrac{1}{2} \leq~F_i$.
    \begin{itemize}
        \item Si $N_i = \dfrac{n}{2} $ ó $ F_i = \dfrac{1}{2} \Rightarrow M_e = e_i$.
        \item Si $N_i > \dfrac{n}{2}$ ó $F_i > \dfrac{1}{2} \Rightarrow$ La mediana está dentro de $I_i$, que se denomina el intervalo
              mediano y, para calcularla, hacemos una interpolación lineal:
              $$M_e = e_{i-1} + \dfrac{\dfrac{n}{2}-N_{i-1}}{n_i}(e_i - e_{i-1}) = e_{i-1} + \dfrac{\dfrac{1}{2} - F_{i-1}}{f_i}(e_i - e_{i-1})$$
              Dicha fórmula se deduce aplicando semejanza de triángulos a la gráfica de la curva de distribución.
    \end{itemize}
\end{itemize}

\begin{prop}
    La desviación absoluta media respecto a la mediana es mínima:
    $$\sum_{i=1}^k f_i |x_i - Me| < \sum_{i=1}^k f_i |x_i - a| \quad \forall a \neq Me$$
\end{prop}

\subsubsection{Percentiles}
El percentil de orden $r \in \{1, \ldots, 100\}$ es un valor $P_r$ que divide al conjunto ordenado de datos en dos partes tales que el $r\%$ del total son inferiores o iguales a~$P_r$.

\begin{itemize}
    \item \underline{Variables discretas}:
          Se busca:
          $$x_i \mid N_{i-1} < \dfrac{nr}{100} \leq N_i \hspace{1cm} \left(\text{Equivalentemente}, F_{i-1}<\dfrac{r}{100} \leq F_i\right)$$

          \begin{itemize}
              \item Si $N_i > \frac{nr}{100} \Rightarrow P_r = x_i$.
              \item Si $N_i = \frac{nr}{100}$, todo número del intervalo $\left[x_i, x_{i+1}\right[$ es percentil de oden $r$. Por lo que se suele
                    tomar como $P_r$ el punto medio de dicho intervalo.
          \end{itemize}

    \item \underline{Variables continuas}:
          Se busca:
          $$I_i = (e_{i-1}, e_i] \mid N_{i-1} < \dfrac{nr}{100} \leq N_i \hspace{1cm} \left(\text{Equivalentemente}, F_{i-1}<\dfrac{r}{100} \leq F_i\right)$$

          \begin{itemize}
              \item Si $N_i = \frac{nr}{100} \Rightarrow P_r = e_i$.
              \item Si $N_i > \frac{nr}{100} \Rightarrow P_r = e_{i-1} + \dfrac{\dfrac{nr}{100} - N_{i-1}}{n_i} (e_i - e_{i-1})$
          \end{itemize}
\end{itemize}


Los cuartiles $Q_1, Q_2, Q_3, Q_4$ coinciden con los percentiles $P_{25}, P_{50}, P_{75}, P_{100}$.

Además, el decil $D_r$ coincide con el percentil $P_{r0}$.

Observemos que la mediana es el percentil $P_{50}$.

El percentil $P_r$ nos indica que el r\% de la población presenta al menos $P_r$ valor en la variable $X$.

\subsection{Medidas de dispersión}
Buscamos ver cuanto se desvían los datos respecto de alguna medida de posición central.
Hay varios tipos de medidas de dispersión:

\begin{itemize}
    \item \underline{Medidas de dispersión absolutas}:\\
    Tienen un comportamiento global y dependen de las unidades de medida de la variable.
          \begin{itemize}
              \item Recorrido o rango.
              \item Recorrido intercuartílico.
              \item Desviación absoluta respecto a la media aritmética.
              \item Desviación absoluta respecto a la mediana.
              \item Varianza.
              \item Desviación típica.
          \end{itemize}
    \item \underline{Medidas de dispersión relativas}:\\
    Se definen de forma individualizada para cada distribución y son adimensionales, lo que nos permite comparar distribuciones.
          \begin{itemize}
              \item Coeficiente de apertura.
              \item Recorrido relativo.
              \item Recorrido semi-intercuartílico.
              \item Coeficiente de variación.
              \item Índice de dispersión respecto a la mediana.
          \end{itemize}
\end{itemize}

\subsubsection{Recorrido o rango}

Bajo el supuesto de que los valores de la variable estén ordenados en sentido creciente:
$$R = x_k - x_1$$

Cuanto mayor sea el rango, más dispersa será nuestra distribución.

\subsubsection{Recorrido intercuartílico}
$$R_I = Q_3 - Q_1$$
Indica la longitud del intervalo en el que está incluido el 50\% central de los datos.

\subsubsection{Desviación absoluta media respecto a $\overline{x}$}
$$D_{\overline{x}} = \dfrac{\sum\limits_{i=1}^k |x_i - \overline{x}|n_i}{n} = \sum_{i=1}^k f_i |x_i - \overline{x}|$$

Cuanto mayor sea esta, menos representativa será la media. Una desviación media elevada implica mucha variabilidad en los datos.

\subsubsection{Desviación absoluta media respecto a $M_e$}
$$D_{M_e} = \dfrac{\sum\limits_{i=1}^k|x_i - M_e| n_i}{n}$$

Cuanto mayor sea esta, menos representativa será la mediana.

\subsubsection{Varianza}
\begin{equation*}
    Var(X)=\sigma^2 = \dfrac{\sum\limits_{i=1}^k n_i (x_i - \overline{x})^2}{n} = \sum_{i=1}^k f_i (x_i - \overline{x})^2
\end{equation*}

Es la media del área de los cuadrados de lado $x_i - \overline{x}$, el cuadrado de la media cuadrática de
la desviación de los datos a su media.\\


\begin{lema}
    La varianza nunca puede ser negativa ($\sigma^2 \geq 0$).
\end{lema}
\begin{proof}
    Se deduce directamente de su definición, ya que es la media aritmética de términos no negativos.
\end{proof}

\begin{prop}
    La varianza es la media cuadrática de dispersión óptima:
    $$\sum\limits_{i=1}^k f_i(x_i - \overline{x})^2 < \sum\limits_{i=1}^k f_i(x_i - a)^2,\qquad \forall~a \neq \overline{x}$$
\end{prop}
\begin{proof}
    Ver la Proposición \ref{prop:1.4}.
\end{proof}

\begin{prop}
    La varianza está acotada superior e inferiormente en cada distribución de frecuencias:
    $$\min(x_i - \overline{x})^2 < \sigma^2 < \max(x_i - \overline{x})^2$$
\end{prop}

\begin{teo}[Teorema de König] Para cualquier $a\in \mathbb{R}$ y para cualquier variable estadística $X$, se verifica:
\begin{equation*}
    \sum_{i=1}^k f_i (x_i-a)^2 = \sum_{i=1}^k f_i (x_i-\bar{x})^2 +(a-\bar{x})^2
\end{equation*}
En concreto, para $a=0$, tenemos una forma más cómoda de calcular la varianza:
\begin{equation*}
    \sigma_x^2 = \sum_{i=1}^k f_i (x_i-\bar{x})^2 = \sum_{i=1}^k f_i x_i^2 -\bar{x}^2
\end{equation*}
\end{teo}
\begin{proof}
     \begin{multline*}
         \sum_{i=1}^k f_i (x_i-a)^2
         = \sum_{i=1}^k f_i (x_i^2 + a^2 - 2ax_i)
         = \sum_{i=1}^k f_i (x_i^2 + a^2 - 2ax_i +\bar{x}^2 - \bar{x}^2 + 2x_i\bar{x} - 2x_i\bar{x})
         =\\=
         \sum_{i=1}^k f_i (x_i^2 - 2x_i\bar{x} + \bar{x}^2 + a^2 - 2ax_i  - \bar{x}^2 + 2x_i\bar{x})
         =\\=
         \sum_{i=1}^k f_i (x_i + \bar{x})^2 +\sum_{i=1}^k f_i( a^2 - 2ax_i  - \bar{x}^2 + 2x_i\bar{x})
         =\\=
         \sum_{i=1}^k f_i (x_i + \bar{x})^2 +a^2 -2a\bar{x} -\bar{x}^2 +2\bar{x}^2
         = \sum_{i=1}^k f_i (x_i-\bar{x})^2 +(a-\bar{x})^2
     \end{multline*}
\end{proof}

\begin{prop}
    Si se someten los datos a una transformación afín $y_i=ax_i+b$ $i = 1, \dots ,k$, la varianza de los datos transformados es $\sigma^2_y = a^2\sigma^2_x$.

    Es decir, no se ve afectada por cambios de origen pero sí se ve afectada por cambios de escala.
\end{prop}
\begin{proof}
    \begin{multline*}
        y=ax+b \Longrightarrow \sigma_y^2 = \sum (y_i-\bar{y})^2f_i = \sum ((ax_i+\cancel{b})-(a\bar{x}+\cancel{b}))^2 f_i = \sum a^2(x_i-\bar{x})^2f_i =\\
        =a^2 \sum (x_i-\bar{x})^2f_i = a^2 \sigma^2_x
    \end{multline*}
\end{proof}

\subsubsection{Desviación típica}

Se define como la raíz cuadrada positiva de la varianza:
$$\sigma = \sqrt{\sigma^2}$$

Nos ayuda a tipificar distribuciones para compararlas. Representa la dispersión de los datos de la distribución respecto de la media. Esto quiere decir que la mayoría de los datos de la distribución se encuentran en el intervalo
$[\overline{x} - \sigma, \overline{x} + \sigma]$

La gran mayoría de las propiedades se deducen directamente de las propiedades de la varianza.

\begin{lema}
    Es no negativa ($\sigma \geq 0$).
\end{lema}
\begin{prop}
    Es una medida de dispersión óptima. $$\sigma < \sqrt{\sum\limits_{i=1}^k f_i(x_i - b)^2} \qquad \forall~b \neq \overline{x}$$
\end{prop}
\begin{prop}
    Está acotada superior e inferiormente en cada distribución.
\end{prop}
\begin{prop}
    Si se someten los datos a una transformación afín $y_i=ax_i+b$\qquad $i = 1, \dots ,k$, la desviación típica de los datos transformados es $\sigma_y = |a|\sigma_x$.

    Es decir, no se ve afectada por cambios de origen pero sí se ve afectada por cambios de escala.
\end{prop}
\begin{proof}
    \begin{equation*}
        y=ax+b \Longrightarrow \sigma_y^2 = a^2\sigma_x^2 \Longrightarrow \sigma_y = |a|\sigma_x
    \end{equation*}
\end{proof}

\subsubsection{Coeficiente de apertura}

Se define como el cociente entre los dos valores extremos de una distribución. Supuestos ordenamos crecientemente los valores:
$$C_A = \dfrac{x_k}{x_1}$$

Si trabajamos con variables continuas, es el extremo superior del último intervalo entre el extremo inferior del primero:
$$C_A = \dfrac{e_k}{e_0}$$

\subsubsection{Recorrido relativo}

Se define como el cociente entre el recorrido y la media aritmética:
$$R_R = \dfrac{R}{\overline{x}}= \dfrac{x_k - x_1}{\overline{x}}$$

\subsubsection{Recorrido semi-intercuartílico}

Se define como el cociente entre el recorrido intercuartílico y la suma del primer tercer cuartil:
$$R_{SI} = \dfrac{Q_3 - Q_1}{Q_3 + Q_1}$$

\subsubsection{Coeficiente de variación de Pearson}

Se define como la relación por cociente entre la desviación típica y la media:
$$CV(X)= \dfrac{\sigma_x}{|\overline{x}|}$$

A mayor valor del coeficiente, mayor heterogeneidad de los valores de la variable. Se usa para comparar las dispersiones de las variables estadísticas.

\subsubsection{Índice de dispersión respecto a la mediana}

Se define como el cociente entre la desviación absoluta media respecto a la mediana y la mediana:
$$V_{M_e} = \dfrac{D_{M_e}}{M_e}$$

\subsection{Momentos}

Nos permiten simplificar los cálculos.

 Sea $r \in \N \cup \{0\}$. Se llama momento de orden $r$ respecto al valor $a$ a la cantidad:
$$_am_r = \sum_{i=1}^k f_i (x_i - a)^r = \frac{1}{n} \sum_{i=1}^k n_i (f_i - a)^r$$

Según los valores de $a$ distinguimos dos tipos de momentos:
\begin{itemize}
    \item \textbf{Momentos no centrales} ($a=0$):
        $$m_r = \sum_{i=1}^k f_i x_i^r$$

        Algunos momentos no centrales especiales son:
        $$m_0 = 1 \hspace{2cm} m_1 = \bar{x} \hspace{2cm} m_2\footnote{Término del Teorema de König} = \sum_{i=1}^k f_i x_i^2$$

    \item \textbf{Momentos centrales} ($a=\overline{x}$):
        $$\mu_r = \sum_{i=1}^k f_i (x_i - \overline{x})^r$$

        Algunos momentos centrales especiales son:
        $$\mu_0 = 1 \hspace{2cm} \mu_1 = 0 \hspace{2cm} \mu_2 = \sigma^2$$
\end{itemize}


Para la simplificación del cálculo de momentos, podemos expresar momentos centrales en función de otros
no centrales más simples y viceversa:

\begin{itemize}
    \item Momentos centrales en función de los no centrales:
    \begin{equation*}
        \begin{split}
            \mu_r &= \sum_{i=1}^k f_i (x_i - m_1)^r = \sum_{i=1}^k f_i \sum_{t=0}^r (-1)^t \binom{r}{t} m_1^t x_i^{r-t}=\\
            &=\sum_{t=0}^r(-1)^t \binom{r}{t}m_1^r \sum_{i=1}^k f_i x_i^{r-t}=\sum_{t=0}^r (-1)^t \binom{r}{t}m_1^t m_{r-t}
        \end{split}
    \end{equation*}
    

    \item Momentos no centrales en función de los centrales y de $m_1$:
    \begin{equation*}
        \begin{split}
            m_r &= \sum_{i=1}^k f_ix_i^r=\sum_{i=1}^kf_i [(x_i-m_1)+m_1]^r = \sum_{i=1}^k f_i \sum_{t=0}^r \binom{r}{t}m_1^t (x_i - m_1)^{r-t}=\\
            &=\sum_{t=0}^r \binom{r}{t} m_1^t \sum_{i=1}^k f_i (x_i - m_1)^{r-t}=\sum_{t=0}^r \binom{r}{t} m_1^t \mu_{r-t}
        \end{split}
    \end{equation*}
\end{itemize}

\noindent De tal forma que:
\begin{equation*}
    \begin{array}{lcl}
        \mu_2 = m_2 - m_1^2 & \hspace{1cm} & m_2 = \mu_2 + m_1^2\\
        \mu_3 = m_3 - 3m_2m_1 + 2m_1^3 & \hspace{1cm} & m_3 = \mu_3 + 3\mu_2 m_1 + m_1^3\\
        \mu_4 = m_4 - 4m_3m_1 + 6m_1^2m_2 - 3 m_1^4 & \hspace{1cm} & m_4 = \mu_4 + 4\mu_3 m_1 + 6\mu_2 m_1^2 + m_1^4\\
    \end{array}
\end{equation*}

\subsection{Medidas de forma}
\subsubsection{Medidas de asimetría}

Entendemos por asimetría a la falta de simetría respecto del eje vertical $x=\overline{x}$.

Diremos que una distribución es simétrica si la media divide a la distribución en dos partes iguales.

Diremos a su vez que una distribución es asimétrica por la izquierda (negativa) o por la derecha (positiva) si
por la izquierda o por la derecha presenta más datos, respectivamente.\\

\textbf{Coeficiente de Fisher}
$$\gamma_1(X) = \dfrac{\mu_3}{\sigma_x^3} = \sum_{i=1}^k f_i \left( \dfrac{x_i - \overline{x}}{\sigma_x} \right)^3$$

\begin{itemize}
    \item Si $\gamma_1(X) > 0$ la distribución es asimétrica por la derecha o positiva.
    \item Si $\gamma_1(X) < 0$ la distribución es asimétrica por la izquierda o negativa.
    \item Si la distribución es simétrica $\Rightarrow \gamma_1(X)=0$.

    Sin embargo, se puede dar que $\gamma_1(X)=0$ y que la distribución sea asimétrica. Por tanto, cuando esto suceda deberemos representar nuestra distribución.
\end{itemize}

\textbf{Coeficiente de Pearson}

Válida sólo para distribuciones campaniformes:
$$A_p = \dfrac{\overline{x} - Mo}{\sigma_x}$$

Se verifica (empíricamente) que $(\overline{x}-Mo) \approx 3(\overline{x}-Me)$, por lo que:
$$A_p^\ast = \dfrac{3(\overline{x} - Me)}{\sigma_x}$$

Este coeficiente tiene la misma interpretación que el de Fisher.


\subsubsection{Medidas de apuntamiento o curtosis}


Miden la concentración central de frecuencias de una distribución. Para ello, la comparamos con una distribución
normal, con la misma media y desviación típica que nuestra distribución.
Se presentan tres casos:
\begin{itemize}
    \item Leptocúrtica: La distribución está más concentrada que la normal.
    \item Mesocúrtica: La distribución se asemeja a la normal.
    \item Platicúrtica: La distribución está menos concentrada que la normal.
\end{itemize}

\textbf{Coeficiente de curtosis de Fisher}
$$\gamma_2(X) = \dfrac{\mu_4}{\sigma^4} - 3$$
\begin{itemize}
    \item Si $\gamma_2(X) > 0$ nuestra distribución es leptocúrtica.
    \item Si $\gamma_2(X) = 0$ nuestra distribución es mesocúrtica.
    \item Si $\gamma_2(X) < 0$ nuestra distribución es platicúrtica.
\end{itemize}

\textbf{Coeficiente de curtosis de Kelley}
$$K = \dfrac{1}{2} \dfrac{Q_3 - Q_1}{D_9 - D_1} - 0.263$$

Con la misma interpretación que el coeficiente de curtosis de Fisher.\\


\begin{teo}[Desigualdad de Tchebychev]
    El porcentaje de datos en cualquier intervalo de la forma $(\overline{x} - k\sigma_x, \overline{x}+k\sigma_x)$ es de al menos $100(1-\frac{1}{k^2})$\%.
\end{teo}