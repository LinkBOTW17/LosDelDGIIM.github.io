\chapter{Variables aleatorias}
\section{Definiciones}


Para dar la definición de variable aleatoria, es necesario pararnos a observar que hasta ahora hemos estado trabajando con el espacio probabilístico $(\Omega, \mathcal{A}, P)$.
A continuación, nos será de especial importancia tener en cuenta el espacio probabilístico $(\R, \mathcal{B})$ donde $\R$ es el conjunto de números reales y $\mathcal{B}$ es una $\sigma$-álgebra sobre $\R$ que contiene a todos sus intervalos.
Esta $\mathcal{B}$ recibe el nombre de $\sigma$-álgebra de Borel\footnote{Se estudiará a fondo en Análisis Matemático II.}.

\begin{definicion}
    Una variable aleatoria $X$ es una función medible\footnote{Este concepto se introducirá en la Teoría de Integración que se verá en Análisis Matemático II.} sobre un espacio de probabilidad. 
    Es decir, una función:
    $$X:(\Omega, \mathcal{A}, P) \rightarrow (\R, \mathcal{B})$$
    tal que la imagen inversa de cualquier conjunto de Borel es medible (es decir, un suceso de la $\sigma$-álgebra $\A$):
    $$X^{-1}(B) \in \mathcal{A} \qquad \forall B \in \mathcal{B}$$
\end{definicion}

Notemos que para comprobar que dicha variable sea aleatoria basta con que la imagen inversa de cualquier intervalo de la forma $]-\infty, x]$ sea medible (es decir, que pertenezca a $\A$).

Por tanto, $X$ será una variable aleatoria si es una función $X :(\Omega, \A, P) \rightarrow (\R, \B)$ tal que
$$X^{-1}(]-\infty, x]) \in \A \qquad \forall x \in \R$$

\begin{ejemplo}
    Consideramos el experimento aleatorio de lanzar una moneda:
    $$\Omega = \{c, +\} \mbox{ (c cara, + cruz)}$$
    $$\mathcal{A} = \{\emptyset, \{c\}, \{+\}, \Omega \}$$
    
    Definimos $X$ como el número de caras al lanzar una moneda:
    $$X(\omega) = \left\{ \begin{array}{lcl}
        0 & \mbox{ si } & c \notin \omega \\
        1 & \mbox{ si } & c \in \omega    \\
      \end{array} \right.~~~\omega \in \Omega$$

    Comprobamos que se trata de una variable aleatoria. Trivialmente sabemos que se trata de una función del tipo:
    $$X : (\Omega, \mathcal{A}, P) \rightarrow (\R, \mathcal{B})$$
    
    Comprobamos que $X^{-1}(B) \in \mathcal{A}~~\forall B \in \mathcal{B}$:
    
    $$\begin{array}{ll}
        \mbox{Si } x<0       & X^{-1}(\left] -\infty, x \right] ) = \emptyset \in \mathcal{A} \\
        \mbox{Si } 0\leq x<1 & X^{-1}(\left] -\infty, x \right] ) = + \in \mathcal{A}         \\
        \mbox{Si } x\geq 1   & X^{-1}(\left] -\infty, x \right] ) = \Omega \in \mathcal{A}
      \end{array}$$
\end{ejemplo}

\section{Probabilidad inducida}
\begin{definicion}[Probabilidad inducida]
    Sea $X:(\Omega, \A, P) \rightarrow (\R, \B)$ una variable aleatoria, podemos definir una nueva función $P_X : (\R, \B) \rightarrow [0,1]$ como sigue:
    $$P_X(B) = P(X^{-1}(B)) \qquad \forall B \in \B$$
    
    Dando lugar al espacio probabilístico $(\R, \B, P_X)$.
\end{definicion}
\begin{notacion}
    Podemos encontrar $P_X(B)$ notado como $P(X \in B)$.
\end{notacion}

\begin{prop}
    La función $P_X$ es una función de probabilidad.
\end{prop}
\begin{proof} Demostramos cada una de las 3 condiciones,
    usando para ello que $P$ es una función de probabilidad:
    \begin{itemize}
        \item \ul{Axioma de no negatividad}:
              $$P_X(B) = P(X^{-1}(B)) \geq 0 \qquad \forall B \in \B$$
        \item \ul{Axioma del suceso seguro}:
              $$P_X(\R) = P(X^{-1}(\R)) = P(\Omega) = 1$$
        \item \ul{Axioma de $\sigma$-aditividad}:
        
        Sean $B_1, B_2, \ldots \in \B$ disjuntos dos a dos, entonces:
        \begin{align*}
            P_X\left(\bigcup\limits_{i=1}^{\infty} B_i\right) &= P\left(X^{-1}\left(\bigcup_{i=1}^{\infty} B_i\right)\right) = P\left(\bigcup_{i=1}^{\infty} X^{-1}(B_i)\right) =\\&= \sum_{i=1}^{\infty} P(X^{-1}(B_i)) = \sum_{i=1}^{\infty} P_X(B_i)
        \end{align*}
    \end{itemize}
\end{proof}

Notemos que era necesario imponer la medibilidad de nuestra función variable aleatoria $X$, ya que lo que pretendemos es poder asignar a cada valor del codominio de nuestra variable aleatoria una probabilidad inducida $P_X$ por la función probabilidad $P$ ya definida en nuestra $\sigma$-álgebra original, y para ello, naturalmente, necesitamos una correspondencia entre reales (codominio particular en este caso) y elementos de $\A$ (donde ya tenemos definida $P$).\\

Esta función es de gran relevancia pues es la pieza fundamental para la definición de la función de distribución, tomando $B=]-\infty, x] \mid x \in \R$, y también para la definición de la función masa de probabilidad, tomando $B=[x,x] \mid x \in \R = \{x\}\in \bb{R}$.\\

Notemos que, tras haber demostrado que $P_X$ es una función de probabilidad,
podemos aplicar los resultados ya conocidos de probabilidad a esta nueva función de probabilidad. Así, tenemos que:
\begin{itemize}
    \item $P_X(]-\infty, x]) = P_X(]-\infty, x[) + P_X(x), \quad \forall x \in \R$
    
    Se ha usado la Proposición \ref{prop:prob_union}, donde hemos usado que $$P_X(]-\infty, x[~\cap ~\{x\}) = P_X(\emptyset) = 0$$

    \item $P_X(]-\infty, x]) = 1 - P_X(]x, +\infty[), \quad \forall x \in \R$
    
    Se ha usado la Proposición \ref{prop:prob_complementario}, donde hemos usado que $\left]x, +\infty\right[ = \ol{\left]-\infty, x\right]}$.

    \item $P_X([a,b]) = P_X(]-\infty, b]) - P_X(]-\infty, a[), \quad \forall a,b \in \R, a \leq b$
    
    Se ha usado la Proposición \ref{prop:prob_monotona}, sabiendo que $[a,b] = \left]-\infty, b\right] \setminus \left]-\infty, a\right[$, y que $\left]-\infty, a\right]\subset \left]-\infty, b\right]$.
    
\end{itemize}

\section{Función de distribución}
\begin{definicion}[Función de distribución]
Se define la función de distribución de una variable aleatoria como:
\Func{F_X}{\R}{[0,1]}{x}{P_X\left(]-\infty, x]\right)}
\end{definicion}
\begin{notacion}
Notemos que:
\begin{multline*}
    P_X(]-\infty, x]) = (P \circ X^{-1})(]-\infty, x]) = P(\{\omega \in \Omega \mid X(\omega) \in ]-\infty, x] \}) =\\
    =P(\{\omega \in \Omega \mid X(\omega) \leq x\})
\end{multline*}

Por tanto, será más común encontrar $F_X(x)$ notado como $P(X \leq x)$ o como $P[X \leq x]$, siendo los paréntesis y los corchetes equivalentes.
\end{notacion}

\begin{definicion}[Distribución de probabilidad]
    Dada una variable aleatoria $X$, su distribución de probabilidad será el conjunto $\{(x_i, F_X(x_i))\}$.
\end{definicion}

\subsection{Propiedades}
\begin{itemize}
\item $F_X$ es creciente.

Usamos la Proposición \ref{prop:prob_monotona}, y vemos que si $x \leq y$, entonces $]-\infty, x] \subseteq ]-\infty, y]$, y por tanto $P_X(]-\infty, x]) \leq P_X(]-\infty, y])$.

\item $F_X$ es continua por la derecha. Es decir, para todo $x \in \R$, se cumple que:
\begin{equation*}
    \lim_{t \to x^{+}} F_X(t) =
    \lim_{t \to x^{+}} P_X(]-\infty, t]) =
    F_X(x)
\end{equation*}
% // TODO: Continuidad por la derecha

\item $\exists m,M \in \R$ tal que $\forall x,y \in \R \mid x \leq m \ \land \ y \geq M$ entonces $F_X(x)=0$
        y $F_X(y)=1$.\par
      También notado como $F_X(-\infty)=0$ y $F_X(+\infty)=1$

% // TODO: Existencia de m y M en R
\item El conjunto de puntos de discontinuidad de una función de distribución es numerable.
\item $\forall y \in \R \Rightarrow \lim\limits_{x \to y^{-}} F_X(x) = P_X(]-\infty, y[)$\par
      También notado como $F_X(x^{-})=P(X<x)$.
\item La función de distribución sólo puede presentar discontinuidades de salto. Además, la longitud del salto
      en un punto es la probabilidad que toma dicho punto:
      $$P_X(x) = P_X(]-\infty, x]) - P_X(]-\infty, x[) = F_X(x) - \lim\limits_{y \to x^{-}}F_X(x)$$
      También notado como $P_X(x) = F_X(x) - F_X(x^{-})$.
\item La función de distribución es continua en $x \in \R \Longleftrightarrow P_X(x) = 0$.
\end{itemize}

\section{Clasificaciones de variables aleatorias}

Dependiendo de la forma de la distribución, podemos distinguir distintos tipos de variables aleatorias.
\begin{definicion}[Recorrido de una variable aleatoria]
    Dada una variable aleatoria $X$, definimos su recorrido, $Re_X$ como:
    $$Re_X = \{x \in \R \mid \ \exists \omega \in \Omega \mid X(\omega) = x\} = Img(X)$$
\end{definicion}

\subsection{Variables aleatorias discretas, función masa de probabilidad}

\begin{definicion}[Variable aleatoria discreta]
    Una variable aleatoria se dice que es discreta si $Re_X = E \subset \R$ con $E$ numerable, es decir, que sólo toma una cantidad numerable de valores: $E = \{x_1, x_2, \ldots\}$. Es decir, $P_X(E)=1$.
\end{definicion}

\begin{definicion}[Función masa de probabilidad]
    Sea $X: (\Omega, \A, P) \rightarrow (\R, \B, P_X)$ una variable aleatoria discreta con valores en $E$, definimos la función masa de probabilidad como:
    \Func{P}{E}{[0,1]}{x_i}{P(x_i)=P_X(x_i)}

    Esta ha de verificar:
    \begin{itemize}
        \item $0 \leq p_i \leq 1 \qquad \forall x_i \in E$.
        \item $\sum\limits_{i = 1}^N p_i = 1 \qquad $ con $N = |E|$
    \end{itemize}
\end{definicion}
\begin{notacion}
    A continuación, a cada $P(x_i)$ lo notaremos por $p_i$.
\end{notacion}

La función de distribución de la variable $X$ a partir de la función masa de probabilidad queda como:
$$F_X(x_i) = P_X(]-\infty, x_i]) = \sum_{j=1}^i p_j \qquad \forall x_i \in E$$


También es posible expresar la función masa de probabilidad a partir de la función de distribución de la variable $X$:
$$p_i = F_X(x_i) - F_X(x_{i-1}) \qquad \forall x_i,x_{i-1}\in E$$
Notemos que la función de distribución de variables discretas es escalonada y creciente.

\begin{ejemplo}
    Dado el experimento de lanzar una moneda, damos su espacio muestral y $\sigma$-álgebra asociados:
    $$\Omega = \{c, +\} \qquad \A=\{\emptyset, \{c\}, \{+\}, \Omega\}$$
    
    Con los que podemos definir la siguiente variable aleatoria, que nos da el número de caras,
    $X:(\Omega, \A, P) \rightarrow (\R, \B, P_X)$ por:
    $$X(\omega) = \left\{ \begin{array}{cc}
        0 & c \notin \omega \\
        1 & c \in \omega
    \end{array} \right.$$
    
    Esta definición de variable aleatoria, de recorrido $Re_X = \{0,1\}$ nos induce una función masa de probabilidad $P$:
    $$p_0 = P(0) = \frac{1}{2} \qquad p_1 = P(1) = \frac{1}{2}$$
\end{ejemplo}

\subsection{Variables aleatorias continuas, función de densidad}

\begin{definicion}
    Una variable aleatoria se dice que es continua si su función de distribución $F_X$ es absolutamente continua, es decir, si existe una función $f:\R \rightarrow \R$ tal que:
    $$F_X(x) = \int_{-\infty}^x f(t) dt$$
\end{definicion}

Llamaremos a dicha función $f$ \textbf{función de densidad}, que verifica:
\begin{itemize}
  \item $f(x) \geq 0 \qquad \forall x \in \R$.
  \item $f$ es Riemman integrable (ya que $F$ tiene a lo sumo un número finito de discontinuidades sobre cada intervalo finito de $\R$).
  \item $\displaystyle \int_{-\infty}^{+\infty}f(x) dx = 1$
\end{itemize}

Como consecuencia del Teorema Fundamental del Cálculo, podemos obtener la función de densidad a partir de la función de distribución:
$$f(x) = F_X'(x) \qquad \forall x \in \R$$

Esta nueva función nos permitirá también calcular probabilidades asociadas a un intervalo:
$$P_X([a,b]) = \int_a^b f(x)~dx$$

Notemos, por tanto, que $P_X([a,b]) = P_X(]a,b[) = P_X([a,b[) = P_X(]a,b])$, puesto que no interfieren en los límites de integración.\\

Además, en el caso continuo, la probabilidad inducida en un punto será siempre~$0$:
$$P_X(x) = \int_x^x f(t)~dt = 0 \qquad \forall x \in \R$$

En el caso de las variables continuas, el recorrido de la variable aleatoria será un intervalo $Re_X = [a,b] \subseteq \R$.

\begin{ejemplo}
    Comprobar si la función $f:\R \rightarrow \R$ definida a continuación puede ser una función de densidad. En caso afirmativo, construir la función de distribución asociada a una variable aleatoria $X:(\Omega, \A, P) \rightarrow (\R, \B, P_X)$.

    $$f(x) = \left\{ \begin{array}{ll}
        0  & x < 0           \\
        2x & 0 \leq x \leq 1 \\
        0  & x > 1
    \end{array} \right.$$
      
    Comprobamos que pueda tratarse de una función de densidad:
    \begin{enumerate}
        \item $f(x) \geq 0 \qquad \forall x \in \R$

        \item Es Riemman Integrable, por ser la imagen acotada.

        \item $\displaystyle \int_{-\infty}^{+\infty} f(x) dx = \int_{-\infty}^0 0~dx+ \int_0^1 2x~dx + \int_1^{+\infty}0~dx = \int_0^1 2x~dx = x^2]_0^1=1$
    \end{enumerate}

    Por tanto, $f$ es una función de densidad, y podemos definir a partir de ella una función de distribución $F:\R \rightarrow \R$:
    \begin{itemize}
        \item \underline{Si $x<0$}:
        $$F_X(x) = \int_{-\infty}^x f(t)~dt = \int_{-\infty}^x 0~dt = 0$$

        \underline{Si $0 \leq x \leq 1$}:
        $$F_X(x) = \int_{-\infty}^x f(t)~dt = \int_{-\infty}^0 0~dt + \int_{0}^x 2t~dt = t^2]_0^x = x^2$$
        
        
        \underline{Si $x>1$}:
        $$F_X(x) = \int_{-\infty}^x f(t)~dt = \int_{-\infty}^0 0~dt + \int_{0}^1 2t~dt + \int_1^{+\infty} 0~dt = t^2]_0^1 = 1$$
    \end{itemize}

    Por tanto, la función de distribución es:
    $$F_X(x) = \left\{ \begin{array}{lc}
        0   & x < 0           \\
        x^2 & 0 \leq x \leq 1 \\
        1   & x > 1
    \end{array} \right.$$
\end{ejemplo}

\subsection{Variables aleatorias mixtas}

\begin{definicion}
    Una variable aleatoria se dice que es mixta si $Re_X = E \cup [a,b]$ con $E$ numerable y $[a,b]\subseteq \R$.
    Si se da que $E \subset [a,b] \Rightarrow X$ será una variable continua de recorrido $[a,b]$.
\end{definicion}

Dicha variable aleatoria tendrá asociadas una función masa de probabilidad y una función de densidad:
\begin{itemize}
    \item Tendremos $P:E\rightarrow [0,1]$ dada por $p_i = P(x_i) = P_X(x_i) \qquad \forall x_i \in E$ tal que:
    \begin{itemize}
      \item $0 \leq p_i \leq 1 \qquad \forall x_i \in E$.
      \item $\sum\limits_{i=1}^N p_i = P \qquad $ con $P\in [0,1]$ y $N=|E|$.
    \end{itemize}
    
    \item Y además existirá una función $f:\R \rightarrow \R$ Riemman integrable tal que:
    \begin{itemize}
      \item $f(x) \geq 0 \qquad \forall x \in \R$.
      \item $\displaystyle \int_{-\infty}^{+\infty} f(x)~dx = 1-P$
    \end{itemize}
\end{itemize}

\bigskip

De esta forma, podemos calcular la probabilidad de cualquier intervalo $[c,d]$ definiendo el intervalo $[y,z] = [a,b] \cap [c,d]$ y mediante la siguiente expresión:

$$P_X([c,d]) = \sum_{\substack{x_i \in E \\ x_i \in [c,d]}} p_i + \int_y^z f(x)~dx $$

También se puede calcular el valor de la función de distribución en un punto x:
$$F_X(x) = \sum_{\substack{x_i \in E \\ x_i \leq x}} p_i + \int_{-\infty}^x f(t)~dt$$

\section{Cambio de variable}

En varias ocasiones, nos será de gran interés dar la distribución de probabilidad de una variable aleatoria $Y$, que depende de otra variable aleatoria $X$, en función de esta última.

Notemos que si conocemos la probabilidad inducida $P_X$ de una variable aleatoria $X$, entonces conocemos la función de distribución $F_X$ de dicha variable aleatoria y, por tanto, conocemos la distribución de probabilidad asociada a dicha variable.

\begin{teo}[Teorema general de cambio de variable]
  Sea $X: (\Omega, \A, P) \rightarrow (\R, \B, P_X)$ una variable aleatoria con una probabilidad inducida $P_X$.
  Sea $Y=h(x)$ otra variable aleatoria, con $h:(\R, \B) \rightarrow (\R, \B)$ medible, entonces la probabilidad inducida de $Y$ puede obtenerse a partir de $P_X$ como:
  $$P_Y(B) = P_X(h^{-1}(B)) \qquad \forall B \in \B$$
\end{teo}
\begin{proof}
  $$P_Y(B) = P(Y^{-1}(B)) = P(X^{-1}(h^{-1}(B))) = P_X(h^{-1}(B)) \qquad \forall B \in \B$$
\end{proof}

Por este teorema, podemos obtener la función de distribución de $Y$ mediante:
$$F_Y(x) = P_X(h^{-1}(]-\infty, x])) \qquad \forall x\in \R$$

El cambio de variable en el caso de una variable discreta dará lugar a una variable discreta, mientras que
si efectuamos un cambio de variable a una variable continua, podremos obtener una variable discreta, una
variable continua o una variable mixta. Abordaremos dichos casos:

\subsection{Cambio en variable aleatoria discreta}\label{subsec:CV_Discreta}

Sea $X$ una variable aleatoria discreta con valores en $E=\{x_1, x_2, \ldots\} \subset \R$ de función masa $P$
y $h:\R \rightarrow \R$ medible tal que $Y=h(x)$, podemos definir su función masa de probabilidad $\hat{P}$ por:
$$\hat{P}(y) = \left\{ \begin{array}{lc}
    \sum\limits_{x \mid h(x)=y}P(x) & y \in h(E)    \\
    0                               & y \notin h(E)
  \end{array} \right. \qquad \forall y \in \R$$

\begin{ejemplo}
    Dada la variable aleatoria $X$ con $Re_X = \{-1, 0, 1\}$ y su función masa de probabilidad dada por:
    $$P(x) = \left\{ \begin{array}{cl}
        1/3 & x = -1 \\
        1/3 & x = 0  \\
        1/3 & x = 1
    \end{array} \right.$$
    
    
    Definimos la variable aleatoria $Y$ por $Y=h(X)=X^2$. Se pide dar la función masa de probabilidad de $Y$, $\hat{P}$.\\
    
    El recorrido de $Y$ será: $Re_Y = \{h(-1), h(0), h(1)\} = \{0, 1\}$.
    $$\hat{P}(y) = \left\{ \begin{array}{ll}
        P(0) = 1/3         & y = 0 \\
        P(-1) + P(1) = 2/3 & y = 1
      \end{array} \right.$$
\end{ejemplo}

\subsection{Cambio de variable aleatoria continua a discreta}

Sea $X$ una variable aleatoria continua con función de densidad $f$ y con valores en un conjunto $A \subset \R$.
Si $h$ es una función medible tal que $Y=h(x)$ es una variable aleatoria discreta (es decir, que $h(A)$ es numerable).
Entonces, podemos definir la función masa de probabilidad $P$ de la variable $Y$ como sigue:

$$P(y) = \left\{ \begin{array}{ll}
    \displaystyle \int_{x \in \R \mid h(x) = y} f(x)~dx & y \in h(A)    \\
    0                                     & y \notin h(A)
\end{array} \right. \qquad \forall y \in \R$$

\bigskip

La integral anterior nos indica que, por ejemplo, en el caso en el que:
$$h([a,b] \cup [c,d]) = y \Rightarrow P(y) = \int_a^b f(x)~dx + \int_c^d f(x)~dx$$

\begin{ejemplo}
    Dada la variable aleatoria $X$ con $Re_X=\R$ y su función de densidad $f:\R \rightarrow \R$ dada por:
    $$f(x) = \left\{ \begin{array}{ll}
        0   & x \leq -1  \\
        1/2 & -1 < x < 1 \\
        0   & x \geq 1
    \end{array} \right.$$
    
    
    Definimos la variable aleatoria $Y$ por $Y=h(x)$. Se pide dar la función masa de probabilidad de $Y$, sabiendo que:
    $$h(x) = \left\{ \begin{array}{ll}
        0 & x < 0    \\
        1 & x \geq 0
    \end{array} \right.$$
    
    En primer lugar, damos el recorrido de $Y$: $Re_Y = \{h(\R)\} = \{0,1\}$.
    $$P(y) = \left\{ \begin{array}{ll}
        \displaystyle \int_{-\infty}^0 f(x)~dx = \int_{-\infty}^{-1} 0~dx + \int_{-1}^0 1/2~dx = \left.\frac{x}{2}\right]_{-1}^0 = 1/2 & y=0   \\ \\
        \displaystyle \int_0^{+\infty} f(x)~dx = \int_0^1 1/2~dx + \int_1^{+\infty} 0~dx = \left.\frac{x}{2}\right]_0^1 = 1/2          & y = 1
      \end{array} \right.$$
\end{ejemplo}

\subsection{Cambio de variable aleatoria continua a continua}
\label{subsec:CV_Continua}

Sea $X$ una variable aleatoria continua con función de densidad $f$ y recorrido $Re_X=[a,b]\subseteq \R$. Si $h$
es una función medible estrictamente monótona y derivable en $[a,b]$, entonces $Y=h(x)$ es una variable
aleatoria continua con función de densidad:
$$g(y) = \left\{ \begin{array}{cc}
    f(h^{-1}(y)) \cdot |(h^{-1})'(y)| & y \in h([a,b])    \\ \\
    0                                 & y \notin h([a,b])
  \end{array} \right. \qquad \forall y \in \R$$

\subsubsection{Generalización.}
Una generalización del teorema puede hacerse en el caso de que $h$ no tenga una única inversa y cada valor de la variable $Y=h(x)$ proceda de un número finito o infinito de valores de $X$. En dicho caso, la función de densidad de $Y$ será:
$$g(y) = \sum_{k=1}^{\infty} f(h^{-1}_k(y)) \cdot |(h^{-1}_k)'(y)|$$

Siendo $h_1^{-1}(y),h_2^{-1}(y), \ldots$ las antiimágenes de $y~~\forall y \in h([a,b])$.

\begin{ejemplo}
    Dada la variable aleatoria $X$ con $Re_X=]-1, 1[$ y su función de densidad $f:\R \rightarrow \R$ dada por:
    $$f(x) = \left\{ \begin{array}{ll}
        0           & x \leq -1  \\
        \frac{1}{2} & -1 < x < 1 \\
        0           & x \geq 1
    \end{array} \right. $$
    
    Definimos la variable aleatoria $Y$ por $Y=h(X) =X^2$. Se pide dar la función de densidad de $Y$.
    
    En primer lugar, calculamos el recorrido de $Y$: $Re_Y=\{h(]-1,1[)\} = [0,1[$. Además, al no ser $h$ inyectiva en el dominio de definición, tiene dos inversas: la raíz positiva y la negativa.
    \begin{gather*}
        h^{-1}(y) = \pm \sqrt{y}\\
        (h^{-1})'(y) = \pm \dfrac{1}{2\sqrt{y}}
    \end{gather*}
    
    Damos la función de densidad de $Y$:
    $$g(y) = \sum_{k=1}^{\infty} f(h^{-1}_k(y)) \cdot |(h^{-1}_k)'(y)|
    =  \dfrac{1}{2} \dfrac{1}{2\sqrt{y}} + \left|-\dfrac{1}{2} \dfrac{1}{2\sqrt{y}}\right|
    =  \dfrac{1}{2\sqrt{y}} \qquad \forall y \in ]0,1[$$
\end{ejemplo}

\subsection{Cambio de una variable aleatoria continua a mixta}

Sea $X$ una variable aleatoria continua con función de densidad $f$ y recorrido $Re_X=[a,b]\subseteq \R$. Si $h$ es una función medible y definimos $Y=h(x)$ como una nueva variable aleatoria tal que $Y$ presenta una distribución mixta, entonces tendremos que su función de densidad viene dada por:
\begin{ejemplo}
    Dada una variable aleatoria $X$ con $Re_X = ]-1, 1[$ y su función de densidad $f:\R \rightarrow \R$ dada por:
    $$f(x) = \left\{ \begin{array}{ll}
        0           & x \leq -1  \\
        \frac{1}{2} & -1 < x < 1 \\
        0           & x \geq 1
    \end{array} \right. $$

    Definimos la variable aleatoria $Y$ por $Y=h(X)$. Se pide dar la función de distribución de $Y$.
    $$h(x) = \left\{ \begin{array}{ll}
        x & x < 0    \\
        1 & x \geq 0
    \end{array} \right.$$

        
    Calculamos el recorrido de $Y$: $Re_Y = ]-1, 0[ \cup \{1\}$. Por tanto, aplicando el teorema del cambio de variable:
    $$F_Y(y) = \left\{ \begin{array}{cl}
        0 & y \leq -1    \\ \\
        \displaystyle\int_{-1}^y \dfrac{1}{2}~dt = \left. \dfrac{t}{2} \right]_{-1}^y = \dfrac{y+1}{2} & -1 < y < 0   \\ \\
        \dfrac{1}{2} & 0 \leq y < 1 \\ \\
        1 & y \geq 1
  \end{array} \right.$$
\end{ejemplo}

\section{Esperanza matemática}
\subsection{Variables aleatorias discretas}

\begin{definicion}
    Sea $X$ una variable aleatoria discreta con valores en $Re_X = E = \{x_1, x_2, \ldots\} \subset \R$ y sea $P$ la función masa de probabilidad de $X$, se define la esperanza matemática, media o valor esperado de $X$, denotado $E[X]$ como:
    $$E[X] = \sum\limits_{x_i \in E} x_i P(x_i)$$

    Esta existe siempre y cuando la serie previamente mencionada converja absolutamente.
\end{definicion}
\begin{observacion}
    A lo largo de este documento, cada vez que hagamos referencia a la esperanza de una variable aleatoria $X$, hemos supuesto previamente que existe. Es decir, siempre que encontremos que: Sea $X$ una variable aleatoria y aparezca $E[X]$, hemos supuesto implícitamente que su varianza existe. En caso contrario, no tendría sentido hablar de $E[X]$.
\end{observacion}

\begin{ejemplo}
    Dada la variable aleatoria $X$ con $Re_X = \{-1, 0, 1\}$ y su función masa de probabilidad dada por:
    $$P(x) = \left\{ \begin{array}{cl}
        1/3 & x = -1 \\
        1/3 & x = 0  \\
        1/3 & x = 1
      \end{array} \right.$$
    Se pide calcular la esperanza matemática de $X$.
    
    $$E[X] = -1 \cdot \dfrac{1}{3} + 0 \cdot \dfrac{1}{3} -1 \cdot \dfrac{1}{3} = 0$$
\end{ejemplo}

\subsection{Variables aleatorias continuas}

\begin{definicion}
    Sea $X$ una variable aleatoria continua con valores en $Re_X = [a,b]$ y $f$ la función de densidad de dicha variable, se define la esperanza matemática de $X$ como:
    $$E[X] = \int_{-\infty}^{+\infty} xf(x)~dx$$

    La esperanza de $X$ existe siempre y cuando la integral sea absolutamente convergente.
\end{definicion}

\begin{ejemplo}
    Sea $X$ una variable aleatoria con valores en $Re_X = [0, \sqrt[3]{3}]$ y función de densidad $f:\R \rightarrow \R$ dada por:
    $$f(x) = \left\{ \begin{array}{ll}
        0   & x < 0                     \\
        x^2 & 0 \leq x \leq \sqrt[3]{3} \\
        0   & x > \sqrt[3]{3}
    \end{array} \right.$$
    
    
    Se pide calcular la esperanza matemática de $X$.
    $$E[X] = \int_{-\infty}^{+\infty} xf(x)~dx = \int_0^{\sqrt[3]{3}} xf(x)~dx = \int_0^{\sqrt[3]{3}} x^3~dx \approx 1.0817$$
\end{ejemplo}


\subsection{Propiedades}

\begin{prop}
    La esperanza de una variable aleatoria constante es la constante.\\
    Es decir, dado $c\in \R$, si $X=c\quad \forall \omega \in \mathcal{A}$, entonces:
    \begin{equation*}
        E[X]=c
    \end{equation*}
\end{prop}
\begin{proof}
    En este caso no tiene sentido considerar el caso continuo, ya que $Re_X=\{c\}$. Para el caso discreto, como $\displaystyle \sum_{i=1}^{|Re_X|}P(x_i)=1$, tenemos que $P(c)=1$. Por tanto,
    \begin{equation*}
        E[X]=\sum_{x_i\in Re_X}x_iP(x_i) = cP(c)=c
    \end{equation*}
\end{proof}

\begin{prop}
    Si una variable aleatoria está acotada; es decir, si $\exists M\in \mathbb{R}\mid |Im(X)|\leq M$, entonces $E[X]\leq M$.
\end{prop}
\begin{proof}
    Hemos de distinguir entre el caso discreto y el caso continuo:
    \begin{itemize}
        \item \underline{Caso discreto}: Supongamos $Re_X = E$.
        \begin{equation*}
            E[X] = \sum_{x_i\in E} x_iP(x_i) \leq \sum_{x_i\in E} M\cdot P(x_i) = 
            M\sum_{x_i\in E} P(x_i) = M
        \end{equation*}

        \item \underline{Caso continuo}: Supongamos $Re_X = [a,b]$.
        \begin{equation*}
            E[X] = \int_a^b xf(x)\;dx
            \leq \int_a^b Mf(x)\;dx = M\int_a^b f(x)\;dx = M
        \end{equation*}
    \end{itemize}
\end{proof}

\begin{prop}\label{prop:6.4}
    Sea $X$ una variable aleatoria. Si $X\geq 0$ y existe esperanza, entonces $E[X]\geq 0$.
\end{prop}
\begin{proof}
    Hemos de distinguir entre el caso discreto y el caso continuo:
    \begin{itemize}
        \item \underline{Caso discreto}: Supongamos $Re_X = E$.
        \begin{equation*}
            E[X] = \sum_{x_i\in E} x_iP(x_i) \geq 0
        \end{equation*}
        donde se ha empleado que $x_i\geq 0$ (hipótesis) y $P(x_i)\geq0$ por definición.

        \item \underline{Caso continuo}: Supongamos $Re_X = [a,b]$.
        \begin{equation*}
            E[X] = \int_a^b xf(x)\;dx
        \end{equation*}
        donde se ha empleado que $x\geq 0$ (hipótesis) y $f(x)\geq0$ por definición.
    \end{itemize}
\end{proof}

\begin{definicion}
    Sea $X$ una variable aleatoria. Se dice que $X$ es simétrica respecto del valor $c$ si $X-c$ y $c-X$ tienen la misma distribución.
    Es decir, en función del tipo:
    \begin{itemize}
        \item \underline{Discreto}: $P[X=c+x]=P[X=c-x]$ para todo $x\in \mathbb{R}$.
        \item \underline{Continuo}: $P[X\leq c-x]=P[X\geq c+x]$ para todo $x\in \mathbb{R}$.
    \end{itemize}
\end{definicion}

\begin{prop}
    Sea $X$ una variable aleatoria con distribución simétrica respecto del valor $c$. Entonces, si $\exists E[X]\Longrightarrow E[X]=c$.
\end{prop}
% // TODO: Simétrico respecto de c -> E[X] = c

\begin{prop}
    Sea $X$ una variable aleatoria. Consideramos $c \in \R$. Entonces, se tiene que $E[cX] = cE[X]$.
\end{prop}
\begin{proof}
    Distinguimos entre el caso disreto y el continuo:
    \begin{itemize}
        \item \underline{Caso discreto}: $Re_X = E$.
        $$E[cX] = \sum_{x_i \in E} c x_i P_Y(c x_i) = c \sum_{x_i \in E} x_i P_Y(c  x_i) = c
        \sum_{x_i \in E} x_i P(x_i) = cE[X]$$
        
        Donde $P_Y$ denota la función masa de probabilidad de la variable aleatoria discreta $Y=cX$. Consúltese el capítulo de cambio de variable discreta (capítulo \ref{subsec:CV_Discreta}) para ver que $P_Y(cx_i) = P(x_i)$ siendo $P$ la función masa de probabilidad de la variable aleatoria $X$.

        \item \underline{Caso continuo}: $Re_X = [a,b]$.
        $$E[cX] = \int_{-\infty}^{+\infty} cx_i f_Y(cx_i)~dx = c \int_{-\infty}^{+\infty} x_i f_Y(cx_i)~dx = c \int_{-\infty}^{+\infty} x_i f(x_i)~dx = cE[X]$$
        Donde $f_Y$ denota la función de densidad de la variable aleatoria continua $Y=cX$. Consúltese el capítulo de cambio de variable continua (capítulo \ref{subsec:CV_Continua}) para ver que $f_Y(cx_i) = f(x_i)$ siendo $f$ la función de densidad de la variable aleatoria $X$.
    \end{itemize}
\end{proof}

\begin{prop}
    Sean $X$ e $Y$ variables aleatorias con recorrido $Re_X, Re_Y$, entonces: $$E[X+Y]=E[X]+E[Y]$$
\end{prop}
\begin{proof} 
    Para el caso discreto, consideramos $Re_X = E, Re_Y = F$ ambos numerables.
    
    Sea $P_X$ la función masa de probabilidad de $X$ y $P_Y$ la de $Y$.
    
    Sea $P_Z$ la función masa de probabilidad de la variable aleatoria $Z=X+Y$, $P_Z:~Re_X \times Re_Y
    \rightarrow [0,1]$.
    \begin{equation*}
        \begin{split}
            E[X+Y] &= \sum_{x_i \in E} \sum_{y_j \in F} (x_i+y_j) P_Z(x_i, y_j) =\\
            &=\sum_{x_i \in E} \sum_{y_j \in F} x_i P_Z(x_i, y_j) + \sum_{x_i \in E} \sum_{y_j \in F} y_j P_Z(x_i, y_j) = \\
            &=\sum_{x_i \in E} x_i \sum_{y_j \in F}P_Z(x_i, y_j) + \sum_{x_i \in E} y_j \sum_{y_j \in F} P_Z(x_i, y_j) =\\
            &= \sum_{x_i \in E}x_i P_X(x_i) +\sum_{y_j \in F}y_j P_Y(y_j) = E[X] + E[y]
        \end{split}
    \end{equation*}
    
    Donde hemos usado que $\sum\limits_{y_j \in F}P_Z(x_i, y_j) = P_X(x_i)$, que excede el conocimiento de este curso.

    La demostración en el caso continuo es análoga.
\end{proof}

\begin{coro}[Linealidad]
    Sea $X_i$ una variable aleatoria $\quad \forall i=1,\dots, n$. Si $\exists E[X_i]$, entonces:
    \begin{equation*}
        \exists E\left[\sum_{i=1}^n a_iX_i\right] = \sum_{i=1}^n a_iE[X_i]
    \end{equation*}
\end{coro}
\begin{proof}
    Se deduce directamente de las dos proposiciones anteriores.
    \begin{equation*}
        E\left[\sum_{i=1}^n a_iX_i\right] = \sum_{i=1}^n E[a_iX_i] = \sum_{i=1}^n a_iE[X_i]
    \end{equation*}
\end{proof}

\begin{prop}
    Dada $X$ una variable aleatoria y se consideran dos funciones de $X$, $g(X), h(X)$, variables aleatorias. Si $g(X)\leq h(X)$, entonces:
    \begin{equation*}
        E[g(X)]\leq E[h(X)]
    \end{equation*}
\end{prop}
\begin{proof}
    Realizamos distinción entre caso discreto y continuo:
    \begin{itemize}
        \item \underline{Caso discreto}. Suponemos $Re_X = E$.

        Sabemos que $f(x_i)\geq 0 \;\forall x_i\in E$. Entonces, no cambia el sentido de la desigualdad, por lo que:
        \begin{equation*}
            g(x_i)f(x_i)\leq h(x_i)f(x_i) \qquad \forall x_i\in E
        \end{equation*}

        Por tanto, tenemos que:
        \begin{equation*}
            \sum_{x_i\in E}g(x_i)f(x_i)\leq \sum_{x_i\in E} h(x_i)f(x_i)
        \end{equation*}
        ya que se cumple para todos los sumandos. Por tanto, usando las definiciones, tenemos que:
        \begin{equation*}
            E[g(X)]\leq E[h(X)]
        \end{equation*}

        \item \underline{Caso continuo}. Suponemos $Re_X = [a,b]$.

        Sabemos que $f(x)\geq 0 \;\forall x\in [a,b]$. Entonces, no cambia el sentido de la desigualdad, por lo que:
        \begin{equation*}
            g(x)f(x)\leq h(x)f(x) \qquad \forall x_i\in [a,b]
        \end{equation*}

        Por tanto, ya que el operador integral mantiene las relaciones de orden, tenemos que:
        \begin{equation*}
            \int_a^b g(x)f(x)\;dx\leq \int_a^b h(x)f(x)\;dx
        \end{equation*}
        
        Por tanto, usando las definiciones, tenemos que:
        \begin{equation*}
            E[g(X)]\leq E[h(X)]
        \end{equation*}
    \end{itemize}
\end{proof}

\begin{coro}
    Sea $X$ una variable aleatoria y $g, h$ funciones reales tales que $\exists E[g(x)], E[h(x)]$, entonces:
    $$\exists E[\alpha g(X) + \beta h(X)] = \alpha E[g(X)] + \beta E[h(X)] \qquad \forall \alpha, \beta \in \R$$
\end{coro}

\begin{prop}
    La esperanza matemática minimiza el error cuadrático medio:
    $$\min_{a \in R} E[(X-a)^2] = E[(X-E[X])^2]$$
\end{prop}
\begin{proof}
    Sea $a \in \R$, y definimos el error cuadrático medio respecto al valor $a$:
    $$\mu(a) = E[(X-a)^2] = E[X^2-2aX+a^2] = E[X^2] - 2aE[X] + a^2$$

    Para minimizar dicha función, hemos de calcular los puntos que anulan la primera derivada. Además, al tratarse de una parábola con coeficiente líder positivo, dicho punto crítico será un mínimo.
    $$\mu'(a) = 2E[X] - 2a = 0 \Longleftrightarrow a = E[X]$$

    Por tanto, $a=E[X]$ es un mínimo de la expresión $\mu(a)$ y, al ser el único, concluimos que es mínimo absoluto.
    Luego, acabamos de ver que la esperanza matemática minimiza el error cuadrático medio.
\end{proof}



\begin{definicion}[Independencia de Variables Aleatorias]
    Dadas $n$ variables aleatorias $X_1,X_2,\ldots,X_n$, se dice que son independientes si y solo si:
    \begin{multline*}
        P[X_1\leq x_1, X_2\leq x_2,\ldots, X_n\leq x_n] = P[X_1\leq x_1]P[X_2\leq x_2]\cdots P[X_n\leq x_n] \\ \forall x_1,x_2,\ldots,x_n\in \mathbb{R}
    \end{multline*}    
\end{definicion}
\begin{ejemplo}
    Sea $X=c$ una variable aleatoria degenerada, y sea $Y$ otra variable aleatoria cualquiera. Entonces, $X$ y $Y$ son independientes, ya que:
    \begin{equation*}
        P[X\leq x] = \begin{cases}
            0 & \text{si } x< c \\
            1 & \text{si } x\geq c
        \end{cases}
        \qquad
        P[X\leq x, Y\leq y] = \begin{cases}
            0 & \text{si } x< c \\
            P[Y\leq y] & \text{si } x\geq c
        \end{cases}
    \end{equation*}

    Por tanto, $P[X\leq x, Y\leq y] = P[X\leq x]P[Y\leq y]$.
\end{ejemplo}

\begin{prop} \label{prop:Esperanza_Independendientes}
    Sean $X$ e $Y$ variables aleatorias. Entonces, se tiene que:
    \begin{center}
        $X$ e $Y$ son independientes $\Longleftrightarrow E[XY]=E[X]E[Y]$
    \end{center}
\end{prop}
% // TODO: Teorema de Multiplicación de Esperanzas
% // https://www.ugr.es/~cdpye/CursoProbabilidad/pdf/P_T07_Reproductividad.pdf


\begin{teo}[de Markov: desigualdad básica]
    Sea $X$ una variable aleatoria. Si $X\geq 0$ y $\exists E[X]$, entonces:
    \begin{equation*}
        P[X\geq \varepsilon]\leq \dfrac{E[X]}{\varepsilon} \qquad \forall \varepsilon>0 
    \end{equation*}
\end{teo}
\begin{proof}
    Realizamos la distinción entre el caso discreto y el continuo:
    \begin{itemize}
        \item \underline{Caso discreto}: Supongamos que $Re_X=E$. Entonces:
        \begin{equation*}
            E[X]=\sum_{x_i\in E}x_iP(x_i)
            = \sum_{\mathclap{x_i\in E\mid x_i<\varepsilon}}x_iP(x_i) + \sum_{\mathclap{x_i\in E\mid x_i\geq \varepsilon}}x_iP(x_i)
        \end{equation*}

        Por la Proposición \ref{prop:6.4}, tenemos que $\displaystyle \sum\limits_{\mathclap{x_i\in E\mid x_i<\varepsilon}}x_iP(x_i)\geq 0$. Por tanto,
        \begin{multline*}
            E[X]
            =\sum_{x_i\in E}x_iP(x_i)
            = \sum_{\mathclap{x_i\in E\mid x_i<\varepsilon}}x_iP(x_i) + \sum_{\mathclap{x_i\in E\mid x_i\geq \varepsilon}}x_iP(x_i)
            \geq \sum_{\mathclap{x_i\in E\mid x_i\geq \varepsilon}}x_iP(x_i)
            \geq\\
            \geq \sum_{\mathclap{x_i\in E\mid x_i\geq \varepsilon}}\varepsilon P(x_i)
            = \varepsilon \sum_{\mathclap{x_i\in E\mid x_i\geq \varepsilon}} P(x_i)
            = \varepsilon P[X\geq \varepsilon]
        \end{multline*}

        Por tanto, despejando $P[X\geq \varepsilon]$, tenemos que:
        \begin{equation*}
            P[X\geq \varepsilon] \leq \frac{E[X]}{\varepsilon}
        \end{equation*}

        \item \underline{Caso continuo}: Supongamos $Re_X=[a,b]$. 
        \begin{equation*}
            E[X]
            =\int_a^b xP(x)~dx
            =\int_a^\varepsilon xP(x)~dx + \int_\varepsilon^b xP(x)~dx
            \stackrel{(\ast)}{=} \varepsilon \int_\varepsilon^b P(x)~dx
            = \varepsilon P[X\geq \varepsilon]
        \end{equation*}
        donde en $(\ast)$ hemos empleado la Proposición \ref{prop:6.4}.

        Por tanto, despejando $P[X\geq \varepsilon]$, tenemos que:
        \begin{equation*}
            P[X\geq \varepsilon] \leq \frac{E[X]}{\varepsilon}
        \end{equation*}
    \end{itemize}
\end{proof}

\begin{coro}[Desigualdad de Markov]
    Sea $X$ es una variable aleatoria y sea $\alpha\in \bb{R}^+$. Si $\exists E[|X|^\alpha]$, se tiene:
    \begin{equation*}
        P[|X|\geq k]\leq \frac{E[|X|^\alpha]}{k^\alpha},\qquad \forall k>0
    \end{equation*}
\end{coro}
\begin{proof}
    En primer lugar, es importante señalar que:
    \begin{equation*}
        P[|X|\geq k]=P[|X|^\alpha \geq k^\alpha]
    \end{equation*}
    Esto se debe al Teorema de Cambio de Variable y a que la trasformación $h(|X|)=|X|^\alpha$ es inyectiva, ya que la base y el exponente son positivos.

    Además, aplicando la desigualdad básica a la variable $|X|^\alpha$, con $\varepsilon=k^\alpha$, se tiene que:
    \begin{equation*}
        P[|X^\alpha\geq k^\alpha]\leq \frac{E[|X|^\alpha]}{k^\alpha}
    \end{equation*}

    Uniendo ambas ecuaciones, se tiene lo pedido.
\end{proof}

\begin{coro}[Desigualdad de Chebychev]
    Si $X$ es una variable aleatoria tal que $\exists E[X^2]$, se tiene
    \begin{equation*}
        P[|X-E[X]|\geq k]\leq \frac{\Var[X]}{k^2},\qquad \forall k>0
    \end{equation*}
\end{coro}
\begin{proof}
    Se basa en aplicar la desigualdad básica a la variable $(X-E[X])^2$. Para $\varepsilon=k^2$, se tiene que:
    \begin{equation*}
        P[|X-E[X]|\geq k] = P[(X-E[X])^2\geq k^2] \leq \frac{E[(X-E[X])^2]}{k^2} = \frac{\Var[X]}{k^2}
    \end{equation*}
\end{proof}

\textbf{Expresiones alternativas de la desigualdad}:
\begin{enumerate}
    \item De forma directa, se deduce que:
    \begin{equation*}
        P[|X-E[X]| < k]\geq 1-\frac{\Var[X]}{k^2},\qquad \forall k>0
    \end{equation*}
    Esta expresión proporciona una cota inferior para la probabilidad de que una variable tome valores en cualquier intervalo real centrado en la media de la variable.

    \item Empleando ahora $\varepsilon=\Var[X]k^2$, de forma idéntica se deduce que:
    \begin{equation*}
        P[|X-E[X]|\geq \sqrt{\Var[X]}k]\leq \frac{1}{k^2},\qquad \forall k>0
    \end{equation*}

    \item De forma directa, se deduce que:
    \begin{equation*}
        P[|X-E[X]|< \sqrt{\Var[X]}k]\geq 1-\frac{1}{k^2},\qquad \forall k>0
    \end{equation*}
    Esta expresión proporciona una cota inferior para la probabilidad de que una variable tome valores en cualquier intervalo real centrado en la media de la variable con una amplitud de $k\sqrt{\Var[X]}$.
\end{enumerate}

\subsection{Cambio de variable aleatoria discreta}

Sea $X$ una variable aleatoria discreta con $Re_X=E$ e $Y=h(X)$ otra variable aleatoria discreta, entonces,
si existe $E[Y]$ (existe si la serie converje absolutamente), entonces:
$$E[Y] = \sum_{x_i \in E}h(x_i)P(x_i)$$

\subsection{Cambio de variable aleatoria continua}

Sea $X$ una variable aleatoria continua con $Re_X=[a,b]$ e $Y=h(X)$ otra variable aleatoria continua, entonces,
si existe $E[Y]$ (existe si la integral converje absolutamente), entonces:
$$E[Y] = \int_{-\infty}^{+\infty} h(x)f(x)~dx$$

\section{Moda}
\subsection{Variables aleatorias discretas}
\begin{definicion}
    Sea $X$ una variable aleatoria discreta con recorrido $Re_X=E$, se define la moda de $X$ como aquel valor del recorrido de $X$ cuya imagen por su función masa de probabilidad sea mayor, es decir:
    $$Mo_X = \max \{x \in E \mid P(x) \geq P(y)~~\forall y \in E\}$$
\end{definicion}

\subsection{Variables aleatorias continuas}
\begin{definicion}
    Sea $X$ una variable aleatoria continua con recorrido $Re_X=[a,b]$, se define la moda de $X$ como aquel valor del recorrido de $X$ cuya imagen por su función de densidad sea mayor, es decir:
    $$Mo_X = \max \{x \in [a,b] \mid f(x) \geq f(y)~~\forall y \in [a,b]\}$$
    
    Dicho de otra forma, la moda de $X$ es la abscisa en la que se alcanza el máximo absoluto de $f$.
\end{definicion}

\begin{ejemplo}
    Sea $X$ una variable aleatoria con función de densidad:
    $$f(x) = \left\{ \begin{array}{ll}
        0               & x < 1           \\
        \dfrac{8}{7x^2} & 1 \leq x \leq 8 \\
        0               & x > 8
      \end{array} \right.$$
    
    Se pide calcular la moda de $X$.\\
    
    En este caso, hemos de de maximizar $f(X)$.
    \begin{equation*}
        f'(x)= -2\frac{8}{7x^3} = -\frac{16}{7x^3}< 0
    \end{equation*}

    Por tanto, como $f(x)$ es estrictamente decreciente y positiva en $[1,8]$, tenemos que la moda es el mínimo de dicho intervalo, es decir:
    $$Mo_X=1$$
\end{ejemplo}

\section{Percentiles}
\subsection{Variables aleatorias discretas}

\begin{definicion}
    Sea $X$ una variable aleatoria discreta con $Re_X=E$. Definimos el percentil $q\in [0, 1]$ de la variable aleatoria $X$ como el valor $X_q \in E$ tal que:
    $$\begin{array}{c}
        P_X(]-\infty, X_q]) \geq q \\
        P_X([X_q, +\infty[) \geq 1-q
    \end{array}$$

    En el caso de que el valor buscado esté entre dos elementos del recorrido de $X$, $x_i, x_j \in E$, entonces el percentil $X_q$ buscado es la media de ambos elementos: $X_q = \dfrac{x_i+x_j}{2}$.
\end{definicion}

\begin{notacion}
    Para simplificar la notación, el percentil $X_{80}$ será el valor $X_{80} \in E$ tal que:
    $$\begin{array}{c}
        P_X(]-\infty, X_q]) \geq 0.8 \\
        P_X([X_q, +\infty[) \geq 0.2
    \end{array}$$
\end{notacion}

\subsection{Variables aleatorias continuas}
\begin{definicion}
    Sea $X$ una variable aleatoria continua con $Re_X = [a,b]$. Definimos el percentil $q \in [0,1]$ de la variable
    aleatoria $X$ como el valor $X_q \in [a,b]$ tal que:
    $$\begin{array}{c}
        P_X(]-\infty, X_q]) = q \\
        P_X([X_q, +\infty[) = 1-q
    \end{array}$$
\end{definicion}
\begin{notacion}
    Para simplificar la notación, el percentil $X_{80}$ será el valor $X_{80} \in [a,b]$ tal que:
    $$\begin{array}{c}
        P_X(]-\infty, X_q]) = 0.8 \\
        P_X([X_q, +\infty[) = 0.2
    \end{array}$$
\end{notacion}

\subsection{Mediana}
\begin{definicion}
    Dada una variable aleatoria $X$ con recorrido $Re_X$, se define la media de la variable aleatoria, notada $Me$ como:
    $$Me = X_{50}$$
\end{definicion}

\begin{ejemplo}
    Sea $X$ una variable aleatoria discreta con $Re_X = [0,3] \cap \Z$ con función masa de densidad:
    $$P(x) = \left\{ \begin{array}{cc}
        3/16 & x = 0 \\
        7/16 & x = 1 \\
        5/16 & x = 2 \\
        1/16 & x = 3
      \end{array} \right.$$
    Se pide calcular la mediana de la variable aleatoria.\\
    
    
    Buscamos $Me \in [0,3] \cap \Z$ tal que:
    $$\begin{array}{c}
        P_X([0, Me] \cap \Z) = F_X(Me) \geq 1/2 \\
        P_X([Me, 3] \cap \Z) \geq 1/2
      \end{array}$$
    
    
    Supongamos que $Me=1$, veamos que es cierto:
    $$\begin{array}{c}
        P_X([0, 1] \cap \Z) = F_X(1) = 10/16 \geq 1/2 \\
        P_X([1, 3] \cap \Z) = 13/16 \geq 1/2
      \end{array}$$
    
    Luego:
    $$Me = 1$$
\end{ejemplo}


\section{Momentos de una variable aleatoria}

Sea $X$ una variable aleatoria. Definimos el momento de orden $k\in \mathbb{N}$ centrado en el punto $a\in \mathbb{R}$ como:
\begin{equation*}
    _a m_k = E[(X-a)^k] \qquad k \in \N \cup \{0\} \ \land \ a \in \R
\end{equation*}

\subsection{Momentos no centrales}

\begin{definicion}[Momentos no centrales]
    Sea $X$ una variable aleatoria con recorrido $Re_X$, definimos el momento no centrado de orden $k \in \N \cup \{0\}$, notado $m_k$ como la cantidad:
    $$m_k = E[X^k]$$
\end{definicion}

Algunos momentos no centrales relevantes son:
$$\begin{array}{l}
    m_0 = E[X^0] = E[1] = 1 \\
    m_1 = E[X^1] = E[X]     \\
    m_2 = E[X^2]
\end{array}$$

\subsection{Momentos centrales}

\begin{definicion}[Momentos centrales]
    Sea $X$ una variable aleatoria, definimos el momento centrado de orden $k \in \N \cup \{0\}$, notado $\mu_k$ como la cantidad:
    $$\mu_k = E[(X - E[X])^k]$$
\end{definicion}

Algunos momentos centrales relevantes son:
$$\begin{array}{l}
    \mu_0 = E[(X-E[X])^0] = E[1] = 1                     \\
    \mu_1 = E[X-E[X]] = E[X] - E[E[X]] = E[X] - E[X] = 0 \\
    \mu_2 = E[(X-E[X])^2]
  \end{array}$$

Tenemos los siguientes resultados demostrados para la estadística unidimensional. La demostración en este caso es análoga:
\begin{equation*}
    m_{k} = \sum_{i=0}^k\binom{k}{i} \mu_{k-i}m_1^i
    \hspace{2cm}
    \mu_{k} = \sum_{i=0}^k\binom{k}{i} (-1)^i m_{k-i} m_1^i
\end{equation*}

\subsection{Varianza}
\begin{definicion}
    Sea $X$ una variable aleatoria, definimos la varianza de $X$, notada $\sigma_X^2$ o $\Var[X]$ por:
    $$\sigma_X^2 = \Var[X] := \mu_2(X) = E[(X-E[X])^2]$$
\end{definicion}


\begin{prop}
    Dada una variable aleatoria $X$, tenemos que:
    \begin{equation*}
        \Var[X] = E[X^2] - (E[X])^2
    \end{equation*}
\end{prop}
\begin{proof}
    Teniendo en cuenta que $E[X]$ es una constante, es decir, $E[XE[X]]=E[X]^2$, tenemos que:
    \begin{multline*}
        \Var[X] = E[(X-E[X])^2] = E[X^2 + (E[X])^2 - 2XE[X]]
        = E[X^2] + E[E[X]^2] - E[2XE[X]] =\\=
        E[X^2] + (E[X])^2 -2(E[X])^2
        = E[X^2] - (E[X])^2 = m_2-m_1^2
    \end{multline*}
\end{proof}


\begin{prop}
    Sea $X$ una variable aleatoria cuya varianza existe, y consideramos $Y=aX+b,\quad a,b\in \mathbb{R}$. Entonces:
    \begin{equation*}
        \exists \Var[Y] := \Var[aX+Y] = a^2\Var[X]
    \end{equation*}
\end{prop}
\begin{proof}
    \begin{multline*}
        \Var[aX+b]
        = E[(aX+b)^2] -E[aX+b]^2
        = E[a^2X^2 + b^2 +2abX] - (aE[X]+b)^2
        =\\= a^2E[X^2] + b^2 +2abE[X] -a^2E[X]^2 -b^2 -2abE[X] =  a^2(E[X^2] - E[X]^2) = a^2\Var[X]
    \end{multline*}
\end{proof}


\begin{prop}
    Sean $X$ e $Y$ variables aleatorias independientes. Entonces:
    \begin{equation*}
        \exists  \Var[X\pm Y] = \Var[X] + \Var[Y]
    \end{equation*}
\end{prop}
\begin{proof}
    Tenemos que:
    \begin{align*}
        \Var[X \pm Y] &= E[(X\pm Y)^2] - E[X\pm Y]^2
        =\\&= E[X^2 + Y^2 \pm 2XY] - E[X]^2 - E[Y]^2 \mp 2E[X]E[Y]
        =\\&= E[X^2] - E[X]^2 + E[Y^2] -E[Y]^2 \pm 2E[XY] \mp 2E[X]E[Y]
        \AstIg\\&\AstIg \Var[X] + \Var[Y]
    \end{align*}
    donde en $(\ast)$ hemos usado que $E[XY]=E[X]E[Y]$ por la Proposición \ref{prop:Esperanza_Independendientes}.
\end{proof}

\begin{coro}
    Sean $X_1,\dots,X_n$ variables aleatorias independientes. Entonces:
    \begin{equation*}
        \exists  Var\left[\sum_{i=1}^n a_iX_i\right] = \sum_{i=1}^n a_i^2 \Var[X_i]
    \end{equation*}
\end{coro}
\begin{proof}
    \begin{equation*}
        Var\left[\sum_{i=1}^n a_iX_i\right]
        \AstIg \sum_{i=1}^n \Var[a_iX_i]
        = \sum_{i=1}^n a_i^2 \Var[X_i]
    \end{equation*}
    donde en $(\ast)$ hemos usado el resultado anterior.
\end{proof}


\begin{prop}\label{prop:6.13}
    Sea $X$ una variable aleatoria. Entonces:
    \begin{equation*}
        \Var[X]=0 \Longleftrightarrow X=c\in \mathbb{R}
    \end{equation*}
    Es decir, la varianza de una variable aleatoria es nula si y solo si dicha variable aleatoria es una constante.
\end{prop}
\begin{proof}
    Procedemos mediante doble implicación:
    \begin{description}
        \item [$\Longleftarrow$)] Suponemos $X=c\in \mathbb{R}$. Entonces,
        \begin{equation*}
            \Var[X] = E[X^2]-E[X]^2 = c^2 -c^2 = 0
        \end{equation*}

        \item [$\Longrightarrow$)] Suponemos $\Var[X]=0$. Entonces,
        \begin{itemize}
            \item \underline{Caso discreto.} Consideramos $Re_X = E$:
            \begin{equation*}
                \Var[X] = 0 = E[(X-E[X])^2]
                = \sum_{x_i\in E}(x_i-E[X])^2 f(x_i)
            \end{equation*}

            Como tenemos que $f(x_i)> 0\;\forall x_i$, entonces tenemos que todos los términos son no-negativos. Por tanto, para que se igualen a $0$ todos ellos han de ser nulos. Por tanto,
            \begin{equation*}
                x_i = E[X] \qquad \forall x_i \in E
            \end{equation*}

            Por tanto, llamando $E[X]=c\in \mathbb{R}$, tenemos $X=c$.



            \item \underline{Caso continuo.} Consideramos $Re_X = [a,b]$:
            \begin{equation*}
                \Var[X] = 0 = E[(X-E[X])^2]
                = \int_a^b (x-E[X])^2 f(x)\;dx
            \end{equation*}

            Como tenemos que $f(x)> 0\;\forall x$, entonces tenemos que el integrando es no-negativo. Por tanto, para que se iguale la integral a $0$ el integrando ha de ser nulo. Por tanto,
            \begin{equation*}
                x = E[X] \qquad \forall x \in [a,b]
            \end{equation*}

            Por tanto, llamando $E[X]=c\in \mathbb{R}$, tenemos $X=c$.
        \end{itemize}
    \end{description}
\end{proof}

\section{Función generatriz de momentos}

Sea $X$ una variable aleatoria. Si $\exists t_0 \in \R \mid \; \forall t \in ]-t_0,t_0[$ existe la esperanza
$E[e^{tX}]$,
se dice entonces que existe la \textbf{función generatriz de momentos de $X$}, notada $M_X$ y definida como:
$$M_X(t)=E[e^{tX}] = \left\{ \begin{array}{ll}
    \sum\limits_{x_i \in E} e^{tx_i} P(x_i) & \mbox{ caso discreto} \\ \\
    \displaystyle \int_{-\infty}^{+\infty} e^{tx}f(x)~dx  & \mbox{ caso continuo}
  \end{array} \right.~~\forall t \in ]-t_0, t_0[$$
La función generatriz de momentos de una variable aleatoria no tiene por qué existir (por ejemplo, para la
distribución de Cauchy). Pero si la variable aleatoria está acotada, entonces siempre existe.

\begin{teo}[de unicidad]
    La función generatriz de momentos de una variable aleatoria, si existe, es única y determina de forma única la distribución de la variable.
    % // TODO: Unicidad de la función generatriz de momentos
\end{teo}

Es decir, una variable aleatoria no puede tener dos funciones generatrices de momentos y dos variable aleatorias con distinta distribución tampoco pueden tener la misma función generatriz de momentos.

\begin{teo} [Relación con los momentos]
    Si existe la función generatriz de momentos de una variable aleatoria, entonces:
    \begin{enumerate}
        \item Existen todos los momentos de la variable aleatoria.

        \item $\forall t \in ]-t_0, t_0[$:
        $$M_X(t) = \sum_{n=0}^\infty \dfrac{t^nE[X^n]}{n!}$$

        \item Existe la derivada de todos los órdenes de $M_X(t)$ en un entorno de cero y:
        $$M_X^{n)}(t)\Big|_{t=0} = E[X^n] \qquad n = 1, 2, \ldots$$
    \end{enumerate}
\end{teo}
\begin{proof}
    Demostramos cada resultado por separado:
    \begin{enumerate}
        \item Se deja como ejercicio al lector.
        \item Sabemos\footnote{Se demuestra mediante el desarrollo en serie de Taylor de la exponencial, conceptos estudiados en Cálculo II.} que $e^x = \sum\limits_{n=0}^\infty \frac{x^n}{n!}$. Por tanto,
        \begin{multline*}
            M_X(t)=E[e^{tX}]
            = E\left[\sum_{n=0}^\infty \frac{(tX)^n}{n!}\right]
            = E\left[\sum_{n=0}^\infty \frac{t^n X^n}{n!}\right]
            =\\= \sum_{n=0}^\infty E\left[ \frac{t^n X^n}{n!}\right]
            = \sum_{n=0}^\infty \frac{t^n E\left[X^n\right]}{n!}
        \end{multline*}

        \item Tenemos que:
        \begin{align*}
            M_X^{n)}(t)\Big|_{t=0} &= \dfrac{d^n}{dt^n}E[e^{tX}]\Big|_{t=0} = E\left[\dfrac{d^n}{dt^n}e^{tX}\right]\Big|_{t=0} =\\
            &= E\left[X^n e^{tX}\right]\Big|_{t=0} = E[X^n]
        \end{align*}
    \end{enumerate}
\end{proof}

\begin{ejemplo}
    Sea $X$ una variable aleatoria continua con recorrido $Re_X = \R^{+}$ y función de densidad:
    $$f(x) = \left\{ \begin{array}{ll}
        0      & x \leq 0 \\
        e^{-x} & x > 0
      \end{array} \right.$$
    
    Se pide calcular la función generatriz de momentos de $X$, $M_X(t)$.
    \begin{equation*}\begin{split}
        M_X(t) &= E[e^{tX}] = \int_0^{+\infty} e^{tx} e^{-x}~dx = \int_0^{+\infty} e^{x(t-1)}~dx =\\
        &=\dfrac{1}{t-1} \int_0^{+\infty} (t-1) e^{x(t-1)}~dx = \left. \dfrac{e^{x(t-1)}}{t-1} \right]_0^{+\infty} = \dfrac{1}{1-t}
    \end{split}\end{equation*}
    
    Con $t<1$ para que la integral converja y exista la esperanza.\\
    
    Comprobamos que $M_X(t) = \dfrac{1}{1-t},\quad t<1$ es nuestra función generatriz de momentos (al menos para $m_0,m_1,m_2$):
    
    $$M_X(0) = 1 = \int_0^{+\infty} f(x)~dx = \int_0^{+\infty} e^{-x}~dx = m_0$$
    
    $$M_X'(t) = \dfrac{1}{(1-t)^2}\Longrightarrow M_X'(0) = 1 = \int_0^{+\infty} xf(x)~dx = \int_0^{+\infty} xe^{-x}~dx = m_1$$
    
    $$M_X''(t) = \dfrac{2}{(1-t)^3} \Longrightarrow M_X''(0) = 2 = \int_0^{+\infty} x^2f(x)~dx = \int_0^{+\infty} x^2e^{-x}~dx = m_2$$
\end{ejemplo}

Algunas de sus propiedades son:
\begin{lema}
    Sea $X$ una variable aleatoria y sea $M_X(t)$ su función generatriz de momentos. Entonces:
    $$M_X(0)=1$$
\end{lema}
\begin{proof}
    $$M_X(0) = E[e^{0X}] = E[1] = 1$$
\end{proof}

\begin{prop}
    Sea $X$ una variable aleatoria con función generatriz de momentos $M_X(t)\;\forall t \in ]-t_0, t_0[$, sea $Y = aX +b\;a, b \in \mathbb{R}$, entonces la función generatriz de momentos de $Y$, para $t$ tal que $at \in ]-t_0, t_0[$ verifica:
    \begin{equation*}
        M_Y(t) = e^{bt}M_X(at)
    \end{equation*}
\end{prop}
\begin{proof}
    Realizamos distinción entre caso continuo y caso discreto:
    \begin{itemize}
        \item \underline{Caso discreto}. Suponemos $Re_X = E$. Entonces:
        \begin{multline*}
            M_Y(t) = E[e^{ty}] = E[e^{t(ax+b)}] = \sum_{x_i\in E} e^{t(ax_i+b)}f(x_i)
            = e^{tb}\sum_{x_i\in E} e^{t(ax_i)}f(x_i)
            =\\= e^{tb}E[e^{atx}] = e^{bt}M_X(at)
        \end{multline*}

        \item \underline{Caso continuo}. Suponemos $Re_X = [a,b]$. Entonces:
        \begin{multline*}
            M_Y(t) = E[e^{ty}] = E[e^{t(ax+b)}] = \int_a^b e^{t(ax+b)}f(x)\;dx
            = e^{tb}\int_a^b e^{t(ax)}f(x)\;dx
            =\\= e^{tb}E[e^{atx}] = e^{bt}M_X(at)
        \end{multline*}
    \end{itemize}
\end{proof}



\begin{prop}\label{prop:generatriz_momentos_independientes}
    Sean $X_1,X_2,\ldots,X_n$ variables aleatorias independientes con función generatriz de momentos $M_{X_i}(t)$ para todo $i=1,\dots,n$. Entonces, la función generatriz de momentos de la variable aleatoria $X=\sum\limits_{i=1}^n X_i$ es:
    \begin{equation*}
        M_X(t)=\prod_{i=1}^n M_{X_i}(t)
    \end{equation*}
\end{prop}
\begin{proof}
    \begin{equation*}\begin{split}
        M_X(t)
        &= E[e^{tX}]
        = E\left[e^{t\sum\limits_{i=1}^n X_i}\right]
        = E\left[\prod_{i=1}^n e^{tX_i}\right]
        \AstIg \prod_{i=1}^n E[e^{tX_i}]
        = \prod_{i=1}^n M_{X_i}(t)
    \end{split}\end{equation*}
    donde en $(\ast)$ hemos empleado la Proposición \ref{prop:Esperanza_Independendientes}.
\end{proof}