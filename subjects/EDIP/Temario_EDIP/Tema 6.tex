\chapter{Variables aleatorias}
\section{Definiciones}


Para dar la definición de variable aleatoria, es necesario pararnos a observar que hasta ahora hemos estado trabajando con el espacio probabilístico $(\Omega, \mathcal{A}, P)$.
A continuación, nos será de especial importancia tener en cuenta el espacio probabilístico $(\R, \mathcal{B})$ donde $\R$ es el conjunto de números reales y $\mathcal{B}$ es una $\sigma$-álgebra sobre $\R$ que contiene a todos sus intervalos.
Esta $\mathcal{B}$ recibe el nombre de $\sigma$-álgebra de Borel\footnote{Se estudiará a fondo en Análisis Matemático II.}.

\begin{definicion}
    Una variable aleatoria $X$ es una función medible\footnote{Este concepto se introducirá en la Teoría de Integración que se verá en Análisis Matemático II.} sobre un espacio de probabilidad. 
    Es decir, una función:
    $$X:(\Omega, \mathcal{A}, P) \rightarrow (\R, \mathcal{B})$$
    tal que la imagen inversa de cualquier conjunto de Borel es medible. Esto se caracteriza por:
    $$X^{-1}(B) \in \mathcal{A} \qquad \forall B \in \mathcal{B}$$
\end{definicion}

Notemos que para comprobar que dicha variable sea aleatoria basta con que la imagen inversa de cualquier intervalo de la forma $]-\infty, x]$ sea medible (análogamente, que pertenezca a $\A$).

Por tanto, $X$ será una variable aleatoria si es una función $X :(\Omega, \A, P) \rightarrow (\R, \B)$ tal que
$$X^{-1}(]-\infty, x]) \in \A \qquad \forall x \in \R$$

\begin{ejemplo}
    Consideramos el experimento aleatorio de lanzar una moneda:
    $$\Omega = \{c, +\} \mbox{ (c cara, + cruz)}$$
    $$\mathcal{A} = \{\emptyset, \{c\}, \{+\}, \Omega \}$$
    
    Definimos $X$ como el número de caras al lanzar una moneda:
    $$X(\omega) = \left\{ \begin{array}{lcl}
        0 & \mbox{ si } & c \notin \omega \\
        1 & \mbox{ si } & c \in \omega    \\
      \end{array} \right.~~~\omega \in \Omega$$

    Comprobamos que se trata de una variable aleatoria. Trivialmente sabemos que se trata de una función del tipo:
    $$X : (\Omega, \mathcal{A}, P) \rightarrow (\R, \mathcal{B})$$
    
    Comprobamos que $X^{-1}(B) \in \mathcal{A}~~\forall B \in \mathcal{B}$:
    
    $$\begin{array}{ll}
        \mbox{Si } x<0       & X^{-1}(\left] -\infty, x \right] ) = \emptyset \in \mathcal{A} \\
        \mbox{Si } 0\leq x<1 & X^{-1}(\left] -\infty, x \right] ) = + \in \mathcal{A}         \\
        \mbox{Si } x\geq 1   & X^{-1}(\left] -\infty, x \right] ) = \Omega \in \mathcal{A}
      \end{array}$$
\end{ejemplo}

\section{Probabilidad inducida}
\begin{definicion}[Probabilidad inducida]
    Sea $X:(\Omega, \A, P) \rightarrow (\R, \B)$ una variable aleatoria, podemos definir una nueva función
    \Func{P_X}{(\bb{R},\cc{B})}{[0,1]}{B}{P(X^{-1}(B))}
    A esta función se le llama probabilidad inducida por $X$.
\end{definicion}
\begin{notacion}
    Podemos encontrar $P_X(B)$ notado como $P[X \in B]$.
\end{notacion}

\begin{prop}
    Sea $X:(\Omega, \A, P) \rightarrow (\R, \B)$ una variable aleatoria y $P_X$ su probabilidad inducida.
    Entonces, $(\R, \B, P_X)$ es un espacio de probabilidad.
\end{prop}
\begin{proof} Para ello, hemos de ver que $P_X$ es una función de probabilidad, es decir, que cumple los axiomas de probabilidad:
    \begin{itemize}
        \item \ul{Axioma de no negatividad}:
              $$P_X(B) = P(X^{-1}(B)) \geq 0 \qquad \forall B \in \B$$
        \item \ul{Axioma del suceso seguro}:
              $$P_X(\R) = P(X^{-1}(\R)) = P(\Omega) = 1$$
        \item \ul{Axioma de $\sigma$-aditividad}:
        
        Sean $B_1, B_2, \ldots \in \B$ disjuntos dos a dos, entonces:
        \begin{align*}
            P_X\left(\bigcup\limits_{i=1}^{\infty} B_i\right) &= P\left(X^{-1}\left(\bigcup_{i=1}^{\infty} B_i\right)\right) = P\left(\bigcup_{i=1}^{\infty} X^{-1}(B_i)\right) =\\&= \sum_{i=1}^{\infty} P(X^{-1}(B_i)) = \sum_{i=1}^{\infty} P_X(B_i)
        \end{align*}
    \end{itemize}
\end{proof}

Notemos que era necesario imponer la medibilidad de nuestra función variable aleatoria $X$, ya que lo que pretendemos es poder asignar a cada valor del codominio de nuestra variable aleatoria una probabilidad inducida $P_X$ por la función probabilidad $P$ ya definida en nuestra $\sigma$-álgebra original, y para ello, naturalmente, necesitamos una correspondencia entre reales (codominio particular en este caso) y elementos de $\A$ (donde ya tenemos definida $P$).\\

Esta función de probabilidad es de gran relevancia, pues es la pieza fundamental para la definición de la función de distribución, tomando $B=\left]-\infty, x\right] \mid x \in \R$, y también para la definición de la función masa de probabilidad, tomando $B=[x,x] \mid x \in \R = \{x\}\subset \bb{R}$.\\

Notemos que, tras haber demostrado que $P_X$ es una función de probabilidad,
podemos aplicar los resultados ya conocidos de probabilidad a esta nueva función de probabilidad. Así, tenemos que:
\begin{itemize}
    \item $P_X(]-\infty, x]) = P_X(]-\infty, x[) + P_X(x), \quad \forall x \in \R$
    
    Se ha usado la Proposición \ref{prop:prob_union}, donde hemos usado que $$P_X(]-\infty, x[~\cap ~\{x\}) = P_X(\emptyset) = 0$$

    \item $P_X(]-\infty, x]) = 1 - P_X(]x, +\infty[), \quad \forall x \in \R$
    
    Se ha usado la Proposición \ref{prop:prob_complementario}, donde hemos usado que $\left]x, +\infty\right[ = \ol{\left]-\infty, x\right]}$.

    \item $P_X([a,b]) = P_X(]-\infty, b]) - P_X(]-\infty, a[), \quad \forall a,b \in \R, a \leq b$
    
    Se ha usado la Proposición \ref{prop:prob_monotona}, sabiendo que $[a,b] = \left]-\infty, b\right] \setminus \left]-\infty, a\right[$, y que $\left]-\infty, a\right]\subset \left]-\infty, b\right]$.
    
\end{itemize}

\section{Función de distribución}
\begin{definicion}[Función de distribución]
Se define la función de distribución de una variable aleatoria como:
\Func{F_X}{\R}{[0,1]}{x}{P_X\left(]-\infty, x]\right)}
\end{definicion}
\begin{notacion}
Notemos que:
\begin{align*}
    F_x(x) &= P_X(]-\infty, x]) = (P \circ X^{-1})(]-\infty, x]) = P(\{\omega \in \Omega \mid X(\omega) \in ]-\infty, x] \}) =\\
    &=P(\{\omega \in \Omega \mid X(\omega) \leq x\})
\end{align*}

Por tanto, será más común encontrar $F_X(x)$ notado como $P(X \leq x)$ o como $P[X \leq x]$, siendo los paréntesis y los corchetes equivalentes.
\end{notacion}

\begin{definicion}[Distribución de probabilidad]
    Dada una variable aleatoria $X$ definida sobre un espacio de probabilidad $(\Omega, \A, P)$, su distribución de probabilidad será el conjunto:
    \begin{equation*}
        \{(x_i, F_X(x_i)) \mid x_i\in X(\Omega)\}.
    \end{equation*}
\end{definicion}

\subsection{Propiedades}
\begin{itemize}
\item $F_X$ es creciente.

Usamos la Proposición \ref{prop:prob_monotona}, y vemos que si $x < y$, entonces $]-\infty, x] \subset ]-\infty, y]$, y por tanto $P_X(]-\infty, x]) \leq P_X(]-\infty, y])$.

\item $F_X$ es continua por la derecha. Es decir, para todo $x \in \R$, se cumple que:
\begin{equation*}
    \lim_{t \to x^{+}} F_X(t) =
    \lim_{t \to x^{+}} P_X(]-\infty, t]) =
    F_X(x)
\end{equation*}
% // TODO: Continuidad por la derecha
% https://www.ugr.es/~cdpye/CursoProbabilidad/pdf/P_T03_FuncionDistribucion.pdf

\item $\exists m,M \in \R$ tal que $\forall x,y \in \R \mid x \leq m \ \land \ y \geq M$ entonces $F_X(x)=0$
        y $F_X(y)=1$.\par
      También notado como $F_X(-\infty)=0$ y $F_X(+\infty)=1$. Notemos que esto implica:
      \begin{equation*}
            \lim_{x \to -\infty} F_X(x) = 0 \qquad \lim_{x \to +\infty} F_X(x) = 1
      \end{equation*}

% // TODO: Existencia de m y M en R
% https://www.ugr.es/~cdpye/CursoProbabilidad/pdf/P_T03_FuncionDistribucion.pdf
\item El conjunto de puntos de discontinuidad de una función de distribución es numerable.

% // TODO: El conjunto de puntos de discontinuidad de una función de distribución es numerable
% https://www.ugr.es/~cdpye/CursoProbabilidad/pdf/P_T03_DiscontinuidadesFD.pdf
\item $\forall y \in \R \Rightarrow \lim\limits_{x \to y^{-}} F_X(x) = P_X(]-\infty, y[)$

      También notado como $F_X(x^{-})=P(X<x)$.
\item La función de distribución sólo puede presentar discontinuidades de salto. Además, la longitud del salto
      en un punto es la probabilidad que toma dicho punto:
      $$P_X(x) = P_X(]-\infty, x]) - P_X(]-\infty, x[) = F_X(x) - \lim\limits_{y \to x^{-}}F_X(x)$$
      También notado como $P_X(x) = F_X(x) - F_X(x^{-})$.
\item La función de distribución es continua en $x \in \R \Longleftrightarrow P_X(x) = 0$.
\end{itemize}

\section{Clasificaciones de variables aleatorias}

Dependiendo de la forma de la distribución, podemos distinguir distintos tipos de variables aleatorias.
\begin{definicion}[Recorrido de una variable aleatoria]
    Dada una variable aleatoria $X$ definida sobre un espacio de probabilidad $(\Omega, \A, P)$, definimos su recorrido, $Re_X$ como:
    $$Re_X = \{x \in \R \mid \ \exists \omega \in \Omega \mid X(\omega) = x\} = X(\Omega)$$
\end{definicion}

\subsection{Variables aleatorias discretas, función masa de probabilidad}

\begin{definicion}[Variable aleatoria discreta]
    Una variable aleatoria $X$ se dice que es discreta si $\exists E \subset \R$ numerable tal que:
    \begin{equation*}
        P[X \in E] = 1
    \end{equation*}
\end{definicion}

Como consecuencia directa, tenemos que:
\begin{equation*}
    P[X=x] = 0\qquad \forall x \notin E
\end{equation*}
Por tanto, tenemos que $E$ es el conjunto de puntos cuya preimagen por $X$ es un suceso posible en $\Omega$.

\begin{definicion}[Función masa de probabilidad]
    Sea $X: (\Omega, \A, P) \rightarrow (\R, \B, P_X)$ una variable aleatoria discreta con valores en $Re_X$, definimos la función masa de probabilidad como:
    \Func{P}{Re_X}{[0,1]}{x_i}{P[X=x_i]}
\end{definicion}
Esta verifica:
\begin{itemize}
    \item $0 \leq P[X=x_i] \leq 1 \qquad \forall x_i \in Re_X$.
    
    Es directo por ser $P_X$ una función de probabilidad.
    \item $\sum\limits_{x\in Re_X} P[X=x] = 1$.
    
    Por ser $P_X$ una función de probabilidad, tenemos que:
    \begin{equation*}
        \sum_{x\in Re_X} P[X=x] \AstIg P\left[X\in \bigcup_{x\in Re_X} \{x\}\right] = P[X\in Re_X] = 1
    \end{equation*}
    donde en $(\ast)$ hemos usado la $\sigma$-aditividad de $P_X$.
\end{itemize}
\begin{notacion}
    A continuación, para cada $x_i \in Re_X$, podremos notar $p_i = P[X=x_i]$.
\end{notacion}

La función de distribución de la variable $X$ a partir de la función masa de probabilidad queda como:
$$F_X(x_i) = P_X(]-\infty, x_i]) = \sum_{j=1}^i p_j \qquad \forall x_i \in Re_X$$


También es posible expresar la función masa de probabilidad a partir de la función de distribución de la variable $X$:
$$P[X=x_i] = F_X(x_i) - F_X(x_{i-1}) \qquad \forall x_i,x_{i-1}\in Re_X$$
Notemos que la función de distribución de variables discretas es escalonada y creciente.

\begin{ejemplo}
    Dado el experimento de lanzar una moneda, damos su espacio muestral y $\sigma$-álgebra asociados:
    $$\Omega = \{c, +\} \qquad \A=\{\emptyset, \{c\}, \{+\}, \Omega\}$$
    
    Con los que podemos definir la siguiente variable aleatoria, que nos da el número de caras,
    $X:(\Omega, \A, P) \rightarrow (\R, \B, P_X)$ por:
    $$X(\omega) = \left\{ \begin{array}{cc}
        0 & c \notin \omega \\
        1 & c \in \omega
    \end{array} \right.$$
    
    Esta definición de variable aleatoria, de recorrido $Re_X = \{0,1\}$ nos induce una función masa de probabilidad $P_X$:
    $$p_0 = P_X(0) = \frac{1}{2} \qquad p_1 = P_X(1) = \frac{1}{2}$$
\end{ejemplo}

\subsection{Variables aleatorias continuas, función de densidad}

\begin{definicion}
    Una variable aleatoria se dice que es continua si su función de distribución $F_X$ es absolutamente continua\footnote{Concepto que se estudiará en Análisis Matemático II}, es decir, si existe una función $f:\R \rightarrow \R$ integrable tal que:
    $$F_X(x) = \int_{-\infty}^x f(t) dt$$
\end{definicion}

Llamaremos a dicha función $f$ \textbf{función de densidad}, y verifica:
\begin{itemize}
  \item $f(x) \geq 0 \qquad \forall x \in \R$.
  \item $f$ es integrable.
  \item $\displaystyle \int_{-\infty}^{+\infty}f(x) dx = 1$
  \begin{equation*}
      \int_{-\infty}^{+\infty}f(x) dx = \lim_{x\to +\infty} \int_{-\infty}^x f(t) dt = \lim_{x\to +\infty} F_X(x) = 1
  \end{equation*}
  donde hemos usado que $F_X(+\infty) = 1$.
\end{itemize}

Como consecuencia del Teorema Fundamental del Cálculo, podemos obtener la función de densidad a partir de la función de distribución en los puntos en los que $f$ es continua:
$$f(x) = F_X'(x) \qquad \forall x \in C(f)$$
donde $C(f)\subset \bb{R}$ es el conjunto de puntos en los que $f$ es continua.

Esta nueva función nos permitirá también calcular probabilidades asociadas a un intervalo:
$$P_X([a,b]) = \int_a^b f(x)~dx$$

Notemos, por tanto, que $P_X([a,b]) = P_X(]a,b[) = P_X([a,b[) = P_X(]a,b])$, puesto que no interfieren en los límites de integración.\\

Además, en el caso continuo, la probabilidad inducida en un punto será siempre~$0$:
$$P_X(x) = \int_x^x f(t)~dt = 0 \qquad \forall x \in \R$$

En el caso de las variables continuas, el recorrido de la variable aleatoria será un intervalo $Re_X = [a,b] \subseteq \R$.

\begin{ejemplo}
    Comprobar si la función $f:\R \rightarrow \R$ definida a continuación puede ser una función de densidad. En caso afirmativo, construir la función de distribución asociada a una variable aleatoria $X:(\Omega, \A, P) \rightarrow (\R, \B, P_X)$.

    $$f(x) = \left\{ \begin{array}{ll}
        0  & x < 0           \\
        2x & 0 \leq x \leq 1 \\
        0  & x > 1
    \end{array} \right.$$
      
    Comprobamos que pueda tratarse de una función de densidad:
    \begin{enumerate}
        \item $f(x) \geq 0 \qquad \forall x \in \R$

        \item Es Riemman Integrable, por ser la imagen acotada.

        \item $\displaystyle \int_{-\infty}^{+\infty} f(x) dx = \int_{-\infty}^0 0~dx+ \int_0^1 2x~dx + \int_1^{+\infty}0~dx = \int_0^1 2x~dx = x^2]_0^1=1$
    \end{enumerate}

    Por tanto, $f$ es una función de densidad, y podemos definir a partir de ella una función de distribución $F:\R \rightarrow \R$:
    \begin{itemize}
        \item \underline{Si $x<0$}:
        $$F_X(x) = \int_{-\infty}^x f(t)~dt = \int_{-\infty}^x 0~dt = 0$$

        \item \underline{Si $0 \leq x \leq 1$}:
        $$F_X(x) = \int_{-\infty}^x f(t)~dt = \int_{-\infty}^0 0~dt + \int_{0}^x 2t~dt = t^2]_0^x = x^2$$
        
        
        \item \underline{Si $x>1$}:
        $$F_X(x) = \int_{-\infty}^x f(t)~dt = \int_{-\infty}^0 0~dt + \int_{0}^1 2t~dt + \int_1^{+\infty} 0~dt = t^2]_0^1 = 1$$
    \end{itemize}

    Por tanto, la función de distribución es:
    $$F_X(x) = \left\{ \begin{array}{lc}
        0   & x < 0           \\
        x^2 & 0 \leq x \leq 1 \\
        1   & x > 1
    \end{array} \right.$$
\end{ejemplo}

\subsection{Variables aleatorias mixtas}

\begin{definicion}
    Una variable aleatoria se dice que es mixta si $Re_X = E \cup [a,b]$ con $E$ numerable y $[a,b]\subseteq \R$.
    Si se da que $E \subset [a,b] \Rightarrow X$ será una variable continua de recorrido $[a,b]$.
\end{definicion}

Dicha variable aleatoria tendrá asociadas una función masa de probabilidad y una función de densidad:
\begin{itemize}
    \item Tendremos $P:E\rightarrow [0,1]$ dada por $p_i = P_X(x_i) = P_X(x_i) \qquad \forall x_i \in E$ tal que:
    \begin{itemize}
      \item $0 \leq p_i \leq 1 \qquad \forall x_i \in E$.
      \item $\sum\limits_{i=1}^N p_i = P \qquad $ con $P\in [0,1]$ y $N=|E|$.
    \end{itemize}
    
    \item Y además existirá una función $f:\R \rightarrow \R$ Riemman integrable tal que:
    \begin{itemize}
      \item $f(x) \geq 0 \qquad \forall x \in \R$.
      \item $\displaystyle \int_{-\infty}^{+\infty} f(x)~dx = 1-P$
    \end{itemize}
\end{itemize}

\bigskip

De esta forma, podemos calcular la probabilidad de cualquier intervalo $[c,d]$ definiendo el intervalo $[y,z] = [a,b] \cap [c,d]$ y mediante la siguiente expresión:

$$P_X([c,d]) = \sum_{\substack{x_i \in E \\ x_i \in [c,d]}} p_i + \int_y^z f(x)~dx $$

También se puede calcular el valor de la función de distribución en un punto x:
$$F_X(x) = \sum_{\substack{x_i \in E \\ x_i \leq x}} p_i + \int_{-\infty}^x f(t)~dt$$

\section{Cambio de variable}

En varias ocasiones, nos será de gran interés dar la distribución de probabilidad de una variable aleatoria $Y$, que depende de otra variable aleatoria $X$, en función de esta última. Si la función es $h$, lo notaremos como $Y=h(X)$, que siendo formales representa:
\begin{equation*}
    Y=h\circ X
\end{equation*}

Notemos que si conocemos la probabilidad inducida $P_X$ de una variable aleatoria $X$, entonces conocemos la función de distribución $F_X$ de dicha variable aleatoria y, por tanto, conocemos la distribución de probabilidad asociada a dicha variable.

\begin{teo}[Teorema general de cambio de variable]
  Sea una variable aleatoria $X: (\Omega, \A, P) \rightarrow (\R, \B, P_X)$.
  Sea $Y=h(X)$ otra variable aleatoria, con $h:(\R, \B) \rightarrow (\R, \B)$ medible, entonces la probabilidad inducida de $Y$ puede obtenerse a partir de $P_X$ como:
  $$P_Y(B) = P_X(h^{-1}(B)) \qquad \forall B \in \B$$
\end{teo}
\begin{proof} Su demostración es directa, ya que:
  $$P_Y(B) = P(Y^{-1}(B)) = P(X^{-1}(h^{-1}(B))) = P_X(h^{-1}(B)) \qquad \forall B \in \B$$
\end{proof}

Por este teorema, podemos obtener la función de distribución de $Y$ mediante:
$$F_Y(y) = P_X(h^{-1}(]-\infty, y])) \qquad \forall y\in \R$$

Veamos dos corolarios, que nos serán de gran utilidad en la práctica:
\begin{coro}
    Sea $X$ una variable aleatoria con función de distribución $F_X$. Entonces:
    \begin{equation*}
        P[X\leq x] = P[X+k\leq x+k]\qquad \forall x,k \in \bb{R}
    \end{equation*}
\end{coro}
\begin{proof}
    Sea la transformación dada por:
    \Func{h}{\R}{\R}{x}{x+k}
    
    Definimos además:
    \Func{h^{-1}}{\R}{\R}{x}{x-k}

    Veamos que, efectivamente, $h^{-1}$ es la inversa de $h$:
    $$h^{-1}(h(x)) = h^{-1}(x+k) = x+k-k = x\qquad \forall x \in \R$$

    Por tanto, $h$ es biyectiva y $h^{-1}$ es su inversa. Por el Teorema de Cambio de Variable, tenemos que:
    $$P[X+k\leq x+k] = P_Y(\left]-\infty, x+k\right]) = P_X(h^{-1}(\left]-\infty, x+k\right])) = P_X(\left]-\infty, x\right]) = P[X\leq x]$$
\end{proof}

\begin{coro}
    Sea $X$ una variable aleatoria con función de distribución $F_X$. Entonces:
    \begin{equation*}
        P[X\leq x] = P\left[\frac{X}{k} \leq \frac{x}{k}\right]\qquad \forall x\in \bb{R}, k\in \bb{R}^+
    \end{equation*}
\end{coro}
\begin{proof}
    Sea la transformación dada por:
    \Func{h}{\R}{\R}{x}{\nicefrac{x}{k}}
    
    Definimos además:
    \Func{h^{-1}}{\R}{\R}{x}{kx}

    Veamos que, efectivamente, $h^{-1}$ es la inversa de $h$:
    $$h^{-1}(h(x)) = h^{-1}\left(\frac{x}{k}\right) = k\cdot \frac{x}{k} = x\qquad \forall x \in \R$$

    Por tanto, $h$ es biyectiva y $h^{-1}$ es su inversa. Por el Teorema de Cambio de Variable, tenemos que:
    $$P\left[\frac{X}{k} \leq \frac{x}{k}\right] = P_Y\left(\left]-\infty, \frac{x}{k}\right]\right) = P_X\left(h^{-1}\left(\left]-\infty, \frac{x}{k}\right]\right)\right) = P_X(\left]-\infty, x\right]) = P[X\leq x]$$
\end{proof}

El cambio de variable en el caso de una variable discreta dará lugar a una variable discreta, mientras que
si efectuamos un cambio de variable a una variable continua, podremos obtener una variable discreta, una
variable continua o una variable mixta. Abordaremos dichos casos en las siguientes secciones.
\subsection{Cambio en variable aleatoria discreta}\label{subsec:CV_Discreta}

\begin{coro}
    Sea $X$ una variable aleatoria sobre el espacio probabilístico $(\Omega,\/,P)$ discreta con valores en el conjunto $Re_X=\{x_1, x_2, \ldots\} \subset \R$ y $h:\R \rightarrow \R$ medible tal que $Y=h(X)$. Entonces $Y$ es discreta, con valores en $Re_Y=h(Re_X)$ y la función masa de probabilidad de $Y$ será:
    \begin{equation*}
        P[Y=y] = \sum_{x\in h^{-1}(y)\cap Re_X} P[X=x] \qquad \forall y \in Re_Y
    \end{equation*}
\end{coro}
\begin{proof}
    Como es directo apreciar, $x\in Re_X\Longrightarrow h(x)\in h(Re_X)$. Entonces:
    \begin{equation*}
        \left\{\omega \in \Omega \mid X(\omega) \in Re_X\right\} \subseteq \left\{\omega \in \Omega \mid h(X(\omega)) \in h(Re_X)\right\}
    \end{equation*}

    Por la monotonía de $P$, tenemos que:
    \begin{equation*}
        1=P[X\in Re_X] \leq P[h(X)\in h(Re_X)] \leq 1
    \end{equation*}

    Por tanto, $P[h(X)\in h(Re_X)]=1$. Como $Re_X$ es numerable, entonces $h(Re_X)$ es numerable, por lo que $Y$ es discreta. Además, toma valores en $Re_Y=h(Re_X)$.
    
    Por el Teorema de Cambio de Variable, tenemos que:
    \begin{equation*}
        P[Y=y]=P[X\in h^{-1}(y)] = P_X(h^{-1}(y)) = \sum_{x\in h^{-1}(y)\cap Re_X} P[X=x],\qquad \forall y \in Re_Y
    \end{equation*}
\end{proof}

\begin{ejemplo}
    Dada la variable aleatoria $X$ con $Re_X = \{-1, 0, 1\}$ y su función masa de probabilidad dada por:
    $$P(x) = \left\{ \begin{array}{cl}
        \nicefrac{1}{3} & x = -1 \\
        \nicefrac{1}{3} & x = 0  \\
        \nicefrac{1}{3} & x = 1
    \end{array} \right.$$
    
    
    Definimos la variable aleatoria $Y$ por $Y=h(X)=X^2$. Se pide dar la función masa de probabilidad de $Y$, $\hat{P}$.\\
    
    El recorrido de $Y$ será: $Re_Y = \{h(-1), h(0), h(1)\} = \{0, 1\}$.
    $$\hat{P}(y) = \left\{ \begin{array}{ll}
        P(0) = \nicefrac{1}{3}         & y = 0 \\
        P(-1) + P(1) = \nicefrac{2}{3} & y = 1
      \end{array} \right.$$
\end{ejemplo}

\subsection{Cambio de variable aleatoria continua a discreta}
Si la variable aleatoria de partida es continua, pueden suceder varios casos que relatamos a continuación.
\begin{coro}
    Sea $X$ una variable aleatoria continua con función de densidad $f_X$, y consideramos una función medible $h$ tal que $Y=h(X)$ es una variable aleatoria discreta con valores en $Re_Y=h(X)$. La función masa de probabilidad de $Y$ será:
    $$P[Y=y] = \int_{h^{-1}(y)} f_X(x)~dx \qquad \forall y \in Re_Y$$
\end{coro}
\begin{proof}
    Esto sale de forma directa por el Teorema de Cambio de Variable, ya que:
    $$P[Y=y] = P[X\in (h^{-1}(y))] = \int_{h^{-1}(y)} f_X(x)~dx$$
\end{proof}

El corolario anterior nos indica que, por ejemplo, en el caso en el que:
$$h([a,b] \cup [c,d]) = y \Rightarrow P(y) = \int_a^b f(x)~dx + \int_c^d f(x)~dx$$

\begin{ejemplo}
    Dada la variable aleatoria $X$ con $Re_X=\R$ y su función de densidad $f:\R \rightarrow \R$ dada por:
    $$f(x) = \left\{ \begin{array}{ll}
        0   & x \leq -1  \\
        \nicefrac{1}{2} & -1 < x < 1 \\
        0   & x \geq 1
    \end{array} \right.$$
    
    
    Definimos la variable aleatoria $Y$ por $Y=h(X)$. Se pide dar la función masa de probabilidad de $Y$, sabiendo que:
    $$h(x) = \left\{ \begin{array}{ll}
        0 & x < 0    \\
        1 & x \geq 0
    \end{array} \right.$$
    
    En primer lugar, damos el recorrido de $Y$: $Re_Y = \{h(\R)\} = \{0,1\}$.
    $$P(y) = \left\{ \begin{array}{ll}
        \displaystyle \int_{-\infty}^0 f(x)~dx = \int_{-\infty}^{-1} 0~dx + \int_{-1}^0 \nicefrac{1}{2}~dx = \left.\frac{x}{2}\right]_{-1}^0 = \nicefrac{1}{2} & y=0   \\ \\
        \displaystyle \int_0^{+\infty} f(x)~dx = \int_0^1 \nicefrac{1}{2}~dx + \int_1^{+\infty} 0~dx = \left.\frac{x}{2}\right]_0^1 = \nicefrac{1}{2}          & y = 1
      \end{array} \right.$$
\end{ejemplo}

\subsection{Cambio de variable aleatoria continua a continua}
\label{subsec:CV_Continua}

\begin{coro}
    Sea $X$ una variable aleatoria continua con función de densidad $f_X$ y recorrido $Re_X=\left]a,b\right[\subseteq \R$, donde $a,b\in \bb{R}\cup \{\pm \infty\}$.
    Si $h:]a,b[\to \bb{R}$ es derivable y estrictamente monótona, $Y=g(X)$ es una variable aleatoria continua con función de densidad:
    \begin{equation*}
        f_Y(y)=\begin{cases}
            f_X(h^{-1}(y))\cdot |(h^{-1})'(y)| & y \in h(]a,b[)\\
            0 & y \notin h(]a,b[)
        \end{cases}
    \end{equation*}
\end{coro}
% // TODO: Demostración CV continua a continua
% https://www.ugr.es/~cdpye/CursoProbabilidad/pdf/P_T03_CVContinuo.pdf
\subsubsection{Generalización.}
Una generalización del teorema puede hacerse en el caso de que $h$ no tenga una única inversa y cada valor de la variable $Y=h(X)$ proceda de un número finito o infinito de valores de $X$. En dicho caso, la función de densidad de $Y$ será:
$$g(y) = \sum_{k=1}^{\infty} f(h^{-1}_k(y)) \cdot |(h^{-1}_k)'(y)|$$

Siendo $h_1^{-1}(y),h_2^{-1}(y), \ldots$ las antiimágenes de $y~~\forall y \in h([a,b])$.

\begin{ejemplo}
    Dada la variable aleatoria $X$ con $Re_X=]-1, 1[$ y su función de densidad $f:\R \rightarrow \R$ dada por:
    $$f(x) = \left\{ \begin{array}{ll}
        0           & x \leq -1  \\
        \nicefrac{1}{2} & -1 < x < 1 \\
        0           & x \geq 1
    \end{array} \right. $$
    
    Definimos la variable aleatoria $Y$ por $Y=h(X) =x^2$. Se pide dar la función de densidad de $Y$.
    
    En primer lugar, calculamos el recorrido de $Y$: $Re_Y=\{h(]-1,1[)\} = [0,1[$. Además, al no ser $h$ inyectiva en el dominio de definición, tiene dos inversas: la raíz positiva y la negativa.
    \begin{gather*}
        h^{-1}(y) = \pm \sqrt{y}\\
        (h^{-1})'(y) = \pm \dfrac{1}{2\sqrt{y}}
    \end{gather*}
    
    Damos la función de densidad de $Y$:
    $$g(y) = \sum_{k=1}^{\infty} f(h^{-1}_k(y)) \cdot |(h^{-1}_k)'(y)|
    =  \dfrac{1}{2} \dfrac{1}{2\sqrt{y}} + \left|-\dfrac{1}{2} \dfrac{1}{2\sqrt{y}}\right|
    =  \dfrac{1}{2\sqrt{y}} \qquad \forall y \in ]0,1[$$
\end{ejemplo}

\subsection{Cambio de una variable aleatoria continua a mixta}

Sea $X$ una variable aleatoria continua con función de densidad $f$ y recorrido $Re_X=[a,b]\subseteq \R$. Si $h$ es una función medible y definimos $Y=h(X)$ como una nueva variable aleatoria tal que $Y$ presenta una distribución mixta, entonces hemos de dividir ambos casos, como muestra el siguiente ejemplo.
\begin{ejemplo}
    Dada una variable aleatoria $X$ con $Re_X = ]-1, 1[$ y su función de densidad $f:\R \rightarrow \R$ dada por:
    $$f(x) = \left\{ \begin{array}{ll}
        0           & x \leq -1  \\
        \nicefrac{1}{2} & -1 < x < 1 \\
        0           & x \geq 1
    \end{array} \right. $$

    Definimos la variable aleatoria $Y$ por $Y=h(X)$. Se pide dar la función de distribución de $Y$.
    $$h(x) = \left\{ \begin{array}{ll}
        x & x < 0    \\
        1 & x \geq 0
    \end{array} \right.$$

        
    Calculamos el recorrido de $Y$: $Re_Y = ]-1, 0[ \cup \{1\}$. Por tanto, aplicando el teorema del cambio de variable:
    $$F_Y(y) = \left\{ \begin{array}{cl}
        0 & y \leq -1    \\ \\
        \displaystyle\int_{-1}^y \dfrac{1}{2}~dt = \left. \dfrac{t}{2} \right]_{-1}^y = \dfrac{y+1}{2} & -1 < y < 0   \\ \\
        \dfrac{1}{2} & 0 \leq y < 1 \\ \\
        1 & y \geq 1
  \end{array} \right.$$
\end{ejemplo}

\section{Esperanza matemática}

Este valor, la esperanza, se define de forma distinta en función de si la variable aleatoria es discreta o continua.
\begin{definicion}
    Sea $X$ una variable aleatoria discreta con valores en el conjunto $Re_X = \{x_1, x_2, \ldots\} \subset \R$ y sea $P$ la función masa de probabilidad de $X$. Entonces, se define la esperanza matemática, media o valor esperado de $X$, denotado $E[X]$ como:
    $$E[X] = \sum\limits_{x_i \in Re_X} x_i P_X(x_i)$$

    Esta existe siempre y cuando la serie previamente mencionada converja absolutamente; es decir:
    $$\sum\limits_{x_i \in Re_X} |x_i| P_X(x_i) < \infty$$
\end{definicion}

\begin{ejemplo}
    Dada la variable aleatoria $X$ con $Re_X = \{-1, 0, 1\}$ y su función masa de probabilidad dada por:
    $$P(x) = \left\{ \begin{array}{cl}
        \nicefrac{1}{3} & x = -1 \\
        \nicefrac{1}{3} & x = 0  \\
        \nicefrac{1}{3} & x = 1
      \end{array} \right.$$
    Se pide calcular la esperanza matemática de $X$.
    
    $$E[X] = -1 \cdot \dfrac{1}{3} + 0 \cdot \dfrac{1}{3} -1 \cdot \dfrac{1}{3} = 0$$
\end{ejemplo}

\begin{definicion}
    Sea $X$ una variable aleatoria continua y $f_X$ su función de densidad, se define la esperanza matemática de $X$ como:
    $$E[X] = \int_{-\infty}^{+\infty} xf_X(x)~dx$$

    La esperanza de $X$ existe siempre y cuando la integral sea absolutamente convergente\footnote{En Análisis Matemático II se dirá que $xf_X(x)$ sea integrable en el sentido de Lesbegue.}, es decir:
    $$\int_{-\infty}^{+\infty} |x|f_X(x)~dx < \infty$$
\end{definicion}

\begin{ejemplo}
    Sea $X$ una variable aleatoria continua y función de densidad $f:\R \rightarrow \R$ dada por:
    $$f(x) = \left\{ \begin{array}{ll}
        0   & x < 0                     \\
        x^2 & 0 \leq x \leq \sqrt[3]{3} \\
        0   & x > \sqrt[3]{3}
    \end{array} \right.$$
    
    
    Se pide calcular la esperanza matemática de $X$.
    $$E[X] = \int_{-\infty}^{+\infty} xf(x)~dx = \int_0^{\sqrt[3]{3}} xf(x)~dx = \int_0^{\sqrt[3]{3}} x^3~dx \approx 1.0817$$
\end{ejemplo}

\begin{observacion}
A lo largo de este documento, cada vez que hagamos referencia a la esperanza de una variable aleatoria $X$ (ya sea esta discreta o continua), habremos supuesto previamente que existe.
\end{observacion}
\subsection{Propiedades}

\begin{prop}\label{prop:Esp_De_Constante}
    La esperanza de una variable aleatoria constante es la constante.\\
    Es decir, dado $c\in \R$, si $X$ es una variable aleatoria sobre el espacio de probabilidad $(\Omega, \A, P)$ tal que
    $X=c$, entonces:
    \begin{equation*}
        E[X]=c
    \end{equation*}
\end{prop}
\begin{proof}
    En este caso no tiene sentido considerar el caso continuo, ya que $Re_X=\{c\}$. Tenemos entonces que:
    \begin{equation*}
        E[X] = \sum_{x_i\in Re_X}x_iP_X(x_i) = \sum_{x_i\in Re_X}cP_X(x_i) = c\sum_{x_i\in Re_X}P_X(x_i) = c\cdot 1=c
    \end{equation*}
\end{proof}

\begin{prop}
    Sea $X$ es una variable aleatoria está acotada; es decir, $\exists M\in \mathbb{R}\mid |X|\leq M$. Entonces:
    \begin{equation*}
        |E[X]|\leq M
    \end{equation*}
\end{prop}
\begin{proof}
    Hemos de distinguir entre el caso discreto y el caso continuo:
    \begin{itemize}
        \item \underline{Caso discreto}: Supongamos $Re_X = E$.
        \begin{equation*}
            \left|E[X]\right| = \left|\sum_{x_i\in E} x_iP_X(x_i)\right| \leq \sum_{x_i\in E} \left|x_i\right|P_X(x_i) \leq \sum_{x_i\in E} M\cdot P_X(x_i) = M\sum_{x_i\in E} P_X(x_i) = M
        \end{equation*}
        donde en la primera desigualdad se ha empleado la desigualdad triangular y en la segunda que $|X|\leq M$, por lo que $|x_i|\leq M$ para todo $x_i\in E$.

        \item \underline{Caso continuo}: Sea $f_X$ la función de densidad de $X$:
        \begin{equation*}
            \left|E[X]\right| =  \left|\int_{-\infty}^\infty xf_X(x)\;dx\right|
            \leq \int_{-\infty}^\infty \left|x\right|f_X(x)\;dx
            \leq 
            \int_{-\infty}^\infty Mf_X(x)\;dx = M\int_{-\infty}^\infty f(x)\;dx = M
        \end{equation*}
        donde en la primera desigualdad se ha empleado la positividad de la integral y en la segunda que $|X|\leq M$, por lo que $|x|\leq M$ para todo $x\in \R$.
    \end{itemize}
\end{proof}

\begin{prop}\label{prop:6.4}
    Sea $X$ una variable aleatoria. Si $X\geq 0$ y existe esperanza, entonces $E[X]\geq 0$.
\end{prop}
\begin{proof}
    Hemos de distinguir entre el caso discreto y el caso continuo:
    \begin{itemize}
        \item \underline{Caso discreto}: Supongamos $Re_X = E$.
        \begin{equation*}
            E[X] = \sum_{x_i\in E} x_iP_X(x_i) \geq 0
        \end{equation*}
        donde se ha empleado que $x_i\geq 0$ (hipótesis) y $P_X(x_i)\geq0$ por definición.

        \item \underline{Caso continuo}: Sea $f$ la función de densidad de $X$:
        \begin{equation*}
            E[X] = \int_{-\infty}^{\infty} xf(x)\;dx \geq 0
        \end{equation*}
        donde se ha empleado que $x\geq 0$ (hipótesis) y $f(x)\geq0$ por definición.
    \end{itemize}
\end{proof}

\begin{coro}
    Sea $X$ una variable aleatoria tal que $X\geq 0$. Si $\exists E[X]$, tenemos:
    \begin{equation*}
        E[X]=0\Longleftrightarrow X=0
    \end{equation*}
\end{coro}
\begin{proof}
    Demostramos ambas implicaciones:
    \begin{description}
        \item[$\Longrightarrow)$] Supongamos que $E[X]=0$. Por un razonamiento idéntico al de la proposición anterior, tenemos que $X=0$.
        
        \item[$\Longleftarrow)$] Supongamos que $X=0$. Entonces, por la proposición \ref{prop:Esp_De_Constante}, tenemos que $E[X]=0$.
    \end{description}
\end{proof}

\begin{definicion}[Simetría]
    Sea $X$ una variable aleatoria. Se dice que $X$ es simétrica respecto del valor $c$ si $X-c$ y $c-X$ tienen la misma distribución.
    Es decir, en función del tipo:
    \begin{itemize}
        \item \underline{Discreto}: $P[X=c+x]=P[X=c-x]$ para todo $x\in \mathbb{R}$.
        \item \underline{Continuo}: $P[X\leq c-x]=P[X\geq c+x]$ para todo $x\in \mathbb{R}$.
    \end{itemize}
\end{definicion}

\begin{prop}
    Sea $X$ una variable aleatoria con distribución simétrica respecto del valor $c$. Entonces, si $\exists E[X]\Longrightarrow E[X]=c$.
\end{prop}
% // TODO: Simétrico respecto de c -> E[X] = c

\begin{prop}
    Sea $X$ una variable aleatoria. Consideramos $c \in \R$. Entonces, se tiene que $E[cX] = cE[X]$.
\end{prop}
\begin{proof}
    Distinguimos entre el caso disreto y el continuo:
    \begin{itemize}
        \item \underline{Caso discreto}: $Re_X = E$.
        $$E[cX] = \sum_{x_i \in E} c x_i P_Y(c x_i) = c \sum_{x_i \in E} x_i P_Y(c  x_i) = c
        \sum_{x_i \in E} x_i P_X(x_i) = cE[X]$$
        
        Donde $P_Y$ denota la función masa de probabilidad de la variable aleatoria discreta $Y=cX$. Consúltese el capítulo de cambio de variable discreta (capítulo \ref{subsec:CV_Discreta}) para ver que $P_Y(cx_i) = P_X(x_i)$ siendo $P$ la función masa de probabilidad de la variable aleatoria $X$.

        \item \underline{Caso continuo}: Sea $f$ la función de densidad de $X$.
        $$E[cX] = \int_{-\infty}^{+\infty} cx f_Y(cx)~dx = c \int_{-\infty}^{+\infty} x f_Y(cx)~dx = c \int_{-\infty}^{+\infty} x f(x)~dx = cE[X]$$
        Donde $f_Y$ denota la función de densidad de la variable aleatoria continua $Y=cX$. Consúltese el capítulo de cambio de variable continua (capítulo \ref{subsec:CV_Continua}) para ver que $f_Y(cx) = f(x)$ siendo $f$ la función de densidad de la variable aleatoria $X$.
    \end{itemize}
\end{proof}

Introducimos ahora el siguiente resultado, que no podremos demostrar aún\footnote{Se demostrará de forma muy sencilla en la asignatura de Probabilidad}. No obstante, se incluye por ser de gran utilidad.
\begin{prop}
    Sean $X$ e $Y$ variables aleatorias definidas en el mismo espacio de probabilidad $\Omega$. Si $\exists E[X], E[Y]$, entonces:
    $$E[X+Y]=E[X]+E[Y]$$
\end{prop}

\begin{coro}[Linealidad]
    Sea $X_i$ una variable aleatoria $\quad \forall i=1,\dots, n$. Si $\exists E[X_i]$, entonces:
    \begin{equation*}
        \exists E\left[\sum_{i=1}^n a_iX_i\right] = \sum_{i=1}^n a_iE[X_i]
    \end{equation*}
\end{coro}
\begin{proof}
    Se deduce directamente de las dos proposiciones anteriores.
    \begin{equation*}
        E\left[\sum_{i=1}^n a_iX_i\right] = \sum_{i=1}^n E[a_iX_i] = \sum_{i=1}^n a_iE[X_i]
    \end{equation*}
\end{proof}
\begin{coro}
    Sea $X$ una variable aleatoria y $g, h$ funciones reales tales que $\exists E[g(x)], E[h(x)]$, entonces:
    $$\exists E[\alpha g(X) + \beta h(X)] = \alpha E[g(X)] + \beta E[h(X)] \qquad \forall \alpha, \beta \in \R$$
\end{coro}

\begin{coro}
    Sean $X_1,X_2$ dos variables aleatorias definidas en el mismo espacio de probabilidad $\Omega$ tales que $X_1\leq X_2$.
    Entonces:
    \begin{equation*}
        E[X_1]\leq E[X_2]
    \end{equation*}
\end{coro}
\begin{proof}
    Como $X_2\geq X_1$, entonces $E[X_2-X_1]\geq 0$. Por la linealidad, tenemos que:
    \begin{equation*}
        E[X_2-X_1] = E[X_2]-E[X_1]\geq 0
    \end{equation*}
    Por tanto, $E[X_2]\geq E[X_1]$.
\end{proof}

\begin{coro}
    Dada $X$ una variable aleatoria y se consideran dos funciones de $X$, $g(X), h(X)$, variables aleatorias. Si $g(X)\leq h(X)$, entonces:
    \begin{equation*}
        E[g(X)]\leq E[h(X)]
    \end{equation*}
\end{coro}
\begin{comment}
\begin{proof}
    Realizamos distinción entre caso discreto y continuo:
    \begin{itemize}
        \item \underline{Caso discreto}. Suponemos $Re_X = E$.

        Sabemos que $f(x_i)\geq 0 \;\forall x_i\in E$. Entonces, no cambia el sentido de la desigualdad, por lo que:
        \begin{equation*}
            g(x_i)f(x_i)\leq h(x_i)f(x_i) \qquad \forall x_i\in E
        \end{equation*}

        Por tanto, tenemos que:
        \begin{equation*}
            \sum_{x_i\in E}g(x_i)f(x_i)\leq \sum_{x_i\in E} h(x_i)f(x_i)
        \end{equation*}
        ya que se cumple para todos los sumandos. Por tanto, usando las definiciones, tenemos que:
        \begin{equation*}
            E[g(X)]\leq E[h(X)]
        \end{equation*}

        \item \underline{Caso continuo}. Suponemos $Re_X = [a,b]$.

        Sabemos que $f(x)\geq 0 \;\forall x\in [a,b]$. Entonces, no cambia el sentido de la desigualdad, por lo que:
        \begin{equation*}
            g(x)f(x)\leq h(x)f(x) \qquad \forall x_i\in [a,b]
        \end{equation*}

        Por tanto, ya que el operador integral mantiene las relaciones de orden, tenemos que:
        \begin{equation*}
            \int_a^b g(x)f(x)\;dx\leq \int_a^b h(x)f(x)\;dx
        \end{equation*}
        
        Por tanto, usando las definiciones, tenemos que:
        \begin{equation*}
            E[g(X)]\leq E[h(X)]
        \end{equation*}
    \end{itemize}
\end{proof}
\end{comment}



\begin{prop}
    La esperanza matemática minimiza el error cuadrático medio:
    $$\min_{a \in R} E[(X-a)^2] = E[(X-E[X])^2]$$
\end{prop}
\begin{proof}
    Sea $a \in \R$, y definimos el error cuadrático medio respecto al valor $a$:
    $$\mu(a) = E[(X-a)^2] = E[X^2-2aX+a^2] = E[X^2] - 2aE[X] + a^2$$

    Para minimizar dicha función, hemos de calcular los puntos que anulan la primera derivada. Además, al tratarse de una parábola con coeficiente líder positivo, dicho punto crítico será un mínimo.
    $$\mu'(a) = 2E[X] - 2a = 0 \Longleftrightarrow a = E[X]$$

    Por tanto, $a=E[X]$ es un mínimo de la expresión $\mu(a)$ y, al ser el único, concluimos que es mínimo absoluto.
    Luego, acabamos de ver que la esperanza matemática minimiza el error cuadrático medio.
\end{proof}

\begin{teo}[de Markov: desigualdad básica]
    Sea $X$ una variable aleatoria. Si $X\geq 0$ y $\exists E[X]$, entonces:
    \begin{equation*}
        P[X\geq \varepsilon]\leq \dfrac{E[X]}{\varepsilon} \qquad \forall \varepsilon\in \bb{R}^+
    \end{equation*}
\end{teo}
\begin{proof}
    Fijado $\veps\in \bb{R}^+$, realizamos la distinción entre el caso discreto y el continuo:
    \begin{itemize}
        \item \underline{Caso discreto}: Supongamos que $Re_X=E$. Entonces:
        \begin{equation*}
            E[X]=\sum_{x_i\in E}x_iP_X(x_i)
            = \sum_{\mathclap{x_i\in E\mid x_i<\varepsilon}}x_iP_X(x_i) + \sum_{\mathclap{x_i\in E\mid x_i\geq \varepsilon}}x_iP_X(x_i)
        \end{equation*}

        Como $X\geq 0$ tenemos que $\displaystyle \sum\limits_{\mathclap{x_i\in E\mid x_i<\varepsilon}}x_iP_X(x_i)\geq 0$. Por tanto,
        \begin{multline*}
            E[X]
            =\sum_{x_i\in E}x_iP_X(x_i)
            = \sum_{\mathclap{x_i\in E\mid x_i<\varepsilon}}x_iP_X(x_i) + \sum_{\mathclap{x_i\in E\mid x_i\geq \varepsilon}}x_iP_X(x_i)
            \geq \sum_{\mathclap{x_i\in E\mid x_i\geq \varepsilon}}x_iP_X(x_i)
            \geq\\
            \geq \sum_{\mathclap{x_i\in E\mid x_i\geq \varepsilon}}\varepsilon P_X(x_i)
            = \varepsilon \sum_{\mathclap{x_i\in E\mid x_i\geq \varepsilon}} P_X(x_i)
            = \varepsilon P[X\geq \varepsilon]
        \end{multline*}

        Por tanto, despejando $P[X\geq \varepsilon]$, tenemos que:
        \begin{equation*}
            P[X\geq \varepsilon] \leq \frac{E[X]}{\varepsilon}
        \end{equation*}

        \item \underline{Caso continuo}: Sea $f$ la función de densidad de $X$.
        \begin{align*}
            E[X]
            &= \int_{-\infty}^\infty xP(x)~dx
            = \int_0^\infty xP(x)~dx
            =\int_0^\varepsilon xP(x)~dx + \int_\varepsilon^\infty xP(x)~dx
            \stackrel{(\ast)}{\geq} \\&\stackrel{(\ast)}{\geq} \int_\varepsilon^\infty xP(x)~dx
            \geq \int_\varepsilon^\infty \veps P(x)~dx            
            = \varepsilon P[X\geq \varepsilon]
        \end{align*}
        donde en $(\ast)$ hemos empleado que $x\geq 0$ y $P(x)\geq 0$.

        Por tanto, despejando $P[X\geq \varepsilon]$, tenemos que:
        \begin{equation*}
            P[X\geq \varepsilon] \leq \frac{E[X]}{\varepsilon}
        \end{equation*}
    \end{itemize}
\end{proof}

\begin{coro}[Desigualdad de Markov]
    Sea $X$ es una variable aleatoria y sea $\alpha\in \bb{R}^+$. Si $\exists E[|X|^\alpha]$, se tiene:
    \begin{equation*}
        P[|X|\geq k]\leq \frac{E[|X|^\alpha]}{k^\alpha},\qquad \forall k>0
    \end{equation*}
\end{coro}
\begin{proof}
    En primer lugar, es importante señalar que:
    \begin{equation*}
        P[|X|\geq k]=P[|X|^\alpha \geq k^\alpha]
    \end{equation*}
    Esto se debe al Teorema de Cambio de Variable y a que la trasformación dada por $h(|X|)=|X|^\alpha$ es inyectiva, ya que la base y el exponente son positivos.

    Además, aplicando la desigualdad básica a la variable $|X|^\alpha$, con $\varepsilon=k^\alpha$, se tiene que:
    \begin{equation*}
        P[|X^\alpha\geq k^\alpha]\leq \frac{E[|X|^\alpha]}{k^\alpha}
    \end{equation*}

    Uniendo ambas ecuaciones, se tiene lo pedido.
\end{proof}

\begin{coro}[Desigualdad de Chebychev]
    Si $X$ es una variable aleatoria tal que $\exists E[X^2]$, se tiene
    \begin{equation*}
        P[|X-E[X]|\geq k]\leq \frac{\Var[X]}{k^2},\qquad \forall k>0
    \end{equation*}
\end{coro}
\begin{proof}
    Se basa en aplicar la desigualdad básica a la variable $(X-E[X])^2$. Para $\varepsilon=k^2$, se tiene que:
    \begin{equation*}
        P[|X-E[X]|\geq k] = P[(X-E[X])^2\geq k^2] \leq \frac{E[(X-E[X])^2]}{k^2} = \frac{\Var[X]}{k^2}
    \end{equation*}
\end{proof}

\textbf{Expresiones alternativas de la desigualdad}:
\begin{enumerate}
    \item De forma directa, se deduce que:
    \begin{equation*}
        P[|X-E[X]| < k]\geq 1-\frac{\Var[X]}{k^2},\qquad \forall k>0
    \end{equation*}
    Esta expresión proporciona una cota inferior para la probabilidad de que una variable tome valores en cualquier intervalo real centrado en la media de la variable.

    \item Empleando ahora $\varepsilon=\Var[X]k^2$, de forma idéntica se deduce que:
    \begin{equation*}
        P[|X-E[X]|\geq \sqrt{\Var[X]}k]\leq \frac{1}{k^2},\qquad \forall k>0
    \end{equation*}

    \item De forma directa, se deduce que:
    \begin{equation*}
        P[|X-E[X]|< \sqrt{\Var[X]}k]\geq 1-\frac{1}{k^2},\qquad \forall k>0
    \end{equation*}
    Esta expresión proporciona una cota inferior para la probabilidad de que una variable tome valores en cualquier intervalo real centrado en la media de la variable con una amplitud de $k\sqrt{\Var[X]}$.
\end{enumerate}

\subsection{Cambio de variable aleatoria discreta}

\begin{teo}
    Si $X$ es una variable aleatoria discreta definida en el espacio de probabilidad $(\Omega, \A, P)$ con valores en el conjunto $Re_X \subset \R$ y $Y=h(X)$ es otra variable aleatoria, entonces:
    \begin{enumerate}
        \item $\displaystyle \exists E[Y]\Longleftrightarrow \sum_{x\in Re_X} |h(x)|P_X(x) < \infty$
        \item Si $\displaystyle \exists E[Y]$, entonces:
        \begin{equation*}
            E[Y] = \sum_{x\in Re_X} h(x)P_X(x)
        \end{equation*}
    \end{enumerate}
\end{teo}
\begin{proof}
    Demostramos cada uno de los apartados por separado:
    \begin{enumerate}
        \item Por el Teorema de Cambio de Variable Discreto, sabemos que $Re_Y = h(Re_X)$ y:
        \begin{equation*}
            P[Y=y] = \sum_{{x\in h^{-1}(y)\cap Re_X}} P_X(x) \qquad \forall y\in Re_Y
        \end{equation*}

        Por tanto, veamos que $\exists E[Y]$. Dado que $Re_Y = h(Re_X)$, tenemos que:
        \begin{equation*}
            \sum_{y\in Re_Y} |y|P_Y(y) = \sum_{y\in h(Re_X)} |y|P_Y(y) = \sum_{y\in h(Re_X)} \sum_{{x\in h^{-1}(y)\cap Re_X}} |y|P_X(x)
        \end{equation*}

        Llegados a este punto, vemos que la variable $x$ recorre todos los puntos de $h^{-1}(y)$ para cada $y\in h(Re_X)$; por lo que tenemos:
        \begin{equation*}
            \sum_{y\in Re_Y} |y|P_Y(y) = \sum_{x\in Re_X} |h(x)|P_X(x)
        \end{equation*}

        Por tanto, como la primera serie es convergente si y solo si lo es la segunda, se tiene lo buscado.

        \item Si $\exists E[Y]$, entonces por un razonamiento análogo llegamos a que:
        \begin{equation*}
            E[Y] = \sum_{y\in Re_Y} yP_Y(y) = \sum_{x\in Re_X} h(x)P_X(x)
        \end{equation*}
        como queríamos demostrar.
    \end{enumerate}
\end{proof}

\subsection{Cambio de variable aleatoria continua}

\begin{teo}
    Si $X$ es una variable aleatoria continua definida en el espacio de probabilidad $(\Omega, \A, P)$ con valores en el conjunto $Re_X \subset \R$ y $Y=h(X)$ es otra variable aleatoria, entonces:
    \begin{enumerate}
        \item $\displaystyle \exists E[Y]\Longleftrightarrow \int_{-\infty}^{+\infty} |h(x)|f_X(x)~dx < \infty$
        \item Si $\displaystyle \exists E[Y]$, entonces:
        \begin{equation*}
            E[Y] = \int_{-\infty}^{+\infty} h(x)f_X(x)~dx
        \end{equation*}
    \end{enumerate}
\end{teo}
% // TODO: Demostración del teorema de CV continuo con esperanza
% https://www.ugr.es/~cdpye/CursoProbabilidad/pdf/P_T04_EsperanzaFuncion.pdf

\section{Moda}

La moda de una variable aleatoria es aquel valor que maximiza la función de masa de probabilidad (en el caso discreto) o la función de densidad (en el caso continuo). Formalmente, distinguimos en función del tipo de variable aleatoria:
\begin{definicion}
    Sea $X$ una variable aleatoria discreta con recorrido $Re_X=E$, se define la moda de $X$ como aquel valor del recorrido de $X$ cuya imagen por su función masa de probabilidad sea mayor, es decir:
    $$Mo_X = \{x \in E \mid P(x) \geq P(y)~~\forall y \in E\}$$
\end{definicion}

\begin{definicion}
    Sea $X$ una variable aleatoria continua con función den densidad $f$. Se define la moda de $X$ como aquel valor del recorrido de $X$ cuya imagen por su función de densidad sea mayor, es decir:
    $$Mo_X = \{x \in \bb{R} \mid f(x) \geq f(y)~~\forall y \in \bb{R}\}$$
    
    Dicho de otra forma, la moda de $X$ es la abscisa en la que se alcanza el máximo absoluto de $f$.
\end{definicion}

Como hemos visto, esta moda no tiene por qué ser única. En tal caso, se dice que la variable aleatoria es \emph{multimodal}.

\begin{ejemplo}
    Sea $X$ una variable aleatoria con función de densidad:
    $$f(x) = \left\{ \begin{array}{ll}
        0               & x < 1           \\
        \dfrac{8}{7x^2} & 1 \leq x \leq 8 \\
        0               & x > 8
      \end{array} \right.$$
    
    Se pide calcular la moda de $X$.\\
    
    En este caso, hemos de de maximizar $f(X)$.
    \begin{equation*}
        f'(x)= -2\frac{8}{7x^3} = -\frac{16}{7x^3}< 0
    \end{equation*}

    Por tanto, como $f(x)$ es estrictamente decreciente y positiva en $[1,8]$, tenemos que la moda es el mínimo de dicho intervalo, es decir:
    $$Mo_X=1$$
\end{ejemplo}

\section{Percentiles}

Distinguimos entre el caso discreto y el continuo:
\begin{definicion}
    Sea $X$ una variable aleatoria discreta con $Re_X=E$. Definimos el percentil $q\in [0, 1]$ de la variable aleatoria $X$ como el valor $X_q \in E$ tal que:
    $$\begin{array}{c}
        P_X(]-\infty, X_q]) \geq q \\
        P_X([X_q, +\infty[) \geq 1-q
    \end{array}$$

    En el caso de que el valor buscado esté entre dos elementos del recorrido de $X$, $x_i, x_j \in E$, entonces el percentil $X_q$ buscado es la media de ambos elementos: $X_q = \dfrac{x_i+x_j}{2}$.
\end{definicion}

\begin{notacion}
    Para simplificar la notación, el percentil $X_{80}$ será el valor $X_{80} \in E$ tal que:
    $$\begin{array}{c}
        P_X(]-\infty, X_q]) \geq 0.8 \\
        P_X([X_q, +\infty[) \geq 0.2
    \end{array}$$
\end{notacion}

\subsection{Variables aleatorias continuas}
\begin{definicion}
    Sea $X$ una variable aleatoria continua. Definimos el percentil $q \in [0,1]$ de la variable
    aleatoria $X$ como el valor $X_q \in \bb{R}$ tal que:
    $$\begin{array}{c}
        P_X(]-\infty, X_q]) = q \\
        P_X([X_q, +\infty[) = 1-q
    \end{array}$$
\end{definicion}
\begin{notacion}
    Para simplificar la notación, el percentil $X_{80}$ será el valor $X_{80} \in [a,b]$ tal que:
    $$\begin{array}{c}
        P_X(]-\infty, X_q]) = 0.8 \\
        P_X([X_q, +\infty[) = 0.2
    \end{array}$$
\end{notacion}

\subsection{Mediana}
\begin{definicion}
    Dada una variable aleatoria $X$, se define la media de la variable aleatoria, notada $Me$ como:
    $$Me = X_{50}$$
\end{definicion}

\begin{ejemplo}
    Sea $X$ una variable aleatoria discreta con $Re_X = [0,3] \cap \Z$ con función masa de densidad:
    $$P(x) = \left\{ \begin{array}{cc}
        \nicefrac{3}{16} & x = 0 \\
        \nicefrac{7}{16} & x = 1 \\
        \nicefrac{5}{16} & x = 2 \\
        \nicefrac{1}{16} & x = 3
      \end{array} \right.$$
    Se pide calcular la mediana de la variable aleatoria.\\
    
    
    Buscamos $Me \in [0,3] \cap \Z$ tal que:
    $$\begin{array}{c}
        P_X([0, Me] \cap \Z) = F_X(Me) \geq \nicefrac{1}{2} \\
        P_X([Me, 3] \cap \Z) \geq \nicefrac{1}{2}
      \end{array}$$
    
    
    Supongamos que $Me=1$, veamos que es cierto:
    $$\begin{array}{c}
        P_X([0, 1] \cap \Z) = F_X(1) = 10/16 \geq \nicefrac{1}{2} \\
        P_X([1, 3] \cap \Z) = 13/16 \geq \nicefrac{1}{2}
      \end{array}$$
    
    Luego:
    $$Me = 1$$
\end{ejemplo}


\section{Momentos de una variable aleatoria}

Sea $X$ una variable aleatoria. Definimos el momento de orden $k\in \mathbb{N}\cup \{0\}$ centrado en el punto $a\in \mathbb{R}$ como:
\begin{equation*}
    _a m_k = E[(X-a)^k]
\end{equation*}

\subsection{Momentos no centrales}

\begin{definicion}[Momentos no centrales]
    Sea $X$ una variable aleatoria. Definimos el momento no centrado de orden $k \in \N \cup \{0\}$, notado $m_k$ como el momento de orden $k$ centrado en el punto $a=0$, es decir:
    \begin{equation*}
        m_0:=~{_0 m_k} = E[X^k]
    \end{equation*}
\end{definicion}

Algunos momentos no centrales relevantes son:
$$\begin{array}{l}
    m_0 = E[X^0] = E[1] = 1 \\
    m_1 = E[X^1] = E[X]     \\
    m_2 = E[X^2]
\end{array}$$

\subsection{Momentos centrales}

\begin{definicion}[Momentos centrales]
    Sea $X$ una variable aleatoria. Definimos el momento centrado de orden $k \in \N \cup \{0\}$, notado $\mu_k$ como el momento de orden $k$ centrado en el punto $a=E[X]$, es decir:
    $$\mu_k :=~{_{E[X]} m_k}=  E[(X - E[X])^k]$$
\end{definicion}

Algunos momentos centrales relevantes son:
$$\begin{array}{l}
    \mu_0 = E[(X-E[X])^0] = E[1] = 1                     \\
    \mu_1 = E[X-E[X]] = E[X] - E[E[X]] = E[X] - E[X] = 0 \\
    \mu_2 = E[(X-E[X])^2]
  \end{array}$$

Tenemos los siguientes resultados demostrados para la estadística unidimensional. La demostración en este caso es análoga:
\begin{equation*}
    m_{k} = \sum_{i=0}^k\binom{k}{i} \mu_{k-i}m_1^i
    \hspace{2cm}
    \mu_{k} = \sum_{i=0}^k\binom{k}{i} (-1)^i m_{k-i} m_1^i
\end{equation*}

Por tanto, la existencia de los momentos no centrales implica la existencia de los momentos centrales y viceversa.

\subsection{Varianza}
\begin{definicion}
    Sea $X$ una variable aleatoria, definimos la varianza de $X$, notada $\sigma_X^2$ o $\Var[X]$ por:
    $$\sigma_X^2 = \Var[X] := \mu_2(X) = E[(X-E[X])^2]$$
\end{definicion}


\begin{prop}
    Dada una variable aleatoria $X$, tenemos que:
    \begin{equation*}
        \Var[X] = E[X^2] - (E[X])^2
    \end{equation*}
\end{prop}
\begin{proof}
    Teniendo en cuenta que $E[X]$ es una constante, es decir, $E[XE[X]]=E[X]^2$, tenemos que:
    \begin{align*}
        \Var[X] &= E[(X-E[X])^2] = E[X^2 + (E[X])^2 - 2XE[X]]
        = E[X^2] + E[E[X]^2] - E[2XE[X]] =\\&=
        E[X^2] + (E[X])^2 -2(E[X])^2
        = E[X^2] - (E[X])^2
    \end{align*}
\end{proof}


\begin{prop}
    Sea $X$ una variable aleatoria cuya varianza existe, y consideramos $Y=aX+b,\quad a,b\in \mathbb{R}$. Entonces:
    \begin{equation*}
        \exists \Var[Y] := \Var[aX+b] = a^2\Var[X]
    \end{equation*}
\end{prop}
\begin{proof}
    \begin{align*}
        \Var[aX+b]
        &= E[(aX+b)^2] -E[aX+b]^2
        = E[a^2X^2 + b^2 +2abX] - (aE[X]+b)^2
        =\\&= a^2E[X^2] + b^2 +2abE[X] -a^2E[X]^2 -b^2 -2abE[X] =  a^2(E[X^2] - E[X]^2) =\\&= a^2\Var[X]
    \end{align*}
\end{proof}

\begin{prop}\label{prop:6.13}
    Sea $X$ una variable aleatoria. Entonces:
    \begin{equation*}
        \Var[X]=0 \Longleftrightarrow X=c\in \mathbb{R}
    \end{equation*}
    Es decir, la varianza de una variable aleatoria es nula si y solo si dicha variable aleatoria es una constante.
\end{prop}
\begin{proof}
    Procedemos mediante doble implicación:
    \begin{description}
        \item [$\Longleftarrow$)] Suponemos $X=c\in \mathbb{R}$. Entonces,
        \begin{equation*}
            \Var[X] = E[X^2]-E[X]^2 = c^2 -c^2 = 0
        \end{equation*}

        \item [$\Longrightarrow$)] Suponemos $\Var[X]=0$. Entonces,
        \begin{itemize}
            \item \underline{Caso discreto.} Consideramos $Re_X = E$:
            \begin{equation*}
                \Var[X] = 0 = E[(X-E[X])^2]
                = \sum_{x_i\in E}(x_i-E[X])^2 f(x_i)
            \end{equation*}

            Como tenemos que $f(x_i)> 0\;\forall x_i$, entonces tenemos que todos los términos son no-negativos. Por tanto, para que se igualen a $0$ todos ellos han de ser nulos. Por tanto,
            \begin{equation*}
                x_i = E[X] \qquad \forall x_i \in E
            \end{equation*}

            Por tanto, llamando $E[X]=c\in \mathbb{R}$, tenemos $X=c$.



            \item \underline{Caso continuo.} Consideramos $f$ la función de densidad de $X$:
            \begin{equation*}
                \Var[X] = 0 = E[(X-E[X])^2]
                = \int_{-\infty}^\infty (x-E[X])^2 f(x)\;dx
            \end{equation*}

            Como tenemos que $f(x)> 0\;\forall x$, entonces tenemos que el integrando es no-negativo. Por tanto, para que se iguale la integral a $0$ el integrando ha de ser nulo. Por tanto,
            \begin{equation*}
                x = E[X] \qquad \forall x \in \bb{R}
            \end{equation*}

            Por tanto, llamando $E[X]=c\in \mathbb{R}$, tenemos $X=c$.
        \end{itemize}
    \end{description}
\end{proof}

\section{Función generatriz de momentos}

Sea $X$ una variable aleatoria. Si $\exists t_0 \in \R \mid \; \forall t \in ]-t_0,t_0[$ existe la esperanza
$E[e^{tX}]$,
se dice entonces que existe la \textbf{función generatriz de momentos de $X$}, notada $M_X$ y definida como:
$$M_X(t)=E[e^{tX}] = \left\{ \begin{array}{ll}
    \sum\limits_{x_i \in E} e^{tx_i} P_X(x_i) & \mbox{ caso discreto} \\ \\
    \displaystyle \int_{-\infty}^{+\infty} e^{tx}f(x)~dx  & \mbox{ caso continuo}
  \end{array} \right.~~\forall t \in ]-t_0, t_0[$$
La función generatriz de momentos de una variable aleatoria no tiene por qué existir (por ejemplo, para la
distribución de Cauchy). Pero si la variable aleatoria está acotada, entonces siempre existe.

\begin{teo}[de unicidad]
    La función generatriz de momentos de una variable aleatoria, si existe, es única y determina de forma única la distribución de la variable.
\end{teo}

Es decir, una variable aleatoria no puede tener dos funciones generatrices de momentos y dos variable aleatorias con distinta distribución tampoco pueden tener la misma función generatriz de momentos.

\begin{teo} [Relación con los momentos]
    Si existe la función generatriz de momentos de una variable aleatoria, entonces:
    \begin{enumerate}
        \item Existen todos los momentos de la variable aleatoria.

        \item $\forall t \in ]-t_0, t_0[$:
        $$M_X(t) = \sum_{n=0}^\infty \dfrac{t^nE[X^n]}{n!}$$

        \item Existe la derivada de todos los órdenes de $M_X(t)$ en un entorno de cero y:
        $$M_X^{n)}(t)\Big|_{t=0} = E[X^n] \qquad n = 1, 2, \ldots$$
    \end{enumerate}
\end{teo}
\begin{proof}
    Demostramos cada resultado por separado:
    \begin{enumerate}
        \item Se deja como ejercicio al lector.
        \item Sabemos\footnote{Se demuestra mediante el desarrollo en serie de Taylor de la exponencial, conceptos estudiados en Cálculo II.} que $e^x = \sum\limits_{n=0}^\infty \frac{x^n}{n!}$. Por tanto,
        \begin{multline*}
            M_X(t)=E[e^{tX}]
            = E\left[\sum_{n=0}^\infty \frac{(tX)^n}{n!}\right]
            = E\left[\sum_{n=0}^\infty \frac{t^n X^n}{n!}\right]
            =\\= \sum_{n=0}^\infty E\left[ \frac{t^n X^n}{n!}\right]
            = \sum_{n=0}^\infty \frac{t^n E\left[X^n\right]}{n!}
        \end{multline*}

        \item Tenemos que:
        \begin{align*}
            M_X^{n)}(t)\Big|_{t=0} &= \dfrac{d^n}{dt^n}E[e^{tX}]\Big|_{t=0} = E\left[\dfrac{d^n}{dt^n}e^{tX}\right]\Big|_{t=0} =\\
            &= E\left[X^n e^{tX}\right]\Big|_{t=0} = E[X^n]
        \end{align*}
    \end{enumerate}
\end{proof}

\begin{ejemplo}
    Sea $X$ una variable aleatoria continua con función de densidad:
    $$f(x) = \left\{ \begin{array}{ll}
        0      & x \leq 0 \\
        e^{-x} & x > 0
      \end{array} \right.$$
    
    Se pide calcular la función generatriz de momentos de $X$, $M_X(t)$.
    \begin{equation*}\begin{split}
        M_X(t) &= E[e^{tX}] = \int_0^{+\infty} e^{tx} e^{-x}~dx = \int_0^{+\infty} e^{x(t-1)}~dx =\\
        &=\dfrac{1}{t-1} \int_0^{+\infty} (t-1) e^{x(t-1)}~dx = \left. \dfrac{e^{x(t-1)}}{t-1} \right]_0^{+\infty} = \dfrac{1}{1-t}
    \end{split}\end{equation*}
    
    Con $t<1$ para que la integral converja y exista la esperanza.\\
    
    Comprobamos que $M_X(t) = \dfrac{1}{1-t},\quad t<1$ es nuestra función generatriz de momentos (al menos para $m_0,m_1,m_2$):
    
    $$M_X(0) = 1 = \int_0^{+\infty} f(x)~dx = \int_0^{+\infty} e^{-x}~dx = m_0$$
    
    $$M_X'(t) = \dfrac{1}{(1-t)^2}\Longrightarrow M_X'(0) = 1 = \int_0^{+\infty} xf(x)~dx = \int_0^{+\infty} xe^{-x}~dx = m_1$$
    
    $$M_X''(t) = \dfrac{2}{(1-t)^3} \Longrightarrow M_X''(0) = 2 = \int_0^{+\infty} x^2f(x)~dx = \int_0^{+\infty} x^2e^{-x}~dx = m_2$$
\end{ejemplo}

Algunas de sus propiedades son:
\begin{lema}
    Sea $X$ una variable aleatoria y sea $M_X(t)$ su función generatriz de momentos. Entonces:
    $$M_X(0)=1$$
\end{lema}
\begin{proof}
    $$M_X(0) = E[e^{0X}] = E[1] = 1$$
\end{proof}

\begin{prop}
    Sea $X$ una variable aleatoria con función generatriz de momentos $M_X(t)\;\forall t \in ]-t_0, t_0[$, sea $Y = aX +b\;a, b \in \mathbb{R}$, entonces la función generatriz de momentos de $Y$, para $t$ tal que $at \in ]-t_0, t_0[$ verifica:
    \begin{equation*}
        M_Y(t) = e^{bt}M_X(at)
    \end{equation*}
\end{prop}
\begin{proof}
    Realizamos distinción entre caso continuo y caso discreto:
    \begin{itemize}
        \item \underline{Caso discreto}. Suponemos $Re_X = E$. Entonces:
        \begin{multline*}
            M_Y(t) = E[e^{ty}] = E[e^{t(ax+b)}] = \sum_{x_i\in E} e^{t(ax_i+b)}f(x_i)
            = e^{tb}\sum_{x_i\in E} e^{t(ax_i)}f(x_i)
            =\\= e^{tb}E[e^{atx}] = e^{bt}M_X(at)
        \end{multline*}

        \item \underline{Caso continuo}. Sea $f$ la función de densidad de $X$. Entonces:
        \begin{multline*}
            M_Y(t) = E[e^{ty}] = E[e^{t(ax+b)}] = \int_{-\infty}^{\infty} e^{t(ax+b)}f(x)\;dx
            = e^{tb}\int_{-\infty}^{\infty} e^{t(ax)}f(x)\;dx
            =\\= e^{tb}E[e^{atx}] = e^{bt}M_X(at)
        \end{multline*}
    \end{itemize}
\end{proof}
