\chapter{Arquitecturas TLP}
En este capítulo, nos centraremos en arquitecturas que permiten ejecutar de forma paralela o concurrente múltiples flujos de instrucciones (o \emph{threads}) que comparten memoria. Se tratan de arquitecturas con paralelismo a nivel de \emph{thread} (\emph{Thread-Level Parallelism}) con una única instancia del Sistema Operativo. Por tanto, cada vez que mencionemos arquitecturas TLP, nos estamos refiriendo a arquitecturas TLP con una única instancia del Sistema Operativo. En este contexto, el SO es el encargado de gestionar los flujos de instrucciones.

Los paradigmas de programación paralela por variables compartidas son los más fáciles de implementar en este tipo de arquitecturas, mientras que las orientadas a paso de mensajes están más relacionadas con arquitecturas TLP con múltiples instancias del SO\@.

La compartición de memoria que se da trae conceptos como la coherencia del sistema de memoria, consistencia del sistema de memoria o la sincronización entre flujos; conceptos que estudiaremos a lo largo de este capítulo.

\section{Arquitecturas}
\subsection{Objetivos}
Esta sección está orientada a:
\begin{itemize}
    \item Distinguir entre multhread, multicores y multiprocesadores.
    \item Comparar entre cores multithread de grano fino, grueso y cores con multithread simultáneo.
\end{itemize}

% // TODO: COmpletar todo esto

\subsection{Clasificaciones}
Las arquitecturas TLP con una instancia del SO pueden clasificarse en:
\begin{description}
    \item [Multiprocesadores] Son capaces de ejecutar en paralelo varios flujos de instrucciones en un computador con varios núcleos o procesadores de forma que cada flujo se ejecuta en un núcleo o procesador distinto. Pueden encontrarse multiprocesadores en un chip (como los multinúcleos), en una placa o en uno o varios armarios.
    \item [Multinúcleos (\emph{multicores})] Pueden ejecutar en paralelo varios flujos de instrucciones en un chip de procesamiento con múltiples núcleos de forma que cada flujo se ejecuta en un núcleo distinto. Un chip multinúcleo es un multiprocesador en un chip. La denominación de \emph{multicores} proviene de un nombre comercial que dio Intel a sus multiprocesadores en un chip. De esta forma, se denomica procesador a los chips o encapsulados de procesamiento y núcleo (o core) a los procesadores.
    \item [Núcleos (o cores) \emph{multithread}] Se trata de un núcleo de procesamiento (procesador) en el que se ha modificado su estructura (ILP) para poder ejecutar flujos de instrucciones de forma concurrente o en paralelo.
\end{description}


\subsubsection{Clasificaciones de cores multithread}
A su vez, los cores multithread pueden clasificarse en:
\begin{description}
    \item [Temporal Multithreading (TMT)] Son capaces de ejecutar varios \emph{threads} de forma \underline{concurrente} en el mismo core. El hardware es el encargado de realizar la conmutación entre \emph{threads}. Emite las instruccinoes de un único \emph{thread} en un ciclo.
    \item [Simultaneous MultiThreading (SMT)] También llamado \emph{Horizontal multithread}, ejecuta en un core superescalar varios \emph{threads} en \underline{paralelo}. Son capaces de emitir instrucciones de varios \emph{threads} en un ciclo y no implementan conmutaciones entre \emph{threads}.
\end{description}

\subsubsection{Clasificaciones de cores TMT}
\begin{description}
    \item [Fine-grain multithreading (FGMT)] También conocido como \emph{interleaved multithreading}, la conmutación entre threads la decide el hardware en cada ciclo (tiene un coste nulo):
        \begin{itemize}
            \item Por turno rotatorio, \emph{round-robin}.
            \item Por eventos de cierta latencia y una técnica de planificación. Ejemplos de eventos son:
                \begin{itemize}
                    \item Dependencia funcional.
                    \item Acceso a datos de caché L1.
                    \item Saltos no predecibles.
                    \item Operaciones de cierta latencia.
                    \item \ldots
                \end{itemize}
        \end{itemize}
    \item [Coarse-grain multithreading (CGMT)] También conocido como \emph{blocked multithreading}, la conmutación entre threads la decide el hardware (con un costo nulo o de varios ciclos):
        \begin{itemize}
            \item Tras un intervalo de tiepmo prefijado, \emph{timeslice multithreading}.
            \item Por eventos de cierta latencia, \emph{switch-on-event multithreading}.
        \end{itemize}
\end{description}

\subsubsection{Clasificación de cores con CGMT con conmutación por eventos}
\begin{description}
    \item [Estática] Presenta una comutación implícita para instrucciones de carga, almacenamiento y salto; e instrucciones explícitas para conmutaciones, tales como instrucciones añadidas al repertorio.
        \begin{itemize}
            \item Ventaja: Coste de cambio de contexto bajo, de 1 o 0 ciclos.
            \item Inconveniente: Cambios de contextos innecesarios.
        \end{itemize}
    \item [Dinámica] La conmutación se realiza típicamente por fallos en la última caché dentro del chip de procesamiento (conmutación por fallo de caché), interrupciones (conmutación por señal), \ldots
        \begin{itemize}
            \item Ventaja: Reduce cambios de contexto innecesarios.
            \item Inconveniente: mayor sobrecarga al cambiar de contexto.
        \end{itemize}
\end{description}

% // TODO: COmpletar
\section{Apuntes clase}
Con multithread temporal (durante un tiempo instrucciones de un hilo y durante otro instrucciones de otro) puedo eliminar huecos verticales pero no horizontales. Grano grueso cada cierto número de ciclos. En un grano grueso, un cambio de contexto puede provocar una penalización en ciclos, lo que supone un retardo. Grano fino cambio de contexto en cada ciclo.

Con un multithread simultáneo podemos eliminar más huecos que un un temporal.

Diapositiva 20:
En coremultithread sólo puedo emitir una instruccio de cada tipo por ciclo.
En 2 cores multithread tengo 2 unidades de ese tipo, que puede ejecutar a la vez FX/B y M/FP.
Puedo hacer a la vez:
FX M FX FP, FX M B M, \ldots
En core multithread tengo menos huecos.

Diap 22, solo leer
CMP chip multi procesador (multinucleo): varios procesadores (que llamamos núcleos), tenemos replicado todo el cauce (todas las unidades de la etapa de ejecucion). Es lo mas caro.
Lo más barato es CGMT, multiplexa uso del hardware, muchos usos sobre el mismo hardware. Sólo replicamos el banco de registros (aunque hay arquitecturas donde solo se replica el PC).
SMT: multithread temporal, ejecutar distintos hilos a la par. Las unidades funcionales se comparten (UF compartidas). 

En un nucleo multithread se usan modificaciones para ejecutar varios hilos k puede ser:
- multiplexar
- repartir
- Compartir: es mejor porque en repartir un hilo puede quedarse atascado de formas más fácil.
- Replicar.
El precio en orden creciente.

Diap 14: IB compartido. Si usamos repartir, hacemos que ciertas posiciones sólo sean para un hilo y ciertas para otro. Compartido es una especie de "reparto" dinamico.

\subsection{Leccion 8}
Puedo tener varias copias de una misma parte de memoria en distintas partes del memory system.
Existe un hardware automatica de precaptacion: tras varios fallos, el hardware precide la siguiente linea a usar, gracias a un patron de acceso.

incoherencia: las copias no tienen todas el mismo contenido. Debemos tratar las incoherencias.
 Podemos generalizar incoherencia entre cache-MP poniendo l_i - l_k con k < i (incoherencias en distintos niveles de jerarquia de memoria).

incoherencias entre distinto nivel de jerarquia (cache-MP)
write-through: Cada vez que se escribe la copia de un bloque que hay en cache se escribe en memoria principal. No se admiten incoherencias.
write-bach: Cuando se escribe, en cache, no se modifica inmediatamente la memoria principal. Se modifica al desalojar de cache. Se pueden dar por tanto incoherencias.

Escribir en memoria N bytes = N * T_acceso
El acceso a memoria esta segmentado, transferir un bloque no es N * T_acceso

Hay que hacer modificaciones en write-back en el bus para k no se den incoherencias: si el controlador de la cache modificada detecta el acceso a un bloque modificado (hay un protocolo de sondeo, espionaje en cada controlador), inibe la respuesta de la memoria y responde él.

PROPAGACIONES
Cuando se modifica una cache, se propaga a todos los bloques:
write-update: actualiza las instancias. Mejor para escribir y leer por otros.
write-invalidate: invalida las instancias antes de modificar su propia copia, se consigue acceso exclusivo al bloque. Es la más utilizada.

En la BIOS puede configurarse todo esto.

CLASIFICACIONES Y DISEÑO

Paquetes que genera un controlador de cache:
PtEx - En buses no se usa pero en redes sí.
PtLec, PtLecEx - Se generan como consecuencia de eventos de origen el procesador. Peticiones de lectura y escritura por parte del procesador.
PtPEsc - Para escribir en memoria.
RpBloque - Respuesta de un bloque. Peticiones puestas en el bus por otros nodos.

MSI de espionaje
post-escritura e invalidacion: 2 bits:
01 modificado - M. Unica copia del bloque valida en todo el sistema. Memoria inválida.
00 ninguno (compartido) - S. Bloque válido en caché. Memoria válida.
10 invalido - I. 

La memoria siempre constesta, pero si un controlador detecta algo, el controlador \emph{inhibe} la respuesta de la memoria.

MESI de espionaje
En las placas de Intel se usa una variante de MESI. En las AMD una variante de MOESI.
4 estados.




\section{Coherencia del sistema de memoria}
\subsection{Objetivos}
Tras esta sección, debería ser capaz de:
\begin{itemize}
    \item Comparar los métodos de actualización de memoria principal implementados en caché.
    \item Comparar las alternativas para propagar una escritura en protocolos de coherencia de caché.
    \item Explicar qué debe garantizar el sistema de memoria para evitar problemas por incoherencias.
    \item Descibir las partes en las que se puede dividir el análisis o el diseño de protocolos de coherencia.
    \item Distinguir entre protocolos basados en directorios y protocolos de espionaje (snoopy).
    \item Explicar el protocolo de mantenimiento de coherencia de espionaje MSI.
    \item Explicar el protocolo de mantenimiento de coherencia de espionaje MESI.
    \item Explicar el protocolo de mantenimiento de coherencia MSI basado en directorios con difusión y sin difusión.
\end{itemize}

\section{Consistencia del sistema de memoria}
\subsection{Objetivos}
Esta sección está orientada a adquirir los conocimientos necesarios para:
\begin{itemize}
    \item Explicar el concepto de consistencia.
    \item Distinguir entre coherencia y consistencia.
    \item Distinguir entre el modelo de consistencia secuencial y los modelos relajados.
    \item Distinguir entre los diferentes modelos de consistencia relajados.
\end{itemize}

\section{Sincronización}
\subsection{Objetivos}
Tras esta sección, debería ser capaz de:
\begin{itemize}
    \item Explicar por qué es necesaria la sincronización en multiprocesadores.
    \item Describir las primitivas para sincronización que ofrece el hardware.
    \item Implementar cerrojos simples, cerrojos con etiqueta y barreras a partir de instrucciones máquina de sincronización y ordenación de accesos a memoria.
\end{itemize}
