\chapter{Arquitecturas TLP}
En este capítulo, nos centraremos en arquitecturas que permiten ejecutar de forma paralela o concurrente múltiples flujos de instrucciones (o \emph{threads}) que comparten memoria. Se tratan de arquitecturas con paralelismo a nivel de \emph{thread} (\emph{Thread-Level Parallelism}) con una única instancia del Sistema Operativo. Por tanto, cada vez que mencionemos arquitecturas TLP, nos estamos refiriendo a arquitecturas TLP con una única instancia del Sistema Operativo. En este contexto, el SO es el encargado de gestionar los flujos de instrucciones.\\

Los paradigmas de programación paralela por variables compartidas son los más fáciles de implementar en este tipo de arquitecturas, mientras que las orientadas a paso de mensajes están más relacionadas con arquitecturas TLP con múltiples instancias del SO\@.\\

La compartición de memoria que se da trae conceptos como la coherencia del sistema de memoria, consistencia del sistema de memoria o la sincronización entre flujos; conceptos que estudiaremos a lo largo de este capítulo.

\section{Tipos de Arquitecturas}
\subsection{Objetivos}
Esta sección está orientada a:
\begin{itemize}
    \item Distinguir entre cores multhread, multicores y multiprocesadores.
    \item Comparar entre cores multithread de grano fino, grueso y cores con multithread simultáneo.
\end{itemize}

\subsection{Clasificaciones de arquitecturas TLP}
Las arquitecturas TLP con una instancia del SO pueden clasificarse en:
\begin{description}
    \item [Multiprocesadores.] Son capaces de ejecutar en paralelo varios flujos de instrucciones (hilos) en un computador con varios núcleos o procesadores de forma que cada flujo se ejecuta en un núcleo o procesador distinto. 

        Podemos encontrarnos multiprocesadores en un chip (como los multinúcleos), en una placa o en uno o varios armarios.
    \item [Multinúcleos (\emph{multicores}).] Pueden ejecutar en paralelo varios flujos de instrucciones en un chip de procesamiento con múltiples núcleos de forma que cada flujo se ejecuta en un núcleo distinto. Un chip multinúcleo no es más que un multiprocesador en un chip. 

        La denominación de \emph{multicores} proviene de un nombre comercial que dio Intel a sus multiprocesadores en un chip. Además, denominó \emph{procesador} a los chips o encapsulados de procesamiento y \emph{núcleos} (o \emph{cores}) a los procesadores.
    \item [Núcleos (o cores) \emph{multithread}.] Se trata de un núcleo de procesamiento (un procesador) en el que se ha modificado su arquitectura ILP (\emph{Instruction Level Parallelism}) para poder ejecutar flujos de instrucciones de forma concurrente o en paralelo.
\end{description}

\subsection{Repaso de arquitecturas ILP}
Recordamos lo que eran las arquitecturas ILP (\emph{Instruction Level Parallelism}): son la capacidad por parte de un procesador de ejecutar múltiples instrucciones en paralelo para mejorar el rendimiento del sistema. Las arquitecturas se centran en identificar y aprovechar las dependencias de datos entre las instrucciones para ejecutarlas de forma eficiente.

\subsubsection{Etapas de ejecucución}
Antes de continuar, recordamos las etapas básicas para la ejecución de una instrucción:
\begin{description}
    \item [Etapa de captación de instrucciones (\emph{Instruction Fetch}).]~\\
        Etapa en la que se capta de la caché de instrucciones la siguiente instrucción a ejecutar, incrementando el valor del PC\@ (\emph{Program Counter}).
    \item [Etapa de decodificación de instrucciones (\emph{Instruction Decode}).]~\\
        Etapa en la que se decofica la instrucción captada para determinar su tipo y operaciones a realizar. Se identifican aquí las dependencias de datos y condiciones de control que pueden afectar la ejecución de la instrucicón.
    \item [Etapa de ejecución (\emph{Execution}).]~\\
        Se lleva a cabo la ejecución de la instrucción. Podemos encontrarnos 4 tipos de instrucciónes (en relación a ellos se ejecutará una cosa u otra).
        \begin{itemize}
            \item Operaciones de enteros.
            \item Operaciones de coma flotante.
            \item Saltos.
            \item Escrituras o lecturas de memoria.
        \end{itemize}
        Aunque esta última no se realizaría en esta etapa, es importante para el desarrollo que vamos a hacer de arquitecturas ILP\@.
    \item [Etapa de acceso a memoria (\emph{Memmory}).]~\\
        Se accede a memoria en caso de que sea necesario (depende de la instrucción).
    \item [Etapa de almacenamiento de resultados en registros (\emph{Write-Back}).]~\\
        Se almacenan en los registros del procesador los resultados de la instrucción, si es necesario.
\end{description}

\subsubsection{Formas de arquitecturas ILP}
Podemos encontrarnos con dos formas principales de paralelizar estas etapas a la hora de desarrollar una estructura ILP\@:
\begin{description}
    \item [Escalar segmentada.]~\\ Segmentaremos las etapas de ejecución de forma que dispongamos de 5 módulos que sean capaces de procesar su parte de forma paralela. Incluiremos \emph{buffers} auxiliares entre las distintas etapas.
    \item [VLIW y superescalar.]~\\ Consideraremos simplemente 4 etapas (fusionaremos las de ejecución y memoria en una), de forma que replicaremos los componentes de la unidad funcional para que esta sea capaz de ejecutar al mismo tiempo diversos tipos de instrucciones. También es necesario el uso de \emph{buffers} auxiliares.

        Por ejemplo, podemos replicar los componentes de la unidad funcional de forma que podamos ejecutar en paralelo (al mismo tiempo):
        \begin{itemize}
            \item Operaciones con enteros.
            \item Operaciones de coma flotante.
            \item Operaciones de lecturas y escrituras en memoria.
            \item Saltos.
        \end{itemize}
        Podemos además tener no sólo una unidad sino varias de las ya mencionadas (2 unidades para operaciones con enteros, \ldots).

        Además, las 3 etapas restantes estarán segmentadas. Podemos tener también unidades superescalares en las que tengamos replicadas además las etapas de captación, decodificación y \emph{write-back}.
\end{description}

\subsection{Clasificaciones de cores multithread}
Ahora vamos a clasificar los \emph{cores multithread}, que no dejan de ser procesadores con arquitectura ILP que se aprovechan para ejecutar a la vez distintos hilos del sistema operativo de forma concurrente o paralela.
\begin{description}
    \item [\emph{Temporal Multithreading} (TMT)]~\\ Ejecutan distintos hilos de forma \underline{concurrente} en el mismo core. De esta forma, emite instrucciones de un único hilo en cada ciclo. Podemos pensar que el core se está multiplexando.

        La conmutación entre hilos la decide el hardware.
    \item [\emph{Simultaneous MultiThreading} (SMT)]~\\ Ejecuta distintos hilos de forma \underline{paralela} en el mismo core. Pueden llegar a emitir en un sólo ciclo instrucciones de varios hilos. Para llevar esto a cabo, necesitamos un core superescalar.

        No implementa conmutación entre hilos, al no ser necesaria.
\end{description}
Según qué tan seguido intercambiamos los hilos del core, nos encontramos con:
\begin{description}
    \item [TMT de grano fino (\emph{Fine-grain multithreading}, FGMT).]~\\ La conmutación de hilos en el core se realiza en cada ciclo. Presentan un coste de cambio de contexto bajo, no es necesario perder ningún ciclo para realizar los cambios de contexto.

        La planificación del siguiente hilo a ejecutar puede ser \emph{round-robin} u otra técnica de planificación (podemos guiarnos por el hilo menos recientemente ejecutado, por accesos a datos, por saltos no predecibles, por operaciones con gran latencia, \ldots).
    \item [TMT de grano grueso (\emph{Coarse-grain multithreading}, CGMT).]~\\ La conmutación entre hilos no se realiza en cada ciclo. Presentan un mayor coste por cambios de contexto: pueden perderse entre ninguno y varios ciclos debido a los cambios de contexto.

        La planificación puede depender cualquier técnica, como tras intervalos de tiempos prefijados (\emph{timeslice multithreading}), por eventos de cierta latencia (\emph{switch-on-event multithreading}), \ldots
\end{description}

\subsubsection{Clasificación de cores con CGMT con conmutación por eventos}
Podemos conmutar los hilos del core de grano grueso de forma:
\begin{description}
    \item [Estática.]~\\ 
        Realizando la conmutación de forma \emph{explícita}, mediante nuevas instrucciones para conmutación añadidas al repertorio; o de forma \emph{implícita}, al detectar instrucciones e carga, almacenamiento, salto, \ldots

        \begin{itemize}
            \item Como ventaja, destacamos el bajo coste de los cambios de contexto (de 0 o 1 ciclos).
            \item Como inconveniente, pueden producirse cambios de contexto innecesarios.
        \end{itemize}
    \item [Dinámica]~\\
        La conmutación se realiza típicamente por fallos de caché o por interrupciones (interrupciones por señales).

        \begin{itemize}
            \item Como ventaja, reduce los cambios de contexto innecesarios de la estática.
            \item Como inconveniente, la sobrecarga que se añade por los cambios de contexto es mayor.
        \end{itemize}
\end{description}

\subsubsection{Característica}
En un núcleo multithread, podemos usar las siguiente modificaciones con el objetivo de ejecutar varios hilos en un mismo core:
\begin{itemize}
    \item Multiplexado: Hacemos que los hilos se turnen en el uso de una unidad.
    \item Repartición: Repartimos una unidad entre (al menos) dos hilos, de forma que a uno le asociamos su zona y al otro la suya.
    \item Compartición: Hay (al menos) dos hilos que acceden a la misma unidad de forma simultánea.
    \item Replicación: Disponemos de varias unidades, de forma que cada hilo puede hacer uso de una.
\end{itemize}
Notemos que tanto el precio de implementación como la bondad de la técnica se encuentran en orden creciente (siendo más caro y mejor realizar la replicación de unidades).\\

Una vez desarrollada la clasificación de cores multithread, podemos mostrar la Tabla~\ref{tab:resumen_multithreading} a modo de resumen, que nos ayudará a entender mejor cada tipo de multithreading.
\begin{table}
\footnotesize
\centering
\setlength{\tabcolsep}{4pt}
\begin{tabular}{l c c c c}
    \toprule
    Hardware & CGMT & FGMT \\ 
    \midrule
    Registros & Replicado (al menos el PC) & Replicado \\
    \midrule
    Almacenamiento & Multiplexado & Cualquiera de las 4 \\
    \midrule
    Hardware de etapas & Multiplexado & Captación repartida o compartida, \\
    del cauce & & el resto multiplexadas \\
    \midrule
    Necesidad de distinguir & Sí & Sí \\
    el hilo de una instruc. & & \\
    \midrule
    Hardware para conmutar & Sí & Sí \\
    \toprule % ----
    Hardware & SMT & CMP \\ 
    \midrule
    Registros & Replicado & Replicado \\
    \midrule
    Almacenamiento & Todo menos multiplexado & Replicado \\
    \midrule
    Hardware de etapas & Unidad funcional compartida, & Replicado \\
    del cauce & el resto repartidas o compartidas & \\
    \midrule
    Necesidad de distinguir & Sí & No \\
    el hilo de una instruc. & & \\
    \midrule
    Hardware para conmutar & No & No \\
    \bottomrule
\end{tabular}
\caption{Comparación de tipos de multithreading.}
\label{tab:resumen_multithreading}
\end{table}
``CMP'' es un Chip multicore, aquel en el que tenemos replicado todo el cauce (esto es, todas las unidades de la etapa de ejecución).

% // TODO: Hacer
\subsection{Comparativa de cores multithread}



















































% // TODO: COmpletar
% Con multithread temporal (durante un tiempo instrucciones de un hilo y durante otro instrucciones de otro) puedo eliminar huecos verticales pero no horizontales. Grano grueso cada cierto número de ciclos. En un grano grueso, un cambio de contexto puede provocar una penalización en ciclos, lo que supone un retardo. Grano fino cambio de contexto en cada ciclo.
% 
% Con un multithread simultáneo podemos eliminar más huecos que un un temporal.
% 
% Diapositiva 20:
% En coremultithread sólo puedo emitir una instruccio de cada tipo por ciclo.
% En 2 cores multithread tengo 2 unidades de ese tipo, que puede ejecutar a la vez FX/B y M/FP.
% Puedo hacer a la vez:
% FX M FX FP, FX M B M, \ldots
% En core multithread tengo menos huecos.
% 
% \subsection{Leccion 8}
% Existe un hardware automatica de precaptacion: tras varios fallos, el hardware precide la siguiente linea a usar, gracias a un patron de acceso.
% 
% Escribir en memoria N bytes = N * T_acceso
% El acceso a memoria esta segmentado, transferir un bloque no es N * T_acceso

\newpage
\section{Coherencia del sistema de memoria}
A la hora de usar multiprocesadores, surge un problema fundamental de manera natural: las incoherencias en memoria. A lo largo de esta sección definiremos este problema, dando ejemplo y protocolos que lo resuelven. Cabe mencionar que todos los multiprocesadores salvo los NUMA implementan la coherencia del sistema de memoria por hardware.

\subsection{Objetivos}
Tras esta sección, debería ser capaz de:
\begin{itemize}
    \item Comparar los métodos de actualización de memoria principal implementados en caché.
    \item Comparar las alternativas para propagar una escritura en protocolos de coherencia de caché.
    \item Explicar qué debe garantizar el sistema de memoria para evitar problemas por incoherencias.
    \item Descibir las partes en las que se puede dividir el análisis o el diseño de protocolos de coherencia.
    \item Distinguir entre protocolos basados en directorios y protocolos de espionaje (snoopy).
    \item Explicar el protocolo de mantenimiento de coherencia de espionaje MSI\@.
    \item Explicar el protocolo de mantenimiento de coherencia de espionaje MESI\@.
    \item Explicar el protocolo de mantenimiento de coherencia MSI basado en directorios con difusión y sin difusión.
\end{itemize}

\subsection{Definición del problema}
La utilización de memoria caché trae consigo el esquema de jerarquía de memoria y la posibilidad de tener en distintas jerarquías una misma posición de memoria repetida. En sistemas uniprocesador, si tratamos de modificar una posición de memoria, esta se llevará a caché y será modificada en caché, indicando que ha sido modificada. En un cierto momento, la modificación en esta jerarquía de caché será comunicada a jerarquías de memoria mayores, hasta llegar a memoria principal y modificar dicho dato. De esta forma, la próxima vez que se necesite en caché dicha posición, estará actualizada conforme a la última modificación.\\

Recordamos ahora que cada procesador lleva asociada una memoria caché y, al ser mayor la memoria principal que la caché, necesitamos almacenar en algún sitio qué bloque de memoria principal contiene cada entrada de memoria caché. Esta información se almacena en una tabla asociada a la caché. En dicha tabla hay una entrada por cada dirección de la memoria caché y, en cada entrada, se almacena qué bloque de memoria principal está cargado y unos bits de información sobre el bloque cargado. Representamos una aproximación a esta tabla en la Figura~\ref{tab:tabla_cache}. En un sistema uniprocesador, nos basta con un bit sucio (que indique si el bloque ha sido modificado o no, para saber si hay que escribir en jerarquías supsriores) y un bit de validez (que indique si el bloques es válido).\\

\begin{table}
\centering
\begin{tabular}{r|c|c|}
    \cline{2-3}
    0 & Dirección de MP & Bits \\ \cline{2-3}
    1 & Dirección de MP & Bits \\ \cline{2-3}
      & \vdots & \vdots \\ \cline{2-3}
    $N-1$ & Dirección de MP & Bits \\ \cline{2-3}
\end{tabular}
\caption{Tabla para una caché de $N$ direcciones de memoria.}
\label{tab:tabla_cache}
\end{table}

En un multiprocesador, cada procesador lleva consigo una memoria caché, de forma que todos los procesadores comparten el espacio de memoria. Puede suceder que dos procesadores distintos trabajen con la misma posición de memoria $k$ (y por tanto, tengan al bloque que contiene a $k$ en sus respectivas cachés). Si uno de los dos procesadores decide modificar $k$, se modificará la dirección de memoria caché correspondiente, pero el bloque en la caché del otro procesador y en memoria principal quedarán inalterados. Nos acabamos de encontrar con una incoherencia en el sistema de memoria.\\

Concretando las ideas, una \textbf{incoherencia en el sistema de memoria} se produce cuando en el sistema de memoria las copias de una misma dirección no tienen el mismo contenido. Como hemos ya comentado, en sistemas uniprocesdores teníamos este problema: podíamos tener un bloque en memoria caché modificado que no estuviese modificado en memoria principal. En este caso hablamos de incoherencias en distintas jerarquías de memoria. Sin embargo, ahora en multiprocesadores podemos tener incoherencias en la misma jerarquía de memoria, tal y como mencionábamos en el ejemplo anterior.

\subsubsection{Métodos de actualización de memoria principal}
Las situaciones de incoherencia se deben abordar no permitiendo que se produzcan nunca o bien evitando que causen problemas (que algún componente lea el valor no actualizado de la memoria) en caso de permitirse. Las cachés implementan dos métodos de actualización de memoria principal:
\begin{description}
    \item [Escritura directa (\emph{write-through}).]~\\ 
        Con escritura directa, no se permiten situaciones de incoherencia entre caché y memoria principal al escribir en caché: cada vez que se escribe en un bloque de la caché, el correspondiente bloque de la memoria principal es modificado. 

        Por tanto, tenemos una escritura en memoria principal por cada escritura, lo que requiere usar la red de comunicación entre procesador y memoria principal. Este sobreuso de la red empeora más aún en multiprocesadores, al tener múltiples procesadores que son susceptibles de modificar datos de forma paralela.

        Otro problema que se plantea es desaprovechar los principios de localidad espacial y temporal (al modificar una variable, es posible que se modifique otra próxima a ella, o que la ya modificada se vuelva a modificar próximamente), por lo que sería mejor esperar a que termine la modificación en curso (por ejemplo, si estamos iterando sobre un vector y modificando sus componentes), antes de escribir en memoria los cambios modificados.

        Cabe destacar también que sí pueden producirse con escritura directa situaciones de incoherencia entre cachés (dos cachés tienen el mismo bloque y una lo modifica) y entre caché y memoria principal (cuando un componente modifica la dirección de un bloque de memoria principal que se encuentra en alguna caché del multiprocesador). En sistemas uniprocesadores, tenemos la ventaja de no necesitar un bit sucio.

    \item [Posescritura (\emph{write-back}).]~\\
        En posescritura, cuando una dato es modificado por un procesador, sólo se modifica en la caché correspondiente a dicho procesador. La actualización en memoria principal se produce cuando un bloque modificado (un bloque en el que se ha alterado una dirección de memoria mientras estaba en la caché) es retirado de la caché (por ejemplo, para hacer sitio a otro bloque más necesario). De esta forma, minimizamos el número de accesos a memoria y, por tanto, de uso de la red de conexión entre el procesador y la memoria; aprovechando los principios de localidad espacial y temporal.

        De esta forma, se permiten situaciones de incoherencia entre caché y memoria principal (incluso en sistemas uniprocesador). También puede producirse cualquier tipo de incoherencia en este sistema, empeorando la situación que teníamos con escritura directa.

        Es necesario además mantener la información sobre qué bloques han sido modificados en caché y cuales no. Esta labor la realiza un bit en la tabla de la caché, llamdo ``bit sucio''.
\end{description}
Lo usual en cachés es que usen posescritura, debido a sus ventajas frente a escritura directa. A continuación, estaremos hablando siempre de sistemas multiprocesadores, ya que en sistemas uniprocesadores las situaciones de incoherencia ya están resueltas (tanto con escritura directa no permitiendo incoherencias tanto con posescritura, permitiendo incoherencias pero controlando que no provoquen fallos).

\subsection{Protocolos de coherencia entre cachés}
Como ya habrás podido deducir, nuestra tarea ahora es buscar cómo resolver las incoherenias ya mencionadas, y manejar las incoherencias que se permiten para que no provoquen fallos en el sistema. Para evitar situaciones de incoherencias entre cachés, se deben cumplir las siguientes dos condiciones:
\begin{enumerate}
    \item \textbf{Propaganción de escrituras.} Se debe garantizar que todo lo que se escribe en la copia de un bloque en caché se propague a las copias del bloque en otras cachés.
    \item \textbf{Serialización de escrituras.} Se debe garantizar que las escrituras en una dirección se ven en el mismo orden por todos los procesadores: el sistema de memoria debe parecer que realiza en serie las operaciones de escritura en la misma dirección. Debe dar la impresión de que estas operaciones sean \underline{atómicas}. 

        Esto es de vital importancia en arquitecturas donde no todos los procesadores tienen el mismo (o similar) tiempo acceso a sus cachés, como los NUMA, debemos garantizar que el primer procesador que se dispuso a escribir en memoria sea el primero que lo haga.
\end{enumerate}
Los \textbf{protocolos de coherencias de caché} buscan resolver el problema de las incoherencias entre cachés, de forma que cada escritura en caché sea visible para el resto de procesadores, propagando de forma fiable el valor escrito en una dirección. Los protocolos de coherencia usan dos alternativas principales para propagar escrituras a otras cachés:
\begin{description}
    \item [Escritura con actualización (\emph{write-update}).]~\\
        Siempre que se modifique una dirección en la copia de un bloque en una caché, se modifica dicha dirección en las copias del mismo bloque de memoria que tengan el resto de procesadores en sus cachés (en caso de tenerlo). Si se cumplen los principios de localidad espacial y temporal, esto provoca una alta sobrecarga en la red de comunicación, al tener que avisar al resto de procesadores la modificación de una variable.
    \item [Escritura con invalidación (\emph{write-invalidate}).]~\\ 
        Antes de que un procesador modifique un bloque en su memoria caché, invalida el resto de copias del mismo bloque en las cachés de otros procesadores. Posteriormente, es libre de modificar su bloque tantas veces como desee, obteniendo un \emph{acceso exclusivo} al bloque. 

        Cuando otro procesador quiera acceder a dicho bloque desde su caché, en caso de tenerlo, verá que estará invalidado y deberá solicitarlo a la memoria (en caso de que el bloque se encuentre actualizado en memoria) o al procesador que tenía el acceso exclusivo al bloque. Es necesario por tanto disponer de un bit en la tabla de la caché que indique si un bloque se encuentra invalidado o no.

        Notemos que invalidar es más rápido que actualizar, ya que sólo necesitamos recibir la información del bloque invalidado y cambiar un bit, en lugar de reescribir el bloque completo. 

        Esta práctica sólo permite compartir bloques de memoria mientras sólo se lee del bloque.
\end{description}
Si escribimos varias veces sucesivas sin que otro procesador lea de su bloque correspondiente, con invalidación podemos reducir el número de accesos (transferencias) a la red. Por otra parte, si deseamos que un procesador escriba un dato para que el resto lo lean podría ser más eficiente usar escritura con actualización, que disminuye en este caso los accesos a la red (notemos que con invalidación necesitamos un acceso a la red por cada caché que falle, pero con actualización con un único acceso a la red podemos actualizar todas las cachés). Cabe destacar que esta ventaja de la actualización no se da en arquitecturas que no implementan difusión. Podemos decir que en general, la política de actualización genera un tráfico innecesario cuando los datos compartidos se leen por pocos procesadores.\\

La propagación de las actualizaciones o invalidaciones entre los procesadores se puede realizar:
\begin{itemize}
    \item Con una \textbf{difusión} de los paquetes de actualización o invalidación a \underline{todas} las cachés.
    \item Con el envío de los paquetes de actualización o invalidación \underline{sólo} a aquellas cachés con copias del bloque, que son sólo las que necesitan recibirlo. Es decir, realizar un \textbf{envío selectivo}.

        Para esta última alternativa, necesitamos mantener una tabla o directorio de memoria, que informe de las cachés que tienen copia de un determinado bloque para poder realizar la comunicación. Esta tabla tendría una entrada por cada dirección de memoria de cada caché y contendría el bloque que contiene, junto con bits de estado.
\end{itemize}

\subsection{Protocolos de mantenimiento de coherencia}
En una arquitectura UMA, podemos utilizar una red bus para las transferencias entre los procesadores y la memoria que comparten. Los buses implementan la difusión de forma natural. De esta forma, todos los paquetes enviados a la red son visibles por todos los componentes conectados al bus, de forma que toos ven las peticiones en el orden en el que se solicitan (dándose las dos condiciones para evitar situaciones de incoherencias). Todo esto hace que en el caso de los multiprocesadores UMA con red bus no sea necesarios mantener información de la cachés con copias de los bloques, pudiendo suprimir incluso el directorio de memoria del que antes se hablaba. 

En este tipo de arquitecturas, es común el uso de \textbf{protocolos de espionaje} (\emph{snoopy}), ya que todos los componentes pueden ver (espiar) dicho bus. Cada controlador de caché espía los paquetes del bus y actúa en consecuencia (si por ejemplo otro controlador solicita un paquete invalidado del que nuestra caché tiene acceso exclusivo y no está actualizado en memoria, nuestro controlador invalida la respuesta de la memoria y es él quien responde a la petición del paquete, devolviendo el paquete actualizado). Es por ello sencillo implementar protocolos de coherencia en una arquitectura que use buses. Sin embargo, los protocolos de espionaje no escalan bien debido a retardos que introducen otro tipo de redes\footnote{Al tener que esperar a que todos los procesadores reciban el paquete enviado.}.\\

En redes en las que la difusión es costosa de implementar o redes que requieren de una gran escalabilidad, se usan \textbf{esquemas basados en directorios}, en los que para reducir el tráfico, se envían los paquetes únicamente a las cachés implicadas (cachés con copia del bloque al que se accede). Es necesario por tanto el uso del directorio de memoria. Sin embargo, también obtenemos un cuello de botella al tener que acceder por cada procesador a dicho directorio. Se obtienen mejores prestaciones distribuyendo el directorio entre los módulos de memoria principal, de forma que el subdirectorio de cada módulo mantenga la información sobre sólo los bloques que contiene cada módulo. De esta forma, los diferentes subdirectorios pueden procesar peticiones en paralelo.

Cabe destacar que no son los únicos tipos de protocolos de coherencia, sino que hay también esquemas organizados en \textbf{jerarquía}, compuestos de protocolos de espionaje y directorios, que dependen de la red utilizada en cada nivel.\\

Resumiento toda esta introducción a los protocolos de coherencia realizada, debemos tener claro que para diseñar un protocolo de mantenimiento de coherencia, debemos planificar:
\begin{itemize}
    \item La política de actualización en memoria principal: escritura directa o posescritura.
    \item La política de propagación de escrituras entre cachés: escrituras con actualizción o con invalidación.
    \item El comportamiento:
        \begin{itemize}
            \item Los posibles estados de un bloque en caché y las acciones que el controlador de caché debe realizar ante eventos recibidos.
            \item Los posibles estados de un bloque en memoria principal, junto con las acciones que el controlador de memoria principal debe hacer ante eventos.
            \item Los paquetes que genera el controlador de memoria principal.
            \item Saber relacionar las acciones con eventos y estados.
        \end{itemize}
\end{itemize}
A continuación, vamos a estudiar cuatro protocolos de mantenimiento de coherencia, dos para multiprocesadores UMA con red bus (MSI y MESI) y dos para multiprocesadores NUMA en una placa (MSI con y sin difusión). Todos ellos usan posescritura y escrituras con invalidación, como cabría esperar.\\

Los protocolos de espionaje que estudiaremos se basan en la difusión de los paquetes asociados al mantenimiento de coherencia a todas las cachés. Se implementan de forma eficiente en sistemas basados en buses.

\subsection{Protocolo MSI (\emph{Modified-Shared-Invalid}) de espionaje}
Describimos a continuación el protocolo MSI, el protocolo con menor número de estados que utiliza posescritura e invalidación. Debe su nombre a cada estado de un bloque en caché.

\subsubsection{Estados de un bloque en caché}\label{sec:prot_MSI}
\begin{description}
    \item [Modificado (M).]~\\
        Un bloque modificado en caché es la única copia del bloque válida en todo el sistema de memoria. 
        \begin{itemize}
            \item En caso de que otro módulo solicite este bloque por el bus, el controlador de su caché debe invalidar la respuesta de la memoria principal (la memoria principal siempre intentará responder)\footnote{En caso de estar así implementado; puede haber implementaciones que no realicen esta función, como se verá en breves.} y el controlador de caché debe responder con su propio bloque, que es el único válido.
            \item El controlador de su caché debe escribir dicho bloque en memoria en caso de ser extraído de su caché.
            \item El controlador de su caché debe invalidar el bloque si le llega por el bus una petición de invalidación del bloque correspondiente.
        \end{itemize}

    \item [Compartido (S).]~\\
        Un bloque compartido en caché indica que todas las copias de dicho bloque que pueda haber en la jerarquía de memoria están actualizadas.

        \begin{itemize}
            \item El controlador de su caché debe invalidar el bloque si le llega por el bus una petición de invalidación del bloque correspondiente.
        \end{itemize}

    \item [Inválido (I).]~\\
        Un bloque inválido en caché es un bloque que o no está físicamente en caché (esa posición de caché está vacía) o que está invalidado (por progragación de invalidaciones desde otra caché).

        \begin{itemize}
            \item Si el procesador de la caché accede a un bloque en estado inválido, enviará un paquete de petición del bloque por el bus de la red.
        \end{itemize}
\end{description}
Podemos ordenar estos estados en relación al grado de disponibilidad del bloque por parte del procesador al que pertenece la caché en orden creciente por:
\begin{itemize}
    \item Inválido.
    \item Compartido.
    \item Modificado.
\end{itemize}
El estado modificado supone que el procesador tiene el uso exclusivo del bloque, de forma que puede disponer de él tanto par aleer como para escribir, sin informar al resto del sistema. Como el módulo que contiene al bloque es el único que dispone de una copia válida del mismo, se trata del encargado de responder a todas las peticiones de este por el bus.\\

Todos estos estados se implementan añadiendo a la tabla de caché de cada módulo (Tabla~\ref{tab:tabla_cache}) una serie de bits. Necesitamos representar 3 estados, luego nos será suficiente con disponer de mínimo 2 bits por cada entrada de la tabla. Las implementaciones suelen añadir normalmente los bits de invalidez (indica si el bloque en dicha posición de caché es válido) y sucio (indica si el bloque en dicha posición de caché ha sido modificado) en relación a nuestro modelo de estados MSI\@. De esta forma:
\begin{table}[H]
\centering
\begin{tabular}{c c c c}
    Estados & Bit de invalidez & Bit sucio & Ambos bits \\
    \midrule
    M & 0 & 1 & 01 \\
    S & 0 & 0 & 00 \\
    I & 1 & 0 & 10
\end{tabular}
\end{table}

\subsubsection{Estados de un bloque en memoria}
Según lo anteriormente explicado, podemos evitar establecer estados para bloques en memoria (habilitando que los controladores de caché puedan inhibir respuestas del controlador de memoria principal). Sin embargo, si se desea almacenar puede hacerse simplemente con dos estados:
\begin{description}
    \item [Válido.] El bloque está actualizado en memoria principal y puede haber una copia en una o varias cachés (sin acceso exclusivo). 

        \begin{itemize}
            \item El controlador de memoria principal responde con el bloque si ve en el bus una petición con lectura de un bloque que en memoria principal es válido.
        \end{itemize}
    \item [Inválido.] El bloque no está actualiza en la memoria principal y hay una copia válida en alguna caché.

        \begin{itemize}
            \item En caso de que este bloque sea pedido por el bus, será el controlador de caché de la caché correspondiente quien proporcione el bloque.
        \end{itemize}
\end{description}
En caso de desear implementar la validez o no de los bloques en memoria, nos bastaría con disponer de un bit de invalidez por bloque de memoria.

\subsubsection{Paquetes que genera un controlador de caché}
Hemos comentado varias veces que los distintos controladores de caché de cada nodo tienen que tener un trabajo en la red de comunicación, pero no hemos especificado cómo se realizan estas comunicaciones. 

Un controlador de caché puede generar los siguiente tipos de transferencias como consecuencia de acciones en caché del procesador, o como consecuencia de paquetes recibidos por otros nodos. Puede generar paquetes de petición (comienzan por \verb|Pt|) o de respuesta (comienzan por \verb|Rp|).
\begin{description}
    \item [Petición de lectura de un bloque] \verb|PtLec(B)|\textbf{.}~\\
        Se genera como consecuencia de una lectura con fallo de caché del procesador del nodo (evento \verb|PrLec|) en relación al bloque \verb|B|. El paquete contendrá la dirección del bloque \verb|B|.

        Como respuesta a esta petición, recibirá un paquete de respuesta con el bloque (\verb|RpBloque(B)|) de memoria principal o de la caché que lo tiene en estado modificado, en caso de haberlo.
    \item [Petición de acceso exclusivo a un bloque con lectura de bloque] \verb|PtLecEx(B)|\textbf{.}~\\
        Se genera como consecuencia de una escritura con fallo de caché del procesador (evento \verb|PrEsc|) en un bloque inválido \verb|B| en la caché. El paquete contendrá la dirección del bloque \verb|B|.

        Como respuesta se invalidarán las copias del bloque en otras cachés y memoria principal; y se recibirá un paquete de respuesta con el bloque (\verb|RpBloque(B)|) de memoria o de la caché que lo tiene en estado modificado, en caso de haberlo.
    \item [Petición de acceso exclusivo a un bloque] \verb|PtEx(B)|\textbf{.}~\\
        Se genera como consecuencia de una escritura del procesador (evento \verb|PrEsc|) en un bloque \verb|B| en estado compartido en la caché (si estuviera en estado modificado, no hace falta generar este paquete). El paquete contendrá la dirección del bloque \verb|B|.

        Como respuesta se invalidarán las copias del bloque en otras cachés y memoria principal.

        En ciertas implementaciones no existe este paquete; en su lugar se usa el paquete \verb|PtLecEx(B)| descartando el paquete de respuesta (\verb|RpBloque(B)|) que es enviado a través del bus.
    \item [Petición de posescritura de un bloque] \verb|PtPEsc(B)|\textbf{.}~\\
        Se genera por el reeemplazo en caché de un bloque \verb|B| en estado modificado, como consecuencia del acceso del procesador a un bloque que no se encuentra en caché. El paquete contendrá la dirección del bloque \verb|B|, así como su contenido.

        El procesador no espera ninguna respuesta.
        

    \item [Respuesta con bloque] \verb|RpBloque(B)|\textbf{.}~\\
        Se genera por el controlador de la caché que tiene el bloque \verb|B| solicitado en estado modificado, cuando detecta por el bus una petición \verb|PtLec(B)| o \verb|PtLecEx(B)|.
\end{description}

\subsubsection{Paquetes que genera el controlador de memoria principal}
El controlador de memoria principal sólo genera paquetes de respuesta:
\begin{description}
    \item [Respuesta con bloque] \verb|RpBloque(B)|\textbf{.}~\\
        Se genera como respuesta a paquetes de peticiones de un bloque \verb|B| por \verb|PtLec(B)| o \verb|PtLecEx(B)|.

        \begin{itemize}
            \item Si la memoria guarda el estado de sus bloques de memoria (esto es, los controladores de caché no inhiben la respuesta de la memoria principal), espiará el bus y sólo generará el paquete de respuesta si el bloque \verb|B| se encuentra en estado válido en memoria.
            \item Si la memoria no guarda el estado de sus bloques de memoria, siempre reponderá con estos paquetes, siendo su respuesta inhibida por el controlador correspondiente.
        \end{itemize}
\end{description}

\subsubsection{Transiciones de estado de un bloque}
En la Tabla~\ref{tab:acciones_controlador_MSI} podemos ver las acciones del controlador de caché de un nodo (los paquetes que genera y los cambios de estado que realiza sobre sus bloques) que provocan los eventos relacionados con un bloque \verb|B|, teniendo en cuenta el estado del bloque en la caché (eventos del procesador o del controlador de caché del nodo, recibidos del exterior a traés de la red en forma de paquete).

\begin{table}
\centering
\begin{tabular}{c l l c}
    \toprule
    Estado & Evento & Acciones del controlador & Estado final \\
    \toprule
           & \verb|PrLec(B)| & & M \\
    \midrule
    & \verb|PrEsc(B)| & & M \\
    \midrule
    M & \verb|PtLec(B)| & Genera \verb|RpBloque(B)| & S \\
    \midrule
      & \verb|PtLecEx(B)| & Invalida copia local y genera \verb|RpBloque(B)| & I \\
    \midrule
      & \verb|Reemplazo(B)| & Genera \verb|PtPEsc(B)| & I \\
    \bottomrule
      & \verb|PrLec(B)| & & S \\
    \midrule
    S & \verb|PrEsc(B)| & Genera \verb|PtEx(B)| & M \\
    \midrule
      & \verb|PtLec(B)| & & S \\
    \midrule
      & \verb|PtLecEx(B)| & Invalida copia local de \verb|B| & I \\
    \toprule
      & \verb|PrLec(B)| & Genera \verb|PtLec(B)| y recibe \verb|RpBloque(B)| & C \\
    \midrule
    I & \verb|PrEsc(B)| & Genera \verb|PtLecEx(B)| invalida en otras cachés & M \\
      & & y recibe \verb|RpBloque(B)| & \\
    \midrule
      & \verb|PtLec(B)| & & I \\
    \midrule
      & \verb|PtLecEx(B)| & & I \\
    \bottomrule
\end{tabular}
\caption{Tabla de acciones del controlador de caché.}
\label{tab:acciones_controlador_MSI}
\end{table}

\begin{description}
    \item [Fallo de lectura.]~\\
    El procesaor lee (\verb|PrLec(B)|) y el bloque no está en caché (o está en estado inválido). El controlador de caché difunde un paquete de petición de lectura del bloque de memoria \verb|PtLec(B)|.

    El estado del bloque en la caché será compartido. La copia del boque en otras cachés también será compartido y en memoria, válido. 

    \verb|PtLec(B)| provoca los siguientes efectos:
    \begin{enumerate}
        \item Si el bloque se encuentra en otra caché en estado modificado, su controlador deposita en el bus el paquete \verb|RpBloque(B)| y pasa a estado compartido. La memoria también recoge el bloque del bus, pasando a estado válido (si tiene estados).
        \item Si el bloque está compartido en otras cachés, la memoria proporciona el bloque a la caché que la solicita. El bloque sigue en estado compartido en cada una de las cachés.
    \end{enumerate}

    \item [Fallo de escritura al no estar el bloque en la caché.]~\\
        El procesador escribe (\verb|PrEsc(B)|) y el bloque no está en caché (o está en estado inválido). El controlador de caché difunde un paquete de petición de acceso exclusivo al bloque de memoria \verb|PtLecEx(B)|. 

    El estado del bloque en la caché después de la escritura será modificado.

    \verb|PtLecEx(B)| provoca los siguientes efectos:
    \begin{enumerate}
        \item Si la memoria tiene el bloque válido, lo deposita en el bus y pasa a estado inválido.
        \item Si una caché tiene el bloque en estado modificado, deposita el bloque en el bus (invalidando la respuesta de la memoria) y pasa a estado inválido.
        \item Si una caché tiene el bloque en estado compartido, pasa a estado inválido.
    \end{enumerate}

    \item [Acierto de escritura en bloque compartido.]~\\
    El procesador escribe (\verb|PrEsc(B)|) y el bloque está en caché en estado compartido. El controlador quiere acceso exclusivo al bloque, por lo que difunde un paquete de petición de acceso exclusivo al bloque \verb|PtEx(B)|.

    El estado del bloque en la caché después de la escritura será modificado\footnote{Notemos que el acierto de escritura en un bloque compartido se trata de forma similar al fallo de escritura.}.

    \verb|PtEx(B)| provoca los siguientes efectos:
    \begin{enumerate}
        \item Si la memoria tiene el bloque válido, lo deposita en el bus y pasa a estado inválido.
        \item Si una caché tiene el bloque en estado modificado, deposita el bloque en el bus y pasa a estado inválido.
        \item Si una caché tiene el bloque en estado compartido, pasa a estado inválido.
    \end{enumerate}
    \item [Acierto de escritura en bloque modificado.]~\\
        El procesador escribe (\verb|PrEsc(B)|) y el bloque está en caché en estado modificado. Como el nodo ya tiene acceso exclusivo al bloque, no se genera ningún paquete. El bloque sigue en estado modificado.
    \item [Acierto de lectura.]~\\
        El procesador lee (\verb|PrLec(B)|) y el bloque está en caché en estado compartido o modificado. No se genera ningún paquete y el bloque continúa en su mismo estado.
    \item [Reemplazo.]~\\
        Fallo en el acceso a otro bloque y la política de reemplazo de la caché selecciona a \verb|B| para hacer sitio al nuevo. Si el bloque reemplazado se encuentra en estado modificado, el controlador de caché difunde un paquete de posescritura en memoria \verb|PtPEsc(B)|. 

        El estado del bloque en la caché pasa a ser inválido.

        \verb|PtPEsc(B)| provoca el siguiente efecto:
        \begin{enumerate}
            \item El bloque se transfiere a memoria principal, pasando el estado del bloque en memoria a válido.
        \end{enumerate}
\end{description}

\subsection{Protocolo MESI (\emph{Modified-Exclusive-Shared-Invalid}) de espionaje}
El protocolo que estamos a punto de ver también utiliza posescritura como política de actualización de memoria principal y escritura con invalidación como política para mantener la coherencia entre cachés, como cabría esperar.

Con el protocolo MSI, siempre que se escribía en la copia de un bloque en una caché se genera un paquete de petición con acceso exclusivo al bloque, aunque no haya copias en otras cachés que se tengan que invalidar. Esto generaba un tráfico innecesario por la red que degrada las prestaciones de las aplicaciones, especialmente en aplicaciones secuenciales. Es por esto que el protocolo MESI divide el anterior estado compartido en dos (con la filosofía de que si un bloque está en estado compartido en un único nodo no está siendo compartido realmente).

Un bloque en estado \emph{exclusivo} será válido sólo en dicha caché y en memoria principal. Si un bloque está en estado exclusivo en un nodo y el procesador del nodo escribe en el bloque, no se generará paquete para solicitar uso exclusivo del bloque (invalidando copias), ya que ninguna otra caché tiene copias del bloque. Si un bloque está en estado exclusivo, entonces son dos los propietarios del bloque: la memoria principal y una única caché. 

Reordenamos ahora el esquema de disponibilidad de bloques según su estado, desarrollando a continuación cada estado en este nuevo protocolo:
\begin{itemize}
    \item Inválido.
    \item Compartido.
    \item Exclusivo.
    \item Modificado.
\end{itemize}

\subsubsection{Estados de un bloque en caché}
\begin{description}
    \item [Modificado (M).]~\\
        Si el bloque en la caché se encuentra en estado modificado, significa que ese es el único nodo del sistema con una copia válida del bloque, mientras que el resto de cachés y memoria tienen una copia desactualizada (no válida).

        El controlador de su caché debe proporcionar el bloque si observa al espiar el bus que algún componente lo solicita y debe invalidar su propia copia si algún otro nodo solicita una copia exclusiva del bloque para su modificación.
    \item [Exclusivo (E).]~\\
        Si el bloque en caché se encuentra en este estado, significa que es la única caché en el sistema con una copia válida del bloque: el resto de cachés tienen una copia no válida. La memoria tiene también una copia actualizada el bloque. 

        La caché debe invalidar su copia si observa al espiar el bus que algún nodo solicita una copia exclusiva del bloque para su modificación.
    \item [Compartido (C).]~\\
        Supone que el bloque es válido en esta caché, en memoria y en al menos alguna otra caché. 

        La caché debe invalidar su copia si al espiar el bus algún otro nodo solicita una copia exclusiva del bloque para su modificación.
    \item [Inválido (I).]~\\
        Supone que el bloque no está físicamente en lacaché, o si se encuentra, ha sido invalidado por el controlador como consecuencia de la escritura en la copia del bloque situado en otra caché.
\end{description}
En cuanto a los paquetes que usa MESI, son los mismos que MSI\@.

\subsubsection{Transiciones de estado de un bloque}
En la Tabla~\ref{tab:acciones_controlador_MESI} podemos ver las nuevas acciones del controlador de caché de un nodo que provocan los eventos relacionados con un bloque \verb|B|, teniendo en cuenta el estado del bloque en la caché que ahora origina el protocolo MESI frente a MSI (es decir, tener en cuenta la Tabla~\ref{tab:acciones_controlador_MSI} y agregarle las acciones de la Tabla~\ref{tab:acciones_controlador_MESI}).

Detallamos las acciones que se cometen tras la disparación de cada evento con detalle.

\begin{table}
\centering
\begin{tabular}{c l l c}
    \toprule
    Estado & Evento & Acciones del controlador & Estado final \\
    \toprule
       & \verb|PrLec(B)| & & E \\
    \midrule
    E  & \verb|PrEsc(B)| & & M \\
    \midrule
       & \verb|PrLec(B)| & & S \\
    \midrule
       & \verb|PrLecEx(B)| & & I \\
    \bottomrule
    I & \verb|PrLec(B)| y no hay & Genera \verb|PtLec(B)| y recibe \verb|RpBloque(B)| & S \\
      & cachés con copias de \verb|B| & & \\
    \bottomrule
\end{tabular}
\caption{Tabla de nuevas acciones del controlador de caché.}
\label{tab:acciones_controlador_MESI}
\end{table}

\begin{description}
    \item [Fallo de lectura.]~\\
    El procesaor lee (\verb|PrLec(B)|) y el bloque no está en caché (o está en estado inválido). El controlador de caché difunde un paquete de petición de lectura del bloque de memoria \verb|PtLec(B)|.

    El estado del bloque en la caché será pasará a ser compartido si hay copias del bloque en otras cachés y exclusivo en caso contrario. Se puede añadir una línea \verb|OR| cableada que informe si hay cachés con copias del bloque solicitado. El estado en memoria será válido.

    \verb|PtLec(B)| provoca los siguientes efectos:
    \begin{enumerate}
        \item Si el bloque se encuentra en otra caché en estado modificado, su controlador deposita en el bus el paquete \verb|RpBloque(B)| y pasa a estado compartido. La memoria también recoge el bloque del bus, pasando a estado válido (si tiene estados).
        \item Si el bloque está compartido en otras cachés, la memoria proporciona el bloque a la caché que la solicita. El bloque sigue en estado compartido en cada una de las cachés.
        \item Si el bloque se encuentra en estado exclusivo, pasa a estado compartido. En este caso, la respuesta con el bloque que llega a la caché del nodo solicitante procede de la memoria principal.
    \end{enumerate}
    Hay implementaciones en las que si el bloque solicitado está disponible en estado válido en alguna caché, en lugar de proporcionar el bloque la memoria lo proporciona la caché. Es necesario aquí añadir hardware que realice esta funcionalidad (que decida qué caché seleccionar). Esta alternativa es interesante en sistemas con memoria físicamente distribuida (que probablemente use protocolos basados en directorios), ya que se puede proporcionar el bloque desde el nodo más cercano al que lo solicita, reduciendo tiempos.

    \item [Fallo de escritura al no estar el bloque en la caché.]~\\
        El procesador escribe (\verb|PrEsc(B)|) y el bloque no está en caché (o está en estado inválido). El controlador de caché difunde un paquete de petición de acceso exclusivo al bloque de memoria \verb|PtLecEx(B)|. 

    El estado del bloque en la caché después de la escritura será modificado.

    \verb|PtLecEx(B)| provoca los siguientes efectos:
    \begin{enumerate}
        \item Si una caché tiene el bloque en estado modificado, deposita el bloque en el bus (invalidando la respuesta de la memoria) y pasa a estado inválido.
        \item Si una caché tiene el bloque en estado exclusivo o compartido, pasa a estado inválido.
    \end{enumerate}

    \item [Acierto de escritura en bloque compartido.]~\\
    El procesador escribe (\verb|PrEsc(B)|) y el bloque está en caché en estado compartido (es decir, está en algún otra caché también). El controlador quiere acceso exclusivo al bloque, por lo que difunde un paquete de petición de acceso exclusivo al bloque \verb|PtEx(B)|.

    El estado del bloque en la caché después de la escritura será modificado\footnote{Notemos que el acierto de escritura en un bloque compartido se trata de forma similar al fallo de escritura.}.

    \verb|PtEx(B)| provoca los siguientes efectos:
    \begin{enumerate}
        \item Si la memoria tiene el bloque válido, lo deposita en el bus y pasa a estado inválido.
        \item Si una caché tiene el bloque en estado modificado, deposita el bloque en el bus y pasa a estado inválido.
        \item Si una caché tiene el bloque en estado compartido, pasa a estado inválido.
    \end{enumerate}
    \item [Acierto de escritura en bloque modificado o exclusivo.]~\\
        El procesador escribe (\verb|PrEsc(B)|) y el bloque está en caché en estado modificado o exclusivo. Como no hay ningún otro nodo con acceso al bloque, no se genera ningún paquete. El bloque pasa a estado modificado si estaba en estado exclusivo y si no, no se modifica su estado.
    \item [Acierto de lectura.]~\\
        El procesador lee (\verb|PrLec(B)|) y el bloque está en caché en estado compartido, exclusivo o modificado. No se genera ningún paquete y el bloque continúa en su mismo estado.
    \item [Reemplazo.]~\\
        Fallo en el acceso a otro bloque y la política de reemplazo de la caché selecciona a \verb|B| para hacer sitio al nuevo. Si el bloque reemplazado se encuentra en estado modificado, el controlador de caché difunde un paquete de posescritura en memoria \verb|PtPEsc(B)|. 

        El estado del bloque en la caché pasa a ser inválido.

        \verb|PtPEsc(B)| provoca el siguiente efecto:
        \begin{enumerate}
            \item El bloque se transfiere a memoria principal, pasando el estado del bloque en memoria a válido.
        \end{enumerate}
\end{description}

\subsection{Protocolos basados en directorios}
Los protocolos de espionaje son apropiados para redes que implementan comunicaciones con comunicaciones uno-a-todos, tales como los buses. Sin embargo, para redes en las que las difusiones son costosas o cuando necesitamos una gran escalabilidad en el sistema, es mejor usar protocolos basados en directorios. Por tanto, nos serán útiles tanto en multiprocesadores con memoria físicamente distribuida (los NUMA) como en multiprocesadores con memoria centralizada (los UMA) con red escalable.

Estos protocolos de mantenimiento de coherencia reducen el tráfico en la red enviando selectivamente órdenes sólo a las cachés que disponen de una copia válida del bloque implicado en la operación de memoria. Para que esto sea posible, debe existir (como ya se ha comentado previamente) una tabla de memoria (o directorio de memoria) en la que haya una entrada de directorio asociada a cada bloque de memoria principal, con información de las cachés que tienen copia de dicho bloque; y de toda la información necesaria para tratar las situaciones de incoherencias. 

Por ejemplo, en la Tabla~\ref{tab:directorio_memoria}, representamos una tabla con una entrada por cada bloque de memoria y una fila por cada cahé en el sistema, junto con sus bits de presencia. La última fila corresponde con el bit de presencia en memoria.\\

\begin{table}[H]
\centering
\begin{tabular}{c c c c c c}
    Bloque & $C_0$ & $C_1$ & \ldots & $C_{N-1}$ & \\
    \bottomrule
    0 & 1 & 0 & \ldots & 1 & 0 \\
    1 & 0 & 0 & \ldots & 1 & 1 \\
    \vdots & \vdots & \vdots & \vdots & \vdots & \vdots \\
    $M-1$ & 1 & 1 & \ldots & 1 & 0 \\
\end{tabular}
\caption{Directorio de memoria, mediante vector de bits.}
\label{tab:directorio_memoria}
\end{table}

Según cómo esté distribuido el almacenamiento del directorio en la jerarquía de memoria, podemos clasificar los tipos de directorios de memoria en:
\begin{itemize}
    \item Directorio centralizado.
    \item Directorio distribuido entre módulos de memoria principal.
    \item Directorio distribuido entre módulos de memoria principal y caché.
\end{itemize}
El primer protocolo basado en directorio que se implementó consistía en un directorio centralizado monolítico, con una entrada para cada uno de los bloques de memoria principal con información de estado e información de las cachés con copias del mismo.

Este directorio tenía que atender todas las peticiones de acceso a memoria generadas por el sistema, lo que introducía un cuello de botella que degradaba las prestaciones del sistema. Buscamos por tanto repartir el directorio en el sistema. Esta repartición puede realizarse tanto por filas como por columnas (o ambas).\\

En una implementación distribuida entre los módulos de memoria principal, cada módulo tiene asociado un subdirectorio con información para los bloques de memoria de dicho módulo. En este caso, hemos repartido la tabla por filas, de forma que las peticiones podrán ser atendidas por los subdirectorios en paralelo.

En una implementación distribuida entre los módulos de memoria principal y cachés, además de distribuir las filas entre los módulos de memoria principal, se distribuye cada una de las filas entre las cachés con copia del bloque.

\subsubsection{Protocolo MSI para multiprocesadores NUMA}
A continuación, vamos a describir dos protocolos MSI con prosescritra e invalidación para NUMA basado en directorios: uno que difunde las peticiones a todos los nodos (con difusión) y uno que envía las peticiones sólo al nodo que tiene el bloque en el trozo de memoria principal más cercano al nodo (sin difusión). Al seguir esta filosofía, nos aparecen tres roles que desempeñan los nodos en la red NUMA\@:
\begin{description}
    \item [Nodo solicitante de un bloque] (S)\textbf{.} Es un nodo que genera una petición del bloque (\verb|PtLec|, \verb|PtEx|, \verb|PtLecEx| o \verb|PtPEsc|).
    \item [Nodo origen de un bloque] (O)\textbf{.} Recordamos que en un multiprocesador NUMA la memoria está repartida físicamente entre los nodos, de forma que cada uno tiene en módulos de memoria más cercanos un trozo del espacio de direcciones total del multiprocesador. Decimos que esos módulos de memoria más cercanos se hospedan en el nodo. El nodo origen o \emph{home} de un bloque es aquél que tiene el bloque en el trozo de memoria que hospeda.
    \item [Nodo propietario de un bloque] (P)\textbf{.} Es un nodo que tiene copia del bloque en su caché.
\end{description}

\subsection{Protocolo MSI para procesadores NUMA sin difusión}
Como en este protocolo no usamos difusión, necesitamos almacenar en el directorio de memoria prncipal, además del estado del bloque en memoria, información sobre las cachés con copia del bloque, para que las invalidaciones se puedan propagar sólo a los nodos con copia del bloque.

Al igual que en la Tabla~\ref{tab:directorio_memoria}, se puede usar un vector de bits de presencia para almacenar dicha información. Habría un bit para cada caché conectada a la red NUMA, de forma que un bit activo (un 1) significa que hay una copia válida del bloque en esa caché. El directorio a usar se encuentra distribuido entre módulos de memoria principal (entre los nodos del computador NUMA). En la Tabla~\ref{tab:subdirectorio_memoria} podemos observar cómo es uno de estos subdirectorios de un nodo. Este protocolo es el más básico a la hora de usar un directorio con posescritura, invalidación y sin difusión.

\begin{table}
\centering
\begin{tabular}{c c c c c c}
    \toprule
    Bloque & Estado Memoria & $C_0$ & $C_1$ & \ldots & $C_{N-1}$ \\
    \bottomrule
    \vdots & \vdots & \vdots & \vdots & \vdots & \vdots \\
    $B-1$ & V & 0 & 0 & \ldots & 0 \\
    $B$ & V & 1 & 1 & \ldots & 1 \\
    $B+1$ & I & 0 & 0 & \ldots & 1 \\
    \vdots & \vdots & \vdots & \vdots & \vdots & \vdots \\
    \bottomrule
\end{tabular}
\caption{Subdirectorio de memoria principal para un nodo de un NUMA.}
\label{tab:subdirectorio_memoria}
\end{table}

Todas las peticiones de un bloque se envían al nodo origen del bloque, que es quien tiene el subdirectorio con información sobre el bloque. El nodo origen propagará las invalidaciones a los nodos con copia de un bloque. Con esta propagación, cumplimos la condición 1 de coherencia. El orden de llegada de las peticiones de un bloque al origen será el orden en el que los nodos van a ver los accesos a memoria de ese bloque. Todos van a ver el mismo orden en las escrituras, cumplíendose la segunda condición de coherencia.

\subsubsection{Estados de un bloque en caché}
Son los mismos que teníamos ya en el protocolo MSI de la sección~\ref{sec:prot_MSI}, Modificado (M), Compartido (C) e Inválido (I).

\subsubsection{Estados de un bloque en memoria}
En la implementación más sencilla de este protocolo nos encontraríamos con dos estados estables:
\begin{description}
    \item [Válido.] Puede haber copias válidas en una o en más cachés.
    \item [Inválido.] Hay una copia válida en una caché en estado Modificado.
\end{description}
Además, podríamos encontrar implementaciones con estados ``pendientes'' de un estado estable, como \emph{pendiente de válido} o \emph{pendiente de inválido}. Un estado pendiente indica que se está procesando un acceso a memoria del bloque. Hasta que no se pueda procesar una nueva petición sobre ese bloque, su estado continuará en pendiente. 

A las peticiones que se reciben de un bloque pendiente se responde con un paquete de reconocimiento negativo al solicitante, para que intente de nuevo la petición más tarde.

\subsubsection{Paquetes generados por controladores}
A continuación, desarrollamos cada una de las 4 interacciones posibles entre los posibles roles de nodos de un NUMA:

\begin{enumerate}
    \item Paquete de petición (\verb|Pt|) desde $S$ hasta $O$ (cuando son distintos nodos).
    \begin{enumerate}
        \item Cuando se produce una lectura del procesador del nodo $S$ (\verb|PrLec(B)|) con fallo de caché (no hay copia válida del bloque \verb|B| en la caché privada del nodo), se genera el paquete de lectura de bloque \verb|PtLec(B)|. 

            Cuando reciba el paquete de respuesta \verb|RpBloque(B)|, introducirá el bloque en la caché, poniendo su estado en Compartido.
        \item Cuando se produce una escritura del procesador del nodo $S$ (\verb|PrEsc(B)|) en bloque \verb|B| en estado Compartido, se genera el paquete de petición de acceso exclusivo sin lectura \verb|PtEx(B)|.

            Cuando reciba el paquete de respuesta \verb|RpInv(B)| que confirma la invalidación en memoria y en otras cachés, modificará el bloque y cambiará el estado de \verb|B| a Modificado.
        \item Cuando se produce una escritura del procesador del nodo $S$ (\verb|PrEsc(B)|) en el bloque \verb|B| en estado Inválido, se genera el paquete de petición de lectura con acceso exclusivo \verb|PtLecEx(B)|.

            Cuando reciba el paquet ee respuesta \verb|RpBloqueInv(B)| que confirma la invalidación en memoria y en otras cachés, junto con el propio bloque \verb|B|, lo modificará y cambiará el estado de \verb|B| a Modificado.
        \item Cuando el controlador de caché del nodo $S$ reemplaza un bloque \verb|B| que se encuentra en estado Modificado, se genera el paquet ede petición de posescritura \verb|PtPEsc(B)|.

            Posteriormente, el bloque dejará de estar físicamente en la caché.
    \end{enumerate}
    \item Paquete de reenvío (\verb|Rv|), de petición desde $O$ a nodos con copia $P$.
    \begin{enumerate}
        \item Cuando $O$ recibe el paquete \verb|PtLec(B)| y el bloque \verb|B| está en estado Inválido en memoria principal, entonces algún nodo dispone del bloque válido en su caché. Si es el nodo $O$, no se crea paquete de reenvío y se devuelve \verb|RpBloque(B)|; por otra parte, si no es el nodo $O$, se envía el paquete de reenvío de lectura del bloque \verb|RvLec(B)| a algún nodo que tenga a \verb|B| válido en su caché.

            El nodo $O$ pone el bloque en el directorio en estado Pendiente de válido hasta que se actualice el bloque en memoria una vez recibido de la única caché con copia válida. Entonces, pasará a estado Válido y podrá responder a $S$.
        \item Cuando $O$ recibe el paquete \verb|PtEx(B)| de $S$ y el bloque \verb|B| está válido en cachés de otros nodos ó recibe el paquete \verb|PtLecEx(B)| de $S$ y el bloque \verb|B| está válido tanto en cachés de otros nodos como en memoria, se envía el paquete de invalidación \verb|RvInc(B)| a los nodos que tengan válido el bloque \verb|B|.

            El nodo $O$ pondrá el estado de \verb|B| en su directorio a Pendiente de inválido (para que el resto de llamadas no sean atendidas). Cuando $O$ confirma la invalidación en el resto de cachés:
            \begin{itemize}
                \item Dejará activo sólo el bit de presencia de $S$ en el directorio.
                \item Pondrá el estado de \verb|B| en memoria a Inválido.
                \item Responderá a $S$ confirmando su invalidación en memoria y en otras cachés con \verb|RpInv(B)| (en caso de \verb|PtLecEx(B)|, incluirá el bloque en el paquete y será de tipo \verb|RpBloqueInv(B)|).
            \end{itemize}

            % // TODO: Continuar por 106 en libro chiquito


    \end{enumerate}
\end{enumerate}

% // TODO: Continuar por fin de pág 103 en libro chiquito y por 10.1.3 de 537 libro tocho


\newpage
\section{Consistencia del sistema de memoria}
\subsection{Objetivos}
Esta sección está orientada a adquirir los conocimientos necesarios para:
\begin{itemize}
    \item Explicar el concepto de consistencia.
    \item Distinguir entre coherencia y consistencia.
    \item Distinguir entre el modelo de consistencia secuencial y los modelos relajados.
    \item Distinguir entre los diferentes modelos de consistencia relajados.
\end{itemize}

\newpage
\section{Sincronización}
\subsection{Objetivos}
Tras esta sección, debería ser capaz de:
\begin{itemize}
    \item Explicar por qué es necesaria la sincronización en multiprocesadores.
    \item Describir las primitivas para sincronización que ofrece el hardware.
    \item Implementar cerrojos simples, cerrojos con etiqueta y barreras a partir de instrucciones máquina de sincronización y ordenación de accesos a memoria.
\end{itemize}
