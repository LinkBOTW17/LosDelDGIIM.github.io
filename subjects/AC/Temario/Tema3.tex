\chapter{Arquitecturas TLP}
En este capítulo, nos centraremos en arquitecturas que permiten ejecutar de forma paralela o concurrente múltiples flujos de instrucciones (o \emph{threads}) que comparten memoria. Se tratan de arquitecturas con paralelismo a nivel de \emph{thread} (\emph{Thread-Level Parallelism}) con una única instancia del Sistema Operativo. Por tanto, cada vez que mencionemos arquitecturas TLP, nos estamos refiriendo a arquitecturas TLP con una única instancia del Sistema Operativo. En este contexto, el SO es el encargado de gestionar los flujos de instrucciones.\\

Los paradigmas de programación paralela por variables compartidas son los más fáciles de implementar en este tipo de arquitecturas, mientras que las orientadas a paso de mensajes están más relacionadas con arquitecturas TLP con múltiples instancias del SO\@.\\

La compartición de memoria que se da trae conceptos como la coherencia del sistema de memoria, consistencia del sistema de memoria o la sincronización entre flujos; conceptos que estudiaremos a lo largo de este capítulo.

\section{Tipos de Arquitecturas}
\subsection{Objetivos}
Esta sección está orientada a:
\begin{itemize}
    \item Distinguir entre cores multhread, multicores y multiprocesadores.
    \item Comparar entre cores multithread de grano fino, grueso y cores con multithread simultáneo.
\end{itemize}

% // TODO: COmpletar todo esto

\subsection{Clasificaciones de arquitecturas TLP}
Las arquitecturas TLP con una instancia del SO pueden clasificarse en:
\begin{description}
    \item [Multiprocesadores.] Son capaces de ejecutar en paralelo varios flujos de instrucciones (hilos) en un computador con varios núcleos o procesadores de forma que cada flujo se ejecuta en un núcleo o procesador distinto. 

        Podemos encontrarnos multiprocesadores en un chip (como los multinúcleos), en una placa o en uno o varios armarios.
    \item [Multinúcleos (\emph{multicores}).] Pueden ejecutar en paralelo varios flujos de instrucciones en un chip de procesamiento con múltiples núcleos de forma que cada flujo se ejecuta en un núcleo distinto. Un chip multinúcleo no es más que un multiprocesador en un chip. 

        La denominación de \emph{multicores} proviene de un nombre comercial que dio Intel a sus multiprocesadores en un chip. Además, denominó \emph{procesador} a los chips o encapsulados de procesamiento y \emph{núcleos} (o \emph{cores}) a los procesadores.
    \item [Núcleos (o cores) \emph{multithread}.] Se trata de un núcleo de procesamiento (un procesador) en el que se ha modificado su arquitectura ILP (\emph{Instruction Level Parallelism}) para poder ejecutar flujos de instrucciones de forma concurrente o en paralelo.
\end{description}

\subsection{Repaso de arquitecturas ILP}
Recordamos lo que eran las arquitecturas ILP (\emph{Instruction Level Parallelism}): son la capacidad por parte de un procesador de ejecutar múltiples instrucciones en paralelo para mejorar el rendimiento del sistema. Las arquitecturas se centran en identificar y aprovechar las dependencias de datos entre las instrucciones para ejecutarlas de forma eficiente.

\subsubsection{Etapas de ejecucución}
Antes de continuar, recordamos las etapas básicas para la ejecución de una instrucción:
\begin{description}
    \item [Etapa de captación de instrucciones (\emph{Instruction Fetch}).]~\\
        Etapa en la que se capta de la caché de instrucciones la siguiente instrucción a ejecutar, incrementando el valor del PC\@ (\emph{Program Counter}).
    \item [Etapa de decodificación de instrucciones (\emph{Instruction Decode}).]~\\
        Etapa en la que se decofica la instrucción captada para determinar su tipo y operaciones a realizar. Se identifican aquí las dependencias de datos y condiciones de control que pueden afectar la ejecución de la instrucicón.
    \item [Etapa de ejecución (\emph{Execution}).]~\\
        Se lleva a cabo la ejecución de la instrucción. Podemos encontrarnos 4 tipos de instrucciónes (en relación a ellos se ejecutará una cosa u otra).
        \begin{itemize}
            \item Operaciones de enteros.
            \item Operaciones de coma flotante.
            \item Saltos.
            \item Escrituras o lecturas de memoria.
        \end{itemize}
        Aunque esta última no se realizaría en esta etapa, es importante para el desarrollo que vamos a hacer de arquitecturas ILP\@.
    \item [Etapa de acceso a memoria (\emph{Memmory}).]~\\
        Se accede a memoria en caso de que sea necesario (depende de la instrucción).
    \item [Etapa de almacenamiento de resultados en registros (\emph{Write-Back}).]~\\
        Se almacenan en los registros del procesador los resultados de la instrucción, si es necesario.
\end{description}

\subsubsection{Formas de arquitecturas ILP}
Podemos encontrarnos con dos formas principales de paralelizar estas etapas a la hora de desarrollar una estructura ILP\@:
\begin{description}
    \item [Escalar segmentada.]~\\ Segmentaremos las etapas de ejecución de forma que dispongamos de 5 módulos que sean capaces de procesar su parte de forma paralela. Incluiremos \emph{buffers} auxiliares entre las distintas etapas.
    \item [VLIW y superescalar.]~\\ Consideraremos simplemente 4 etapas (fusionaremos las de ejecución y memoria en una), de forma que replicaremos los componentes de la unidad funcional para que esta sea capaz de ejecutar al mismo tiempo diversos tipos de instrucciones. También es necesario el uso de \emph{buffers} auxiliares.

        Por ejemplo, podemos replicar los componentes de la unidad funcional de forma que podamos ejecutar en paralelo (al mismo tiempo):
        \begin{itemize}
            \item Operaciones con enteros.
            \item Operaciones de coma flotante.
            \item Operaciones de lecturas y escrituras en memoria.
            \item Saltos.
        \end{itemize}
        Podemos además tener no sólo una unidad sino varias de las ya mencionadas (2 unidades para operaciones con enteros, \ldots).

        Además, las 3 etapas restantes estarán segmentadas. Podemos tener también unidades superescalares en las que tengamos replicadas además las etapas de captación, decodificación y \emph{write-back}.
\end{description}

\subsection{Clasificaciones de cores multithread}
Ahora vamos a clasificar los \emph{cores multithread}, que no dejan de ser procesadores con arquitectura ILP que se aprovechan para ejecutar a la vez distintos hilos del sistema operativo de forma concurrente o paralela.
\begin{description}
    \item [\emph{Temporal Multithreading} (TMT)]~\\ Ejecutan distintos hilos de forma \underline{concurrente} en el mismo core. De esta forma, emite instrucciones de un único hilo en cada ciclo. Podemos pensar que el core se está multiplexando.

        La conmutación entre hilos la decide el hardware.
    \item [\emph{Simultaneous MultiThreading} (SMT)]~\\ Ejecuta distintos hilos de forma \underline{paralela} en el mismo core. Pueden llegar a emitir en un sólo ciclo instrucciones de varios hilos. Para llevar esto a cabo, necesitamos un core superescalar.

        No implementa conmutación entre hilos, al no ser necesaria.
\end{description}
Según qué tan seguido intercambiamos los hilos del core, nos encontramos con:
\begin{description}
    \item [TMT de grano fino (\emph{Fine-grain multithreading}, FGMT).]~\\ La conmutación de hilos en el core se realiza en cada ciclo. Presentan un coste de cambio de contexto bajo, no es necesario perder ningún ciclo para realizar los cambios de contexto.

        La planificación del siguiente hilo a ejecutar puede ser \emph{round-robin} u otra técnica de planificación (podemos guiarnos por el hilo menos recientemente ejecutado, por accesos a datos, por saltos no predecibles, por operaciones con gran latencia, \ldots).
    \item [TMT de grano grueso (\emph{Coarse-grain multithreading}, CGMT).]~\\ La conmutación entre hilos no se realiza en cada ciclo. Presentan un mayor coste por cambios de contexto: pueden perderse entre ninguno y varios ciclos debido a los cambios de contexto.

        La planificación puede depender cualquier técnica, como tras intervalos de tiempos prefijados (\emph{timeslice multithreading}), por eventos de cierta latencia (\emph{switch-on-event multithreading}), \ldots
\end{description}

\subsubsection{Clasificación de cores con CGMT con conmutación por eventos}
Podemos conmutar los hilos del core de grano grueso de forma:
\begin{description}
    \item [Estática.]~\\ 
        Realizando la conmutación de forma \emph{explícita}, mediante nuevas instrucciones para conmutación añadidas al repertorio; o de forma \emph{implícita}, al detectar instrucciones e carga, almacenamiento, salto, \ldots

        \begin{itemize}
            \item Como ventaja, destacamos el bajo coste de los cambios de contexto (de 0 o 1 ciclos).
            \item Como inconveniente, pueden producirse cambios de contexto innecesarios.
        \end{itemize}
    \item [Dinámica]~\\
        La conmutación se realiza típicamente por fallos de caché o por interrupciones (interrupciones por señales).

        \begin{itemize}
            \item Como ventaja, reduce los cambios de contexto innecesarios de la estática.
            \item Como inconveniente, la sobrecarga que se añade por los cambios de contexto es mayor.
        \end{itemize}
\end{description}

\subsubsection{Característica}
En un núcleo multithread, podemos usar las siguiente modificaciones con el objetivo de ejecutar varios hilos en un mismo core:
\begin{itemize}
    \item Multiplexado: Hacemos que los hilos se turnen en el uso de una unidad.
    \item Repartición: Repartimos una unidad entre (al menos) dos hilos, de forma que a uno le asociamos su zona y al otro la suya.
    \item Compartición: Hay (al menos) dos hilos que acceden a la misma unidad de forma simultánea.
    \item Replicación: Disponemos de varias unidades, de forma que cada hilo puede hacer uso de una.
\end{itemize}
Notemos que tanto el precio de implementación como la bondad de la técnica se encuentran en orden creciente (siendo más caro y mejor realizar la replicación de unidades).\\

Una vez desarrollada la clasificación de cores multithread, podemos mostrar la siguiente tabla a modo de resumen, que nos ayudará a entender mejor cada tipo de multithreading:
% // TODO: Arreglar esta tabla
\begin{table}
\footnotesize
\centering
\setlength{\tabcolsep}{4pt}
\begin{tabular}{l c c c c}
    \toprule
    Hardware & CGMT & FGMT & SMT & CMP \\ % // qué es cmp?
    \midrule
    Registros & Replicado (al menos el PC) & Replicado & Replicado & Replicado \\
    \midrule
    Almacenamiento & Multiplexado & Cualquiera de las 4 & Multiplexado no & Replicado \\
    \midrule
    Hardware de etapas & Multiplexado & Captación repartida o compartida, & Unidad funcional compartida, & Replicado \\
    del cauce & el resto multiplexadas & el resto repartidas o compartidas & Replicado \\
    \midrule
    Necesidad de distinguir & Sí & Sí & Sí & No \\
    el hilo de una instruc. & & & & \\
    \midrule
    Hardware para conmutar & Sí & Sí & No & No \\
    \bottomrule
\end{tabular}
\end{table}
``CMP'' es un Chip multicore, aquel en el que tenemos replicado todo el cauce (esto es, todas las unidades de la etapa de ejecución).

% // TODO: Hacer
\subsection{Comparativa de cores multithread}



















































% // TODO: COmpletar
% Con multithread temporal (durante un tiempo instrucciones de un hilo y durante otro instrucciones de otro) puedo eliminar huecos verticales pero no horizontales. Grano grueso cada cierto número de ciclos. En un grano grueso, un cambio de contexto puede provocar una penalización en ciclos, lo que supone un retardo. Grano fino cambio de contexto en cada ciclo.
% 
% Con un multithread simultáneo podemos eliminar más huecos que un un temporal.
% 
% Diapositiva 20:
% En coremultithread sólo puedo emitir una instruccio de cada tipo por ciclo.
% En 2 cores multithread tengo 2 unidades de ese tipo, que puede ejecutar a la vez FX/B y M/FP.
% Puedo hacer a la vez:
% FX M FX FP, FX M B M, \ldots
% En core multithread tengo menos huecos.
% 
% \subsection{Leccion 8}
% Puedo tener varias copias de una misma parte de memoria en distintas partes del memory system.
% Existe un hardware automatica de precaptacion: tras varios fallos, el hardware precide la siguiente linea a usar, gracias a un patron de acceso.
% 
% incoherencia: las copias no tienen todas el mismo contenido. Debemos tratar las incoherencias.
 % Podemos generalizar incoherencia entre cache-MP poniendo l_i - l_k con k < i (incoherencias en distintos niveles de jerarquia de memoria).
% 
% incoherencias entre distinto nivel de jerarquia (cache-MP)
% write-through: Cada vez que se escribe la copia de un bloque que hay en cache se escribe en memoria principal. No se admiten incoherencias.
% write-bach: Cuando se escribe, en cache, no se modifica inmediatamente la memoria principal. Se modifica al desalojar de cache. Se pueden dar por tanto incoherencias.
% 
% Escribir en memoria N bytes = N * T_acceso
% El acceso a memoria esta segmentado, transferir un bloque no es N * T_acceso
% 
% Hay que hacer modificaciones en write-back en el bus para k no se den incoherencias: si el controlador de la cache modificada detecta el acceso a un bloque modificado (hay un protocolo de sondeo, espionaje en cada controlador), inibe la respuesta de la memoria y responde él.
% 
% PROPAGACIONES
% Cuando se modifica una cache, se propaga a todos los bloques:
% write-update: actualiza las instancias. Mejor para escribir y leer por otros.
% write-invalidate: invalida las instancias antes de modificar su propia copia, se consigue acceso exclusivo al bloque. Es la más utilizada.
% 
% En la BIOS puede configurarse todo esto.
% 
% CLASIFICACIONES Y DISEÑO
% 
% Paquetes que genera un controlador de cache:
% PtEx - En buses no se usa pero en redes sí.
% PtLec, PtLecEx - Se generan como consecuencia de eventos de origen el procesador. Peticiones de lectura y escritura por parte del procesador.
% PtPEsc - Para escribir en memoria.
% RpBloque - Respuesta de un bloque. Peticiones puestas en el bus por otros nodos.
% 
% MSI de espionaje
% post-escritura e invalidacion: 2 bits:
% 01 modificado - M. Unica copia del bloque valida en todo el sistema. Memoria inválida.
% 00 ninguno (compartido) - S. Bloque válido en caché. Memoria válida.
% 10 invalido - I. 
% 
% La memoria siempre constesta, pero si un controlador detecta algo, el controlador \emph{inhibe} la respuesta de la memoria.
% 
% MESI de espionaje
% En las placas de Intel se usa una variante de MESI. En las AMD una variante de MOESI.
% 4 estados.



\newpage
\section{Coherencia del sistema de memoria}
A la hora de usar multiprocesadores, surge un problema fundamental de manera natural: las incoherencias en memoria. A lo largo de esta sección definiremos este problema, dando ejemplo y protocolos que lo resuelven. Cabe mencionar que todos los multiprocesadores salvo los NUMA implementan la coherencia del sistema de memoria por hardware.

\subsection{Objetivos}
Tras esta sección, debería ser capaz de:
\begin{itemize}
    \item Comparar los métodos de actualización de memoria principal implementados en caché.
    \item Comparar las alternativas para propagar una escritura en protocolos de coherencia de caché.
    \item Explicar qué debe garantizar el sistema de memoria para evitar problemas por incoherencias.
    \item Descibir las partes en las que se puede dividir el análisis o el diseño de protocolos de coherencia.
    \item Distinguir entre protocolos basados en directorios y protocolos de espionaje (snoopy).
    \item Explicar el protocolo de mantenimiento de coherencia de espionaje MSI\@.
    \item Explicar el protocolo de mantenimiento de coherencia de espionaje MESI\@.
    \item Explicar el protocolo de mantenimiento de coherencia MSI basado en directorios con difusión y sin difusión.
\end{itemize}

\subsection{Definición del problema}
La utilización de memoria caché trae consigo el esquema de jerarquía de memoria y la posibilidad de tener en distintas jerarquías una misma posición de memoria repetida. En sistemas uniprocesador, si tratamos de modificar una posición de memoria, esta se llevará a caché y será modificada en caché, indicando que ha sido modificada. En un cierto momento, la modificación en esta jerarquía de caché será comunicada a jerarquías de memoria mayores, hasta llegar a memoria principal y modificar dicho dato. De esta forma, la próxima vez que se necesite en caché dicha posición, estará actualizada conforme a la última modificación.\\

Recordamos ahora que cada procesador lleva asociada una memoria caché y, al ser mayor la memoria principal que la caché, necesitamos almacenar en algún sitio qué bloque de memoria principal contiene cada entrada de memoria caché. Esta información se almacena en una tabla asociada a la caché. En dicha tabla hay una entrada por cada dirección de la memoria caché y, en cada entrada, se almacena qué bloque de memoria principal está cargado y unos bits de información sobre el bloque cargado. Representamos una aproximación a esta tabla en la Figura~\ref{tab:tabla_cache}. En un sistema uniprocesador, nos basta con un bit sucio (que indique si el bloque ha sido modificado o no, para saber si hay que escribir en jerarquías supsriores) y un bit de validez (que indique si el bloques es válido).\\

\begin{table}
\centering
\begin{tabular}{r|c|c|}
    \cline{2-3}
    0 & Dirección de MP & Bits \\ \cline{2-3}
    1 & Dirección de MP & Bits \\ \cline{2-3}
      & \vdots & \vdots \\ \cline{2-3}
    $N-1$ & Dirección de MP & Bits \\ \cline{2-3}
\end{tabular}
\caption{Tabla para una caché de $N$ direcciones de memoria.}
\label{tab:tabla_cache}
\end{table}

En un multiprocesador, cada procesador lleva consigo una memoria caché, de forma que todos los procesadores comparten el espacio de memoria. Puede suceder que dos procesadores distintos trabajen con la misma posición de memoria $k$ (y por tanto, tengan al bloque que contiene a $k$ en sus respectivas cachés). Si uno de los dos procesadores decide modificar $k$, se modificará la dirección de memoria caché correspondiente, pero el bloque en la caché del otro procesador y en memoria principal quedarán inalterados. Nos acabamos de encontrar con una incoherencia en el sistema de memoria.\\

Concretando las ideas, una \textbf{incoherencia en el sistema de memoria} se produce cuando en el sistema de memoria las copias de una misma dirección no tienen el mismo contenido. Como hemos ya comentado, en sistemas uniprocesdores teníamos este problema: podíamos tener un bloque en memoria caché modificado que no estuviese modificado en memoria principal. En este caso hablamos de incoherencias en distintas jerarquías de memoria. Sin embargo, ahora en multiprocesadores podemos tener incoherencias en la misma jerarquía de memoria, tal y como mencionábamos en el ejemplo anterior.\\

Las situaciones de incoherencia se deben abordar no permitiendo que se produzcan nunca o bien evitando que causen problemas (que algún componente lea el valor no actualizado de la memoria) en caso de permitirse. Las cachés implementan dos métodos de actualización de memoria principal:
\begin{description}
    \item [Escritura directa (\emph{write-through}).]~\\ 
        Con escritura directa, no se permiten situaciones de incoherencia entre caché y memoria principal al escribir en caché: cada vez que se escribe en un bloque de la caché, el correspondiente bloque de la memoria principal es modificado. 

        Por tanto, tenemos una escritura en memoria principal por cada escritura, lo que requiere usar la red de comunicación entre procesador y memoria principal. Este sobreuso de la red empeora más aún en multiprocesadores, al tener múltiples procesadores que son susceptibles de modificar datos de forma paralela.

        Otro problema que se plantea es desaprovechar los principios de localidad espacial y temporal (al modificar una variable, es posible que se modifique otra próxima a ella, o que la ya modificada se vuelva a modificar próximamente), por lo que sería mejor esperar a que termine la modificación en curso (por ejemplo, si estamos iterando sobre un vector y modificando sus componentes), antes de escribir en memoria los cambios modificados.

        Cabe destacar también que sí pueden producirse con escritura directa situaciones de incoherencia entre cachés (dos cachés tienen el mismo bloque y una lo modifica) y entre caché y memoria principal (cuando un componente modifica la dirección de un bloque de memoria principal que se encuentra en alguna caché del multiprocesador). En sistemas uniprocesadores, tenemos la ventaja de no necesitar un bit sucio.

    \item [Posescritura (\emph{write-back}).]~\\
        En posescritura, cuando una dato es modificado por un procesador, sólo se modifica en la caché correspondiente a dicho procesador. La actualización en memoria principal se produce cuando un bloque modificado (un bloque en el que se ha alterado una dirección de memoria mientras estaba en la caché) es retirado de la caché (por ejemplo, para hacer sitio a otro bloque más necesario). De esta forma, minimizamos el número de accesos a memoria y, por tanto, de uso de la red de conexión entre el procesador y la memoria; aprovechando los principios de localidad espacial y temporal.

        De esta forma, se permiten situaciones de incoherencia entre caché y memoria principal (incluso en sistemas uniprocesador). También puede producirse cualquier tipo de incoherencia en este sistema, empeorando la situación que teníamos con escritura directa.

        Es necesario además mantener la información sobre qué bloques han sido modificados en caché y cuales no. Esta labor la realiza un bit en la tabla de la caché, llamdo ``bit sucio''.
\end{description}
Lo usual en cachés es que usen posescritura, debido a sus ventajas frente a escritura directa. A continuación, estaremos hablando siempre de sistemas multiprocesadores, ya que en sistemas uniprocesadores las situaciones de incoherencia ya están resueltas (tanto con escritura directa no permitiendo incoherencias tanto con posescritura, permitiendo incoherencias pero controlando que no provoquen fallos).

\subsection{Protocolos de coherencia entre cachés}
Como ya habrás podido deducir, nuestra tarea ahora es buscar cómo resolver las incoherenias ya mencionadas, y manejar las incoherencias que se permiten para que no provoquen fallos en el sistema. Para evitar situaciones de incoherencias entre cachés, se deben cumplir las siguientes dos condiciones:
\begin{enumerate}
    \item \textbf{Propaganción de escrituras.} Se debe garantizar que todo lo que se escribe en la copia de un bloque en caché se propague a las copias del bloque en otras cachés.
    \item \textbf{Serialización de escrituras.} Se debe garantizar que las escrituras en una dirección se ven en el mismo orden por todos los procesadores: el sistema de memoria debe parecer que realiza en serie las operaciones de escritura en la misma dirección. Debe dar la impresión de que estas operaciones sean \underline{atómicas}. 

        Esto es de vital importancia en arquitecturas donde no todos los procesadores tienen el mismo (o similar) tiempo acceso a sus cachés, como los NUMA, debemos garantizar que el primer procesador que se dispuso a escribir en memoria sea el primero que lo haga.
\end{enumerate}
Los \textbf{protocolos de coherencias de caché} buscan resolver el problema de las incoherencias entre cachés, de forma que cada escritura en caché sea visible para el resto de procesadores, propagando de forma fiable el valor escrito en una dirección. Los protocolos de coherencia usan dos alternativas principales para propagar escrituras a otras cachés:
\begin{description}
    \item [Escritura con actualización (\emph{write-update}).]~\\
        Siempre que se modifique una dirección en la copia de un bloque en una caché, se modifica dicha dirección en las copias del mismo bloque de memoria que tengan el resto de procesadores en sus cachés (en caso de tenerlo). Si se cumplen los principios de localidad espacial y temporal, esto provoca una alta sobrecarga en la red de comunicación, al tener que avisar al resto de procesadores la modificación de una variable.
    \item [Escritura con invalidación (\emph{write-invalidate}).]~\\ 
        Antes de que un procesador modifique un bloque en su memoria caché, invalida el resto de copias del mismo bloque en las cachés de otros procesadores. Posteriormente, es libre de modificar su bloque tantas veces como desee, obteniendo un \emph{acceso exclusivo} al bloque. 

        Cuando otro procesador quiera acceder a dicho bloque desde su caché, en caso de tenerlo, verá que estará invalidado y deberá solicitarlo a la memoria (en caso de que el bloque se encuentre actualizado en memoria) o al procesador que tenía el acceso exclusivo al bloque. Es necesario por tanto disponer de un bit en la tabla de la caché que indique si un bloque se encuentra invalidado o no.

        Notemos que invalidar es más rápido que actualizar, ya que sólo necesitamos recibir la información del bloque invalidado y cambiar un bit, en lugar de reescribir el bloque completo. 

        Esta práctica sólo permite compartir bloques de memoria mientras sólo se lee del bloque.
\end{description}
Si escribimos varias veces sucesivas sin que otro procesador lea de su bloque correspondiente, con invalidación podemos reducir el número de accesos (transferencias) a la red. Por otra parte, si deseamos que un procesador escriba un dato para que el resto lo lean podría ser más eficiente usar escritura con actualización, que disminuye en este caso los accesos a la red (notemos que con invalidación necesitamos un acceso a la red por cada caché que falle, pero con actualización con un único acceso a la red podemos actualizar todas las cachés). Cabe destacar que esta ventaja de la actualización no se da en arquitecturas que no implementan difusión. Podemos decir que en general, la política de actualización genera un tráfico innecesario cuando los datos compartidos se leen por pocos procesadores.\\

La propagación de las actualizaciones o invalidaciones entre los procesadores se puede realizar:
\begin{itemize}
    \item Con una \textbf{difusión} de los paquetes de actualización o invalidación a \underline{todas} las cachés.
    \item Con el envío de los paquetes de actualización o invalidación \underline{sólo} a aquellas cachés con copias del bloque, que son sólo las que necesitan recibirlo. Es decir, realizar un \textbf{envío selectivo}.

        Para esta última alternativa, necesitamos mantener una tabla o directorio de memoria, que informe de las cachés que tienen copia de un determinado bloque para poder realizar la comunicación. Esta tabla tendría una entrada por cada dirección de memoria de cada caché y contendría el bloque que contiene, junto con bits de estado.
\end{itemize}

\subsection{Protocolos de mantenimiento de coherencia}
En una arquitectura UMA, podemos utilizar una red bus para las transferencias entre los procesadores y la memoria que comparten. Los buses implementan la difusión de forma natural. De esta forma, todos los paquetes enviados a la red son visibles por todos los componentes conectados al bus, de forma que toos ven las peticiones en el orden en el que se solicitan (dándose las dos condiciones para evitar situaciones de incoherencias). Todo esto hace que en el caso de los multiprocesadores UMA con red bus no sea necesarios mantener información de la cachés con copias de los bloques, pudiendo suprimir incluso el directorio de memoria del que antes se hablaba. 

En este tipo de arquitecturas, es común el uso de \textbf{protocolos de espionaje} (\emph{snoopy}), ya que todos los componentes pueden ver (espiar) dicho bus. Cada controlador de caché espía los paquetes del bus y actúa en consecuencia (si por ejemplo otro controlador solicita un paquete invalidado del que nuestra caché tiene acceso exclusivo y no está actualizado en memoria, nuestro controlador invalida la respuesta de la memoria y es él quien responde a la petición del paquete, devolviendo el paquete actualizado). Es por ello sencillo implementar protocolos de coherencia en una arquitectura que use buses. Sin embargo, los protocolos de espionaje no escalan bien debido a retardos que introducen otro tipo de redes\footnote{al tener que esperar a que todos los procesadores reciban el paquete enviado.}.\\

En redes en las que la difusión es costosa de implementar o redes que requieren de una gran escalabilidad, se usan \textbf{esquemas basados en directorios}, en los que para reducir el tráfico, se envían los paquetes únicamente a las cachés implicadas (cachés con copia del bloque al que se accede). Es necesario por tanto el uso del directorio de memoria. Sin embargo, también obtenemos un cuello de botella al tener que acceder por cada procesador a dicho directorio. Se obtienen mejores prestaciones distribuyendo el directorio entre los módulos de memoria principal, de forma que el subdirectorio de cada módulo mantenga la información sobre sólo los bloques que contiene cada módulo. De esta forma, los diferentes subdirectorios pueden procesar peticiones en paralelo.

Cabe destacar que no son los únicos tipos de protocolos de coherencia, sino que hay también esquemas organizados en \textbf{jerarquía}, compuestos de protocolos de espionaje y directorios, que dependen de la red utilizada en cada nivel.\\

Resumiento toda esta introducción a los protocolos de coherencia realizada, debemos tener claro que para diseñar un protocolo de mantenimiento de coherencia, debemos planificar:
\begin{itemize}
    \item La política de actualización en memoria principal: escritura directa o posescritura.
    \item La política de propagación de escrituras entre cachés: escrituras con actualizción o con invalidación.
    \item El comportamiento:
        \begin{itemize}
            \item Los posibles estados de un bloque en caché y las acciones que el controlador de caché debe realizar ante eventos recibidos.
            \item Los posibles estados de un bloque en memoria principal, junto con las acciones que el controlador de memoria principal debe hacer ante eventos.
            \item Los paquetes que genera el controlador de memoria principal.
            \item Saber relacionar las acciones con eventos y estados.
        \end{itemize}
\end{itemize}
A continuación, vamos a estudiar cuatro protocolos de mantenimiento de coherencia, dos para multiprocesadores UMA con red bus (MIS y MESI) y dos para multiprocesadores NUMA en una placa (MSI con y sin difusión). Todos ellos usan posescritura y escrituras con invalidación, como cabría esperar.\\

Los protocolos de espionaje que estudiaremos se basan en la difusión de los paquetes asociados al mantenimiento de coherencia a todas las cachés. Se implementan de forma eficiente en sistemas basados en buses.

\subsection{Protocolo MSI (\emph{Modified-Shared-Invalid}) de espionaje}
Describimos a continuación el protocolo MSI, el protocolo con menor número de estados que utiliza posescritura e invalidación. Debe su nombre a cada estado de un bloque en caché.

\subsubsection{Estados de un bloque en caché}
\begin{description}
    \item [Modificado (M).]~\\
        Un bloque en este estado en caché es la única copia del bloque válida en todo el sistema de memoria. 
        \begin{itemize}
            \item El controlador de su caché debe responder con dicho bloque en caso de que otro módulo lo solicite por el bus.
            \item El controlador de su caché debe escribir dicho bloque en memoria en caso de ser extraído de su caché.
            \item El controlador de su caché debe invalidar el bloque si le llega por el bus una petición de invalidación del bloque correspondiente.
        \end{itemize}

    \item [Compartido (S).]~\\
        Un bloque en este estado en caché indica que todas las copias de dicho bloque que pueda haber en la jerarquía de memoria están actualizadas.

        El controlador de su caché debe invalidar el bloque si le llega por el bus una petición de invalidación del bloque correspondiente.
    \item [Inválido (I).]~\\
        
\end{description}

% // TODO: COntinuar por fin de pág 96 en libro chiquito y por "A continuación \ldots" en página 524 libro tocho


\newpage
\section{Consistencia del sistema de memoria}
\subsection{Objetivos}
Esta sección está orientada a adquirir los conocimientos necesarios para:
\begin{itemize}
    \item Explicar el concepto de consistencia.
    \item Distinguir entre coherencia y consistencia.
    \item Distinguir entre el modelo de consistencia secuencial y los modelos relajados.
    \item Distinguir entre los diferentes modelos de consistencia relajados.
\end{itemize}

\newpage
\section{Sincronización}
\subsection{Objetivos}
Tras esta sección, debería ser capaz de:
\begin{itemize}
    \item Explicar por qué es necesaria la sincronización en multiprocesadores.
    \item Describir las primitivas para sincronización que ofrece el hardware.
    \item Implementar cerrojos simples, cerrojos con etiqueta y barreras a partir de instrucciones máquina de sincronización y ordenación de accesos a memoria.
\end{itemize}
