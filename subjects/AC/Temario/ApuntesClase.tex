Sincronizacion

- Codigo de colores:
Variables calabaza: compartidas
Color verde: cerrojos
Color fuxia: cosas nivel hardware
Variables azules: privadas
Variables en negrita: da igual si compartidas o privadas

- Nombres de codigo de sincronizacion
\textbf{Codigo de sincronización de adquisición}: para adquirir el derecho a acceder a variables compartidas.
Los códigos de sincronización que ejecutan los hilos una vez que han accedido a variables compartidas par que otros hilos accedan se le llama codigo de \textbf{sincronizacion de liberacion}.

Funcion de adquisicion, delate del acceso a variables compartidas, lock().
Funcion de liberacion, detras del acceso a variables compartidas, unlock().
Se vera como implementarlos para que funcionen bien.




atomic es mas rapido k critical xq critical implementa cerrojos y atomic una instruccion maquina particular, del estilo *lock addl*.

- - - Como implementar cerrojos - - -
Tiene dos funciones a implementar: cierre del cerrojo (lock()), como adquisicion; apertura del cerrojo (unlock()).
Tenemos en la diapositiva los requisitos software, a cometar sobre el ejemplo.

Un cerrojo abierto es un 0 y uno cerrado es un 1.

- lock: Se deben cumplir las 3 condiciones:
LLega un flujo y ve cerrojo abierto.
Flujo i --> ve lock(k) a 0 --> Cierra cerrojo y entra.

Llegan varios y ven cerrojo cerrado
Flujo j, k, \ldots --> ve lock(k) a 1 --> while(k == 1) espera(); 

Llegan varios y solo uno puede verlo abierto.
Flujo 0, 1, \ldots, n --> ven lock(k) a 0. 
El software debe hacer que sólo 1 vea el cerrojo abierto y pase la seccion critica, que deberia dejar el cerrojo cerrado para k el resto espere.

- unlock: SÓLO VA A LLEGAR UN HILO.
Si hay hilos esperando, deja entrar sólo a uno.
Si no hubiera hilos, deja el cerrojo abierto.

- - Alternativas para espera - -
Si el codigo critico es muy gordo, hacer llamadas al SO para suspender hilos y luego revivirlos. Espera util. Para cuando la region critica suponga un tiempo mayor a suspender y reanimar.
Si es un codigo sencillo, no renta (demasiada sobrecarga). Se implementa una espera ocupada, el procesador está en un bucle consultando el cerrojo y haciendo un trabajo inutil.


- - Metodo de adquisicion - -
Si entran varios a la vez y el cerrojo esta abierto.
Hay dos alternativas:
- x86 y otros procesadores (como ARMv6): utilizan instrucciones de lectura-modificacion-escritura atomicas. Implementan una lectura y escritura de una variable de forma atomica (indivisible, no permite que ninguna instruccion de otro flujo se introduzca en medio). Se puede notar por $(RW)^i$.
- ARMv7,v8: instruccion de carga (LL, load linked) especial (enlazado al almacenamiento condicional) y una instruccion de almacenamiento especial (SC), store condicional. Se intenta el acceso atomico a una variable compartida. Si al ejecutar el almacenamiento condicional descubre (por una linea condicional) que entre el load y esta el acceso atomico no ha surgido efecto, vuelve a intentarlo.
Si LLi --> LLk --> CCi --> CCk
La carga de k no se realiza porque en medio se situa la carga de i, vuelve a intentarse.

- - Implementacion - -  (Cerrojo Simple II)
- La mas sencilla: Se usa una variable k compartida (que toma valores 0 y 1). Cerrojo simple.
Espera ocupada con un bucle mientras cerrojo esta cerrado (ver diapositiva).

lock(k){
    while(leer-asignar_1-escribir(k) == 1){};
}

unlock(k){
    k = 0;
}

Cumple los 2 primeros y el tercero si usamos un metodo de adquisicion de los ya vistos.
Codigo asm: ldrex (carga enlazada), strexeq (almacenamiento condicional) el bucle es para volver a repetir si no ha tenido exito. El dmb establece un orden total (todos los de arriba) deben ejecutarse antes de los de abajo (los accesos a memoria).


¿Puedo implementar un unlock de un cerrojo en un x86 con k = 0?
Consistencia relajada: lectura puede adelantar a escritura.
k = 0 tenemos escritura que puede adelantar a escrituras y lecturas anteriores, pero una escritura no puede adelantar a nada.

¿ARMv7?
No, tengo que usar un dmb delante, ya que la escritura en el cerrojo de 0 podria adelantar a los accesos a variables compartidas (abrir hilo antes de liberar seccion critica => posibilidad de varios hilos en la seccion critica).

- Criticas - 
Funciona bien pero es muy ineficiente: todos los que esperan estan leyendo y escribiendo en cache (invalidando copias de otras caches, 4 paquetes por coherencia).
Podemos hacer que escriban solo cuando el cerrojo este abierto.

Cambios:
Implementar un do while de:
lock(k){
    do{
        while(k == 1){pause;}    // Solo leen
    }while( RW(1) == 1 );   // Solo escribe al salir
}

Usando una instruccion escritura-modificacion atomica

Tambien cambiamos lineas de 0 -> 1 -> 0, \ldots, consumiendo energia.
Se usa la instruccion pause para añadir retardo.

- Critica -
No establece ningun orden en el acceso a la seccion critica: No hay prioridad sobre quien llega primero, entra quien lee antes.

- - Cerrojos con etiqueta - -
Establecen un orden FIFO en el acceso.
El orden con el que llegan al lock es el orden con el que acceden a la seccion critica.
Dos contadores: de adquisicion y de liberacion.

De liberacion: el que da el turno para acceder a la seccion critica. De adquisicion: sirve para cojer un numero.

lock(k){
    contador_local_adq = contadores.adq;
    contadores.adq++;
    while(contador_local_adq != contadores.lib){;}
}
Se deben ejecutar de forma atomica

unlock(k){
    contadores.lib++;
}


- - - Implementar barreras - - -
Un codigo posible si no se reusa la barrera en el codigo varias veces (sirve si sólo sale la barrera una vez en cada hilo).
Barrera(id, numero_flujos)
Tenemos un contador y una bandera que se situan a 0 y se dejan pasar los hilos cuando bandera = 1 (sucede cuando contador = numero_flujos).

Si usamos la barrera dos veces:
Si antes de que el 3er hilo llegue a la primera, el SO suspende el 2o hilo. el 2o hilo no pasa de la barrera cuando la bandera es 1. Puede que un hilo llegue al segundo uso de la barrera, poniendo la bandera a 0. Todos se quedan bloqueados.

Solucion:
En cada uso de la barrera se complementa la bandera de espera (esperan mientras que sea 1).
Usar otra barrera (necesitamos muchas barreras).

¿Podemos quitar la variable local por una compartida?
No.


### Tema 4 ###
# Nomenclatura - Incluir en los apuntes.
Microarquitectura en vez de arquitectura para denominar el repertorio de instrucciones (que verdaderamente es lo que es la arquitectura). No a cómo está implementado el núcleo (qué bloques tiene, cómo se comunican, \ldots).
Las microarquitecturas podemos entenderlas en cómo están implementadas las arquitecturas.

# La diferencia entre ILP y VLIW 
## Diferencias
VLIW (very long instruction word) no hay hardware que se encarga de la planificación de instrucciones. Lo hace el compilador. Pone en palabras de instrucciones (el compilador) largas las instrucciones que se van a emitir juntas en ejecución.
ILP: el hardware se encarga de la planificación de instrucciones. 
ILP: Hardware para decidir qué instrucciones se van a emitir a ejecución a la vez y VLIW no, lo hace el compilador.
VLIW en computadores empotrados (ocultos), usualmente.

Las dos implementaciones están segmentadas (tienen un cauce).
- Las instrucciones se captan en el orden del programa --> buffer de instrucciones y se decodifican en orden del programa.
- UNa vez decodificada se sabe qué se va a usar y en ISS se emite a ejecución.

## Comentarios en el flujo de ejecucion de instrucciones
La emision a ejecucion puede ser en orden del programa o desordenada, con el fin de ahorrar tiempo de ejecución.
Ya sea ordenada o no, como las unidades pueden suponer distinto tiempo, la finalización de las instrucciones también va a ser desordenada (una puede emitirse antes y terminar después que una que se emite después y termina antes).

En los superescalares, la última etapa procesa las instrucciones de forma ordenada (en orden del programa), aunque la ejecución sea en forma desordenada.
Esta última etapa es la que modifica los registros de la arquitectura. Con esto se garantiza la consistencia del procesador, de forma que el resultado coincide con el que se obtendría de forma ordenada. Está claro que la ejecución va a ser de forma desordenada. Sin embargo, obtenemos un resultado como si se obtendria en el orden del programa.

Cuando esta en alguna de las etapas diremos que se esta procesando y cuando este en ejecucion diremos que se esta ejecutando.
En la realidad, cada etapa está compuesta por distintas subetapas. Puede llegar a haber 10, 14, \ldots etapas en el cauce.

## Modificaciones instroducidas en las arquitecturas para reducir tiempos de ejecución
- Segmentación (esto es repaso). Mejora el tiempo de CPU porque reduce el tiempo de ciclo, reduciéndolo entre el N de etapas si todas las etapas duran lo mismo.

Sin embargo, en los códigos hay dependencias (de datos o control) que dan lugar a problemas en un cauce segmentado, que pueden llevar a un resultado incorrecto de la ejecución (distinto al que se obtendría si no estuviera segmentado).

Problemas (llamados hazards, riesgos): Hay riesgos entre dos instrucciones que tienen dependencias. Además, hay riesgos en saltos (de control), ya que la siguiente instruccion despues de un salto no es la que hay despues en el código. Gran problema con saltos condicionales.

### Como prevenir riesgos 
En VLIW el compilador debe añadir instrucciones de no operacion (nop), para eliminar riesgos; tanto de datos como de control. Peores prestaciones, pasamos de un CPI ideal (1) a uno mayor (como 3 ciclos por instruccion).
Un superescalar VLIW (uno real): Vamos a trabajar en cada una de las etapas con varias instrucciones a la vez (tantas como replicado). Tenemos un CPI ideal (0.5, dos resultados por ciclo). Al añadir instrucciones nop, hace el CPI muy malo (de 2.75). Sin considerar dependencias estructurales (que puede empeorar las cosas, si dos instrucciones necesitan acceder en el mismo tiempo a la misma unidad que no se encuentra replicada). Peor es el rendiminto.

Para reducir la penalización el compialdor debe encargarse.

En ILP el hardware se encarga de eliminar los riesgos y reducir el tiempo de penalización que suponen las dependencias. Puede llegar a el 0.5 ideal que teniamos antes.

# Cómo se hace
1. Ver los diagramas.
2. Ver cómo se implementan los bloquecitos (almacenamiento, algoritmos, \ldots) para eliminar riesgos de datos, control y estructurales; reduciendo tiempos.

Vamos a ver un diseño sencillo.

## Vistazo a diagrama de Microarquitectura.
### Diagrama de bloques (ejemplo del ARM a76, con ARMv8).
La emisión forma parte de la codificación. Con la emision se emiten las instrucciones a ejecutar a las unidades funcionales. 
Hay almacenamientos intermedios (llamados estaciones de reserva), anteriormente se presentaron como buffers intermedios.

Dudas posibles: IMPORTANTE
- En los 86 pasa siempre (al ser CISC) y en ARM (es RISC): Puede suceder que uns instrucción esté implementada con varias microinstrucciones (que son las que entiende el núcleo). Por eso hay veces que pasa de 4 flechas a 8.
- En la emisión hay dos partes: una (Intel llama emisión a (estación de reserva) ventana de instrucciones) y luego usa envio cuando se refiere a paso de instrucciones desde estacion de reserva a unidad. En manuales de ARM y PowerPC se usa al revés (envío a estaciones de reserva y luego emisión a unidad funcional).

IMPORTANTE 
IMPORTANTE 
- Que ver con carga y almacenamiento: Se implementa en la ejecución el adelantamiento (también que una escritura propia sea adelantada en cuanto a orden general) (lo pueden hacer todos los núcleos): LSU, una parte donde pone las cargas y otra con almacenamientos. Lo que va delante AGU (generacion de address) genera las direcciones para acceder a memoria. Puede calcular la direccion en cualqueir AGU, pero si es de carga se va a otra y si es de lectura se va a otra. En estas listas una lectura puede coger el contenido de una escritura, viéndola antes que el resto (ya que todavia no se ha llevado a caché, ningun otro nucleo se entera al realizarse de forma interna).

Si es la misma direccion: el cerebro de la LSU mira la direccion de las lecturas que entran y comprueba si hay alguna escritura que escribe en la dirección. Cuando se mete un LOAD se coje la direccion (ya calculada en el AGU) y se mira en todas las tablas a ver si hay escrituras en dicha direccion y la última que haya coge su contenido.
Si se gestiona como una FIFO, se garantizan W->W y R->R (no se realizan dichos adelantamientos). Así es en Intel. En ARM no (implementacion mas compleja).
- Las dos colas del LSU van a su ritmo (cada una al suyo). 

### Esquema de ARM cortex A72
IMPORTANTE
IMPORTANTE
VER DIAPOSITIVA 12, leer qué hace cada etapa.
En la etapa de captacion está la predicción de saltos y la tabla de saltos (se verá después).
En emision se usa la (ventana de instrucciones) estaciones de reserva. Buffer de renombrado (eliminar WAW y WAR), buffer de reorden.
Buffer renombrado y de reorden (ROB) en WB.
Buffer de reorden: 
- puede inbluir buffer de renombreado.
- Permite implementar la eliminacion de riesgos de control de forma sencilla.
- Tarea fundamental: En la ultima etapa, garantiza que registros se modifican en orden del programa (de ahi viene el orden).

Eliminar RAW: ventanas de instrucciones 
Eliminar WAR, WAW: buffer renombre.

Los de control que se escapan (por prediccion incorrecta) se eliminan en WB.
Para eliminar control usamos ROB.



IMPORTANTE
# Detalles

IMPORTANTE
## Como se implmementa la emision
Utilizamos los almacenamientos de negrita y se realizan las tareas de negrita (arriba).
- Eliminan RAW y estructurales con estaciones de reserva o ventanas.
- WAW y WAR con renombrado.
- Cómo se capturan los operandos. Buffer con los registros de la arquitectura.

Si hay un registro no renombrado se capta el operando del buffer de registros.
Si está renombrado, se capta del buffer de renombrado.




A Intel le gusta una estacion de reserva compartida.

Antes de nada:
### Buffer de renombrado
Cuando se emite instruccion se le asigna entrada en estacion de reserva y se renombra el registro en el que se va a escribir asignandole una entrada en el banco de registros de renombrado. (Eso es la tabla Diap 14). Es una tabla con tantas entradas como registros. Campos:
- U Si estoy usando la entrada.
- Dest: registro que estoy renombrando. (2 renombra a 5).
- Valor: Almaceno el valor que se va a guardar en 2
- Valido: Si el valor está calculado o no (1 si esta calculado) y 0 si la instruccion emitida pero no ha terminado.
- Ult: Elimina el WAW: si esta activo dice que es el ultimo renombrado de un registro (si el 5 esta renombrado varias veces), el 1 es que sea valido.

Cuando se emite una instruccion el registro donde se escribe se renombra.
Si 3 y 5 no estan renombrados, se coge el contenido directamente de 3 y 5. Si estan renombrados, se cogen de la tabla.

Siempre que se emite instruccion se le asigna entrada en buffer de renombrado (al registro que almacena) (si no, se producen WAR y WAW). Se ELIMINAN las dependencias, no hace falta detectarlas.
RR: registro en tabla de renombrado.
1. Se renombran 3 y 5. Se meten en la tabla.
2. Se renombra 4.
3. Se espera a 3 en la estacion de reserva.
4. Se renombra nuevamente 3 con la entrada 5.
5. Se renombra nuevamente 7 con la entrada 6.
6. Suponemos division tarda mas que suma. Se completa antes la suma y pasa el campo a valido.
7. Se completa la siguiente suma.
8. Se completa la division, dato ya disponible.
9. Ya lo tiene disponible la estacion de reserva y ya se ejecuta.
10. Termina la entrada 6.

TODO AHORA:
Añadimos estaciones de reserva. Las unidades de mult y suma-resta tienen su propia estacion de reserva.
ESTACION DE RESERVA:
- OC: para instruccion.
- Rdestino: El registro de renombrado donde guardar el resultado. Cuando se calcula se mete y ya.
- VS1: Primero operando.
- VS2: Segundo operando.

Cuando se emite una instruccion se captan los operandos.
Si no estan renombrados los operandos, se captan del registro y se mandan a estacion de reserva (no se renombran).
Si estan renombrados, se coge de la tabla de renombrado en caso de estar calculado.
Si estan renombrados, si no esta calculado, se almacena en OSi/ISi la entrada de la tabla de renombrado en el que se almacena el operando.

Al tener los operandos disponibles en el siguiente ciclo se ejecuta.
Pasa a ejecutar una instruccion de la estacion de reserva cuando ambos operandos estan disponibles (elimina RAW) y la estructura esta disponible (elimina estructural).

Se pueden enviar instrucciones a la par.

- OSi/ISi El registro de renombrado donde se alamcena el operando cuando termina de calcularse.
